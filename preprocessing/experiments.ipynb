{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "2m02J4WyK4"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "YcC0bncuM6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "from glob2 import glob\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "KKwSV9K5Nd"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "Jaacso6eM3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runFullParse (inputPiece, iterations=10):\n",
    "    (corpus, piece) = inputPiece\n",
    "    jsonPath = \"outputs/\"+corpus+\"/\"+piece+\".json\"\n",
    "    cmd = [\"stack\",\"run\",\"fullParse\",\"--\",\"-n\",str(iterations), corpus, piece, \"All\"] \n",
    "    print(\"Running command: \" + (\" \".join(cmd)))\n",
    "    print(\"Expecting results in \" + jsonPath)\n",
    "    \n",
    "    #res = subprocess.run(cmd, cwd=\"..\")\n",
    "    #res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=\"..\")\n",
    "    res = subprocess.run(cmd,stderr=subprocess.PIPE, cwd=\"..\")\n",
    "\n",
    "    if res.returncode != 0:\n",
    "        print(\"Error in subprocess:\")\n",
    "        print(res.stderr)\n",
    "        return;\n",
    "    else:\n",
    "        f = open(jsonPath)\n",
    "        results = json.load(f)\n",
    "        f.close()\n",
    "        return results\n",
    "     \n",
    "def get_corpus_pieces(corpus):\n",
    "    return sorted (os.path.basename(d).split(\".\")[0] for d in glob(\"inputs/slices/\"+corpus+\"/*.csv\"))\n",
    "\n",
    "def get_corpi():\n",
    "    return [os.path.basename(d) for d in glob(\"inputs/slices/*\")][1:]\n",
    "\n",
    "def run_experiment():\n",
    "    corpi = get_corpi()\n",
    "    for corpus in corpi:\n",
    "        pieces = get_corpus_pieces(corpus)\n",
    "        for piece in pieces:\n",
    "            runFullParse((corpus, piece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_corpi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_Experiment(commands,name,threads):\n",
    "    id = datetime.now().strftime('%Y%m-%d%H-%M%S_') + name\n",
    "\n",
    "    commands = [ [\"stack\",\"run\",\"fullParse\",\"--\",\"-n\",str(1), \"-id\", str(id)] + command for command in commands]\n",
    "    with Pool(threads) as p:\n",
    "        p.map(run_command, commands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_command(command):\n",
    "    print(\"\\nRunning command: \" + (\" \".join(command)))    \n",
    "    #res = subprocess.run(cmd, cwd=\"..\")\n",
    "    #res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=\"..\")\n",
    "    res = subprocess.run(command,stderr=subprocess.PIPE, cwd=\"..\")\n",
    "\n",
    "    if res.returncode != 0:\n",
    "        print(\"Error in subprocess:\")\n",
    "        print(res.stderr)\n",
    "        return;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def full_experiment(threads=20):\n",
    "    commands = []\n",
    "    corpi = get_corpi()\n",
    "    for corpus in corpi:\n",
    "        pieces = get_corpus_pieces(corpus)\n",
    "        for piece in pieces:\n",
    "            for algorithm in [\"RandomWalk\", \"RandomSample\", \"RandomReduction\",\"BeamSearch 10\"]:\n",
    "                commands.append([ corpus, piece, algorithm])\n",
    "\n",
    "    run_Experiment(commands, \"baseline\", threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def baseline_experiment(threads=20):\n",
    "    commands = []\n",
    "    corpi = get_corpi()\n",
    "    for corpus in corpi:\n",
    "        pieces = get_corpus_pieces(corpus)\n",
    "        for piece in pieces:\n",
    "            for algorithm in [\"RandomWalk\", \"RandomSample\", \"RandomReduction\"]:\n",
    "                commands.append([ corpus, piece, algorithm])\n",
    "\n",
    "    run_Experiment(commands, \"baseline\", threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beamwidth_experiment(threads=10):\n",
    "    commands = []\n",
    "    corpi = get_corpi()\n",
    "    for corpus in corpi:\n",
    "        pieces = get_corpus_pieces(corpus)\n",
    "        for piece in pieces:\n",
    "            for w in range (1,20):\n",
    "                algo = \"BeamSearch \" + str(w)\n",
    "                commands.append([ corpus, piece, algo])\n",
    "\n",
    "    run_Experiment(commands, \"beamwidth-beamsearch\", threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stochastic_res_experiment(threads=10):\n",
    "    commands = []\n",
    "    corpi = get_corpi()\n",
    "    for corpus in corpi:\n",
    "        pieces = get_corpus_pieces(corpus)\n",
    "        for piece in pieces:\n",
    "            for w in range (2,30,3):\n",
    "                for r in range(200,3000,400):\n",
    "                    algo = \"StochasticBeamSearch {} {}\".format(w,r)\n",
    "                    commands.append([ corpus, piece, algo])\n",
    "\n",
    "    run_Experiment(commands, \"stochastic-all-params\", threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\\"io\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jukit_cell_id": "d0ifs7vsg1"
   },
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "eHdRDnhify",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #algo_experiment()\n",
    "    stochastic_res_experiment(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    algo_experiment()\n",
    "    #beamwidth_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hmm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
