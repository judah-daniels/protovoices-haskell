{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "nmn2Sinrnp"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "F7iRptmN8b"
      },
      "source": [
        "Dependencies:\n",
        "ms3 == 1.2.3\n",
        "dimcat==0.0.post1.dev122+gd1e90a1\n",
        "This is installed from github main branch March 29th\n",
        "setuptools=65.6.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "bHPZ739zX3"
      },
      "source": [
        "import numpy as np\n",
        "import ms3 as ms\n",
        "import dimcat as dc\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "sZbKt7tuyW"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "cAVB9NxDgH"
      },
      "source": [
        "def createDataset(corpi):\n",
        "    dataset = dc.Dataset()\n",
        "\n",
        "    for corpus in corpi:\n",
        "        dataset.load(corpus, parse_tsv=True, parse_scores=False) \n",
        "\n",
        "    return dataset"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "S1f4uM9ksc"
      },
      "source": [
        "# Corpuses to analyse\n",
        "corpi = [ \"../../romantic_piano_corpus/grieg_lyric_pieces\"\n",
        "        , \"../../ABC/\"\n",
        "        , \"../../romantic_piano_corpus/schumann_kinderszenen\"\n",
        "        , \"../../romantic_piano_corpus/chopin_mazurkas\"\n",
        "        , ]\n",
        "\n",
        "# Initialise dataset\n",
        "dataset = createDataset(corpi)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "hQl82FAXdp"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "7m7xrdkNyw"
      },
      "source": [
        "def to_pitch(midi, tpc):\n",
        "    pitch_class = ms.fifths2name(tpc)\n",
        "    octave = str(midi // 12)\n",
        "    return pitch_class + octave \n",
        "\n",
        "# Returns the offset using semitones\n",
        "def get_chord_offset(numeral: str, globalkey_is_minor):\n",
        "    try:\n",
        "        alteration = (numeral.count(\"#\") - numeral.count(\"b\")) * 7\n",
        "    except:\n",
        "        ## NOTE TO SELF WARNING : BUG INDUCED\n",
        "        ## sometimes numeral is just NAN. in which case i just return 0 as a hack.\n",
        "        return 0\n",
        "    #print(alteration)\n",
        "\n",
        "    numeral = numeral.strip(\"#b\")\n",
        "    numeral = numeral.upper()\n",
        "    #numeral_to_interval_major = {\"I\": 0, \"II\": 2, \"III\": 4, \"IV\": 5, \"V\":7, \"VI\":9, \"VII\":11}\n",
        "    #numeral_to_interval_minor = {\"I\": 0, \"II\": 2, \"III\": 3, \"IV\": 5, \"V\":7, \"VI\":8, \"VII\":10}\n",
        "    numeral_to_interval_major = {\"I\": 0, \"II\": 2, \"III\": 4, \"IV\": -1, \"V\":1, \"VI\":3, \"VII\":8}\n",
        "    numeral_to_interval_minor = {\"I\": 0, \"II\": 2, \"III\": -3, \"IV\": -1, \"V\":1, \"VI\":8, \"VII\":-2}\n",
        "\n",
        "    if globalkey_is_minor:\n",
        "        return (numeral_to_interval_minor[numeral] + alteration) % 12\n",
        "    else:\n",
        "        return (numeral_to_interval_major[numeral] + alteration) % 12\n",
        "\n",
        "def interval_union(i1,i2):\n",
        "    return pd.Interval(i1.left,i2.right,'left')\n",
        "\n",
        "def transform_chords_abs(df):\n",
        "    df['rootoffset'] = df.apply(lambda x: int(get_chord_offset(x.numeral,x.globalkey_is_minor)), axis = 1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ntpUNEOfIt"
      },
      "source": [
        "# Returns two dataframes, one for the chords, one for the slices\n",
        "# Splits the piece into slices, simplyifing chord labels.\n",
        "def preprocessPiece(corpus : str, piece : str, labels, salami_notes):\n",
        "    # zoom in on the chords in one piece\n",
        "    chords = labels.loc[(corpus, piece)]\n",
        "\n",
        "    # Translate labels to absolute pitches\n",
        "\n",
        "    desired_chord_columns = ['chord','pedal','numeral','form','figbass','changes','relativeroot','localkey','globalkey']\n",
        "    chordz = chords.copy().reset_index()\n",
        "    chordz = chordz.reset_index()\n",
        "\n",
        "    chords_abs_columns = ['chord', 'globalkey','globalkey_is_minor']\n",
        "\n",
        "    clean_chords = chordz[chordz['chord'] != '@none']\n",
        "    ms.labels2global_tonic(clean_chords, inplace=True)\n",
        "    clean_chords.to_csv(\"chordsbefore.csv\")\n",
        "    transform_chords_abs(clean_chords)\n",
        "\n",
        "    # Recombine the segments with @None labels\n",
        "    full_chords_abs = pd.concat([clean_chords, chordz[chordz['chord'] == '@none']]).sort_index()\n",
        "    full_chords_abs.rootoffset.fillna(0, inplace=True)\n",
        "\n",
        "    # Now we merge repeated chords\n",
        "    relavant_columns = [\"interval\", \"chord_type\", \"rootoffset\", \"globalkey\"]\n",
        "\n",
        "    dfs = pd.DataFrame()\n",
        "    ind = 0\n",
        "    prev = None \n",
        "    for row in full_chords_abs[relavant_columns].iterrows():\n",
        "        v = row[1]\n",
        "        ii = len(dfs.index) - 1\n",
        "        if prev and (v.chord_type == prev[1].chord_type and v.rootoffset == prev[1].rootoffset):\n",
        "            dfs.at[ii, 'interval'] = pd.Interval(dfs.iloc[ii].interval.left, v.interval.right, \"left\")\n",
        "        else:\n",
        "            new_row = pd.DataFrame({'interval':row[1].interval, 'chord_type':v.chord_type,'rootoffset':v.rootoffset,'globalkey':v.globalkey},index=[ind])\n",
        "            dfs = pd.concat([dfs, new_row])\n",
        "            ind += 1\n",
        "    prev = row\n",
        "\n",
        "    dfs.rootoffset = dfs.rootoffset.astype(int)\n",
        "    full_chords_abs = dfs\n",
        "\n",
        "    relavant_columns = [ \"interval\", \"chord_type\", \"rootoffset\", \"globalkey\"]\n",
        "\n",
        "    full_chords_abs = full_chords_abs.reset_index()[relavant_columns]\n",
        "    full_chords_abs.index.name ='segment_id'\n",
        "    full_chords_abs[[\"chord_type\", \"rootoffset\", \"globalkey\"]].to_csv('chords.csv')\n",
        "\n",
        "\n",
        "    salamis = salami_notes.loc[(corpus, piece)]\n",
        "\n",
        "    mini_salamis = salamis[['midi','tpc','tied']]\n",
        "    mini_salamis['tied'] = mini_salamis['tied'].fillna(0).astype('bool')\n",
        "\n",
        "    # Assigning each slice a segment id according to the chord.\n",
        "    dfs = []\n",
        "    for segment, interval in enumerate(full_chords_abs[\"interval\"]):\n",
        "        segMask = mini_salamis.index.get_level_values(0).overlaps(interval)\n",
        "        slicesInInterval = mini_salamis[segMask]\n",
        "        slicesInInterval.insert(0,'segment_id',segment)\n",
        "        dfs.append(slicesInInterval)\n",
        "\n",
        "    segmented_salamis = pd.concat(dfs)\n",
        "\n",
        "    segmented_salamis['slice_id'] = pd.factorize(segmented_salamis.reset_index()['onset_slice'])[0]\n",
        "\n",
        "    segmented_salamis['pitch'] = segmented_salamis.apply(lambda x: to_pitch(x.midi, x.tpc), axis=1)\n",
        "\n",
        "    final_salamis_columns = ['segment_id','slice_id','pitch','tied']\n",
        "    final_salamis = segmented_salamis.reset_index()[final_salamis_columns]\n",
        "\n",
        "    final_salamis[\"new_segment\"] = final_salamis[\"segment_id\"].diff().astype(bool)\n",
        "    final_salamis['new_slice'] = final_salamis[\"slice_id\"].diff().astype(bool)\n",
        "\n",
        "\n",
        "    # Capitalise Global key to fix bug with Haskell Musicology with lowercase b\n",
        "    full_chords_abs.globalkey = full_chords_abs.globalkey.apply(lambda key: key.capitalize())\n",
        "\n",
        "    # Correct the new segment and new slice fields for the first row.\n",
        "    final_salamis.at[0, \"new_segment\"] = False\n",
        "    final_salamis.at[0, \"new_slice\"] = False\n",
        "\n",
        "    final_salamis.to_csv('salamis.csv',columns=[\"new_segment\", \"new_slice\", \"pitch\",\"tied\"], index=False)\n",
        "\n",
        "    return (full_chords_abs[[\"chord_type\", \"rootoffset\", \"globalkey\"]], final_salamis[[\"new_segment\", \"new_slice\", \"pitch\", \"tied\"]])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "catvy1VO1i"
      },
      "source": [
        "# Given a dataset, process all pieces and return labels and slices\n",
        "def processDataset(dataset):\n",
        "    # 3mins\n",
        "    labels = dataset.get_facet(\"expanded\")\n",
        "    \n",
        "    # Process slices \n",
        "    salami_crp = dc.NoteSlicer().process_data(dataset)\n",
        "    salami_notes = salami_crp.get_facet(\"notes\")\n",
        "\n",
        "    corpi = labels.index.unique(0).tolist()\n",
        "    for corpus in corpi:\n",
        "        pieces = labels.loc[corpus].index.unique(0).tolist()\n",
        "        for piece in pieces:\n",
        "            (chords, slices) = preprocessPiece(corpus, piece, labels, salami_notes)\n",
        "            # Create Folders if necessary\n",
        "            if not os.path.isdir(\"inputs/chords/{}\".format(corpus)):\n",
        "                os.makedirs(\"inputs/chords/{}\".format(corpus))\n",
        "            if not os.path.isdir(\"inputs/slices/{}\".format(corpus)):\n",
        "                os.makedirs(\"inputs/slices/{}\".format(corpus))\n",
        "\n",
        "            chords.to_csv(\"inputs/chords/{}/{}.csv\".format(corpus, piece))\n",
        "            slices.to_csv(\"inputs/slices/{}/{}.csv\".format(corpus, piece),index=False)\n",
        "    \n",
        "    return (labels, salami_notes)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "rYAHoMQXiT"
      },
      "source": [
        "## Generate all input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "xvVXToEfKO"
      },
      "source": [
        "processDataset(dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "(                                                mc  mn  ... harmony_layer  regex_match\n corpus             fname        interval                ...                           \n grieg_lyric_pieces op12n01      [0.0, 2.0)       1   1  ...           NaN          NaN\n                                 [2.0, 2.5)       2   2  ...           NaN          NaN\n                                 [2.5, 3.0)       2   2  ...           NaN          NaN\n                                 [3.0, 6.0)       2   2  ...           NaN          NaN\n                                 [6.0, 6.5)       4   4  ...           NaN          NaN\n ...                                             ..  ..  ...           ...          ...\n chopin_mazurkas    BI93-2op67-3 [160.0, 163.0)  55  54  ...           NaN          NaN\n                                 [163.0, 165.0)  56  55  ...           NaN          NaN\n                                 [165.0, 166.0)  56  55  ...           NaN          NaN\n                                 [166.0, 167.0)  57  56  ...           NaN          NaN\n                                 [167.0, 169.0)  57  56  ...           NaN          NaN\n \n [46206 rows x 34 columns],\n                                                                mc  mn  ... volta  tremolo\n corpus             fname        onset_slice    interval                ...               \n grieg_lyric_pieces op12n01      [0.0, 0.25)    [0.0, 0.25)      1   1  ...  <NA>      NaN\n                                                [0.0, 0.25)      1   1  ...  <NA>      NaN\n                                                [0.0, 0.25)      1   1  ...  <NA>      NaN\n                                 [0.25, 0.5)    [0.25, 0.5)      1   1  ...  <NA>      NaN\n                                                [0.25, 0.5)      1   1  ...  <NA>      NaN\n ...                                                            ..  ..  ...   ...      ...\n chopin_mazurkas    BI93-2op67-3 [167.0, 169.0) [167.0, 169.0)  57  56  ...  <NA>      NaN\n                                                [167.0, 169.0)  57  56  ...  <NA>      NaN\n                                                [167.0, 169.0)  57  56  ...  <NA>      NaN\n                                                [167.0, 169.0)  57  56  ...  <NA>      NaN\n                                                [167.0, 169.0)  57  56  ...  <NA>      NaN\n \n [531125 rows x 21 columns])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}