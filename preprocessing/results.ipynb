{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import subprocess\n",
    "from glob2 import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mir_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmir_eval\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mir_eval'"
     ]
    }
   ],
   "source": [
    "import mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcml_chordtype_map = {\n",
    "    \"M\": \"major\",\n",
    "    \"m\": \"minor\",\n",
    "    \"Mm7\": \"dominant-7th\",\n",
    "    \"o\": \"diminished\",\n",
    "    \"o7\": \"full-diminished\",\n",
    "    \"mm7\": \"minor-7th\",\n",
    "    \"%7\": \"half-diminished\",\n",
    "    \"MM7\": \"major-7th\",\n",
    "    \"+\": \"augmented\",\n",
    "    \"mM7\": \"minor-major-7th\",\n",
    "    \"+7\": \"augmented-7th\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = glob(\"inputs/slices/*.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n15op132_03'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices[0][14:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runExp():\n",
    "    slices = glob(\"inputs/slices/*.csv\")\n",
    "    pieceNames = [x[14:-4] for x in slices] # THis is cursed, please remove it at once >:(\n",
    "    for piece in pieceNames:\n",
    "        jsonPath = \"outputs/\"+piece+\".json\"\n",
    "        cmd = [\"stack\",\"run\",\"fullParse\",\"--\",\"-n\",\"1\",piece, \"All\"] \n",
    "        print(\"Running command: \" + (\" \".join(cmd)))\n",
    "        print(\"Expecting results in \" + jsonPath)\n",
    "        #res = subprocess.run(cmd, cwd=\"..\")\n",
    "        res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=\"..\")\n",
    "\n",
    "        if res.returncode != 0:\n",
    "            print(\"Error in subprocess\")\n",
    "            print(res.stderr)\n",
    "            print(res.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runExp()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "Loads all json files from the given folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    jsonFiles = glob(path + '/*.json') #Can be used absolute or relative paths \n",
    "    df = pd.DataFrame() \n",
    "    for jsonFile in jsonFiles:\n",
    "        # df = pd.read_json(jsonFile)\n",
    "        try:\n",
    "            with open(jsonFile, 'r') as f:\n",
    "                data = json.loads(f.read())\n",
    "        except:\n",
    "            print(\"Error with {}\".format(jsonFile))\n",
    "            continue\n",
    "\n",
    "        newdf = pd.json_normalize(data, record_path = ['results'], \n",
    "            meta = ['piece'])\n",
    "        df = pd.concat([df, newdf])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = load_dataset(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(x['piece'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zq/32m4qp9s339211sg4wxlr7dr0000gn/T/ipykernel_31976/1263448163.py:1: FutureWarning: ['chordLabels', 'slices'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  x.groupby([\"piece\", \"algorithm\"]).agg([np.mean, np.std])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece</th>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">n01op18-1_01</th>\n",
       "      <th>RandomParseSBS</th>\n",
       "      <td>0.565432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.209892e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSample</th>\n",
       "      <td>0.027160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.456812e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSampleSBS</th>\n",
       "      <td>0.360494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.728411e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">n01op18-1_03</th>\n",
       "      <th>RandomParseSBS</th>\n",
       "      <td>0.630542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.926271e+05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSample</th>\n",
       "      <td>0.024631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.970465e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">n16op135_04</th>\n",
       "      <th>RandomSample</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.952403e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSampleSBS</th>\n",
       "      <td>0.311905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.428588e+06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">shortest</th>\n",
       "      <th>RandomParseSBS</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.407877e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSample</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.194791e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSampleSBS</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.326117e+01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              accuracy        likelihood    \n",
       "                                  mean std          mean std\n",
       "piece        algorithm                                      \n",
       "n01op18-1_01 RandomParseSBS   0.565432 NaN -3.209892e+06 NaN\n",
       "             RandomSample     0.027160 NaN -3.456812e+06 NaN\n",
       "             RandomSampleSBS  0.360494 NaN -1.728411e+06 NaN\n",
       "n01op18-1_03 RandomParseSBS   0.630542 NaN -4.926271e+05 NaN\n",
       "             RandomSample     0.024631 NaN -1.970465e+06 NaN\n",
       "...                                ...  ..           ...  ..\n",
       "n16op135_04  RandomSample     0.016667 NaN -5.952403e+06 NaN\n",
       "             RandomSampleSBS  0.311905 NaN -1.428588e+06 NaN\n",
       "shortest     RandomParseSBS   0.750000 NaN -1.407877e+01 NaN\n",
       "             RandomSample     0.000000 NaN -2.194791e+01 NaN\n",
       "             RandomSampleSBS  0.750000 NaN -1.326117e+01 NaN\n",
       "\n",
       "[144 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.groupby([\"piece\", \"algorithm\"]).agg([np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zq/32m4qp9s339211sg4wxlr7dr0000gn/T/ipykernel_31976/607374105.py:1: FutureWarning: ['chordLabels', 'slices', 'piece'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  x.groupby([\"algorithm\"]).agg([np.mean, np.std])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomParseSBS</th>\n",
       "      <td>0.513342</td>\n",
       "      <td>0.127909</td>\n",
       "      <td>-3.682068e+06</td>\n",
       "      <td>6.731450e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSample</th>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>-1.231712e+07</td>\n",
       "      <td>1.356395e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSampleSBS</th>\n",
       "      <td>0.316787</td>\n",
       "      <td>0.108288</td>\n",
       "      <td>-2.834742e+06</td>\n",
       "      <td>6.242748e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy              likelihood              \n",
       "                     mean       std          mean           std\n",
       "algorithm                                                      \n",
       "RandomParseSBS   0.513342  0.127909 -3.682068e+06  6.731450e+06\n",
       "RandomSample     0.019084  0.011501 -1.231712e+07  1.356395e+07\n",
       "RandomSampleSBS  0.316787  0.108288 -2.834742e+06  6.242748e+06"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.groupby([\"algorithm\"]).agg([np.mean, np.std])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
