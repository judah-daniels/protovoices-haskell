-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | Dataflow programming and declarative concurrency
--   
--   Browse the documentation at <a>https://streamly.composewell.com</a>.
--   
--   Streamly is a streaming framework to build reliable and scalable
--   software systems from modular building blocks using dataflow
--   programming and declarative concurrency. Stream fusion optimizations
--   in streamly result in high-performance, modular combinatorial
--   programming.
--   
--   Performance with simplicity:
--   
--   <ul>
--   <li>Performance on par with C (<a>Benchmarks</a>)</li>
--   <li>API close to standard Haskell lists (<a>Examples</a>)</li>
--   <li>Declarative concurrency with automatic scaling</li>
--   <li>Filesystem, fsnotify, network, and Unicode support included</li>
--   <li>More functionality provided via many ecosystem packages</li>
--   </ul>
--   
--   Unified and powerful abstractions:
--   
--   <ul>
--   <li>Unifies unfolds, arrays, folds, and parsers with streaming</li>
--   <li>Unifies <tt>Data.List</tt>, <tt>list-t</tt>, and <tt>logict</tt>
--   with streaming</li>
--   <li>Unifies concurrency with standard streaming abstractions</li>
--   <li>Provides time-domain combinators for reactive programming</li>
--   <li>Interworks with bytestring and streaming libraries</li>
--   </ul>
@package streamly
@version 0.8.1.1


-- | Compatibility functions for "base" package.
module Streamly.Internal.BaseCompat
(#.) :: Coercible b c => (b -> c) -> (a -> b) -> a -> c

-- | A variant of <a>error</a> that does not produce a stack trace.
errorWithoutStackTrace :: forall (r :: RuntimeRep) (a :: TYPE r). [Char] -> a

-- | Return the contents of a <a>Left</a>-value or a default value
--   otherwise.
--   
--   <h4><b>Examples</b></h4>
--   
--   Basic usage:
--   
--   <pre>
--   &gt;&gt;&gt; fromLeft 1 (Left 3)
--   3
--   
--   &gt;&gt;&gt; fromLeft 1 (Right "foo")
--   1
--   </pre>
fromLeft :: a -> Either a b -> a

-- | Return the contents of a <a>Right</a>-value or a default value
--   otherwise.
--   
--   <h4><b>Examples</b></h4>
--   
--   Basic usage:
--   
--   <pre>
--   &gt;&gt;&gt; fromRight 1 (Right 3)
--   3
--   
--   &gt;&gt;&gt; fromRight 1 (Left "foo")
--   1
--   </pre>
fromRight :: b -> Either a b -> b
unsafeWithForeignPtr :: ForeignPtr a -> (Ptr a -> IO b) -> IO b
oneShot :: (a -> b) -> a -> b


module Streamly.Internal.Control.Concurrent

-- | A monad that can perform concurrent or parallel IO operations. Streams
--   that can be composed concurrently require the underlying monad to be
--   <a>MonadAsync</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
type MonadAsync m = (MonadIO m, MonadBaseControl IO m, MonadThrow m)
newtype RunInIO m
RunInIO :: (forall b. m b -> IO (StM m b)) -> RunInIO m
[runInIO] :: RunInIO m -> forall b. m b -> IO (StM m b)

-- | When we run computations concurrently, we completely isolate the state
--   of the concurrent computations from the parent computation. The
--   invariant is that we should never be running two concurrent
--   computations in the same thread without using the runInIO function.
--   Also, we should never be running a concurrent computation in the
--   parent thread, otherwise it may affect the state of the parent which
--   is against the defined semantics of concurrent execution.
captureMonadState :: MonadBaseControl IO m => m (RunInIO m)

-- | Fork a thread to run the given computation, installing the provided
--   exception handler. Lifted to any monad with 'MonadBaseControl IO m'
--   capability.
--   
--   TODO: the RunInIO argument can be removed, we can directly pass the
--   action as "mrun action" instead.
doFork :: MonadBaseControl IO m => m () -> RunInIO m -> (SomeException -> IO ()) -> m ThreadId

-- | <a>fork</a> lifted to any monad with 'MonadBaseControl IO m'
--   capability.
fork :: MonadBaseControl IO m => m () -> m ThreadId

-- | Fork a thread that is automatically killed as soon as the reference to
--   the returned threadId is garbage collected.
forkManaged :: (MonadIO m, MonadBaseControl IO m) => m () -> m ThreadId


-- | Additional <a>Control.Exception</a> utilities.
module Streamly.Internal.Control.Exception
assertM :: Applicative f => Bool -> f ()

-- | Like <a>assert</a> but is not removed by the compiler, it is always
--   present in production code.
--   
--   <i>Pre-release</i>
verify :: Bool -> a -> a
verifyM :: Applicative f => Bool -> f ()


-- | Additional <a>Control.Monad</a> utilities.
module Streamly.Internal.Control.Monad

-- | Discard any exceptions or value returned by an effectful action.
--   
--   <i>Pre-release</i>
discard :: MonadCatch m => m b -> m ()


module Streamly.Internal.Data.Atomics
atomicModifyIORefCAS :: IORef a -> (a -> (a, b)) -> IO b
atomicModifyIORefCAS_ :: IORef t -> (t -> t) -> IO ()
writeBarrier :: IO ()
storeLoadBarrier :: IO ()


-- | Continuation style utilities.
module Streamly.Internal.Data.Cont

-- | Given a continuation based transformation from <tt>a</tt> to
--   <tt>b</tt> and a continuation based transformation from <tt>[b]</tt>
--   to <tt>c</tt>, make continuation based transformation from
--   <tt>[a]</tt> to <tt>c</tt>.
--   
--   <i>Pre-release</i>
contListMap :: (a -> (b -> r) -> r) -> ([b] -> (c -> r) -> r) -> [a] -> (c -> r) -> r


-- | | Strict data types to be used as accumulator for strict left folds
--   and scans. For more comprehensive strict data types see
--   <a>https://hackage.haskell.org/package/strict-base-types</a> . The
--   names have been suffixed by a prime so that programmers can easily
--   distinguish the strict versions from the lazy ones.
--   
--   One major advantage of strict data structures as accumulators in folds
--   and scans is that it helps the compiler optimize the code much better
--   by unboxing. In a big tight loop the difference could be huge.
module Streamly.Internal.Data.Either.Strict

-- | A strict <a>Either</a>
data Either' a b
Left' :: !a -> Either' a b
Right' :: !b -> Either' a b

-- | Return <a>True</a> if the given value is a Left', <a>False</a>
--   otherwise.
isLeft' :: Either' a b -> Bool

-- | Return <a>True</a> if the given value is a Right', <a>False</a>
--   otherwise.
isRight' :: Either' a b -> Bool

-- | Return the contents of a Left'-value or errors out.
fromLeft' :: Either' a b -> a

-- | Return the contents of a Right'-value or errors out.
fromRight' :: Either' a b -> b
instance (GHC.Show.Show a, GHC.Show.Show b) => GHC.Show.Show (Streamly.Internal.Data.Either.Strict.Either' a b)


module Streamly.Internal.Data.Fold.Step

-- | Represents the result of the <tt>step</tt> of a <tt>Fold</tt>.
--   <a>Partial</a> returns an intermediate state of the fold, the fold
--   step can be called again with the state or the driver can use
--   <tt>extract</tt> on the state to get the result out. <a>Done</a>
--   returns the final result and the fold cannot be driven further.
--   
--   <i>Pre-release</i>
data Step s b
Partial :: !s -> Step s b
Done :: !b -> Step s b

-- | Map a monadic function over the result <tt>b</tt> in <tt>Step s
--   b</tt>.
--   
--   <i>Internal</i>
mapMStep :: Applicative m => (a -> m b) -> Step s a -> m (Step s b)

-- | If <a>Partial</a> then map the state, if <a>Done</a> then call the
--   next step.
chainStepM :: Applicative m => (s1 -> m s2) -> (a -> m (Step s2 b)) -> Step s1 a -> m (Step s2 b)
instance Data.Bifunctor.Bifunctor Streamly.Internal.Data.Fold.Step.Step
instance GHC.Base.Functor (Streamly.Internal.Data.Fold.Step.Step s)


-- | A value associated with an IO action that is automatically called
--   whenever the value is garbage collected.
module Streamly.Internal.Data.IOFinalizer

-- | An <a>IOFinalizer</a> has an associated IO action that is
--   automatically called whenever the finalizer is garbage collected. The
--   action can be run and cleared prematurely.
--   
--   You can hold a reference to the finalizer in your data structure, if
--   the data structure gets garbage collected the finalizer will be
--   called.
--   
--   It is implemented using <a>mkWeakIORef</a>.
--   
--   <i>Pre-release</i>
data IOFinalizer

-- | Create a finalizer that calls the supplied function automatically when
--   the it is garbage collected.
--   
--   /The finalizer is always run using the state of the monad that is
--   captured at the time of calling <tt>newFinalizer</tt>./
--   
--   Note: To run it on garbage collection we have no option but to use the
--   monad state captured at some earlier point of time. For the case when
--   the finalizer is run manually before GC we could run it with the
--   current state of the monad but we want to keep both the cases
--   consistent.
--   
--   <i>Pre-release</i>
newIOFinalizer :: (MonadIO m, MonadBaseControl IO m) => m a -> m IOFinalizer

-- | Run the action associated with the finalizer and deactivate it so that
--   it never runs again. Note, the finalizing action runs with async
--   exceptions masked.
--   
--   <i>Pre-release</i>
runIOFinalizer :: MonadIO m => IOFinalizer -> m ()

-- | Run an action clearing the finalizer atomically wrt async exceptions.
--   The action is run with async exceptions masked.
--   
--   <i>Pre-release</i>
clearingIOFinalizer :: MonadBaseControl IO m => IOFinalizer -> m a -> m a


-- | | Strict data types to be used as accumulator for strict left folds
--   and scans. For more comprehensive strict data types see
--   <a>https://hackage.haskell.org/package/strict-base-types</a> . The
--   names have been suffixed by a prime so that programmers can easily
--   distinguish the strict versions from the lazy ones.
--   
--   One major advantage of strict data structures as accumulators in folds
--   and scans is that it helps the compiler optimize the code much better
--   by unboxing. In a big tight loop the difference could be huge.
module Streamly.Internal.Data.Maybe.Strict

-- | A strict <a>Maybe</a>
data Maybe' a
Just' :: !a -> Maybe' a
Nothing' :: Maybe' a

-- | Convert strict Maybe' to lazy Maybe
toMaybe :: Maybe' a -> Maybe a

-- | Returns True iff its argument is of the form "Just' _".
isJust' :: Maybe' a -> Bool

-- | Extract the element out of a Just' and throws an error if its argument
--   is Nothing'.
fromJust' :: Maybe' a -> a
instance GHC.Show.Show a => GHC.Show.Show (Streamly.Internal.Data.Maybe.Strict.Maybe' a)


-- | The <tt>Fold</tt> type embeds a default initial value, therefore, it
--   is like a <a>Monoid</a> whereas the <a>Refold</a> type has to be
--   supplied with an initial value, therefore, it is more like a
--   <a>Semigroup</a> operation.
--   
--   Refolds can be appended to each other or to a fold to build the fold
--   incrementally. This is useful in incremental builder like use cases.
--   
--   See the file splitting example in the <tt>streamly-examples</tt>
--   repository for an application of the <a>Refold</a> type. The
--   <tt>Fold</tt> type does not perform as well in this situation.
--   
--   <a>Refold</a> type is to <tt>Fold</tt> as <tt>Unfold</tt> type is to
--   <tt>Stream</tt>. <tt>Unfold</tt> provides better optimizaiton than
--   stream in nested operations, similarly, <a>Refold</a> provides better
--   optimization than <tt>Fold</tt>.
module Streamly.Internal.Data.Refold.Type

-- | Like <tt>Fold</tt> except that the initial state of the accmulator can
--   be generated using a dynamically supplied input. This affords better
--   stream fusion optimization in nested fold operations where the initial
--   fold state is determined based on a dynamic value.
--   
--   <i>Internal</i>
data Refold m c a b

-- | <tt>Fold </tt> <tt> step </tt> <tt> inject </tt> <tt> extract</tt>
Refold :: (s -> a -> m (Step s b)) -> (c -> m (Step s b)) -> (s -> m b) -> Refold m c a b

-- | Make a consumer from a left fold style pure step function.
--   
--   If your <tt>Fold</tt> returns only <a>Partial</a> (i.e. never returns
--   a <a>Done</a>) then you can use <tt>foldl'*</tt> constructors.
--   
--   See also: <tt>Streamly.Prelude.foldl'</tt>
--   
--   <i>Internal</i>
foldl' :: Monad m => (b -> a -> b) -> Refold m b a b

-- | Append the elements of an input stream to a provided starting value.
--   
--   <pre>
--   &gt;&gt;&gt; stream = Stream.map Data.Monoid.Sum $ Stream.enumerateFromTo 1 10
--   
--   &gt;&gt;&gt; Stream.fold (Fold.fromRefold Refold.sconcat 10) stream
--   Sum {getSum = 65}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; sconcat = Refold.foldl' (&lt;&gt;)
--   </pre>
--   
--   <i>Internal</i>
sconcat :: (Monad m, Semigroup a) => Refold m a a a

-- | <i>Internal</i>
drainBy :: Monad m => (c -> a -> m b) -> Refold m c a ()

-- | Keep running the same consumer over and over again on the input,
--   feeding the output of the previous run to the next.
--   
--   <i>Internal</i>
iterate :: Monad m => Refold m b a b -> Refold m b a b

-- | <tt>lmapM f fold</tt> maps the monadic function <tt>f</tt> on the
--   input of the fold.
--   
--   <i>Internal</i>
lmapM :: Monad m => (a -> m b) -> Refold m c b r -> Refold m c a r

-- | Map a monadic function on the output of a fold.
--   
--   <i>Internal</i>
rmapM :: Monad m => (b -> m c) -> Refold m x a b -> Refold m x a c

-- | Supply the output of the first consumer as input to the second
--   consumer.
--   
--   <i>Internal</i>
append :: Monad m => Refold m x a b -> Refold m b a b -> Refold m x a b

-- | Take at most <tt>n</tt> input elements and fold them using the
--   supplied fold. A negative count is treated as 0.
--   
--   <i>Internal</i>
take :: Monad m => Int -> Refold m x a b -> Refold m x a b
instance (GHC.Show.Show a, GHC.Show.Show b) => GHC.Show.Show (Streamly.Internal.Data.Refold.Type.Tuple'Fused a b)


module Streamly.Internal.Data.Ring
data Ring a
Ring :: MutableArray (PrimState IO) a -> IORef Int -> !Int -> Ring a
[arr] :: Ring a -> MutableArray (PrimState IO) a
[ringHead] :: Ring a -> IORef Int
[ringMax] :: Ring a -> !Int
createRing :: Int -> IO (Ring a)
unsafeInsertRing :: Ring a -> Int -> a -> IO ()


module Streamly.Internal.Data.Sink.Type

-- | A <a>Sink</a> is a special type of <tt>Fold</tt> that does not
--   accumulate any value, but runs only effects. A <a>Sink</a> has no
--   state to maintain therefore can be a bit more efficient than a
--   <tt>Fold</tt> with <tt>()</tt> as the state, especially when
--   <a>Sink</a>s are composed with other operations. A Sink can be
--   upgraded to a <tt>Fold</tt>, but a <tt>Fold</tt> cannot be converted
--   into a Sink.
newtype Sink m a
Sink :: (a -> m ()) -> Sink m a


-- | Small arrays are boxed (im)mutable arrays.
--   
--   The underlying structure of the <tt>Array</tt> type contains a card
--   table, allowing segments of the array to be marked as having been
--   mutated. This allows the garbage collector to only re-traverse
--   segments of the array that have been marked during certain phases,
--   rather than having to traverse the entire array.
--   
--   <a>SmallArray</a> lacks this table. This means that it takes up less
--   memory and has slightly faster writes. It is also more efficient
--   during garbage collection so long as the card table would have a
--   single entry covering the entire array. These advantages make them
--   suitable for use as arrays that are known to be small.
--   
--   The card size is 128, so for uses much larger than that,
--   <tt>Array</tt> would likely be superior.
--   
--   The underlying type, <a>SmallArray#</a>, was introduced in GHC 7.10,
--   so prior to that version, this module simply implements small arrays
--   as <tt>Array</tt>.
module Streamly.Internal.Data.SmallArray.Type
data SmallArray a
SmallArray :: SmallArray# a -> SmallArray a
data SmallMutableArray s a
SmallMutableArray :: SmallMutableArray# s a -> SmallMutableArray s a

-- | Create a new small mutable array.
newSmallArray :: PrimMonad m => Int -> a -> m (SmallMutableArray (PrimState m) a)

-- | Read the element at a given index in a mutable array.
readSmallArray :: PrimMonad m => SmallMutableArray (PrimState m) a -> Int -> m a

-- | Write an element at the given idex in a mutable array.
writeSmallArray :: PrimMonad m => SmallMutableArray (PrimState m) a -> Int -> a -> m ()

-- | Copy a slice of an immutable array into a mutable array.
copySmallArray :: PrimMonad m => SmallMutableArray (PrimState m) a -> Int -> SmallArray a -> Int -> Int -> m ()

-- | Copy a slice of one mutable array into another.
copySmallMutableArray :: PrimMonad m => SmallMutableArray (PrimState m) a -> Int -> SmallMutableArray (PrimState m) a -> Int -> Int -> m ()

-- | Look up an element in an immutable array.
indexSmallArray :: SmallArray a -> Int -> a

-- | Look up an element in an immutable array.
--   
--   The purpose of returning a result using a monad is to allow the caller
--   to avoid retaining references to the array. Evaluating the return
--   value will cause the array lookup to be performed, even though it may
--   not require the element of the array to be evaluated (which could
--   throw an exception). For instance:
--   
--   <pre>
--   data Box a = Box a
--   ...
--   
--   f sa = case indexSmallArrayM sa 0 of
--     Box x -&gt; ...
--   </pre>
--   
--   <tt>x</tt> is not a closure that references <tt>sa</tt> as it would be
--   if we instead wrote:
--   
--   <pre>
--   let x = indexSmallArray sa 0
--   </pre>
--   
--   And does not prevent <tt>sa</tt> from being garbage collected.
--   
--   Note that <a>Identity</a> is not adequate for this use, as it is a
--   newtype, and cannot be evaluated without evaluating the element.
indexSmallArrayM :: Monad m => SmallArray a -> Int -> m a

-- | Read a value from the immutable array at the given index, returning
--   the result in an unboxed unary tuple. This is currently used to
--   implement folds.
indexSmallArray## :: SmallArray a -> Int -> (# a #)

-- | Create a copy of a slice of an immutable array.
cloneSmallArray :: SmallArray a -> Int -> Int -> SmallArray a

-- | Create a copy of a slice of a mutable array.
cloneSmallMutableArray :: PrimMonad m => SmallMutableArray (PrimState m) a -> Int -> Int -> m (SmallMutableArray (PrimState m) a)

-- | Create an immutable array corresponding to a slice of a mutable array.
--   
--   This operation copies the portion of the array to be frozen.
freezeSmallArray :: PrimMonad m => SmallMutableArray (PrimState m) a -> Int -> Int -> m (SmallArray a)

-- | Render a mutable array immutable.
--   
--   This operation performs no copying, so care must be taken not to
--   modify the input array after freezing.
unsafeFreezeSmallArray :: PrimMonad m => SmallMutableArray (PrimState m) a -> m (SmallArray a)

-- | Create a mutable array corresponding to a slice of an immutable array.
--   
--   This operation copies the portion of the array to be thawed.
thawSmallArray :: PrimMonad m => SmallArray a -> Int -> Int -> m (SmallMutableArray (PrimState m) a)
runSmallArray :: (forall s. ST s (SmallMutableArray s a)) -> SmallArray a

-- | Render an immutable array mutable.
--   
--   This operation performs no copying, so care must be taken with its
--   use.
unsafeThawSmallArray :: PrimMonad m => SmallArray a -> m (SmallMutableArray (PrimState m) a)
sizeofSmallArray :: SmallArray a -> Int
sizeofSmallMutableArray :: SmallMutableArray s a -> Int

-- | Create a <a>SmallArray</a> from a list.
smallArrayFromList :: [a] -> SmallArray a

-- | Create a <a>SmallArray</a> from a list of a known length. If the
--   length of the list does not match the given length, this throws an
--   exception.
smallArrayFromListN :: Int -> [a] -> SmallArray a

-- | Strict map over the elements of the array.
mapSmallArray' :: (a -> b) -> SmallArray a -> SmallArray b

-- | This is the fastest, most straightforward way to traverse an array,
--   but it only works correctly with a sufficiently "affine"
--   <a>PrimMonad</a> instance. In particular, it must only produce *one*
--   result array. <a>ListT</a>-transformed monads, for example, will not
--   work right at all.
traverseSmallArrayP :: PrimMonad m => (a -> m b) -> SmallArray a -> m (SmallArray b)
instance GHC.Base.Monad Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Classes.Eq (Streamly.Internal.Data.SmallArray.Type.SmallMutableArray s a)
instance (Data.Typeable.Internal.Typeable s, Data.Typeable.Internal.Typeable a) => Data.Data.Data (Streamly.Internal.Data.SmallArray.Type.SmallMutableArray s a)
instance Data.Functor.Classes.Eq1 Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Classes.Eq a => GHC.Classes.Eq (Streamly.Internal.Data.SmallArray.Type.SmallArray a)
instance Data.Functor.Classes.Ord1 Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Classes.Ord a => GHC.Classes.Ord (Streamly.Internal.Data.SmallArray.Type.SmallArray a)
instance Data.Foldable.Foldable Streamly.Internal.Data.SmallArray.Type.SmallArray
instance Data.Traversable.Traversable Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Base.Functor Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Base.Applicative Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Base.Alternative Streamly.Internal.Data.SmallArray.Type.SmallArray
instance Control.Monad.Fail.MonadFail Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Base.MonadPlus Streamly.Internal.Data.SmallArray.Type.SmallArray
instance Control.Monad.Zip.MonadZip Streamly.Internal.Data.SmallArray.Type.SmallArray
instance Control.Monad.Fix.MonadFix Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Base.Semigroup (Streamly.Internal.Data.SmallArray.Type.SmallArray a)
instance GHC.Base.Monoid (Streamly.Internal.Data.SmallArray.Type.SmallArray a)
instance GHC.Exts.IsList (Streamly.Internal.Data.SmallArray.Type.SmallArray a)
instance GHC.Show.Show a => GHC.Show.Show (Streamly.Internal.Data.SmallArray.Type.SmallArray a)
instance Data.Functor.Classes.Show1 Streamly.Internal.Data.SmallArray.Type.SmallArray
instance GHC.Read.Read a => GHC.Read.Read (Streamly.Internal.Data.SmallArray.Type.SmallArray a)
instance Data.Functor.Classes.Read1 Streamly.Internal.Data.SmallArray.Type.SmallArray
instance Data.Data.Data a => Data.Data.Data (Streamly.Internal.Data.SmallArray.Type.SmallArray a)


module Streamly.Internal.Data.Stream.StreamD.Step

-- | A stream is a succession of <a>Step</a>s. A <a>Yield</a> produces a
--   single value and the next state of the stream. <a>Stop</a> indicates
--   there are no more values in the stream.
data Step s a
Yield :: a -> s -> Step s a
Skip :: s -> Step s a
Stop :: Step s a
instance GHC.Base.Functor (Streamly.Internal.Data.Stream.StreamD.Step.Step s)


-- | See <a>Streamly.Internal.Data.Producer</a> for introduction.
module Streamly.Internal.Data.Producer.Type

-- | A <tt>Producer m a b</tt> is a generator of a stream of values of type
--   <tt>b</tt> from a seed of type <tt>a</tt> in <a>Monad</a> <tt>m</tt>.
--   
--   <i>Pre-release</i>
data Producer m a b

-- | <pre>
--   Producer step inject extract
--   </pre>
Producer :: (s -> m (Step s b)) -> (a -> m s) -> (s -> m a) -> Producer m a b
nil :: Monad m => Producer m a b
nilM :: Monad m => (a -> m c) -> Producer m a b
unfoldrM :: Monad m => (a -> m (Maybe (b, a))) -> Producer m a b

-- | Convert a list of pure values to a <tt>Stream</tt>
--   
--   <i>Pre-release</i>
fromList :: Monad m => Producer m [a] a

-- | Interconvert the producer between two interconvertible input types.
--   
--   <i>Pre-release</i>
translate :: Functor m => (a -> c) -> (c -> a) -> Producer m c b -> Producer m a b

-- | Map the producer input to another value of the same type.
--   
--   <i>Pre-release</i>
lmap :: (a -> a) -> Producer m a b -> Producer m a b

-- | State representing a nested loop.
data NestedLoop s1 s2
OuterLoop :: s1 -> NestedLoop s1 s2
InnerLoop :: s1 -> s2 -> NestedLoop s1 s2

-- | Apply the second unfold to each output element of the first unfold and
--   flatten the output in a single stream.
--   
--   <i>Pre-release</i>
concat :: Monad m => Producer m a b -> Producer m b c -> Producer m (NestedLoop a b) c
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Producer.Type.Producer m a)


-- | A CPS style stream using a constructor based representation instead of
--   a function based representation.
--   
--   Streamly internally uses two fundamental stream representations, (1)
--   streams with an open or arbitrary control flow (we call it StreamK),
--   (2) streams with a structured or closed loop control flow (we call it
--   StreamD). The higher level stream types can use any of these
--   representations under the hood and can interconvert between the two.
--   
--   StreamD:
--   
--   StreamD is a non-recursive data type in which the state of the stream
--   and the step function are separate. When the step function is called,
--   a stream element and the new stream state is yielded. The generated
--   element and the state are passed to the next consumer in the loop. The
--   state is threaded around in the loop until control returns back to the
--   original step function to run the next step. This creates a structured
--   closed loop representation (like "for" loops in C) with state of each
--   step being hidden/abstracted or existential within that step. This
--   creates a loop representation identical to the "for" or "while" loop
--   constructs in imperative languages, the states of the steps combined
--   together constitute the state of the loop iteration.
--   
--   Internally most combinators use a closed loop representation because
--   it provides very high efficiency due to stream fusion. The performance
--   of this representation is competitive to the C language
--   implementations.
--   
--   Pros and Cons of StreamD:
--   
--   1) stream-fusion: This representation can be optimized very
--   efficiently by the compiler because the state is explicitly separated
--   from step functions, represented using pure data constructors and
--   visible to the compiler, the stream steps can be fused using
--   case-of-case transformations and the state can be specialized using
--   spec-constructor optimization, yielding a C like tight loop/state
--   machine with no constructors, the state is used unboxed and therefore
--   no unnecessary allocation.
--   
--   2) Because of a closed representation consing too many elements in
--   this type of stream does not scale, it will have quadratic performance
--   slowdown. Each cons creates a layer that needs to return the control
--   back to the caller. Another implementation of cons is possible but
--   that will have to box/unbox the state and will not fuse. So
--   effectively cons breaks fusion.
--   
--   3) unconsing an item from the stream breaks fusion, we have to "pause"
--   the loop, rebox and save the state.
--   
--   3) Exception handling is easy to implement in this model because
--   control flow is structured in the loop and cannot be arbitrary.
--   Therefore, implementing "bracket" is natural.
--   
--   4) Round-robin scheduling for co-operative multitasking is easy to
--   implement.
--   
--   5) It fuses well with the direct style Fold implementation.
--   
--   StreamK/StreamDK:
--   
--   StreamDK i.e. the stream defined in this module, like StreamK, is a
--   recursive data type which has no explicit state defined using
--   constructors, each step yields an element and a computation
--   representing the rest of the stream. Stream state is part of the
--   function representing the rest of the stream. This creates an open
--   computation representation, or essentially a continuation passing
--   style computation. After the stream step is executed, the caller is
--   free to consume the produced element and then send the control
--   wherever it wants, there is no restriction on the control to return
--   back somewhere, the control is free to go anywhere. The caller may
--   decide not to consume the rest of the stream. This representation is
--   more like a "goto" based implementation in imperative languages.
--   
--   Pros and Cons of StreamK:
--   
--   1) The way StreamD can be optimized using stream-fusion, this type can
--   be optimized using foldr<i>build fusion. However, foldr</i>build has
--   not yet been fully implemented for StreamK/StreamDK.
--   
--   2) Using cons is natural in this representation, unlike in StreamD it
--   does not have a quadratic slowdown. Currently, we in fact wrap StreamD
--   in StreamK to support a better cons operation.
--   
--   3) Similarly, uncons is natural in this representation.
--   
--   4) Exception handling is not easy to implement because of the "goto"
--   nature of CPS.
--   
--   5) Composable folds are not implemented/proven, however, intuition
--   says that a push style CPS representation should be able to be used
--   along with StreamK to efficiently implement composable folds.
module Streamly.Internal.Data.Stream.StreamDK.Type
data Step m a
Yield :: a -> Stream m a -> Step m a
Stop :: Step m a
newtype Stream m a
Stream :: m (Step m a) -> Stream m a


module Streamly.Internal.Data.Stream.StreamDK
data Stream m a
data Step m a
Yield :: a -> Stream m a -> Step m a
Stop :: Step m a
nil :: Monad m => Stream m a
cons :: Monad m => a -> Stream m a -> Stream m a
consM :: Monad m => m a -> Stream m a -> Stream m a
unfoldr :: Monad m => (b -> Maybe (a, b)) -> b -> Stream m a
unfoldrM :: Monad m => (s -> m (Maybe (a, s))) -> s -> Stream m a
replicateM :: Monad m => Int -> a -> Stream m a
uncons :: Monad m => Stream m a -> m (Maybe (a, Stream m a))

-- | Lazy right associative fold to a stream.
foldrS :: Monad m => (a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
drain :: Monad m => Stream m a -> m ()


-- | Time utilities for reactive programming.

-- | <i>Deprecated: Please use the "rate" combinator instead of the
--   functions in this module</i>
module Streamly.Internal.Data.Time

-- | Run an action forever periodically at the given frequency specified in
--   per second (Hz).
periodic :: Int -> IO () -> IO ()

-- | Run a computation on every clock tick, the clock runs at the specified
--   frequency. It allows running a computation at high frequency
--   efficiently by maintaining a local clock and adjusting it with the
--   provided base clock at longer intervals. The first argument is a base
--   clock returning some notion of time in microseconds. The second
--   argument is the frequency in per second (Hz). The third argument is
--   the action to run, the action is provided the local time as an
--   argument.
withClock :: IO Int -> Int -> (Int -> IO ()) -> IO ()


module Streamly.Internal.Data.Time.TimeSpec

-- | Data type to represent practically large quantities of time
--   efficiently. It can represent time up to ~292 billion years at
--   nanosecond resolution.
data TimeSpec
TimeSpec :: {-# UNPACK #-} !Int64 -> {-# UNPACK #-} !Int64 -> TimeSpec

-- | seconds
[sec] :: TimeSpec -> {-# UNPACK #-} !Int64

-- | nanoseconds
[nsec] :: TimeSpec -> {-# UNPACK #-} !Int64
instance GHC.Show.Show Streamly.Internal.Data.Time.TimeSpec.TimeSpec
instance GHC.Read.Read Streamly.Internal.Data.Time.TimeSpec.TimeSpec
instance GHC.Classes.Eq Streamly.Internal.Data.Time.TimeSpec.TimeSpec
instance GHC.Classes.Ord Streamly.Internal.Data.Time.TimeSpec.TimeSpec
instance GHC.Num.Num Streamly.Internal.Data.Time.TimeSpec.TimeSpec
instance Foreign.Storable.Storable Streamly.Internal.Data.Time.TimeSpec.TimeSpec


module Streamly.Internal.Data.Time.Units

-- | A type class for converting between time units using <a>Integer</a> as
--   the intermediate and the widest representation with a nanosecond
--   resolution. This system of units can represent arbitrarily large times
--   but provides least efficient arithmetic operations due to
--   <a>Integer</a> arithmetic.
--   
--   NOTE: Converting to and from units may truncate the value depending on
--   the original value and the size and resolution of the destination
--   unit.
--   
--   A type class for converting between units of time using
--   <a>TimeSpec</a> as the intermediate representation. This system of
--   units can represent up to ~292 billion years at nanosecond resolution
--   with reasonably efficient arithmetic operations.
--   
--   NOTE: Converting to and from units may truncate the value depending on
--   the original value and the size and resolution of the destination
--   unit.
class TimeUnit a

-- | A type class for converting between units of time using <a>Int64</a>
--   as the intermediate representation with a nanosecond resolution. This
--   system of units can represent up to ~292 years at nanosecond
--   resolution with fast arithmetic operations.
--   
--   NOTE: Converting to and from units may truncate the value depending on
--   the original value and the size and resolution of the destination
--   unit.
class TimeUnit64 a

-- | Data type to represent practically large quantities of time
--   efficiently. It can represent time up to ~292 billion years at
--   nanosecond resolution.
data TimeSpec
TimeSpec :: {-# UNPACK #-} !Int64 -> {-# UNPACK #-} !Int64 -> TimeSpec

-- | seconds
[sec] :: TimeSpec -> {-# UNPACK #-} !Int64

-- | nanoseconds
[nsec] :: TimeSpec -> {-# UNPACK #-} !Int64

-- | An <a>Int64</a> time representation with a nanosecond resolution. It
--   can represent time up to ~292 years.
newtype NanoSecond64
NanoSecond64 :: Int64 -> NanoSecond64

-- | An <a>Int64</a> time representation with a microsecond resolution. It
--   can represent time up to ~292,000 years.
newtype MicroSecond64
MicroSecond64 :: Int64 -> MicroSecond64

-- | An <a>Int64</a> time representation with a millisecond resolution. It
--   can represent time up to ~292 million years.
newtype MilliSecond64
MilliSecond64 :: Int64 -> MilliSecond64

-- | Convert nanoseconds to a string showing time in an appropriate unit.
showNanoSecond64 :: NanoSecond64 -> String

-- | Absolute times are relative to a predefined epoch in time.
--   <a>AbsTime</a> represents times using <a>TimeSpec</a> which can
--   represent times up to ~292 billion years at a nanosecond resolution.
newtype AbsTime
AbsTime :: TimeSpec -> AbsTime

-- | Convert a <a>TimeUnit</a> to an absolute time.
toAbsTime :: TimeUnit a => a -> AbsTime

-- | Convert absolute time to a <a>TimeUnit</a>.
fromAbsTime :: TimeUnit a => AbsTime -> a
data RelTime
toRelTime :: TimeUnit a => a -> RelTime
fromRelTime :: TimeUnit a => RelTime -> a
diffAbsTime :: AbsTime -> AbsTime -> RelTime
addToAbsTime :: AbsTime -> RelTime -> AbsTime

-- | Relative times are relative to some arbitrary point of time. Unlike
--   <a>AbsTime</a> they are not relative to a predefined epoch.
data RelTime64

-- | Convert a <a>TimeUnit</a> to a relative time.
toRelTime64 :: TimeUnit64 a => a -> RelTime64

-- | Convert relative time to a <a>TimeUnit</a>.
fromRelTime64 :: TimeUnit64 a => RelTime64 -> a

-- | Difference between two absolute points of time.
diffAbsTime64 :: AbsTime -> AbsTime -> RelTime64
addToAbsTime64 :: AbsTime -> RelTime64 -> AbsTime
showRelTime64 :: RelTime64 -> String
instance Data.Primitive.Types.Prim Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Classes.Ord Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Real.Integral Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Real.Real Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Num.Num Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Enum.Bounded Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Enum.Enum Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Show.Show Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Read.Read Streamly.Internal.Data.Time.Units.NanoSecond64
instance GHC.Classes.Eq Streamly.Internal.Data.Time.Units.NanoSecond64
instance Data.Primitive.Types.Prim Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Classes.Ord Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Real.Integral Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Real.Real Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Num.Num Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Enum.Bounded Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Enum.Enum Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Show.Show Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Read.Read Streamly.Internal.Data.Time.Units.MicroSecond64
instance GHC.Classes.Eq Streamly.Internal.Data.Time.Units.MicroSecond64
instance Data.Primitive.Types.Prim Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Classes.Ord Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Real.Integral Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Real.Real Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Num.Num Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Enum.Bounded Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Enum.Enum Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Show.Show Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Read.Read Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Classes.Eq Streamly.Internal.Data.Time.Units.MilliSecond64
instance GHC.Show.Show Streamly.Internal.Data.Time.Units.AbsTime
instance GHC.Classes.Ord Streamly.Internal.Data.Time.Units.AbsTime
instance GHC.Classes.Eq Streamly.Internal.Data.Time.Units.AbsTime
instance GHC.Classes.Ord Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Real.Integral Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Real.Real Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Num.Num Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Enum.Bounded Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Enum.Enum Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Show.Show Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Read.Read Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Classes.Eq Streamly.Internal.Data.Time.Units.RelTime64
instance GHC.Classes.Ord Streamly.Internal.Data.Time.Units.RelTime
instance GHC.Num.Num Streamly.Internal.Data.Time.Units.RelTime
instance GHC.Show.Show Streamly.Internal.Data.Time.Units.RelTime
instance GHC.Read.Read Streamly.Internal.Data.Time.Units.RelTime
instance GHC.Classes.Eq Streamly.Internal.Data.Time.Units.RelTime
instance Streamly.Internal.Data.Time.Units.TimeUnit64 Streamly.Internal.Data.Time.Units.NanoSecond64
instance Streamly.Internal.Data.Time.Units.TimeUnit64 Streamly.Internal.Data.Time.Units.MicroSecond64
instance Streamly.Internal.Data.Time.Units.TimeUnit64 Streamly.Internal.Data.Time.Units.MilliSecond64
instance Streamly.Internal.Data.Time.Units.TimeUnit Streamly.Internal.Data.Time.TimeSpec.TimeSpec
instance Streamly.Internal.Data.Time.Units.TimeUnit Streamly.Internal.Data.Time.Units.NanoSecond64
instance Streamly.Internal.Data.Time.Units.TimeUnit Streamly.Internal.Data.Time.Units.MicroSecond64
instance Streamly.Internal.Data.Time.Units.TimeUnit Streamly.Internal.Data.Time.Units.MilliSecond64


module Streamly.Internal.Data.Time.Clock.Type

-- | Clock types. A clock may be system-wide (that is, visible to all
--   processes) or per-process (measuring time that is meaningful only
--   within a process). All implementations shall support CLOCK_REALTIME.
--   (The only suspend-aware monotonic is CLOCK_BOOTTIME on Linux.)
data Clock

-- | The identifier for the system-wide monotonic clock, which is defined
--   as a clock measuring real time, whose value cannot be set via
--   <tt>clock_settime</tt> and which cannot have negative clock jumps. The
--   maximum possible clock jump shall be implementation defined. For this
--   clock, the value returned by <a>getTime</a> represents the amount of
--   time (in seconds and nanoseconds) since an unspecified point in the
--   past (for example, system start-up time, or the Epoch). This point
--   does not change after system start-up time. Note that the absolute
--   value of the monotonic clock is meaningless (because its origin is
--   arbitrary), and thus there is no need to set it. Furthermore, realtime
--   applications can rely on the fact that the value of this clock is
--   never set.
Monotonic :: Clock

-- | The identifier of the system-wide clock measuring real time. For this
--   clock, the value returned by <a>getTime</a> represents the amount of
--   time (in seconds and nanoseconds) since the Epoch.
Realtime :: Clock

-- | The identifier of the CPU-time clock associated with the calling
--   process. For this clock, the value returned by <a>getTime</a>
--   represents the amount of execution time of the current process.
ProcessCPUTime :: Clock

-- | The identifier of the CPU-time clock associated with the calling OS
--   thread. For this clock, the value returned by <a>getTime</a>
--   represents the amount of execution time of the current OS thread.
ThreadCPUTime :: Clock

-- | (since Linux 2.6.28; Linux and Mac OSX) Similar to CLOCK_MONOTONIC,
--   but provides access to a raw hardware-based time that is not subject
--   to NTP adjustments or the incremental adjustments performed by
--   adjtime(3).
MonotonicRaw :: Clock

-- | (since Linux 2.6.32; Linux and Mac OSX) A faster but less precise
--   version of CLOCK_MONOTONIC. Use when you need very fast, but not
--   fine-grained timestamps.
MonotonicCoarse :: Clock

-- | (since Linux 2.6.39; Linux and Mac OSX) Identical to CLOCK_MONOTONIC,
--   except it also includes any time that the system is suspended. This
--   allows applications to get a suspend-aware monotonic clock without
--   having to deal with the complications of CLOCK_REALTIME, which may
--   have discontinuities if the time is changed using settimeofday(2).
Uptime :: Clock

-- | (since Linux 2.6.32; Linux-specific) A faster but less precise version
--   of CLOCK_REALTIME. Use when you need very fast, but not fine-grained
--   timestamps.
RealtimeCoarse :: Clock
getTime :: Clock -> IO AbsTime
instance GHC.Show.Show Streamly.Internal.Data.Time.Clock.Type.Clock
instance GHC.Read.Read Streamly.Internal.Data.Time.Clock.Type.Clock
instance GHC.Generics.Generic Streamly.Internal.Data.Time.Clock.Type.Clock
instance GHC.Enum.Enum Streamly.Internal.Data.Time.Clock.Type.Clock
instance GHC.Classes.Eq Streamly.Internal.Data.Time.Clock.Type.Clock


module Streamly.Internal.Data.SVar.Type
data ThreadAbort
ThreadAbort :: ThreadAbort

-- | Events that a child thread may send to a parent thread.
data ChildEvent a
ChildYield :: a -> ChildEvent a
ChildStop :: ThreadId -> Maybe SomeException -> ChildEvent a

-- | Sorting out-of-turn outputs in a heap for Ahead style streams
data AheadHeapEntry (t :: (Type -> Type) -> Type -> Type) m a
AheadEntryNull :: AheadHeapEntry (t :: (Type -> Type) -> Type -> Type) m a
AheadEntryPure :: a -> AheadHeapEntry (t :: (Type -> Type) -> Type -> Type) m a
AheadEntryStream :: (RunInIO m, t m a) -> AheadHeapEntry (t :: (Type -> Type) -> Type -> Type) m a
newtype Count
Count :: Int64 -> Count
data Limit
Unlimited :: Limit
Limited :: Word -> Limit

-- | Identify the type of the SVar. Two computations using the same style
--   can be scheduled on the same SVar.
data SVarStyle
AsyncVar :: SVarStyle
WAsyncVar :: SVarStyle
ParallelVar :: SVarStyle
AheadVar :: SVarStyle
data SVarStopStyle
StopNone :: SVarStopStyle
StopAny :: SVarStopStyle
StopBy :: SVarStopStyle
data SVarStats
SVarStats :: IORef Int -> IORef Int -> IORef Int -> IORef Int -> IORef Int -> IORef (Count, NanoSecond64) -> IORef NanoSecond64 -> IORef NanoSecond64 -> IORef (Maybe AbsTime) -> SVarStats
[totalDispatches] :: SVarStats -> IORef Int
[maxWorkers] :: SVarStats -> IORef Int
[maxOutQSize] :: SVarStats -> IORef Int
[maxHeapSize] :: SVarStats -> IORef Int
[maxWorkQSize] :: SVarStats -> IORef Int
[avgWorkerLatency] :: SVarStats -> IORef (Count, NanoSecond64)
[minWorkerLatency] :: SVarStats -> IORef NanoSecond64
[maxWorkerLatency] :: SVarStats -> IORef NanoSecond64
[svarStopTime] :: SVarStats -> IORef (Maybe AbsTime)

-- | An SVar or a Stream Var is a conduit to the output from multiple
--   streams running concurrently and asynchronously. An SVar can be
--   thought of as an asynchronous IO handle. We can write any number of
--   streams to an SVar in a non-blocking manner and then read them back at
--   any time at any pace. The SVar would run the streams asynchronously
--   and accumulate results. An SVar may not really execute the stream
--   completely and accumulate all the results. However, it ensures that
--   the reader can read the results at whatever paces it wants to read.
--   The SVar monitors and adapts to the consumer's pace.
--   
--   An SVar is a mini scheduler, it has an associated workLoop that holds
--   the stream tasks to be picked and run by a pool of worker threads. It
--   has an associated output queue where the output stream elements are
--   placed by the worker threads. A outputDoorBell is used by the worker
--   threads to intimate the consumer thread about availability of new
--   results in the output queue. More workers are added to the SVar by
--   <tt>fromStreamVar</tt> on demand if the output produced is not keeping
--   pace with the consumer. On bounded SVars, workers block on the output
--   queue to provide throttling of the producer when the consumer is not
--   pulling fast enough. The number of workers may even get reduced
--   depending on the consuming pace.
--   
--   New work is enqueued either at the time of creation of the SVar or as
--   a result of executing the parallel combinators i.e. <tt>&lt;|</tt> and
--   <tt>&lt;|&gt;</tt> when the already enqueued computations get
--   evaluated. See <tt>joinStreamVarAsync</tt>.
data WorkerInfo
WorkerInfo :: Count -> IORef Count -> IORef (Count, AbsTime) -> WorkerInfo
[workerYieldMax] :: WorkerInfo -> Count
[workerYieldCount] :: WorkerInfo -> IORef Count
[workerLatencyStart] :: WorkerInfo -> IORef (Count, AbsTime)

-- | Buffering policy for persistent push workers (in ParallelT). In a pull
--   style SVar (in AsyncT, AheadT etc.), the consumer side dispatches
--   workers on demand, workers terminate if the buffer is full or if the
--   consumer is not cosuming fast enough. In a push style SVar, a worker
--   is dispatched only once, workers are persistent and keep pushing work
--   to the consumer via a bounded buffer. If the buffer becomes full the
--   worker either blocks, or it can drop an item from the buffer to make
--   space.
--   
--   Pull style SVars are useful in lazy stream evaluation whereas push
--   style SVars are useful in strict left Folds.
--   
--   XXX Maybe we can separate the implementation in two different types
--   instead of using a common SVar type.
data PushBufferPolicy
PushBufferDropNew :: PushBufferPolicy
PushBufferDropOld :: PushBufferPolicy
PushBufferBlock :: PushBufferPolicy
data LatencyRange
LatencyRange :: NanoSecond64 -> NanoSecond64 -> LatencyRange
[minLatency] :: LatencyRange -> NanoSecond64
[maxLatency] :: LatencyRange -> NanoSecond64
data YieldRateInfo
YieldRateInfo :: NanoSecond64 -> LatencyRange -> Int -> IORef Count -> IORef (Count, AbsTime) -> Maybe NanoSecond64 -> IORef Count -> IORef (Count, Count, NanoSecond64) -> IORef (Count, Count, NanoSecond64) -> IORef NanoSecond64 -> YieldRateInfo
[svarLatencyTarget] :: YieldRateInfo -> NanoSecond64
[svarLatencyRange] :: YieldRateInfo -> LatencyRange
[svarRateBuffer] :: YieldRateInfo -> Int
[svarGainedLostYields] :: YieldRateInfo -> IORef Count
[svarAllTimeLatency] :: YieldRateInfo -> IORef (Count, AbsTime)
[workerBootstrapLatency] :: YieldRateInfo -> Maybe NanoSecond64
[workerPollingInterval] :: YieldRateInfo -> IORef Count
[workerPendingLatency] :: YieldRateInfo -> IORef (Count, Count, NanoSecond64)
[workerCollectedLatency] :: YieldRateInfo -> IORef (Count, Count, NanoSecond64)
[workerMeasuredLatency] :: YieldRateInfo -> IORef NanoSecond64
data SVar t m a
SVar :: SVarStyle -> RunInIO m -> SVarStopStyle -> IORef ThreadId -> IORef ([ChildEvent a], Int) -> MVar () -> m [ChildEvent a] -> m Bool -> IORef ([ChildEvent a], Int) -> MVar () -> Limit -> Limit -> IORef Count -> PushBufferPolicy -> MVar () -> Maybe (IORef Count) -> Maybe YieldRateInfo -> ((RunInIO m, t m a) -> IO ()) -> IO Bool -> IO Bool -> IORef Bool -> (Maybe WorkerInfo -> m ()) -> IORef (Set ThreadId) -> IORef Int -> (ThreadId -> m ()) -> MVar () -> SVarStats -> Maybe (IORef ()) -> Bool -> ThreadId -> IORef (Heap (Entry Int (AheadHeapEntry t m a)), Maybe Int) -> IORef ([t m a], Int) -> SVar t m a
[svarStyle] :: SVar t m a -> SVarStyle
[svarMrun] :: SVar t m a -> RunInIO m
[svarStopStyle] :: SVar t m a -> SVarStopStyle
[svarStopBy] :: SVar t m a -> IORef ThreadId
[outputQueue] :: SVar t m a -> IORef ([ChildEvent a], Int)
[outputDoorBell] :: SVar t m a -> MVar ()
[readOutputQ] :: SVar t m a -> m [ChildEvent a]
[postProcess] :: SVar t m a -> m Bool
[outputQueueFromConsumer] :: SVar t m a -> IORef ([ChildEvent a], Int)
[outputDoorBellFromConsumer] :: SVar t m a -> MVar ()
[maxWorkerLimit] :: SVar t m a -> Limit
[maxBufferLimit] :: SVar t m a -> Limit
[pushBufferSpace] :: SVar t m a -> IORef Count
[pushBufferPolicy] :: SVar t m a -> PushBufferPolicy
[pushBufferMVar] :: SVar t m a -> MVar ()
[remainingWork] :: SVar t m a -> Maybe (IORef Count)
[yieldRateInfo] :: SVar t m a -> Maybe YieldRateInfo
[enqueue] :: SVar t m a -> (RunInIO m, t m a) -> IO ()
[isWorkDone] :: SVar t m a -> IO Bool
[isQueueDone] :: SVar t m a -> IO Bool
[needDoorBell] :: SVar t m a -> IORef Bool
[workLoop] :: SVar t m a -> Maybe WorkerInfo -> m ()
[workerThreads] :: SVar t m a -> IORef (Set ThreadId)
[workerCount] :: SVar t m a -> IORef Int
[accountThread] :: SVar t m a -> ThreadId -> m ()
[workerStopMVar] :: SVar t m a -> MVar ()
[svarStats] :: SVar t m a -> SVarStats
[svarRef] :: SVar t m a -> Maybe (IORef ())
[svarInspectMode] :: SVar t m a -> Bool
[svarCreator] :: SVar t m a -> ThreadId
[outputHeap] :: SVar t m a -> IORef (Heap (Entry Int (AheadHeapEntry t m a)), Maybe Int)
[aheadWorkQueue] :: SVar t m a -> IORef ([t m a], Int)

-- | Specifies the stream yield rate in yields per second (<tt>Hertz</tt>).
--   We keep accumulating yield credits at <a>rateGoal</a>. At any point of
--   time we allow only as many yields as we have accumulated as per
--   <a>rateGoal</a> since the start of time. If the consumer or the
--   producer is slower or faster, the actual rate may fall behind or
--   exceed <a>rateGoal</a>. We try to recover the gap between the two by
--   increasing or decreasing the pull rate from the producer. However, if
--   the gap becomes more than <a>rateBuffer</a> we try to recover only as
--   much as <a>rateBuffer</a>.
--   
--   <a>rateLow</a> puts a bound on how low the instantaneous rate can go
--   when recovering the rate gap. In other words, it determines the
--   maximum yield latency. Similarly, <a>rateHigh</a> puts a bound on how
--   high the instantaneous rate can go when recovering the rate gap. In
--   other words, it determines the minimum yield latency. We reduce the
--   latency by increasing concurrency, therefore we can say that it puts
--   an upper bound on concurrency.
--   
--   If the <a>rateGoal</a> is 0 or negative the stream never yields a
--   value. If the <a>rateBuffer</a> is 0 or negative we do not attempt to
--   recover.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
data Rate
Rate :: Double -> Double -> Double -> Int -> Rate

-- | The lower rate limit
[rateLow] :: Rate -> Double

-- | The target rate we want to achieve
[rateGoal] :: Rate -> Double

-- | The upper rate limit
[rateHigh] :: Rate -> Double

-- | Maximum slack from the goal
[rateBuffer] :: Rate -> Int
data State t m a
magicMaxBuffer :: Word
defState :: State t m a

-- | Adapt the stream state from one type to another.
adaptState :: State t m a -> State t n b
getMaxThreads :: State t m a -> Limit
setMaxThreads :: Int -> State t m a -> State t m a
getMaxBuffer :: State t m a -> Limit
setMaxBuffer :: Int -> State t m a -> State t m a
getStreamRate :: State t m a -> Maybe Rate
setStreamRate :: Maybe Rate -> State t m a -> State t m a
getStreamLatency :: State t m a -> Maybe NanoSecond64
setStreamLatency :: Int -> State t m a -> State t m a
getYieldLimit :: State t m a -> Maybe Count
setYieldLimit :: Maybe Int64 -> State t m a -> State t m a
getInspectMode :: State t m a -> Bool
setInspectMode :: State t m a -> State t m a
instance GHC.Classes.Ord Streamly.Internal.Data.SVar.Type.Count
instance GHC.Real.Integral Streamly.Internal.Data.SVar.Type.Count
instance GHC.Real.Real Streamly.Internal.Data.SVar.Type.Count
instance GHC.Num.Num Streamly.Internal.Data.SVar.Type.Count
instance GHC.Enum.Bounded Streamly.Internal.Data.SVar.Type.Count
instance GHC.Enum.Enum Streamly.Internal.Data.SVar.Type.Count
instance GHC.Show.Show Streamly.Internal.Data.SVar.Type.Count
instance GHC.Read.Read Streamly.Internal.Data.SVar.Type.Count
instance GHC.Classes.Eq Streamly.Internal.Data.SVar.Type.Count
instance GHC.Show.Show Streamly.Internal.Data.SVar.Type.ThreadAbort
instance GHC.Show.Show Streamly.Internal.Data.SVar.Type.SVarStyle
instance GHC.Classes.Eq Streamly.Internal.Data.SVar.Type.SVarStyle
instance GHC.Show.Show Streamly.Internal.Data.SVar.Type.LatencyRange
instance GHC.Show.Show Streamly.Internal.Data.SVar.Type.Limit
instance GHC.Show.Show Streamly.Internal.Data.SVar.Type.SVarStopStyle
instance GHC.Classes.Eq Streamly.Internal.Data.SVar.Type.SVarStopStyle
instance GHC.Classes.Eq Streamly.Internal.Data.SVar.Type.Limit
instance GHC.Classes.Ord Streamly.Internal.Data.SVar.Type.Limit
instance GHC.Exception.Type.Exception Streamly.Internal.Data.SVar.Type.ThreadAbort


-- | Continuation passing style (CPS) stream implementation. The symbol
--   <tt>K</tt> below denotes a function as well as a Kontinuation.
module Streamly.Internal.Data.Stream.StreamK.Type

-- | The type <tt>Stream m a</tt> represents a monadic stream of values of
--   type <tt>a</tt> constructed using actions in monad <tt>m</tt>. It uses
--   stop, singleton and yield continuations equivalent to the following
--   direct style type:
--   
--   <pre>
--   data Stream m a = Stop | Singleton a | Yield a (Stream m a)
--   </pre>
--   
--   To facilitate parallel composition we maintain a local state in an
--   <tt>SVar</tt> that is shared across and is used for synchronization of
--   the streams being composed.
--   
--   The singleton case can be expressed in terms of stop and yield but we
--   have it as a separate case to optimize composition operations for
--   streams with single element. We build singleton streams in the
--   implementation of <a>pure</a> for Applicative and Monad, and in
--   <a>lift</a> for MonadTrans.
newtype Stream m a
MkStream :: (forall r. State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> m r) -> Stream m a
toStreamK :: Stream m a -> Stream m a
fromStreamK :: Stream m a -> Stream m a
mkStream :: (forall r. State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> m r) -> Stream m a

-- | Fold a stream by providing a State, stop continuation, a singleton
--   continuation and a yield continuation. The stream will not use the
--   SVar passed via State.
foldStream :: State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> Stream m a -> m r

-- | Fold a stream by providing an SVar, a stop continuation, a singleton
--   continuation and a yield continuation. The stream would share the
--   current SVar passed via the State.
foldStreamShared :: State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> Stream m a -> m r

-- | Lazy right fold with a monadic step function.
foldrM :: (a -> m b -> m b) -> m b -> Stream m a -> m b

-- | Lazy right associative fold to a stream.
foldrS :: (a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b

-- | Fold sharing the SVar state within the reconstructed stream
foldrSShared :: (a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
foldrSM :: Monad m => (m a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
build :: forall m a. (forall b. (a -> b -> b) -> b -> b) -> Stream m a
buildS :: ((a -> Stream m a -> Stream m a) -> Stream m a -> Stream m a) -> Stream m a
buildM :: Monad m => (forall r. (a -> Stream m a -> m r) -> (a -> m r) -> m r -> m r) -> Stream m a
buildSM :: Monad m => ((m a -> Stream m a -> Stream m a) -> Stream m a -> Stream m a) -> Stream m a
augmentS :: ((a -> Stream m a -> Stream m a) -> Stream m a -> Stream m a) -> Stream m a -> Stream m a
augmentSM :: Monad m => ((m a -> Stream m a -> Stream m a) -> Stream m a -> Stream m a) -> Stream m a -> Stream m a

-- | Make an empty stream from a stop function.
fromStopK :: StopK m -> Stream m a

-- | Make a singleton stream from a callback function. The callback
--   function calls the one-shot yield continuation to yield an element.
fromYieldK :: YieldK m a -> Stream m a

-- | Add a yield function at the head of the stream.
consK :: YieldK m a -> Stream m a -> Stream m a

-- | Construct a stream by adding a pure value at the head of an existing
--   stream. For serial streams this is the same as <tt>(return a) `consM`
--   r</tt> but more efficient. For concurrent streams this is not
--   concurrent whereas <a>consM</a> is concurrent. For example:
--   
--   <pre>
--   &gt; toList $ 1 `cons` 2 `cons` 3 `cons` nil
--   [1,2,3]
--   </pre>
cons :: a -> Stream m a -> Stream m a
infixr 5 `cons`

-- | Operator equivalent of <a>cons</a>.
--   
--   <pre>
--   &gt; toList $ 1 .: 2 .: 3 .: nil
--   [1,2,3]
--   </pre>
(.:) :: a -> Stream m a -> Stream m a
infixr 5 .:
consM :: Monad m => m a -> Stream m a -> Stream m a
infixr 5 `consM`
consMBy :: Monad m => (Stream m a -> Stream m a -> Stream m a) -> m a -> Stream m a -> Stream m a

-- | An empty stream.
--   
--   <pre>
--   &gt; toList nil
--   []
--   </pre>
nil :: Stream m a

-- | An empty stream producing a side effect.
--   
--   <pre>
--   &gt; toList (nilM (print "nil"))
--   "nil"
--   []
--   </pre>
--   
--   <i>Pre-release</i>
nilM :: Applicative m => m b -> Stream m a
fromEffect :: Monad m => m a -> Stream m a
fromPure :: a -> Stream m a
unfoldr :: (b -> Maybe (a, b)) -> b -> Stream m a
unfoldrMWith :: Monad m => (m a -> Stream m a -> Stream m a) -> (b -> m (Maybe (a, b))) -> b -> Stream m a

-- | Generate an infinite stream by repeating a pure value.
--   
--   <i>Pre-release</i>
repeat :: a -> Stream m a

-- | Like <tt>repeatM</tt> but takes a stream <a>cons</a> operation to
--   combine the actions in a stream specific manner. A serial cons would
--   repeat the values serially while an async cons would repeat
--   concurrently.
--   
--   <i>Pre-release</i>
repeatMWith :: (m a -> t m a -> t m a) -> m a -> t m a
replicateMWith :: (m a -> Stream m a -> Stream m a) -> Int -> m a -> Stream m a
fromIndicesMWith :: (m a -> Stream m a -> Stream m a) -> (Int -> m a) -> Stream m a
iterateMWith :: Monad m => (m a -> Stream m a -> Stream m a) -> (a -> m a) -> m a -> Stream m a

-- | <pre>
--   fromFoldable = <a>foldr</a> <a>cons</a> <a>nil</a>
--   </pre>
--   
--   Construct a stream from a <a>Foldable</a> containing pure values:
fromFoldable :: Foldable f => f a -> Stream m a
fromFoldableM :: (Foldable f, Monad m) => f (m a) -> Stream m a
mfix :: Monad m => (m a -> Stream m a) -> Stream m a
uncons :: Applicative m => Stream m a -> m (Maybe (a, Stream m a))

-- | Strict left associative fold.
foldl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> m b

-- | Strict left fold with an extraction function. Like the standard strict
--   left fold, but applies a user supplied extraction function (the third
--   argument) to the folded value at the end. This is designed to work
--   with the <tt>foldl</tt> library. The suffix <tt>x</tt> is a mnemonic
--   for extraction.
--   
--   Note that the accumulator is always evaluated including the initial
--   value.
foldlx' :: forall m a b x. Monad m => (x -> a -> x) -> x -> (x -> b) -> Stream m a -> m b

-- | <pre>
--   drain = foldl' (\_ _ -&gt; ()) ()
--   drain = mapM_ (\_ -&gt; return ())
--   </pre>
drain :: Monad m => Stream m a -> m ()
null :: Monad m => Stream m a -> m Bool
tail :: Applicative m => Stream m a -> m (Maybe (Stream m a))
init :: Applicative m => Stream m a -> m (Maybe (Stream m a))
conjoin :: Monad m => Stream m a -> Stream m a -> Stream m a

-- | Appends two streams sequentially, yielding all elements from the first
--   stream, and then all elements from the second stream.
serial :: Stream m a -> Stream m a -> Stream m a
infixr 6 `serial`
map :: (a -> b) -> Stream m a -> Stream m b
mapMWith :: (m b -> Stream m b -> Stream m b) -> (a -> m b) -> Stream m a -> Stream m b
mapMSerial :: Monad m => (a -> m b) -> Stream m a -> Stream m b

-- | Detach a stream from an SVar
unShare :: Stream m a -> Stream m a

-- | Perform a <a>concatMap</a> using a specified concat strategy. The
--   first argument specifies a merge or concat function that is used to
--   merge the streams generated by the map function. For example, the
--   concat function could be <a>serial</a>, <tt>parallel</tt>,
--   <tt>async</tt>, <tt>ahead</tt> or any other zip or merge function.
concatMapWith :: (Stream m b -> Stream m b -> Stream m b) -> (a -> Stream m b) -> Stream m a -> Stream m b
concatMap :: (a -> Stream m b) -> Stream m a -> Stream m b
bindWith :: (Stream m b -> Stream m b -> Stream m b) -> Stream m a -> (a -> Stream m b) -> Stream m b

-- | See <a>concatPairsWith</a> for documentation.
concatPairsWith :: (Stream m b -> Stream m b -> Stream m b) -> (a -> Stream m b) -> Stream m a -> Stream m b
apWith :: (Stream m b -> Stream m b -> Stream m b) -> Stream m (a -> b) -> Stream m a -> Stream m b
apSerial :: Stream m (a -> b) -> Stream m a -> Stream m b
apSerialDiscardFst :: Stream m a -> Stream m b -> Stream m b
apSerialDiscardSnd :: Stream m a -> Stream m b -> Stream m a

-- | Lazy left fold to a stream.
foldlS :: (Stream m b -> a -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
reverse :: Stream m a -> Stream m a
withLocal :: MonadReader r m => (r -> r) -> Stream m a -> Stream m a
instance GHC.Base.Semigroup (Streamly.Internal.Data.Stream.StreamK.Type.Stream m a)
instance GHC.Base.Monoid (Streamly.Internal.Data.Stream.StreamK.Type.Stream m a)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.StreamK.Type.Stream m)
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.StreamK.Type.Stream
instance GHC.Base.Monad m => GHC.Base.Applicative (Streamly.Internal.Data.Stream.StreamK.Type.Stream m)
instance GHC.Base.Monad m => GHC.Base.Monad (Streamly.Internal.Data.Stream.StreamK.Type.Stream m)


-- | | Strict data types to be used as accumulator for strict left folds
--   and scans. For more comprehensive strict data types see
--   <a>https://hackage.haskell.org/package/strict-base-types</a> . The
--   names have been suffixed by a prime so that programmers can easily
--   distinguish the strict versions from the lazy ones.
--   
--   One major advantage of strict data structures as accumulators in folds
--   and scans is that it helps the compiler optimize the code much better
--   by unboxing. In a big tight loop the difference could be huge.
module Streamly.Internal.Data.Tuple.Strict

-- | A strict <tt>(,)</tt>
data Tuple' a b
Tuple' :: !a -> !b -> Tuple' a b

-- | A strict <tt>(,,)</tt>
data Tuple3' a b c
Tuple3' :: !a -> !b -> !c -> Tuple3' a b c

-- | A strict <tt>(,,,)</tt>
data Tuple4' a b c d
Tuple4' :: !a -> !b -> !c -> !d -> Tuple4' a b c d
instance (GHC.Show.Show a, GHC.Show.Show b) => GHC.Show.Show (Streamly.Internal.Data.Tuple.Strict.Tuple' a b)
instance (GHC.Show.Show a, GHC.Show.Show b, GHC.Show.Show c) => GHC.Show.Show (Streamly.Internal.Data.Tuple.Strict.Tuple3' a b c)
instance (GHC.Show.Show a, GHC.Show.Show b, GHC.Show.Show c, GHC.Show.Show d) => GHC.Show.Show (Streamly.Internal.Data.Tuple.Strict.Tuple4' a b c d)


module Streamly.Internal.Data.Pipe.Type
data Step s a
Yield :: a -> s -> Step s a
Continue :: s -> Step s a
data Pipe m a b
Pipe :: (s1 -> a -> m (Step (PipeState s1 s2) b)) -> (s2 -> m (Step (PipeState s1 s2) b)) -> s1 -> Pipe m a b

-- | Represents a stateful transformation over an input stream of values of
--   type <tt>a</tt> to outputs of type <tt>b</tt> in <a>Monad</a>
--   <tt>m</tt>.
data PipeState s1 s2
Consume :: s1 -> PipeState s1 s2
Produce :: s2 -> PipeState s1 s2

-- | The composed pipe distributes the input to both the constituent pipes
--   and zips the output of the two using a supplied zipping function.
zipWith :: Monad m => (a -> b -> c) -> Pipe m i a -> Pipe m i b -> Pipe m i c

-- | The composed pipe distributes the input to both the constituent pipes
--   and merges the outputs of the two.
tee :: Monad m => Pipe m a b -> Pipe m a b -> Pipe m a b

-- | Lift a pure function to a <a>Pipe</a>.
map :: Monad m => (a -> b) -> Pipe m a b

-- | Compose two pipes such that the output of the second pipe is attached
--   to the input of the first pipe.
compose :: Monad m => Pipe m b c -> Pipe m a b -> Pipe m a c
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Pipe.Type.Pipe m a)
instance GHC.Base.Monad m => GHC.Base.Applicative (Streamly.Internal.Data.Pipe.Type.Pipe m a)
instance GHC.Base.Monad m => GHC.Base.Semigroup (Streamly.Internal.Data.Pipe.Type.Pipe m a b)
instance GHC.Base.Monad m => Control.Category.Category (Streamly.Internal.Data.Pipe.Type.Pipe m)
instance GHC.Base.Monad m => Control.Arrow.Arrow (Streamly.Internal.Data.Pipe.Type.Pipe m)


-- | There are three fundamental types in streamly. They are streams
--   (<a>Streamly.Prelude</a>), pipes (<a>Streamly.Internal.Data.Pipe</a>)
--   and folds (<a>Streamly.Data.Fold</a>). Streams are sources or
--   producers of values, multiple sources can be merged into a single
--   source but a source cannot be split into multiple stream sources.
--   Folds are sinks or consumers, a stream can be split and distributed to
--   multiple folds but the results cannot be merged back into a stream
--   source again. Pipes are transformations, a stream source can be split
--   and distributed to multiple pipes each pipe can apply its own
--   transform on the stream and the results can be merged back into a
--   single pipe. Pipes can be attached to a source to produce a source or
--   they can be attached to a fold to produce a fold, or multiple pipes
--   can be merged or zipped into a single pipe.
--   
--   <pre>
--   import qualified Streamly.Internal.Data.Pipe as Pipe
--   </pre>
module Streamly.Internal.Data.Pipe
data Pipe m a b

-- | Lift a pure function to a <a>Pipe</a>.
map :: Monad m => (a -> b) -> Pipe m a b

-- | Lift a monadic function to a <a>Pipe</a>.
mapM :: Monad m => (a -> m b) -> Pipe m a b

-- | The composed pipe distributes the input to both the constituent pipes
--   and merges the outputs of the two.
tee :: Monad m => Pipe m a b -> Pipe m a b -> Pipe m a b

-- | The composed pipe distributes the input to both the constituent pipes
--   and zips the output of the two using a supplied zipping function.
zipWith :: Monad m => (a -> b -> c) -> Pipe m i a -> Pipe m i b -> Pipe m i c

-- | Compose two pipes such that the output of the second pipe is attached
--   to the input of the first pipe.
compose :: Monad m => Pipe m b c -> Pipe m a b -> Pipe m a c


-- | <h1>Stream Consumers</h1>
--   
--   We can classify stream consumers in the following categories in order
--   of increasing complexity and power:
--   
--   <h2>Accumulators</h2>
--   
--   These are the simplest folds that never fail and never terminate, they
--   accumulate the input values forever and can always accept new inputs
--   (never terminate) and always have a valid result value. A <a>sum</a>
--   operation is an example of an accumulator. Traditional Haskell left
--   folds like <a>foldl</a> are accumulators.
--   
--   We can distribute an input stream to two or more accumulators using a
--   <tt>tee</tt> style composition. Accumulators cannot be applied on a
--   stream one after the other, which we call a <tt>serial</tt> append
--   style composition of folds. This is because accumulators never
--   terminate, since the first accumulator in a series will never
--   terminate, the next one will never get to run.
--   
--   <h2>Terminating Folds</h2>
--   
--   Terminating folds are accumulators that can terminate. Once a fold
--   terminates it no longer accepts any more inputs. Terminating folds can
--   be used in a <tt>serial</tt> append style composition where one fold
--   can be applied after the other on an input stream. We can apply a
--   terminating fold repeatedly on an input stream, splitting the stream
--   and consuming it in fragments. Terminating folds never fail,
--   therefore, they do not need backtracking.
--   
--   The <a>take</a> operation is an example of a terminating fold It
--   terminates after consuming <tt>n</tt> items. Coupled with an
--   accumulator (e.g. sum) it can be used to split and process the stream
--   into chunks of fixed size.
--   
--   <h2>Terminating Folds with Leftovers</h2>
--   
--   The next upgrade after terminating folds is terminating folds with
--   leftover inputs. Consider the example of <tt>takeWhile</tt> operation,
--   it needs to inspect an element for termination decision. However, it
--   does not consume the element on which it terminates. To implement
--   <tt>takeWhile</tt> a terminating fold will have to implement a way to
--   return unconsumed input to the fold driver.
--   
--   Single element leftover case is the most common and its easy to
--   implement it in terminating folds using a <tt>Done1</tt> constructor
--   in the <a>Step</a> type which indicates that the last element was not
--   consumed by the fold. The following additional operations can be
--   implemented as terminating folds if we do that.
--   
--   <pre>
--   takeWhile
--   groupBy
--   wordBy
--   </pre>
--   
--   However, it creates several complications. The <a>many</a> combinator
--   requires a <tt>Partial1</tt> (<a>Partial</a> with leftover) to handle
--   a <tt>Done1</tt> from the top level fold, for efficient
--   implementation. If the collecting fold in "many" returns a
--   <tt>Partial1</tt> or <tt>Done1</tt> then what to do with all the
--   elements that have been consumed?
--   
--   Similarly, in distribute, if one fold consumes a value and others say
--   its a leftover then what do we do? Folds like "many" require the
--   leftover to be fed to it again. So in a distribute operation those
--   folds which gave a leftover will have to be fed the leftover while the
--   folds that consumed will have to be fed the next input. This is very
--   complicated to implement. We have the same issue in backtracking
--   parsers being used in a distribute operation.
--   
--   To avoid these issues we want to enforce by typing that the collecting
--   folds can never return a leftover. So we need a fold type without
--   <tt>Done1</tt> or <tt>Partial1</tt>. This leads us to design folds to
--   never return a leftover and the use cases of single leftover are
--   transferred to parsers where we have general backtracking mechanism
--   and single leftover is just a special case of backtracking.
--   
--   This means: takeWhile, groupBy, wordBy would be implemented as
--   parsers. "take 0" can implemented as a fold if we make initial return
--   <tt>Step</tt> type. "takeInterval" can be implemented without
--   <tt>Done1</tt>.
--   
--   <h2>Parsers</h2>
--   
--   The next upgrade after terminating folds with a leftover are parsers.
--   Parsers are terminating folds that can fail and backtrack. Parsers can
--   be composed using an <tt>alternative</tt> style composition where they
--   can backtrack and apply another parser if one parser fails.
--   <a>satisfy</a> is a simple example of a parser, it would succeed if
--   the condition is satisfied and it would fail otherwise, on failure an
--   alternative parser can be used on the same input.
--   
--   <h1>Types for Stream Consumers</h1>
--   
--   In streamly, there is no separate type for accumulators. Terminating
--   folds are a superset of accumulators and to avoid too many types we
--   represent both using the same type, <a>Fold</a>.
--   
--   We do not club the leftovers functionality with terminating folds
--   because of the reasons explained earlier. Instead combinators that
--   require leftovers are implemented as the <a>Parser</a> type. This is a
--   sweet spot to balance ease of use, type safety and performance. Using
--   separate Accumulator and terminating fold types would encode more
--   information in types but it would make ease of use, implementation,
--   maintenance effort worse. Combining Accumulator, terminating folds and
--   Parser into a single <a>Parser</a> type would make ease of use even
--   better but type safety and performance worse.
--   
--   One of the design requirements that we have placed for better ease of
--   use and code reuse is that <a>Parser</a> type should be a strict
--   superset of the <a>Fold</a> type i.e. it can do everything that a
--   <a>Fold</a> can do and more. Therefore, folds can be easily upgraded
--   to parsers and we can use parser combinators on folds as well when
--   needed.
--   
--   <h1>Fold Design</h1>
--   
--   A fold is represented by a collection of "initial", "step" and
--   "extract" functions. The "initial" action generates the initial state
--   of the fold. The state is internal to the fold and maintains the
--   accumulated output. The "step" function is invoked using the current
--   state and the next input value and results in a <tt>Partial</tt> or
--   <tt>Done</tt>. A <tt>Partial</tt> returns the next intermediate state
--   of the fold, a <tt>Done</tt> indicates that the fold has terminated
--   and returns the final value of the accumulator.
--   
--   Every <tt>Partial</tt> indicates that a new accumulated output is
--   available. The accumulated output can be extracted from the state at
--   any point using "extract". "extract" can never fail. A fold returns a
--   valid output even without any input i.e. even if you call "extract" on
--   "initial" state it provides an output. This is not true for parsers.
--   
--   In general, "extract" is used in two cases:
--   
--   <ul>
--   <li>When the fold is used as a scan <tt>extract</tt> is called on the
--   intermediate state every time it is yielded by the fold, the resulting
--   value is yielded as a stream.</li>
--   <li>When the fold is used as a regular fold, <tt>extract</tt> is
--   called once when we are done feeding input to the fold.</li>
--   </ul>
--   
--   <h1>Alternate Designs</h1>
--   
--   An alternate and simpler design would be to return the intermediate
--   output via <tt>Partial</tt> along with the state, instead of using
--   "extract" on the yielded state and remove the extract function
--   altogether.
--   
--   This may even facilitate more efficient implementation. Extract from
--   the intermediate state after each yield may be more costly compared to
--   the fold step itself yielding the output. The fold may have more
--   efficient ways to retrieve the output rather than stuffing it in the
--   state and using extract on the state.
--   
--   However, removing extract altogether may lead to less optimal code in
--   some cases because the driver of the fold needs to thread around the
--   intermediate output to return it if the stream stops before the fold
--   could <tt>Done</tt>. When using this approach, the <tt>parseMany
--   (FL.take filesize)</tt> benchmark shows a 2x worse performance even
--   after ensuring everything fuses. So we keep the "extract" approach to
--   ensure better perf in all cases.
--   
--   But we could still yield both state and the output in
--   <tt>Partial</tt>, the output can be used for the scan use case,
--   instead of using extract. Extract would then be used only for the case
--   when the stream stops before the fold completes.
--   
--   <h1>Accumulators and Terminating Folds</h1>
--   
--   Folds in this module can be classified in two categories viz.
--   accumulators and terminating folds. Accumulators do not have a
--   terminating condition, they run forever and consume the entire stream,
--   for example the <a>length</a> fold. Terminating folds have a
--   terminating condition and can terminate without consuming the entire
--   stream, for example, the <a>head</a> fold.
--   
--   <h1>Monoids</h1>
--   
--   Monoids allow generalized, modular folding. The accumulators in this
--   module can be expressed using <a>mconcat</a> and a suitable
--   <a>Monoid</a>. Instead of writing folds we can write Monoids and turn
--   them into folds.
--   
--   <h1>Performance Notes</h1>
--   
--   <a>Prelude</a> module provides fold functions to directly fold streams
--   e.g. Streamly.Prelude/<a>sum</a> serves the same purpose as
--   Fold/<a>sum</a>. However, the functions in Streamly.Prelude cannot be
--   efficiently combined together e.g. we cannot drive the input stream
--   through <tt>sum</tt> and <tt>length</tt> fold functions
--   simultaneously. Using the <a>Fold</a> type we can efficiently split
--   the stream across multiple folds because it allows the compiler to
--   perform stream fusion optimizations.
module Streamly.Internal.Data.Fold.Type

-- | Represents the result of the <tt>step</tt> of a <tt>Fold</tt>.
--   <a>Partial</a> returns an intermediate state of the fold, the fold
--   step can be called again with the state or the driver can use
--   <tt>extract</tt> on the state to get the result out. <a>Done</a>
--   returns the final result and the fold cannot be driven further.
--   
--   <i>Pre-release</i>
data Step s b
Partial :: !s -> Step s b
Done :: !b -> Step s b

-- | The type <tt>Fold m a b</tt> having constructor <tt>Fold step initial
--   extract</tt> represents a fold over an input stream of values of type
--   <tt>a</tt> to a final value of type <tt>b</tt> in <a>Monad</a>
--   <tt>m</tt>.
--   
--   The fold uses an intermediate state <tt>s</tt> as accumulator, the
--   type <tt>s</tt> is internal to the specific fold definition. The
--   initial value of the fold state <tt>s</tt> is returned by
--   <tt>initial</tt>. The <tt>step</tt> function consumes an input and
--   either returns the final result <tt>b</tt> if the fold is done or the
--   next intermediate state (see <a>Step</a>). At any point the fold
--   driver can extract the result from the intermediate state using the
--   <tt>extract</tt> function.
--   
--   NOTE: The constructor is not yet exposed via exposed modules, smart
--   constructors are provided to create folds. If you think you need the
--   constructor of this type please consider using the smart constructors
--   in <a>Streamly.Internal.Data.Fold</a> instead.
--   
--   <i>since 0.8.0 (type changed)</i>
data Fold m a b

-- | <tt>Fold </tt> <tt> step </tt> <tt> initial </tt> <tt> extract</tt>
Fold :: (s -> a -> m (Step s b)) -> m (Step s b) -> (s -> m b) -> Fold m a b

-- | Make a fold from a left fold style pure step function and initial
--   value of the accumulator.
--   
--   If your <a>Fold</a> returns only <a>Partial</a> (i.e. never returns a
--   <a>Done</a>) then you can use <tt>foldl'*</tt> constructors.
--   
--   A fold with an extract function can be expressed using fmap:
--   
--   <pre>
--   mkfoldlx :: Monad m =&gt; (s -&gt; a -&gt; s) -&gt; s -&gt; (s -&gt; b) -&gt; Fold m a b
--   mkfoldlx step initial extract = fmap extract (foldl' step initial)
--   </pre>
--   
--   See also: <tt>Streamly.Prelude.foldl'</tt>
foldl' :: Monad m => (b -> a -> b) -> b -> Fold m a b

-- | Make a fold from a left fold style monadic step function and initial
--   value of the accumulator.
--   
--   A fold with an extract function can be expressed using rmapM:
--   
--   <pre>
--   mkFoldlxM :: Functor m =&gt; (s -&gt; a -&gt; m s) -&gt; m s -&gt; (s -&gt; m b) -&gt; Fold m a b
--   mkFoldlxM step initial extract = rmapM extract (foldlM' step initial)
--   </pre>
--   
--   See also: <tt>Streamly.Prelude.foldlM'</tt>
foldlM' :: Monad m => (b -> a -> m b) -> m b -> Fold m a b

-- | Make a strict left fold, for non-empty streams, using first element as
--   the starting value. Returns Nothing if the stream is empty.
--   
--   See also: <tt>Streamly.Prelude.foldl1'</tt>
--   
--   <i>Pre-release</i>
foldl1' :: Monad m => (a -> a -> a) -> Fold m a (Maybe a)

-- | Make a fold using a right fold style step function and a terminal
--   value. It performs a strict right fold via a left fold using function
--   composition. Note that this is strict fold, it can only be useful for
--   constructing strict structures in memory. For reductions this will be
--   very inefficient.
--   
--   For example,
--   
--   <pre>
--   toList = foldr (:) []
--   </pre>
--   
--   See also: <a>foldr</a>
foldr :: Monad m => (a -> b -> b) -> b -> Fold m a b

-- | Like <a>foldr</a> but with a monadic step function.
--   
--   For example,
--   
--   <pre>
--   toList = foldrM (\a xs -&gt; return $ a : xs) (return [])
--   </pre>
--   
--   See also: <a>foldrM</a>
--   
--   <i>Pre-release</i>
foldrM :: Monad m => (a -> b -> m b) -> m b -> Fold m a b

-- | Make a terminating fold using a pure step function, a pure initial
--   state and a pure state extraction function.
--   
--   <i>Pre-release</i>
mkFold :: Monad m => (s -> a -> Step s b) -> Step s b -> (s -> b) -> Fold m a b

-- | Similar to <a>mkFold</a> but the final state extracted is identical to
--   the intermediate state.
--   
--   <pre>
--   mkFold_ step initial = mkFold step initial id
--   </pre>
--   
--   <i>Pre-release</i>
mkFold_ :: Monad m => (b -> a -> Step b b) -> Step b b -> Fold m a b

-- | Make a terminating fold with an effectful step function and initial
--   state, and a state extraction function.
--   
--   <pre>
--   mkFoldM = Fold
--   </pre>
--   
--   We can just use <a>Fold</a> but it is provided for completeness.
--   
--   <i>Pre-release</i>
mkFoldM :: (s -> a -> m (Step s b)) -> m (Step s b) -> (s -> m b) -> Fold m a b

-- | Similar to <a>mkFoldM</a> but the final state extracted is identical
--   to the intermediate state.
--   
--   <pre>
--   mkFoldM_ step initial = mkFoldM step initial return
--   </pre>
--   
--   <i>Pre-release</i>
mkFoldM_ :: Monad m => (b -> a -> m (Step b b)) -> m (Step b b) -> Fold m a b

-- | A fold that always yields a pure value without consuming any input.
--   
--   <i>Pre-release</i>
fromPure :: Applicative m => b -> Fold m a b

-- | A fold that always yields the result of an effectful action without
--   consuming any input.
--   
--   <i>Pre-release</i>
fromEffect :: Applicative m => m b -> Fold m a b

-- | Make a fold from a consumer.
--   
--   <i>Internal</i>
fromRefold :: Refold m c a b -> c -> Fold m a b

-- | A fold that drains all its input, running the effects and discarding
--   the results.
--   
--   <pre>
--   drain = drainBy (const (return ()))
--   </pre>
drain :: Monad m => Fold m a ()

-- | Folds the input stream to a list.
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using
--   <a>Streamly.Data.Array.Foreign</a> instead.
--   
--   <pre>
--   toList = foldr (:) []
--   </pre>
toList :: Monad m => Fold m a [a]

-- | A fold that buffers its input to a pure stream.
--   
--   <pre>
--   &gt;&gt;&gt; toStreamK = foldr StreamK.cons StreamK.nil
--   
--   &gt;&gt;&gt; toStreamK = fmap StreamK.reverse Fold.toStreamKRev
--   </pre>
--   
--   <i>Internal</i>
toStreamK :: Monad m => Fold m a (Stream n a)

-- | Buffers the input stream to a pure stream in the reverse order of the
--   input.
--   
--   <pre>
--   &gt;&gt;&gt; toStreamKRev = Foldable.foldl' (flip StreamK.cons) StreamK.nil
--   </pre>
--   
--   This is more efficient than <a>toStreamK</a>. toStreamK has exactly
--   the same performance as reversing the stream after toStreamKRev.
--   
--   <i>Pre-release</i>
toStreamKRev :: Monad m => Fold m a (Stream n a)

-- | Map a monadic function on the output of a fold.
rmapM :: Monad m => (b -> m c) -> Fold m a b -> Fold m a c

-- | <tt>lmap f fold</tt> maps the function <tt>f</tt> on the input of the
--   fold.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.lmap (\x -&gt; x * x) Fold.sum) (Stream.enumerateFromTo 1 100)
--   338350
--   </pre>
--   
--   <pre>
--   lmap = Fold.lmapM return
--   </pre>
lmap :: (a -> b) -> Fold m b r -> Fold m a r

-- | <tt>lmapM f fold</tt> maps the monadic function <tt>f</tt> on the
--   input of the fold.
lmapM :: Monad m => (a -> m b) -> Fold m b r -> Fold m a r

-- | Include only those elements that pass a predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.filter (&gt; 5) Fold.sum) $ Stream.fromList [1..10]
--   40
--   </pre>
--   
--   <pre>
--   filter f = Fold.filterM (return . f)
--   </pre>
filter :: Monad m => (a -> Bool) -> Fold m a r -> Fold m a r

-- | Like <a>filter</a> but with a monadic predicate.
filterM :: Monad m => (a -> m Bool) -> Fold m a r -> Fold m a r

-- | Modify a fold to receive a <a>Maybe</a> input, the <a>Just</a> values
--   are unwrapped and sent to the original fold, <a>Nothing</a> values are
--   discarded.
catMaybes :: Monad m => Fold m a b -> Fold m (Maybe a) b

-- | Take at most <tt>n</tt> input elements and fold them using the
--   supplied fold. A negative count is treated as 0.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.take 2 Fold.toList) $ Stream.fromList [1..10]
--   [1,2]
--   </pre>
take :: Monad m => Int -> Fold m a b -> Fold m a b

-- | Sequential fold application. Apply two folds sequentially to an input
--   stream. The input is provided to the first fold, when it is done - the
--   remaining input is provided to the second fold. When the second fold
--   is done or if the input stream is over, the outputs of the two folds
--   are combined using the supplied function.
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.serialWith (,) (Fold.take 8 Fold.toList) (Fold.takeEndBy (== '\n') Fold.toList)
--   
--   &gt;&gt;&gt; Stream.fold f $ Stream.fromList "header: hello\n"
--   ("header: ","hello\n")
--   </pre>
--   
--   Note: This is dual to appending streams using <a>serial</a>.
--   
--   Note: this implementation allows for stream fusion but has quadratic
--   time complexity, because each composition adds a new branch that each
--   subsequent fold's input element has to traverse, therefore, it cannot
--   scale to a large number of compositions. After around 100 compositions
--   the performance starts dipping rapidly compared to a CPS style
--   implementation.
--   
--   <i>Time: O(n^2) where n is the number of compositions.</i>
serialWith :: Monad m => (a -> b -> c) -> Fold m x a -> Fold m x b -> Fold m x c

-- | Same as applicative <a>*&gt;</a>. Run two folds serially one after the
--   other discarding the result of the first.
--   
--   This was written in the hope that it might be faster than implementing
--   it using serialWith, but the current benchmarks show that it has the
--   same performance. So do not expose it unless some benchmark shows
--   benefit.
serial_ :: Monad m => Fold m x a -> Fold m x b -> Fold m x b

-- | <tt>teeWith k f1 f2</tt> distributes its input to both <tt>f1</tt> and
--   <tt>f2</tt> until both of them terminate and combines their output
--   using <tt>k</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; avg = Fold.teeWith (/) Fold.sum (fmap fromIntegral Fold.length)
--   
--   &gt;&gt;&gt; Stream.fold avg $ Stream.fromList [1.0..100.0]
--   50.5
--   </pre>
--   
--   <pre>
--   teeWith k f1 f2 = fmap (uncurry k) ((Fold.tee f1 f2)
--   </pre>
--   
--   For applicative composition using this combinator see
--   <a>Streamly.Internal.Data.Fold.Tee</a>.
--   
--   See also: <a>Streamly.Internal.Data.Fold.Tee</a>
teeWith :: Monad m => (a -> b -> c) -> Fold m x a -> Fold m x b -> Fold m x c

-- | Like <a>teeWith</a> but terminates as soon as the first fold
--   terminates.
--   
--   <i>Pre-release</i>
teeWithFst :: Monad m => (b -> c -> d) -> Fold m a b -> Fold m a c -> Fold m a d

-- | Like <a>teeWith</a> but terminates as soon as any one of the two folds
--   terminates.
--   
--   <i>Pre-release</i>
teeWithMin :: Monad m => (b -> c -> d) -> Fold m a b -> Fold m a c -> Fold m a d

-- | Shortest alternative. Apply both folds in parallel but choose the
--   result from the one which consumed least input i.e. take the shortest
--   succeeding fold.
--   
--   If both the folds finish at the same time or if the result is
--   extracted before any of the folds could finish then the left one is
--   taken.
--   
--   <i>Pre-release</i>
shortest :: Monad m => Fold m x a -> Fold m x b -> Fold m x (Either a b)

-- | Longest alternative. Apply both folds in parallel but choose the
--   result from the one which consumed more input i.e. take the longest
--   succeeding fold.
--   
--   If both the folds finish at the same time or if the result is
--   extracted before any of the folds could finish then the left one is
--   taken.
--   
--   <i>Pre-release</i>
longest :: Monad m => Fold m x a -> Fold m x b -> Fold m x (Either a b)
data ManyState s1 s2

-- | Collect zero or more applications of a fold. <tt>many split
--   collect</tt> applies the <tt>split</tt> fold repeatedly on the input
--   stream and accumulates zero or more fold results using
--   <tt>collect</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; two = Fold.take 2 Fold.toList
--   
--   &gt;&gt;&gt; twos = Fold.many two Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold twos $ Stream.fromList [1..10]
--   [[1,2],[3,4],[5,6],[7,8],[9,10]]
--   </pre>
--   
--   Stops when <tt>collect</tt> stops.
--   
--   See also: <a>concatMap</a>, <a>foldMany</a>
many :: Monad m => Fold m a b -> Fold m b c -> Fold m a c

-- | Like many, but inner fold emits an output at the end even if no input
--   is received.
--   
--   <i>Internal</i>
--   
--   <i>See also: <a>concatMap</a>, <a>foldMany</a></i>
manyPost :: Monad m => Fold m a b -> Fold m b c -> Fold m a c

-- | <tt>chunksOf n split collect</tt> repeatedly applies the
--   <tt>split</tt> fold to chunks of <tt>n</tt> items in the input stream
--   and supplies the result to the <tt>collect</tt> fold.
--   
--   <pre>
--   &gt;&gt;&gt; twos = Fold.chunksOf 2 Fold.toList Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold twos $ Stream.fromList [1..10]
--   [[1,2],[3,4],[5,6],[7,8],[9,10]]
--   </pre>
--   
--   <pre>
--   chunksOf n split = many (take n split)
--   </pre>
--   
--   Stops when <tt>collect</tt> stops.
chunksOf :: Monad m => Int -> Fold m a b -> Fold m b c -> Fold m a c

-- | Like <a>many</a> but uses a <a>Refold</a> for collecting.
refoldMany :: Monad m => Fold m a b -> Refold m x b c -> Refold m x a c

-- | Like <a>many</a> but uses a <a>Refold</a> for splitting.
--   
--   <i>Internal</i>
refoldMany1 :: Monad m => Refold m x a b -> Fold m b c -> Refold m x a c

-- | Extract the output of a fold and refold it using a <a>Refold</a>.
--   
--   <i>Internal</i>
refold :: Monad m => Fold m a b -> Refold m b a b -> Fold m a b

-- | Map a <a>Fold</a> returning function on the result of a <a>Fold</a>
--   and run the returned fold. This operation can be used to express data
--   dependencies between fold operations.
--   
--   Let's say the first element in the stream is a count of the following
--   elements that we have to add, then:
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Maybe (fromJust)
--   
--   &gt;&gt;&gt; count = fmap fromJust Fold.head
--   
--   &gt;&gt;&gt; total n = Fold.take n Fold.sum
--   
--   &gt;&gt;&gt; Stream.fold (Fold.concatMap total count) $ Stream.fromList [10,9..1]
--   45
--   </pre>
--   
--   <i>Time: O(n^2) where <tt>n</tt> is the number of compositions.</i>
--   
--   See also: <a>foldIterateM</a>
concatMap :: Monad m => (b -> Fold m a c) -> Fold m a b -> Fold m a c

-- | Run the initialization effect of a fold. The returned fold would use
--   the value returned by this effect as its initial value.
--   
--   <i>Pre-release</i>
initialize :: Monad m => Fold m a b -> m (Fold m a b)

-- | Append a singleton value to the fold.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Data.Foldable as Foldable
--   
--   &gt;&gt;&gt; Foldable.foldlM Fold.snoc Fold.toList [1..3] &gt;&gt;= Fold.finish
--   [1,2,3]
--   </pre>
--   
--   Compare with <a>duplicate</a> which allows appending a stream to the
--   fold.
--   
--   <i>Pre-release</i>
snoc :: Monad m => Fold m a b -> a -> m (Fold m a b)

-- | <a>duplicate</a> provides the ability to run a fold in parts. The
--   duplicated fold consumes the input and returns the same fold as output
--   instead of returning the final result, the returned fold can be run
--   later to consume more input.
--   
--   We can append a stream to a fold as follows:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   foldAppend :: Monad m =&gt; Fold m a b -&gt; SerialT m a -&gt; m (Fold m a b)
--   foldAppend f = Stream.fold (Fold.duplicate f)
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   do
--    sum1 &lt;- foldAppend Fold.sum (Stream.enumerateFromTo 1 10)
--    sum2 &lt;- foldAppend sum1 (Stream.enumerateFromTo 11 20)
--    Stream.fold sum2 (Stream.enumerateFromTo 21 30)
--   :}
--   465
--   </pre>
--   
--   <a>duplicate</a> essentially appends a stream to the fold without
--   finishing the fold. Compare with <a>snoc</a> which appends a singleton
--   value to the fold.
--   
--   <i>Pre-release</i>
duplicate :: Monad m => Fold m a b -> Fold m a (Fold m a b)

-- | Finish the fold to extract the current value of the fold.
--   
--   <pre>
--   &gt;&gt;&gt; Fold.finish Fold.toList
--   []
--   </pre>
--   
--   <i>Pre-release</i>
finish :: Monad m => Fold m a b -> m b
instance (GHC.Show.Show a, GHC.Show.Show b) => GHC.Show.Show (Streamly.Internal.Data.Fold.Type.Tuple'Fused a b)
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Fold.Type.Fold m a)


-- | Continuation passing style (CPS) stream implementation. The symbol
--   <tt>K</tt> below denotes a function as well as a Kontinuation.
--   
--   <pre>
--   import qualified Streamly.Internal.Data.Stream.StreamK as K
--   </pre>
module Streamly.Internal.Data.Stream.StreamK

-- | The type <tt>Stream m a</tt> represents a monadic stream of values of
--   type <tt>a</tt> constructed using actions in monad <tt>m</tt>. It uses
--   stop, singleton and yield continuations equivalent to the following
--   direct style type:
--   
--   <pre>
--   data Stream m a = Stop | Singleton a | Yield a (Stream m a)
--   </pre>
--   
--   To facilitate parallel composition we maintain a local state in an
--   <tt>SVar</tt> that is shared across and is used for synchronization of
--   the streams being composed.
--   
--   The singleton case can be expressed in terms of stop and yield but we
--   have it as a separate case to optimize composition operations for
--   streams with single element. We build singleton streams in the
--   implementation of <a>pure</a> for Applicative and Monad, and in
--   <a>lift</a> for MonadTrans.
newtype Stream m a
MkStream :: (forall r. State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> m r) -> Stream m a
mkStream :: (forall r. State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> m r) -> Stream m a

-- | An empty stream.
--   
--   <pre>
--   &gt; toList nil
--   []
--   </pre>
nil :: Stream m a

-- | An empty stream producing a side effect.
--   
--   <pre>
--   &gt; toList (nilM (print "nil"))
--   "nil"
--   []
--   </pre>
--   
--   <i>Pre-release</i>
nilM :: Applicative m => m b -> Stream m a

-- | Construct a stream by adding a pure value at the head of an existing
--   stream. For serial streams this is the same as <tt>(return a) `consM`
--   r</tt> but more efficient. For concurrent streams this is not
--   concurrent whereas <a>consM</a> is concurrent. For example:
--   
--   <pre>
--   &gt; toList $ 1 `cons` 2 `cons` 3 `cons` nil
--   [1,2,3]
--   </pre>
cons :: a -> Stream m a -> Stream m a
infixr 5 `cons`

-- | Operator equivalent of <a>cons</a>.
--   
--   <pre>
--   &gt; toList $ 1 .: 2 .: 3 .: nil
--   [1,2,3]
--   </pre>
(.:) :: a -> Stream m a -> Stream m a
infixr 5 .:

-- | Fold a stream by providing a State, stop continuation, a singleton
--   continuation and a yield continuation. The stream will not use the
--   SVar passed via State.
foldStream :: State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> Stream m a -> m r

-- | Fold a stream by providing an SVar, a stop continuation, a singleton
--   continuation and a yield continuation. The stream would share the
--   current SVar passed via the State.
foldStreamShared :: State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> Stream m a -> m r

-- | Detach a stream from an SVar
unShare :: Stream m a -> Stream m a
uncons :: Applicative m => Stream m a -> m (Maybe (a, Stream m a))
unfoldr :: (b -> Maybe (a, b)) -> b -> Stream m a
unfoldrM :: Monad m => (b -> m (Maybe (a, b))) -> b -> Stream m a

-- | Generate an infinite stream by repeating a pure value.
--   
--   <i>Pre-release</i>
repeat :: a -> Stream m a
repeatM :: Monad m => m a -> Stream m a
replicate :: Int -> a -> Stream m a
replicateM :: Monad m => Int -> m a -> Stream m a
fromIndices :: (Int -> a) -> Stream m a
fromIndicesM :: Monad m => (Int -> m a) -> Stream m a
iterate :: (a -> a) -> a -> Stream m a
iterateM :: Monad m => (a -> m a) -> m a -> Stream m a
fromPure :: a -> Stream m a
fromEffect :: Monad m => m a -> Stream m a

-- | <pre>
--   fromFoldable = <a>foldr</a> <a>cons</a> <a>nil</a>
--   </pre>
--   
--   Construct a stream from a <a>Foldable</a> containing pure values:
fromFoldable :: Foldable f => f a -> Stream m a
fromList :: [a] -> Stream m a

-- | Lazy right associative fold to a stream.
foldrS :: (a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
foldrSM :: Monad m => (m a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
buildS :: ((a -> Stream m a -> Stream m a) -> Stream m a -> Stream m a) -> Stream m a
augmentS :: ((a -> Stream m a -> Stream m a) -> Stream m a -> Stream m a) -> Stream m a -> Stream m a

-- | Lazy right associative fold.
foldr :: Monad m => (a -> b -> b) -> b -> Stream m a -> m b
foldr1 :: Monad m => (a -> a -> a) -> Stream m a -> m (Maybe a)

-- | Lazy right fold with a monadic step function.
foldrM :: (a -> m b -> m b) -> m b -> Stream m a -> m b

-- | Right associative fold to an arbitrary transformer monad.
foldrT :: (Monad m, Monad (s m), MonadTrans s) => (a -> s m b -> s m b) -> s m b -> Stream m a -> s m b

-- | Strict left associative fold.
foldl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> m b

-- | Like <a>foldl'</a> but with a monadic step function.
foldlM' :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> m b

-- | Lazy left fold to a stream.
foldlS :: (Stream m b -> a -> Stream m b) -> Stream m b -> Stream m a -> Stream m b

-- | Lazy left fold to an arbitrary transformer monad.
foldlT :: (Monad m, Monad (s m), MonadTrans s) => (s m b -> a -> s m b) -> s m b -> Stream m a -> s m b

-- | Strict left fold with an extraction function. Like the standard strict
--   left fold, but applies a user supplied extraction function (the third
--   argument) to the folded value at the end. This is designed to work
--   with the <tt>foldl</tt> library. The suffix <tt>x</tt> is a mnemonic
--   for extraction.
--   
--   Note that the accumulator is always evaluated including the initial
--   value.
foldlx' :: forall m a b x. Monad m => (x -> a -> x) -> x -> (x -> b) -> Stream m a -> m b

-- | Like <tt>foldx</tt>, but with a monadic step function.
foldlMx' :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> Stream m a -> m b
fold :: Monad m => Fold m a b -> Stream m a -> m b

-- | <pre>
--   drain = foldl' (\_ _ -&gt; ()) ()
--   drain = mapM_ (\_ -&gt; return ())
--   </pre>
drain :: Monad m => Stream m a -> m ()
null :: Monad m => Stream m a -> m Bool
head :: Monad m => Stream m a -> m (Maybe a)
tail :: Applicative m => Stream m a -> m (Maybe (Stream m a))
init :: Applicative m => Stream m a -> m (Maybe (Stream m a))
elem :: (Monad m, Eq a) => a -> Stream m a -> m Bool
notElem :: (Monad m, Eq a) => a -> Stream m a -> m Bool
all :: Monad m => (a -> Bool) -> Stream m a -> m Bool
any :: Monad m => (a -> Bool) -> Stream m a -> m Bool

-- | Extract the last element of the stream, if any.
last :: Monad m => Stream m a -> m (Maybe a)
minimum :: (Monad m, Ord a) => Stream m a -> m (Maybe a)
minimumBy :: Monad m => (a -> a -> Ordering) -> Stream m a -> m (Maybe a)
maximum :: (Monad m, Ord a) => Stream m a -> m (Maybe a)
maximumBy :: Monad m => (a -> a -> Ordering) -> Stream m a -> m (Maybe a)
findIndices :: (a -> Bool) -> Stream m a -> Stream m Int
lookup :: (Monad m, Eq a) => a -> Stream m (a, b) -> m (Maybe b)
findM :: Monad m => (a -> m Bool) -> Stream m a -> m (Maybe a)
find :: Monad m => (a -> Bool) -> Stream m a -> m (Maybe a)
(!!) :: Monad m => Stream m a -> Int -> m (Maybe a)

-- | Apply a monadic action to each element of the stream and discard the
--   output of the action.
mapM_ :: Monad m => (a -> m b) -> Stream m a -> m ()
toList :: Monad m => Stream m a -> m [a]
hoist :: (Monad m, Monad n) => (forall x. m x -> n x) -> Stream m a -> Stream n a
scanl' :: (b -> a -> b) -> b -> Stream m a -> Stream m b
scanlx' :: (x -> a -> x) -> x -> (x -> b) -> Stream m a -> Stream m b
filter :: (a -> Bool) -> Stream m a -> Stream m a
take :: Int -> Stream m a -> Stream m a
takeWhile :: (a -> Bool) -> Stream m a -> Stream m a
drop :: Int -> Stream m a -> Stream m a
dropWhile :: (a -> Bool) -> Stream m a -> Stream m a
map :: (a -> b) -> Stream m a -> Stream m b
mapM :: Monad m => (a -> m b) -> Stream m a -> Stream m b
sequence :: Monad m => Stream m (m a) -> Stream m a
intersperseM :: Monad m => m a -> Stream m a -> Stream m a
intersperse :: Monad m => a -> Stream m a -> Stream m a
insertBy :: (a -> a -> Ordering) -> a -> Stream m a -> Stream m a
deleteBy :: (a -> a -> Bool) -> a -> Stream m a -> Stream m a
reverse :: Stream m a -> Stream m a
mapMaybe :: (a -> Maybe b) -> Stream m a -> Stream m b

-- | Zip two streams serially using a pure zipping function.
zipWith :: (a -> b -> c) -> Stream m a -> Stream m b -> Stream m c

-- | Zip two streams serially using a monadic zipping function.
zipWithM :: Monad m => (a -> b -> m c) -> Stream m a -> Stream m b -> Stream m c
mergeBy :: (a -> a -> Ordering) -> Stream m a -> Stream m a -> Stream m a
mergeByM :: Monad m => (a -> a -> m Ordering) -> Stream m a -> Stream m a -> Stream m a

-- | Perform a <a>concatMap</a> using a specified concat strategy. The
--   first argument specifies a merge or concat function that is used to
--   merge the streams generated by the map function. For example, the
--   concat function could be <a>serial</a>, <tt>parallel</tt>,
--   <tt>async</tt>, <tt>ahead</tt> or any other zip or merge function.
concatMapWith :: (Stream m b -> Stream m b -> Stream m b) -> (a -> Stream m b) -> Stream m a -> Stream m b
concatMap :: (a -> Stream m b) -> Stream m a -> Stream m b
bindWith :: (Stream m b -> Stream m b -> Stream m b) -> Stream m a -> (a -> Stream m b) -> Stream m b

-- | See <a>concatPairsWith</a> for documentation.
concatPairsWith :: (Stream m b -> Stream m b -> Stream m b) -> (a -> Stream m b) -> Stream m a -> Stream m b
apWith :: (Stream m b -> Stream m b -> Stream m b) -> Stream m (a -> b) -> Stream m a -> Stream m b
apSerial :: Stream m (a -> b) -> Stream m a -> Stream m b
apSerialDiscardFst :: Stream m a -> Stream m b -> Stream m b
apSerialDiscardSnd :: Stream m a -> Stream m b -> Stream m a
the :: (Eq a, Monad m) => Stream m a -> m (Maybe a)

-- | Appends two streams sequentially, yielding all elements from the first
--   stream, and then all elements from the second stream.
serial :: Stream m a -> Stream m a -> Stream m a
infixr 6 `serial`
consM :: Monad m => m a -> Stream m a -> Stream m a
infixr 5 `consM`
withLocal :: MonadReader r m => (r -> r) -> Stream m a -> Stream m a
mfix :: Monad m => (m a -> Stream m a) -> Stream m a


-- | The <a>Sink</a> type is a just a special case of <a>Fold</a> and we
--   can do without it. However, in some cases <a>Sink</a> is a simpler
--   type and may provide better performance than <a>Fold</a> because it
--   does not maintain any state. Folds can be used for both pure and
--   monadic computations. Sinks are not applicable to pure computations.
module Streamly.Internal.Data.Sink

-- | A <a>Sink</a> is a special type of <tt>Fold</tt> that does not
--   accumulate any value, but runs only effects. A <a>Sink</a> has no
--   state to maintain therefore can be a bit more efficient than a
--   <tt>Fold</tt> with <tt>()</tt> as the state, especially when
--   <a>Sink</a>s are composed with other operations. A Sink can be
--   upgraded to a <tt>Fold</tt>, but a <tt>Fold</tt> cannot be converted
--   into a Sink.
newtype Sink m a
Sink :: (a -> m ()) -> Sink m a

-- | Convert a <a>Sink</a> to a <a>Fold</a>. When you want to compose sinks
--   and folds together, upgrade a sink to a fold before composing.
toFold :: Monad m => Sink m a -> Fold m a ()

-- | Distribute one copy each of the input to both the sinks.
--   
--   <pre>
--                   |-------Sink m a
--   ---stream m a---|
--                   |-------Sink m a
--   </pre>
--   
--   <pre>
--   &gt; let pr x = Sink.drainM (putStrLn . ((x ++ " ") ++) . show)
--   &gt; sink (Sink.tee (pr "L") (pr "R")) (S.enumerateFromTo 1 2)
--   L 1
--   R 1
--   L 2
--   R 2
--   </pre>
tee :: Monad m => Sink m a -> Sink m a -> Sink m a

-- | Distribute copies of the input to all the sinks in a container.
--   
--   <pre>
--                   |-------Sink m a
--   ---stream m a---|
--                   |-------Sink m a
--                   |
--                         ...
--   </pre>
--   
--   <pre>
--   &gt; let pr x = Sink.drainM (putStrLn . ((x ++ " ") ++) . show)
--   &gt; sink (Sink.distribute [(pr "L"), (pr "R")]) (S.enumerateFromTo 1 2)
--   L 1
--   R 1
--   L 2
--   R 2
--   </pre>
--   
--   This is the consumer side dual of the producer side <a>sequence_</a>
--   operation.
distribute :: Monad m => [Sink m a] -> Sink m a

-- | Demultiplex to multiple consumers without collecting the results.
--   Useful to run different effectful computations depending on the value
--   of the stream elements, for example handling network packets of
--   different types using different handlers.
--   
--   <pre>
--                               |-------Sink m a
--   -----stream m a-----Map-----|
--                               |-------Sink m a
--                               |
--                                         ...
--   </pre>
--   
--   <pre>
--   &gt; let pr x = Sink.drainM (putStrLn . ((x ++ " ") ++) . show)
--   &gt; let table = Data.Map.fromList [(1, pr "One"), (2, pr "Two")]
--     in Sink.sink (Sink.demux id table) (S.enumerateFromTo 1 100)
--   One 1
--   Two 2
--   </pre>
demux :: (Monad m, Ord k) => Map k (Sink m a) -> Sink m (a, k)

-- | Split elements in the input stream into two parts using a monadic
--   unzip function, direct each part to a different sink.
--   
--   <pre>
--                             |-------Sink m b
--   -----Stream m a----(b,c)--|
--                             |-------Sink m c
--   </pre>
--   
--   <pre>
--   &gt; let pr x = Sink.drainM (putStrLn . ((x ++ " ") ++) . show)
--     in Sink.sink (Sink.unzip return (pr "L") (pr "R")) (S.fromPure (1,2))
--   L 1
--   R 2
--   </pre>
unzipM :: Monad m => (a -> m (b, c)) -> Sink m b -> Sink m c -> Sink m a

-- | Same as <a>unzipM</a> but with a pure unzip function.
unzip :: Monad m => (a -> (b, c)) -> Sink m b -> Sink m c -> Sink m a

-- | Map a pure function on the input of a <a>Sink</a>.
lmap :: (a -> b) -> Sink m b -> Sink m a

-- | Map a monadic function on the input of a <a>Sink</a>.
lmapM :: Monad m => (a -> m b) -> Sink m b -> Sink m a

-- | Filter the input of a <a>Sink</a> using a pure predicate function.
lfilter :: Monad m => (a -> Bool) -> Sink m a -> Sink m a

-- | Filter the input of a <a>Sink</a> using a monadic predicate function.
lfilterM :: Monad m => (a -> m Bool) -> Sink m a -> Sink m a

-- | Drain all input, running the effects and discarding the results.
drain :: Monad m => Sink m a

-- | <pre>
--   drainM f = lmapM f drain
--   </pre>
--   
--   Drain all input after passing it through a monadic function.
drainM :: Monad m => (a -> m b) -> Sink m a


-- | Streaming and backtracking parsers.
--   
--   Parsers just extend folds. Please read the <a>Fold</a> design notes in
--   <a>Streamly.Internal.Data.Fold.Type</a> for background on the design.
--   
--   <h1>Parser Design</h1>
--   
--   The <a>Parser</a> type or a parsing fold is a generalization of the
--   <a>Fold</a> type. The <a>Fold</a> type <i>always</i> succeeds on each
--   input. Therefore, it does not need to buffer the input. In contrast, a
--   <a>Parser</a> may fail and backtrack to replay the input again to
--   explore another branch of the parser. Therefore, it needs to buffer
--   the input. Therefore, a <a>Parser</a> is a fold with some additional
--   requirements. To summarize, unlike a <a>Fold</a>, a <a>Parser</a>:
--   
--   <ol>
--   <li>may not generate a new value of the accumulator on every input, it
--   may generate a new accumulator only after consuming multiple input
--   elements (e.g. takeEQ).</li>
--   <li>on success may return some unconsumed input (e.g. takeWhile)</li>
--   <li>may fail and return all input without consuming it (e.g.
--   satisfy)</li>
--   <li>backtrack and start inspecting the past input again (e.g.
--   alt)</li>
--   </ol>
--   
--   These use cases require buffering and replaying of input. To
--   facilitate this, the step function of the <a>Fold</a> is augmented to
--   return the next state of the fold along with a command tag using a
--   <a>Step</a> functor, the tag tells the fold driver to manipulate the
--   future input as the parser wishes. The <a>Step</a> functor provides
--   the following commands to the fold driver corresponding to the use
--   cases outlined in the previous para:
--   
--   <ol>
--   <li><a>Continue</a>: buffer the current input and optionally go back
--   to a previous position in the stream</li>
--   <li><a>Partial</a>: buffer the current input and optionally go back to
--   a previous position in the stream, drop the buffer before that
--   position.</li>
--   <li><a>Done</a>: parser succeeded, returns how much input was
--   leftover</li>
--   <li><a>Error</a>: indicates that the parser has failed without a
--   result</li>
--   </ol>
--   
--   <h1>How a Parser Works?</h1>
--   
--   A parser is just like a fold, it keeps consuming inputs from the
--   stream and accumulating them in an accumulator. The accumulator of the
--   parser could be a singleton value or it could be a collection of
--   values e.g. a list.
--   
--   The parser may build a new output value from multiple input items.
--   When it consumes an input item but needs more input to build a
--   complete output item it uses <tt>Continue 0 s</tt>, yielding the
--   intermediate state <tt>s</tt> and asking the driver to provide more
--   input. When the parser determines that a new output value is complete
--   it can use a <tt>Done n b</tt> to terminate the parser with <tt>n</tt>
--   items of input unused and the final value of the accumulator returned
--   as <tt>b</tt>. If at any time the parser determines that the parse has
--   failed it can return <tt>Error err</tt>.
--   
--   A parser building a collection of values (e.g. a list) can use the
--   <tt>Partial</tt> constructor whenever a new item in the output
--   collection is generated. If a parser building a collection of values
--   has yielded at least one value then it considered successful and
--   cannot fail after that. In the current implementation, this is not
--   automatically enforced, there is a rule that the parser MUST use only
--   <tt>Done</tt> for termination after the first <tt>Partial</tt>, it
--   cannot use <tt>Error</tt>. It may be possible to change the
--   implementation so that this rule is not required, but there may be
--   some performance cost to it.
--   
--   <a>takeWhile</a> and <a>some</a> combinators are good examples of
--   efficient implementations using all features of this representation.
--   It is possible to idiomatically build a collection of parsed items
--   using a singleton parser and <tt>Alternative</tt> instance instead of
--   using a multi-yield parser. However, this implementation is amenable
--   to stream fusion and can therefore be much faster.
--   
--   <h1>Error Handling</h1>
--   
--   When a parser's <tt>step</tt> function is invoked it may terminate by
--   either a <a>Done</a> or an <a>Error</a> return value. In an
--   <a>Alternative</a> composition an error return can make the composed
--   parser backtrack and try another parser.
--   
--   If the stream stops before a parser could terminate then we use the
--   <tt>extract</tt> function of the parser to retrieve the last yielded
--   value of the parser. If the parser has yielded at least one value then
--   <tt>extract</tt> MUST return a value without throwing an error,
--   otherwise it uses the <a>ParseError</a> exception to throw an error.
--   
--   We chose the exception throwing mechanism for <tt>extract</tt> instead
--   of using an explicit error return via an <a>Either</a> type for
--   keeping the interface simple as most of the time we do not need to
--   catch the error in intermediate layers. Note that we cannot use
--   exception throwing mechanism in <tt>step</tt> function because of
--   performance reasons. <a>Error</a> constructor in that case allows loop
--   fusion and better performance.
--   
--   <h1>Future Work</h1>
--   
--   It may make sense to move "takeWhile" type of parsers, which cannot
--   fail but need some lookahead, to splitting folds. This will allow such
--   combinators to be accepted where we need an unfailing <a>Fold</a>
--   type.
--   
--   Based on application requirements it should be possible to design even
--   a richer interface to manipulate the input stream/buffer. For example,
--   we could randomly seek into the stream in the forward or reverse
--   directions or we can even seek to the end or from the end or seek from
--   the beginning.
--   
--   We can distribute and scan/parse a stream using both folds and parsers
--   and merge the resulting streams using different merge strategies (e.g.
--   interleaving or serial).
module Streamly.Internal.Data.Parser.ParserD.Type

-- | The type of a <tt>Parser'</tt>s initial action.
--   
--   <i>Internal</i>
data Initial s b

-- | Wait for step function to be called with state <tt>s</tt>.
IPartial :: !s -> Initial s b

-- | Return a result right away without an input.
IDone :: !b -> Initial s b

-- | Return an error right away without an input.
IError :: String -> Initial s b

-- | The return type of a <a>Parser</a> step.
--   
--   The parse operation feeds the input stream to the parser one element
--   at a time, representing a parse <a>Step</a>. The parser may or may not
--   consume the item and returns a result. If the result is <a>Partial</a>
--   we can either extract the result or feed more input to the parser. If
--   the result is <a>Continue</a>, we must feed more input in order to get
--   a result. If the parser returns <a>Done</a> then the parser can no
--   longer take any more input.
--   
--   If the result is <a>Continue</a>, the parse operation retains the
--   input in a backtracking buffer, in case the parser may ask to
--   backtrack in future. Whenever a 'Partial n' result is returned we
--   first backtrack by <tt>n</tt> elements in the input and then release
--   any remaining backtracking buffer. Similarly, 'Continue n' backtracks
--   to <tt>n</tt> elements before the current position and starts feeding
--   the input from that point for future invocations of the parser.
--   
--   If parser is not yet done, we can use the <tt>extract</tt> operation
--   on the <tt>state</tt> of the parser to extract a result. If the parser
--   has not yet yielded a result, the operation fails with a
--   <a>ParseError</a> exception. If the parser yielded a <a>Partial</a>
--   result in the past the last partial result is returned. Therefore, if
--   a parser yields a partial result once it cannot fail later on.
--   
--   The parser can never backtrack beyond the position where the last
--   partial result left it at. The parser must ensure that the backtrack
--   position is always after that.
--   
--   <i>Pre-release</i>
data Step s b

-- | Partial result with an optional backtrack request.
--   
--   <tt>Partial count state</tt> means a partial result is available which
--   can be extracted successfully, <tt>state</tt> is the opaque state of
--   the parser to be supplied to the next invocation of the step
--   operation. The current input position is reset to <tt>count</tt>
--   elements back and any input before that is dropped from the backtrack
--   buffer.
Partial :: Int -> s -> Step s b

-- | Need more input with an optional backtrack request.
--   
--   <tt>Continue count state</tt> means the parser has consumed the
--   current input but no new result is generated, <tt>state</tt> is the
--   next state of the parser. The current input is retained in the
--   backtrack buffer and the input position is reset to <tt>count</tt>
--   elements back.
Continue :: Int -> s -> Step s b

-- | Done with leftover input count and result.
--   
--   <tt>Done count result</tt> means the parser has finished, it will
--   accept no more input, last <tt>count</tt> elements from the input are
--   unused and the result of the parser is in <tt>result</tt>.
Done :: Int -> b -> Step s b

-- | Parser failed without generating any output.
--   
--   The parsing operation may backtrack to the beginning and try another
--   alternative.
Error :: String -> Step s b

-- | A parser is a fold that can fail and is represented as <tt>Parser step
--   initial extract</tt>. Before we drive a parser we call the
--   <tt>initial</tt> action to retrieve the initial state of the fold. The
--   parser driver invokes <tt>step</tt> with the state returned by the
--   previous step and the next input element. It results into a new state
--   and a command to the driver represented by <a>Step</a> type. The
--   driver keeps invoking the step function until it stops or fails. At
--   any point of time the driver can call <tt>extract</tt> to inspect the
--   result of the fold. If the parser hits the end of input
--   <tt>extract</tt> is called. It may result in an error or an output
--   value.
--   
--   <i>Pre-release</i>
data Parser m a b
Parser :: (s -> a -> m (Step s b)) -> m (Initial s b) -> (s -> m b) -> Parser m a b

-- | This exception is used for two purposes:
--   
--   <ul>
--   <li>When a parser ultimately fails, the user of the parser is
--   intimated via this exception.</li>
--   <li>When the "extract" function of a parser needs to throw an
--   error.</li>
--   </ul>
--   
--   <i>Pre-release</i>
newtype ParseError
ParseError :: String -> ParseError

-- | Map a monadic function on the output of a parser.
--   
--   <i>Pre-release</i>
rmapM :: Monad m => (b -> m c) -> Parser m a b -> Parser m a c

-- | See <a>fromPure</a>.
--   
--   <i>Pre-release</i>
fromPure :: Monad m => b -> Parser m a b

-- | See <a>fromEffect</a>.
--   
--   <i>Pre-release</i>
fromEffect :: Monad m => m b -> Parser m a b

-- | See <a>serialWith</a>.
--   
--   Note: this implementation of serialWith is fast because of stream
--   fusion but has quadratic time complexity, because each composition
--   adds a new branch that each subsequent parse's input element has to go
--   through, therefore, it cannot scale to a large number of compositions.
--   After around 100 compositions the performance starts dipping rapidly
--   beyond a CPS style unfused implementation.
--   
--   <i>Pre-release</i>
serialWith :: MonadThrow m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>split_</a>.
--   
--   <i>Pre-release</i>
split_ :: MonadThrow m => Parser m x a -> Parser m x b -> Parser m x b

-- | See <a>die</a>.
--   
--   <i>Pre-release</i>
die :: MonadThrow m => String -> Parser m a b

-- | See <a>dieM</a>.
--   
--   <i>Pre-release</i>
dieM :: MonadThrow m => m String -> Parser m a b

-- | See documentation of <a>some</a>.
--   
--   <i>Pre-release</i>
splitSome :: MonadCatch m => Parser m a b -> Fold m b c -> Parser m a c

-- | See documentation of <a>many</a>.
--   
--   <i>Pre-release</i>
splitMany :: MonadCatch m => Parser m a b -> Fold m b c -> Parser m a c

-- | Like splitMany, but inner fold emits an output at the end even if no
--   input is received.
--   
--   <i>Internal</i>
splitManyPost :: MonadCatch m => Parser m a b -> Fold m b c -> Parser m a c

-- | See <a>alt</a>.
--   
--   <i>Pre-release</i>
alt :: Monad m => Parser m x a -> Parser m x a -> Parser m x a

-- | See <a>concatMap</a>.
--   
--   <i>Pre-release</i>
concatMap :: MonadThrow m => (b -> Parser m a c) -> Parser m a b -> Parser m a c
noErrorUnsafeSplit_ :: MonadThrow m => Parser m x a -> Parser m x b -> Parser m x b

-- | Works correctly only if the first parser is guaranteed to never fail.
noErrorUnsafeSplitWith :: Monad m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c
noErrorUnsafeConcatMap :: MonadThrow m => (b -> Parser m a c) -> Parser m a b -> Parser m a c
instance GHC.Show.Show Streamly.Internal.Data.Parser.ParserD.Type.ParseError
instance GHC.Exception.Type.Exception Streamly.Internal.Data.Parser.ParserD.Type.ParseError
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance Control.Monad.Catch.MonadThrow m => GHC.Base.Applicative (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance Control.Monad.Catch.MonadCatch m => GHC.Base.Alternative (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance Control.Monad.Catch.MonadThrow m => GHC.Base.Monad (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance Control.Monad.Catch.MonadCatch m => GHC.Base.MonadPlus (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance (Control.Monad.Catch.MonadThrow m, Control.Monad.Reader.Class.MonadReader r m, Control.Monad.Catch.MonadCatch m) => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance (Control.Monad.Catch.MonadThrow m, Control.Monad.State.Class.MonadState s m) => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance (Control.Monad.Catch.MonadThrow m, Control.Monad.IO.Class.MonadIO m) => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Parser.ParserD.Type.Parser m a)
instance GHC.Base.Functor (Streamly.Internal.Data.Parser.ParserD.Type.Step s)
instance Data.Bifunctor.Bifunctor Streamly.Internal.Data.Parser.ParserD.Type.Initial
instance GHC.Base.Functor (Streamly.Internal.Data.Parser.ParserD.Type.Initial s)


-- | CPS style implementation of parsers.
--   
--   The CPS representation allows linear performance for Applicative,
--   sequenceA, Monad, sequence, and Alternative, choice operations
--   compared to the quadratic complexity of the corresponding direct style
--   operations. However, direct style operations allow fusion with ~10x
--   better performance than CPS.
--   
--   The direct style representation does not allow for recursive
--   definitions of "some" and "many" whereas CPS allows that.
module Streamly.Internal.Data.Parser.ParserK.Type

-- | A continuation passing style parser representation.
newtype Parser m a b
MkParser :: (forall r. Int -> (Int, Int) -> ((Int, Int) -> Parse b -> m (Driver m a r)) -> m (Driver m a r)) -> Parser m a b
[runParser] :: Parser m a b -> forall r. Int -> (Int, Int) -> ((Int, Int) -> Parse b -> m (Driver m a r)) -> m (Driver m a r)

-- | A parser that always yields a pure value without consuming any input.
--   
--   <i>Pre-release</i>
fromPure :: b -> Parser m a b

-- | See <a>fromEffect</a>.
--   
--   <i>Pre-release</i>
fromEffect :: Monad m => m b -> Parser m a b

-- | A parser that always fails with an error message without consuming any
--   input.
--   
--   <i>Pre-release</i>
die :: String -> Parser m a b

-- | Convert a direct style <a>Parser</a> to a CPS style <a>Parser</a>.
--   
--   <i>Pre-release</i>
toParserK :: MonadCatch m => Parser m a b -> Parser m a b

-- | Convert a CPS style <a>Parser</a> to a direct style <a>Parser</a>.
--   
--   "initial" returns a continuation which can be called one input at a
--   time using the "step" function.
--   
--   <i>Pre-release</i>
fromParserK :: MonadThrow m => Parser m a b -> Parser m a b
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance GHC.Base.Monad m => GHC.Base.Applicative (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance GHC.Base.Monad m => GHC.Base.Monad (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance GHC.Base.Monad m => Control.Monad.Fail.MonadFail (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance (Control.Monad.Catch.MonadThrow m, Control.Monad.Reader.Class.MonadReader r m, Control.Monad.Catch.MonadCatch m) => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance (Control.Monad.Catch.MonadThrow m, Control.Monad.State.Class.MonadState s m) => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance (Control.Monad.Catch.MonadThrow m, Control.Monad.IO.Class.MonadIO m) => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance GHC.Base.Monad m => GHC.Base.Alternative (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance GHC.Base.Monad m => GHC.Base.MonadPlus (Streamly.Internal.Data.Parser.ParserK.Type.Parser m a)
instance GHC.Base.Functor Streamly.Internal.Data.Parser.ParserK.Type.Parse
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Parser.ParserK.Type.Driver m a)


-- | Parallel parsers. Distributing the input to multiple parsers at the
--   same time.
--   
--   For simplicity, we are using code where a particular state is
--   unreachable but it is not prevented by types. Somehow uni-pattern
--   match using "let" produces better optimized code compared to using
--   <tt>case</tt> match and using explicit error messages in unreachable
--   cases.
--   
--   There seem to be no way to silence individual warnings so we use a
--   global incomplete uni-pattern match warning suppression option for the
--   file. Disabling the warning for other code as well has the potential
--   to mask off some legit warnings, therefore, we have segregated only
--   the code that uses uni-pattern matches in this module.
module Streamly.Internal.Data.Parser.ParserD.Tee

-- | See <a>teeWith</a>.
--   
--   <i>Broken</i>
teeWith :: Monad m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>teeWithFst</a>.
--   
--   <i>Broken</i>
teeWithFst :: Monad m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>teeWithMin</a>.
--   
--   <i>Unimplemented</i>
teeWithMin :: (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>shortest</a>.
--   
--   <i>Broken</i>
shortest :: Monad m => Parser m x a -> Parser m x a -> Parser m x a

-- | See <a>longest</a>.
--   
--   <i>Broken</i>
longest :: MonadCatch m => Parser m x a -> Parser m x a -> Parser m x a


-- | Direct style parser implementation with stream fusion.
module Streamly.Internal.Data.Parser.ParserD

-- | A parser is a fold that can fail and is represented as <tt>Parser step
--   initial extract</tt>. Before we drive a parser we call the
--   <tt>initial</tt> action to retrieve the initial state of the fold. The
--   parser driver invokes <tt>step</tt> with the state returned by the
--   previous step and the next input element. It results into a new state
--   and a command to the driver represented by <a>Step</a> type. The
--   driver keeps invoking the step function until it stops or fails. At
--   any point of time the driver can call <tt>extract</tt> to inspect the
--   result of the fold. If the parser hits the end of input
--   <tt>extract</tt> is called. It may result in an error or an output
--   value.
--   
--   <i>Pre-release</i>
data Parser m a b
Parser :: (s -> a -> m (Step s b)) -> m (Initial s b) -> (s -> m b) -> Parser m a b

-- | This exception is used for two purposes:
--   
--   <ul>
--   <li>When a parser ultimately fails, the user of the parser is
--   intimated via this exception.</li>
--   <li>When the "extract" function of a parser needs to throw an
--   error.</li>
--   </ul>
--   
--   <i>Pre-release</i>
newtype ParseError
ParseError :: String -> ParseError

-- | The return type of a <a>Parser</a> step.
--   
--   The parse operation feeds the input stream to the parser one element
--   at a time, representing a parse <a>Step</a>. The parser may or may not
--   consume the item and returns a result. If the result is <a>Partial</a>
--   we can either extract the result or feed more input to the parser. If
--   the result is <a>Continue</a>, we must feed more input in order to get
--   a result. If the parser returns <a>Done</a> then the parser can no
--   longer take any more input.
--   
--   If the result is <a>Continue</a>, the parse operation retains the
--   input in a backtracking buffer, in case the parser may ask to
--   backtrack in future. Whenever a 'Partial n' result is returned we
--   first backtrack by <tt>n</tt> elements in the input and then release
--   any remaining backtracking buffer. Similarly, 'Continue n' backtracks
--   to <tt>n</tt> elements before the current position and starts feeding
--   the input from that point for future invocations of the parser.
--   
--   If parser is not yet done, we can use the <tt>extract</tt> operation
--   on the <tt>state</tt> of the parser to extract a result. If the parser
--   has not yet yielded a result, the operation fails with a
--   <a>ParseError</a> exception. If the parser yielded a <a>Partial</a>
--   result in the past the last partial result is returned. Therefore, if
--   a parser yields a partial result once it cannot fail later on.
--   
--   The parser can never backtrack beyond the position where the last
--   partial result left it at. The parser must ensure that the backtrack
--   position is always after that.
--   
--   <i>Pre-release</i>
data Step s b

-- | Partial result with an optional backtrack request.
--   
--   <tt>Partial count state</tt> means a partial result is available which
--   can be extracted successfully, <tt>state</tt> is the opaque state of
--   the parser to be supplied to the next invocation of the step
--   operation. The current input position is reset to <tt>count</tt>
--   elements back and any input before that is dropped from the backtrack
--   buffer.
Partial :: Int -> s -> Step s b

-- | Need more input with an optional backtrack request.
--   
--   <tt>Continue count state</tt> means the parser has consumed the
--   current input but no new result is generated, <tt>state</tt> is the
--   next state of the parser. The current input is retained in the
--   backtrack buffer and the input position is reset to <tt>count</tt>
--   elements back.
Continue :: Int -> s -> Step s b

-- | Done with leftover input count and result.
--   
--   <tt>Done count result</tt> means the parser has finished, it will
--   accept no more input, last <tt>count</tt> elements from the input are
--   unused and the result of the parser is in <tt>result</tt>.
Done :: Int -> b -> Step s b

-- | Parser failed without generating any output.
--   
--   The parsing operation may backtrack to the beginning and try another
--   alternative.
Error :: String -> Step s b

-- | The type of a <tt>Parser'</tt>s initial action.
--   
--   <i>Internal</i>
data Initial s b

-- | Wait for step function to be called with state <tt>s</tt>.
IPartial :: !s -> Initial s b

-- | Return a result right away without an input.
IDone :: !b -> Initial s b

-- | Return an error right away without an input.
IError :: String -> Initial s b

-- | Map a monadic function on the output of a parser.
--   
--   <i>Pre-release</i>
rmapM :: Monad m => (b -> m c) -> Parser m a b -> Parser m a c

-- | See <a>toFold</a>.
--   
--   <i>Internal</i>
toFold :: MonadThrow m => Parser m a b -> Fold m a b

-- | See <a>fromFold</a>.
--   
--   <i>Pre-release</i>
fromFold :: Monad m => Fold m a b -> Parser m a b

-- | See <a>fromPure</a>.
--   
--   <i>Pre-release</i>
fromPure :: Monad m => b -> Parser m a b

-- | See <a>fromEffect</a>.
--   
--   <i>Pre-release</i>
fromEffect :: Monad m => m b -> Parser m a b

-- | See <a>die</a>.
--   
--   <i>Pre-release</i>
die :: MonadThrow m => String -> Parser m a b

-- | See <a>dieM</a>.
--   
--   <i>Pre-release</i>
dieM :: MonadThrow m => m String -> Parser m a b

-- | See <a>peek</a>.
--   
--   <i>Pre-release</i>
peek :: MonadThrow m => Parser m a a

-- | See <a>eof</a>.
--   
--   <i>Pre-release</i>
eof :: Monad m => Parser m a ()

-- | See <a>satisfy</a>.
--   
--   <i>Pre-release</i>
satisfy :: MonadThrow m => (a -> Bool) -> Parser m a a

-- | See <a>next</a>.
--   
--   <i>Pre-release</i>
next :: Monad m => Parser m a (Maybe a)

-- | See <a>maybe</a>.
--   
--   <i>Pre-release</i>
maybe :: MonadThrow m => (a -> Maybe b) -> Parser m a b

-- | See <a>either</a>.
--   
--   <i>Pre-release</i>
either :: MonadThrow m => (a -> Either String b) -> Parser m a b

-- | See <a>takeBetween</a>.
--   
--   <i>Pre-release</i>
takeBetween :: MonadCatch m => Int -> Int -> Fold m a b -> Parser m a b

-- | See <a>takeEQ</a>.
--   
--   <i>Pre-release</i>
takeEQ :: MonadThrow m => Int -> Fold m a b -> Parser m a b

-- | See <a>takeGE</a>.
--   
--   <i>Pre-release</i>
takeGE :: MonadThrow m => Int -> Fold m a b -> Parser m a b

-- | See <a>takeP</a>.
--   
--   <i>Internal</i>
takeP :: Monad m => Int -> Parser m a b -> Parser m a b

-- | See <a>lookahead</a>.
--   
--   <i>Pre-release</i>
lookAhead :: MonadThrow m => Parser m a b -> Parser m a b

-- | See <a>takeWhile</a>.
--   
--   <i>Pre-release</i>
takeWhile :: Monad m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | See <a>takeWhile1</a>.
--   
--   <i>Pre-release</i>
takeWhile1 :: MonadThrow m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | See <a>sliceSepByP</a>.
--   
--   <i>Pre-release</i>
sliceSepByP :: MonadCatch m => (a -> Bool) -> Parser m a b -> Parser m a b
sliceBeginWith :: Monad m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | See <a>wordBy</a>.
wordBy :: Monad m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | See <a>groupBy</a>.
groupBy :: Monad m => (a -> a -> Bool) -> Fold m a b -> Parser m a b

-- | See <a>groupByRolling</a>.
groupByRolling :: Monad m => (a -> a -> Bool) -> Fold m a b -> Parser m a b
groupByRollingEither :: MonadCatch m => (a -> a -> Bool) -> Fold m a b -> Fold m a c -> Parser m a (Either b c)

-- | See <a>eqBy</a>.
--   
--   <i>Pre-release</i>
eqBy :: MonadThrow m => (a -> a -> Bool) -> [a] -> Parser m a ()

-- | <tt>span p f1 f2</tt> composes folds <tt>f1</tt> and <tt>f2</tt> such
--   that <tt>f1</tt> consumes the input as long as the predicate
--   <tt>p</tt> is <a>True</a>. <tt>f2</tt> consumes the rest of the input.
--   
--   <pre>
--   &gt; let span_ p xs = Stream.parse (Parser.span p Fold.toList Fold.toList) $ Stream.fromList xs
--   
--   &gt; span_ (&lt; 1) <a>1,2,3</a>
--   
--   &gt; span_ (&lt; 2) <a>1,2,3</a>
--   
--   &gt; span_ (&lt; 4) <a>1,2,3</a>
--   </pre>
--   
--   <i>Pre-release</i>
span :: Monad m => (a -> Bool) -> Fold m a b -> Fold m a c -> Parser m a (b, c)

-- | Break the input stream into two groups, the first group takes the
--   input as long as the predicate applied to the first element of the
--   stream and next input element holds <a>True</a>, the second group
--   takes the rest of the input.
--   
--   <i>Pre-release</i>
spanBy :: Monad m => (a -> a -> Bool) -> Fold m a b -> Fold m a c -> Parser m a (b, c)

-- | Like <a>spanBy</a> but applies the predicate in a rolling fashion i.e.
--   predicate is applied to the previous and the next input elements.
--   
--   <i>Pre-release</i>
spanByRolling :: Monad m => (a -> a -> Bool) -> Fold m a b -> Fold m a c -> Parser m a (b, c)

-- | See <a>serialWith</a>.
--   
--   Note: this implementation of serialWith is fast because of stream
--   fusion but has quadratic time complexity, because each composition
--   adds a new branch that each subsequent parse's input element has to go
--   through, therefore, it cannot scale to a large number of compositions.
--   After around 100 compositions the performance starts dipping rapidly
--   beyond a CPS style unfused implementation.
--   
--   <i>Pre-release</i>
serialWith :: MonadThrow m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>split_</a>.
--   
--   <i>Pre-release</i>
split_ :: MonadThrow m => Parser m x a -> Parser m x b -> Parser m x b

-- | See <a>teeWith</a>.
--   
--   <i>Broken</i>
teeWith :: Monad m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>teeWithFst</a>.
--   
--   <i>Broken</i>
teeWithFst :: Monad m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>teeWithMin</a>.
--   
--   <i>Unimplemented</i>
teeWithMin :: (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | See <a>deintercalate</a>.
--   
--   <i>Unimplemented</i>
deintercalate :: Fold m a y -> Parser m x a -> Fold m b z -> Parser m x b -> Parser m x (y, z)

-- | See <a>alt</a>.
--   
--   <i>Pre-release</i>
alt :: Monad m => Parser m x a -> Parser m x a -> Parser m x a

-- | See <a>shortest</a>.
--   
--   <i>Broken</i>
shortest :: Monad m => Parser m x a -> Parser m x a -> Parser m x a

-- | See <a>longest</a>.
--   
--   <i>Broken</i>
longest :: MonadCatch m => Parser m x a -> Parser m x a -> Parser m x a

-- | See <a>sequence</a>.
--   
--   <i>Unimplemented</i>
sequence :: Fold m b c -> t (Parser m a b) -> Parser m a c

-- | See <a>concatMap</a>.
--   
--   <i>Pre-release</i>
concatMap :: MonadThrow m => (b -> Parser m a c) -> Parser m a b -> Parser m a c

-- | See <a>count</a>.
--   
--   <i>Unimplemented</i>
count :: Int -> Parser m a b -> Fold m b c -> Parser m a c

-- | See <a>countBetween</a>.
--   
--   <i>Unimplemented</i>
countBetween :: Int -> Int -> Parser m a b -> Fold m b c -> Parser m a c

-- | See <a>many</a>.
--   
--   <i>Pre-release</i>
many :: MonadCatch m => Parser m a b -> Fold m b c -> Parser m a c

-- | See <a>some</a>.
--   
--   <i>Pre-release</i>
some :: MonadCatch m => Parser m a b -> Fold m b c -> Parser m a c

-- | See <a>manyTill</a>.
--   
--   <i>Pre-release</i>
manyTill :: MonadCatch m => Fold m b c -> Parser m a b -> Parser m a x -> Parser m a c

-- | See <a>choice</a>.
--   
--   <i>Broken</i>
choice :: (MonadCatch m, Foldable t) => t (Parser m a b) -> Parser m a b
instance GHC.Show.Show Streamly.Internal.Data.Parser.ParserD.ParserToFoldError
instance (GHC.Show.Show a, GHC.Show.Show b) => GHC.Show.Show (Streamly.Internal.Data.Parser.ParserD.Tuple'Fused a b)
instance GHC.Exception.Type.Exception Streamly.Internal.Data.Parser.ParserD.ParserToFoldError


-- | A <a>Source</a> is a seed that can be unfolded to a stream with a
--   buffer. Allows to <a>unread</a> data i.e. push unused data back to the
--   source buffer. This is useful in parsing applications with
--   backtracking.
module Streamly.Internal.Data.Producer.Source

-- | A seed with a buffer. It allows us to <a>unread</a> or return some
--   data after reading it. Useful in backtracked parsing.
data Source a b

-- | Make a source from a seed value. The buffer would start as empty.
--   
--   <i>Pre-release</i>
source :: Maybe a -> Source a b

-- | Return some unused data back to the source. The data is prepended (or
--   consed) to the source.
--   
--   <i>Pre-release</i>
unread :: [b] -> Source a b -> Source a b

-- | Determine if the source is empty.
isEmpty :: Source a b -> Bool

-- | Convert a producer to a producer from a buffered source. Any buffered
--   data is read first and then the seed is unfolded.
--   
--   <i>Pre-release</i>
producer :: Monad m => Producer m a b -> Producer m (Source a b) b

-- | Parse a buffered source using a parser, returning the parsed value and
--   the remaining source.
--   
--   <i>Pre-release</i>
parse :: MonadThrow m => Parser m a b -> Producer m (Source s a) a -> Source s a -> m (b, Source s a)

-- | Apply a parser repeatedly on a buffered source producer to generate a
--   producer of parsed values.
--   
--   <i>Pre-release</i>
parseMany :: MonadThrow m => Parser m a b -> Producer m (Source x a) a -> Producer m (Source x a) b
parseManyD :: MonadThrow m => Parser m a b -> Producer m (Source x a) a -> Producer m (Source x a) b


-- | Fast backtracking parsers with stream fusion and native streaming
--   capability.
--   
--   <a>Applicative</a> and <a>Alternative</a> type class based combinators
--   from the <a>parser-combinators</a> package can also be used with the
--   <a>Parser</a> type. However, there are two important differences
--   between <tt>parser-combinators</tt> and the equivalent ones provided
--   in this module in terms of performance:
--   
--   1) <tt>parser-combinators</tt> use plain Haskell lists to collect the
--   results, in a strict Monad like IO, the results are necessarily
--   buffered before they can be consumed. This may not perform optimally
--   in streaming applications processing large amounts of data. Equivalent
--   combinators in this module can consume the results of parsing using a
--   <a>Fold</a>, thus providing a scalability and a composable consumer.
--   
--   2) Several combinators in this module can be many times faster because
--   of stream fusion. For example, <a>many</a> combinator in this module
--   is much faster than the <a>many</a> combinator of <a>Alternative</a>
--   type class.
--   
--   <h1>Errors</h1>
--   
--   Failing parsers in this module throw the <a>ParseError</a> exception.
--   
--   <h1>Naming</h1>
--   
--   As far as possible, try that the names of the combinators in this
--   module are consistent with:
--   
--   <ul>
--   <li><a>base/Text.ParserCombinators.ReadP</a></li>
--   <li><a>parser-combinators</a></li>
--   <li><a>megaparsec</a></li>
--   <li><a>attoparsec</a></li>
--   <li><a>parsec</a></li>
--   </ul>
module Streamly.Internal.Data.Parser

-- | A continuation passing style parser representation.
newtype Parser m a b
MkParser :: (forall r. Int -> (Int, Int) -> ((Int, Int) -> Parse b -> m (Driver m a r)) -> m (Driver m a r)) -> Parser m a b
[runParser] :: Parser m a b -> forall r. Int -> (Int, Int) -> ((Int, Int) -> Parse b -> m (Driver m a r)) -> m (Driver m a r)

-- | This exception is used for two purposes:
--   
--   <ul>
--   <li>When a parser ultimately fails, the user of the parser is
--   intimated via this exception.</li>
--   <li>When the "extract" function of a parser needs to throw an
--   error.</li>
--   </ul>
--   
--   <i>Pre-release</i>
newtype ParseError
ParseError :: String -> ParseError

-- | The return type of a <a>Parser</a> step.
--   
--   The parse operation feeds the input stream to the parser one element
--   at a time, representing a parse <a>Step</a>. The parser may or may not
--   consume the item and returns a result. If the result is <a>Partial</a>
--   we can either extract the result or feed more input to the parser. If
--   the result is <a>Continue</a>, we must feed more input in order to get
--   a result. If the parser returns <a>Done</a> then the parser can no
--   longer take any more input.
--   
--   If the result is <a>Continue</a>, the parse operation retains the
--   input in a backtracking buffer, in case the parser may ask to
--   backtrack in future. Whenever a 'Partial n' result is returned we
--   first backtrack by <tt>n</tt> elements in the input and then release
--   any remaining backtracking buffer. Similarly, 'Continue n' backtracks
--   to <tt>n</tt> elements before the current position and starts feeding
--   the input from that point for future invocations of the parser.
--   
--   If parser is not yet done, we can use the <tt>extract</tt> operation
--   on the <tt>state</tt> of the parser to extract a result. If the parser
--   has not yet yielded a result, the operation fails with a
--   <a>ParseError</a> exception. If the parser yielded a <a>Partial</a>
--   result in the past the last partial result is returned. Therefore, if
--   a parser yields a partial result once it cannot fail later on.
--   
--   The parser can never backtrack beyond the position where the last
--   partial result left it at. The parser must ensure that the backtrack
--   position is always after that.
--   
--   <i>Pre-release</i>
data Step s b

-- | Partial result with an optional backtrack request.
--   
--   <tt>Partial count state</tt> means a partial result is available which
--   can be extracted successfully, <tt>state</tt> is the opaque state of
--   the parser to be supplied to the next invocation of the step
--   operation. The current input position is reset to <tt>count</tt>
--   elements back and any input before that is dropped from the backtrack
--   buffer.
Partial :: Int -> s -> Step s b

-- | Need more input with an optional backtrack request.
--   
--   <tt>Continue count state</tt> means the parser has consumed the
--   current input but no new result is generated, <tt>state</tt> is the
--   next state of the parser. The current input is retained in the
--   backtrack buffer and the input position is reset to <tt>count</tt>
--   elements back.
Continue :: Int -> s -> Step s b

-- | Done with leftover input count and result.
--   
--   <tt>Done count result</tt> means the parser has finished, it will
--   accept no more input, last <tt>count</tt> elements from the input are
--   unused and the result of the parser is in <tt>result</tt>.
Done :: Int -> b -> Step s b

-- | Parser failed without generating any output.
--   
--   The parsing operation may backtrack to the beginning and try another
--   alternative.
Error :: String -> Step s b

-- | Make a <a>Fold</a> from a <a>Parser</a>. The fold just throws an
--   exception if the parser fails or tries to backtrack.
--   
--   This can be useful in combinators that accept a Fold and we know that
--   a Parser cannot fail or failure exception is acceptable as there is no
--   way to recover.
--   
--   <i>Pre-release</i>
toFold :: MonadThrow m => Parser m a b -> Fold m a b

-- | Make a <a>Parser</a> from a <a>Fold</a>.
--   
--   <i>Pre-release</i>
fromFold :: MonadCatch m => Fold m a b -> Parser m a b

-- | A parser that always yields a pure value without consuming any input.
--   
--   <i>Pre-release</i>
fromPure :: MonadCatch m => b -> Parser m a b

-- | A parser that always yields the result of an effectful action without
--   consuming any input.
--   
--   <i>Pre-release</i>
fromEffect :: MonadCatch m => m b -> Parser m a b

-- | A parser that always fails with an error message without consuming any
--   input.
--   
--   <i>Pre-release</i>
die :: MonadCatch m => String -> Parser m a b

-- | A parser that always fails with an effectful error message and without
--   consuming any input.
--   
--   <i>Pre-release</i>
dieM :: MonadCatch m => m String -> Parser m a b

-- | Peek the head element of a stream, without consuming it. Fails if it
--   encounters end of input.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse ((,) &lt;$&gt; Parser.peek &lt;*&gt; Parser.satisfy (&gt; 0)) $ Stream.fromList [1]
--   (1,1)
--   </pre>
--   
--   <pre>
--   peek = lookAhead (satisfy True)
--   </pre>
--   
--   <i>Pre-release</i>
peek :: MonadCatch m => Parser m a a

-- | Succeeds if we are at the end of input, fails otherwise.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse ((,) &lt;$&gt; Parser.satisfy (&gt; 0) &lt;*&gt; Parser.eof) $ Stream.fromList [1]
--   (1,())
--   </pre>
--   
--   <i>Pre-release</i>
eof :: MonadCatch m => Parser m a ()

-- | Returns the next element if it passes the predicate, fails otherwise.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.satisfy (== 1)) $ Stream.fromList [1,0,1]
--   1
--   </pre>
--   
--   <i>Pre-release</i>
satisfy :: MonadCatch m => (a -> Bool) -> Parser m a a

-- | Return the next element of the input. Returns <a>Nothing</a> on end of
--   input. Also known as <a>head</a>.
--   
--   <i>Pre-release</i>
next :: MonadCatch m => Parser m a (Maybe a)

-- | Map a <a>Maybe</a> returning function on the next element in the
--   stream. The parser fails if the function returns <a>Nothing</a>
--   otherwise returns the <a>Just</a> value.
--   
--   <i>Pre-release</i>
maybe :: MonadCatch m => (a -> Maybe b) -> Parser m a b

-- | Map an <a>Either</a> returning function on the next element in the
--   stream. If the function returns 'Left err', the parser fails with the
--   error message <tt>err</tt> otherwise returns the <a>Right</a> value.
--   
--   <i>Pre-release</i>
either :: MonadCatch m => (a -> Either String b) -> Parser m a b

-- | <tt>takeBetween m n</tt> takes a minimum of <tt>m</tt> and a maximum
--   of <tt>n</tt> input elements and folds them using the supplied fold.
--   
--   Stops after <tt>n</tt> elements. Fails if the stream ends before
--   <tt>m</tt> elements could be taken.
--   
--   Examples: -
--   
--   <pre>
--   &gt;&gt;&gt; :{
--     takeBetween' low high ls = Stream.parse prsr (Stream.fromList ls)
--       where prsr = Parser.takeBetween low high Fold.toList
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; takeBetween' 2 4 [1, 2, 3, 4, 5]
--   [1,2,3,4]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; takeBetween' 2 4 [1, 2]
--   [1,2]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; takeBetween' 2 4 [1]
--   *** Exception: ParseError "takeBetween: Expecting alteast 2 elements, got 1"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; takeBetween' 0 0 [1, 2]
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; takeBetween' 0 1 []
--   []
--   </pre>
--   
--   <tt>takeBetween</tt> is the most general take operation, other take
--   operations can be defined in terms of takeBetween. For example:
--   
--   <pre>
--   take = takeBetween 0 n  -- equivalent of take
--   take1 = takeBetween 1 n -- equivalent of takeLE1
--   takeEQ = takeBetween n n
--   takeGE = takeBetween n maxBound
--   </pre>
--   
--   <i>Pre-release</i>
takeBetween :: MonadCatch m => Int -> Int -> Fold m a b -> Parser m a b

-- | Stops after taking exactly <tt>n</tt> input elements.
--   
--   <ul>
--   <li>Stops - after consuming <tt>n</tt> elements.</li>
--   <li>Fails - if the stream or the collecting fold ends before it can
--   collect exactly <tt>n</tt> elements.</li>
--   </ul>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.takeEQ 4 Fold.toList) $ Stream.fromList [1,0,1]
--   *** Exception: ParseError "takeEQ: Expecting exactly 4 elements, input terminated on 3"
--   </pre>
--   
--   <i>Pre-release</i>
takeEQ :: MonadCatch m => Int -> Fold m a b -> Parser m a b

-- | Take at least <tt>n</tt> input elements, but can collect more.
--   
--   <ul>
--   <li>Stops - when the collecting fold stops.</li>
--   <li>Fails - if the stream or the collecting fold ends before producing
--   <tt>n</tt> elements.</li>
--   </ul>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.takeGE 4 Fold.toList) $ Stream.fromList [1,0,1]
--   *** Exception: ParseError "takeGE: Expecting at least 4 elements, input terminated on 3"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.takeGE 4 Fold.toList) $ Stream.fromList [1,0,1,0,1]
--   [1,0,1,0,1]
--   </pre>
--   
--   <i>Pre-release</i>
takeGE :: MonadCatch m => Int -> Fold m a b -> Parser m a b

-- | Takes at-most <tt>n</tt> input elements.
--   
--   <ul>
--   <li>Stops - when the collecting parser stops.</li>
--   <li>Fails - when the collecting parser fails.</li>
--   </ul>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.takeP 4 (Parser.takeEQ 2 Fold.toList)) $ Stream.fromList [1, 2, 3, 4, 5]
--   [1,2]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.takeP 4 (Parser.takeEQ 5 Fold.toList)) $ Stream.fromList [1, 2, 3, 4, 5]
--   *** Exception: ParseError "takeEQ: Expecting exactly 5 elements, input terminated on 4"
--   </pre>
--   
--   <i>Internal</i>
takeP :: MonadCatch m => Int -> Parser m a b -> Parser m a b

-- | Run a parser without consuming the input.
--   
--   <i>Pre-release</i>
lookAhead :: MonadCatch m => Parser m a b -> Parser m a b

-- | Like <a>takeWhile</a> but uses a <a>Parser</a> instead of a
--   <a>Fold</a> to collect the input. The combinator stops when the
--   condition fails or if the collecting parser stops.
--   
--   This is a generalized version of takeWhile, for example
--   <a>takeWhile1</a> can be implemented in terms of this:
--   
--   <pre>
--   takeWhile1 cond p = takeWhile cond (takeBetween 1 maxBound p)
--   </pre>
--   
--   Stops: when the condition fails or the collecting parser stops. Fails:
--   when the collecting parser fails.
--   
--   <i>Unimplemented</i>
takeWhileP :: (a -> Bool) -> Parser m a b -> Parser m a b

-- | Collect stream elements until an element fails the predicate. The
--   element on which the predicate fails is returned back to the input
--   stream.
--   
--   <ul>
--   <li>Stops - when the predicate fails or the collecting fold
--   stops.</li>
--   <li>Fails - never.</li>
--   </ul>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.takeWhile (== 0) Fold.toList) $ Stream.fromList [0,0,1,0,1]
--   [0,0]
--   </pre>
--   
--   We can implement a <tt>breakOn</tt> using <a>takeWhile</a>:
--   
--   <pre>
--   breakOn p = takeWhile (not p)
--   </pre>
--   
--   <i>Pre-release</i>
takeWhile :: MonadCatch m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | Like <a>takeWhile</a> but takes at least one element otherwise fails.
--   
--   <i>Pre-release</i>
takeWhile1 :: MonadCatch m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | Drain the input as long as the predicate succeeds, running the effects
--   and discarding the results.
--   
--   This is also called <tt>skipWhile</tt> in some parsing libraries.
--   
--   <i>Pre-release</i>
drainWhile :: MonadCatch m => (a -> Bool) -> Parser m a ()

-- | <tt>sliceSepByP cond parser</tt> parses a slice of the input using
--   <tt>parser</tt> until <tt>cond</tt> succeeds or the parser stops.
--   
--   This is a generalized slicing parser which can be used to implement
--   other parsers e.g.:
--   
--   <pre>
--   sliceSepByMax cond n p = sliceSepByP cond (take n p)
--   sliceSepByBetween cond m n p = sliceSepByP cond (takeBetween m n p)
--   </pre>
--   
--   <i>Pre-release</i>
sliceSepByP :: MonadCatch m => (a -> Bool) -> Parser m a b -> Parser m a b

-- | Collect stream elements until an elements passes the predicate, return
--   the last element on which the predicate succeeded back to the input
--   stream. If the predicate succeeds on the first element itself then the
--   parser does not terminate there. The succeeding element in the leading
--   position is treated as a prefix separator which is kept in the output
--   segment.
--   
--   <ul>
--   <li>Stops - when the predicate succeeds in non-leading position.</li>
--   <li>Fails - never.</li>
--   </ul>
--   
--   S.splitWithPrefix pred f = S.parseMany (PR.sliceBeginWith pred f)
--   
--   Examples: -
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    sliceBeginWithOdd ls = Stream.parse prsr (Stream.fromList ls)
--        where prsr = Parser.sliceBeginWith odd Fold.toList
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; sliceBeginWithOdd [2, 4, 6, 3]
--   *** Exception: sliceBeginWith : slice begins with an element which fails the predicate
--   ...
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; sliceBeginWithOdd [3, 5, 7, 4]
--   [3]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; sliceBeginWithOdd [3, 4, 6, 8, 5]
--   [3,4,6,8]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; sliceBeginWithOdd []
--   []
--   </pre>
--   
--   <i>Pre-release</i>
sliceBeginWith :: MonadCatch m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | Like <tt>sliceSepBy</tt> but does not drop the separator element,
--   instead separator is emitted as a separate element in the output.
--   
--   <i>Unimplemented</i>
sliceSepWith :: (a -> Bool) -> Fold m a b -> Parser m a b

-- | Like <tt>sliceSepBy</tt> but the separator elements can be escaped
--   using an escape char determined by the second predicate.
--   
--   <i>Unimplemented</i>
escapedSliceSepBy :: (a -> Bool) -> (a -> Bool) -> Fold m a b -> Parser m a b

-- | <tt>escapedFrameBy begin end escape</tt> parses a string framed using
--   <tt>begin</tt> and <tt>end</tt> as the frame begin and end marker
--   elements and <tt>escape</tt> as an escaping element to escape the
--   occurrence of the framing elements within the frame. Nested frames are
--   allowed, but nesting is removed when parsing.
--   
--   For example,
--   
--   <pre>
--   &gt; Stream.parse (Parser.escapedFrameBy (== '{') (== '}') (== <tt>\\</tt>) Fold.toList) $ Stream.fromList "{hello}"
--   "hello"
--   
--   &gt; Stream.parse (Parser.escapedFrameBy (== '{') (== '}') (== <tt>\\</tt>) Fold.toList) $ Stream.fromList "{hello {world}}"
--   "hello world"
--   
--   &gt; Stream.parse (Parser.escapedFrameBy (== '{') (== '}') (== <tt>\\</tt>) Fold.toList) $ Stream.fromList "{hello \{world\}}"
--   "hello {world}"
--   
--   &gt; Stream.parse (Parser.escapedFrameBy (== '{') (== '}') (== <tt>\\</tt>) Fold.toList) $ Stream.fromList "{hello {world}"
--   ParseError "Unterminated '{'"
--   </pre>
--   
--   <i>Unimplemented</i>
escapedFrameBy :: (a -> Bool) -> (a -> Bool) -> (a -> Bool) -> Fold m a b -> Parser m a b

-- | Like <tt>splitOn</tt> but strips leading, trailing, and repeated
--   separators. Therefore, <tt>".a..b."</tt> having <a>.</a> as the
--   separator would be parsed as <tt>["a","b"]</tt>. In other words, its
--   like parsing words from whitespace separated text.
--   
--   <ul>
--   <li>Stops - when it finds a word separator after a non-word
--   element</li>
--   <li>Fails - never.</li>
--   </ul>
--   
--   <pre>
--   S.wordsBy pred f = S.parseMany (PR.wordBy pred f)
--   </pre>
wordBy :: MonadCatch m => (a -> Bool) -> Fold m a b -> Parser m a b

-- | Given an input stream <tt>[a,b,c,...]</tt> and a comparison function
--   <tt>cmp</tt>, the parser assigns the element <tt>a</tt> to the first
--   group, then if <tt>a `cmp` b</tt> is <a>True</a> <tt>b</tt> is also
--   assigned to the same group. If <tt>a `cmp` c</tt> is <a>True</a> then
--   <tt>c</tt> is also assigned to the same group and so on. When the
--   comparison fails the parser is terminated. Each group is folded using
--   the <a>Fold</a> <tt>f</tt> and the result of the fold is the result of
--   the parser.
--   
--   <ul>
--   <li>Stops - when the comparison fails.</li>
--   <li>Fails - never.</li>
--   </ul>
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    runGroupsBy eq =
--        Stream.toList
--            . Stream.parseMany (Parser.groupBy eq Fold.toList)
--            . Stream.fromList
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; runGroupsBy (&lt;) []
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; runGroupsBy (&lt;) [1]
--   [[1]]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; runGroupsBy (&lt;) [3, 5, 4, 1, 2, 0]
--   [[3,5,4],[1,2],[0]]
--   </pre>
--   
--   <i>Pre-release</i>
groupBy :: MonadCatch m => (a -> a -> Bool) -> Fold m a b -> Parser m a b

-- | Unlike <a>groupBy</a> this combinator performs a rolling comparison of
--   two successive elements in the input stream. Assuming the input stream
--   to the parser is <tt>[a,b,c,...]</tt> and the comparison function is
--   <tt>cmp</tt>, the parser first assigns the element <tt>a</tt> to the
--   first group, then if <tt>a `cmp` b</tt> is <a>True</a> <tt>b</tt> is
--   also assigned to the same group. If <tt>b `cmp` c</tt> is <a>True</a>
--   then <tt>c</tt> is also assigned to the same group and so on. When the
--   comparison fails the parser is terminated. Each group is folded using
--   the <a>Fold</a> <tt>f</tt> and the result of the fold is the result of
--   the parser.
--   
--   <ul>
--   <li>Stops - when the comparison fails.</li>
--   <li>Fails - never.</li>
--   </ul>
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    runGroupsByRolling eq =
--        Stream.toList
--            . Stream.parseMany (Parser.groupByRolling eq Fold.toList)
--            . Stream.fromList
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; runGroupsByRolling (&lt;) []
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; runGroupsByRolling (&lt;) [1]
--   [[1]]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; runGroupsByRolling (&lt;) [3, 5, 4, 1, 2, 0]
--   [[3,5],[4],[1,2],[0]]
--   </pre>
--   
--   <i>Pre-release</i>
groupByRolling :: MonadCatch m => (a -> a -> Bool) -> Fold m a b -> Parser m a b

-- | Like <a>groupByRolling</a>, but if the predicate is <a>True</a> then
--   collects using the first fold as long as the predicate holds
--   <a>True</a>, if the predicate is <a>False</a> collects using the
--   second fold as long as it remains <a>False</a>. Returns <a>Left</a>
--   for the first case and <a>Right</a> for the second case.
--   
--   For example, if we want to detect sorted sequences in a stream, both
--   ascending and descending cases we can use 'groupByRollingEither
--   (&lt;=) Fold.toList Fold.toList'.
--   
--   <i>Unimplemented</i>
groupByRollingEither :: MonadCatch m => (a -> a -> Bool) -> Fold m a b -> Fold m a c -> Parser m a (Either b c)

-- | Match the given sequence of elements using the given comparison
--   function.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.eqBy (==) "string") $ Stream.fromList "string"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.eqBy (==) "mismatch") $ Stream.fromList "match"
--   *** Exception: ParseError "eqBy: failed, yet to match 7 elements"
--   </pre>
--   
--   <i>Pre-release</i>
eqBy :: MonadCatch m => (a -> a -> Bool) -> [a] -> Parser m a ()

-- | Sequential parser application. Apply two parsers sequentially to an
--   input stream. The input is provided to the first parser, when it is
--   done the remaining input is provided to the second parser. If both the
--   parsers succeed their outputs are combined using the supplied
--   function. The operation fails if any of the parsers fail.
--   
--   Note: This is a parsing dual of appending streams using <a>serial</a>,
--   it splits the streams using two parsers and zips the results.
--   
--   This implementation is strict in the second argument, therefore, the
--   following will fail:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.serialWith const (Parser.satisfy (&gt; 0)) undefined) $ Stream.fromList [1]
--   *** Exception: Prelude.undefined
--   ...
--   </pre>
--   
--   Compare with <a>Applicative</a> instance method <a>&lt;*&gt;</a>. This
--   implementation allows stream fusion but has quadratic complexity. This
--   can fuse with other operations and can be faster than
--   <a>Applicative</a> instance for small number (less than 8) of
--   compositions.
--   
--   Many combinators can be expressed using <tt>serialWith</tt> and other
--   parser primitives. Some common idioms are described below,
--   
--   <pre>
--   span :: (a -&gt; Bool) -&gt; Fold m a b -&gt; Fold m a b -&gt; Parser m a b
--   span pred f1 f2 = serialWith (,) (<a>takeWhile</a> pred f1) (<a>fromFold</a> f2)
--   </pre>
--   
--   <pre>
--   spanBy :: (a -&gt; a -&gt; Bool) -&gt; Fold m a b -&gt; Fold m a b -&gt; Parser m a b
--   spanBy eq f1 f2 = serialWith (,) (<a>groupBy</a> eq f1) (<a>fromFold</a> f2)
--   </pre>
--   
--   <pre>
--   spanByRolling :: (a -&gt; a -&gt; Bool) -&gt; Fold m a b -&gt; Fold m a b -&gt; Parser m a b
--   spanByRolling eq f1 f2 = serialWith (,) (<a>groupByRolling</a> eq f1) (<a>fromFold</a> f2)
--   </pre>
--   
--   <i>Pre-release</i>
serialWith :: MonadCatch m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | Sequential parser application ignoring the output of the first parser.
--   Apply two parsers sequentially to an input stream. The input is
--   provided to the first parser, when it is done the remaining input is
--   provided to the second parser. The output of the parser is the output
--   of the second parser. The operation fails if any of the parsers fail.
--   
--   This implementation is strict in the second argument, therefore, the
--   following will fail:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.split_ (Parser.satisfy (&gt; 0)) undefined) $ Stream.fromList [1]
--   *** Exception: Prelude.undefined
--   ...
--   </pre>
--   
--   Compare with <a>Applicative</a> instance method <a>*&gt;</a>. This
--   implementation allows stream fusion but has quadratic complexity. This
--   can fuse with other operations, and can be faster than
--   <a>Applicative</a> instance for small number (less than 8) of
--   compositions.
--   
--   <i>Pre-release</i>
split_ :: MonadCatch m => Parser m x a -> Parser m x b -> Parser m x b

-- | <tt>teeWith f p1 p2</tt> distributes its input to both <tt>p1</tt> and
--   <tt>p2</tt> until both of them succeed or anyone of them fails and
--   combines their output using <tt>f</tt>. The parser succeeds if both
--   the parsers succeed.
--   
--   <i>Pre-release</i>
teeWith :: MonadCatch m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | Like <a>teeWith</a> but ends parsing and zips the results, if
--   available, whenever the first parser ends.
--   
--   <i>Pre-release</i>
teeWithFst :: MonadCatch m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | Like <a>teeWith</a> but ends parsing and zips the results, if
--   available, whenever any of the parsers ends or fails.
--   
--   <i>Unimplemented</i>
teeWithMin :: MonadCatch m => (a -> b -> c) -> Parser m x a -> Parser m x b -> Parser m x c

-- | Apply two parsers alternately to an input stream. The input stream is
--   considered an interleaving of two patterns. The two parsers represent
--   the two patterns.
--   
--   This undoes a "gintercalate" of two streams.
--   
--   <i>Unimplemented</i>
deintercalate :: Fold m a y -> Parser m x a -> Fold m b z -> Parser m x b -> Parser m x (y, z)

-- | Sequential alternative. Apply the input to the first parser and return
--   the result if the parser succeeds. If the first parser fails then
--   backtrack and apply the same input to the second parser and return the
--   result.
--   
--   Note: This implementation is not lazy in the second argument. The
--   following will fail:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.satisfy (&gt; 0) `Parser.alt` undefined) $ Stream.fromList [1..10]
--   1
--   </pre>
--   
--   Compare with <tt>Alternative</tt> instance method <tt>&lt;|&gt;</tt>.
--   This implementation allows stream fusion but has quadratic complexity.
--   This can fuse with other operations and can be much faster than
--   <tt>Alternative</tt> instance for small number (less than 8) of
--   alternatives.
--   
--   <i>Pre-release</i>
alt :: MonadCatch m => Parser m x a -> Parser m x a -> Parser m x a

-- | Shortest alternative. Apply both parsers in parallel but choose the
--   result from the one which consumed least input i.e. take the shortest
--   succeeding parse.
--   
--   <i>Pre-release</i>
shortest :: MonadCatch m => Parser m x a -> Parser m x a -> Parser m x a

-- | Longest alternative. Apply both parsers in parallel but choose the
--   result from the one which consumed more input i.e. take the longest
--   succeeding parse.
--   
--   <i>Pre-release</i>
longest :: MonadCatch m => Parser m x a -> Parser m x a -> Parser m x a

-- | <tt>concatSequence f t</tt> collects sequential parses of parsers in
--   the container <tt>t</tt> using the fold <tt>f</tt>. Fails if the input
--   ends or any of the parsers fail.
--   
--   This is same as <a>sequence</a> but more efficient.
--   
--   <i>Unimplemented</i>
concatSequence :: Fold m b c -> t (Parser m a b) -> Parser m a c

-- | Map a <a>Parser</a> returning function on the result of a
--   <a>Parser</a>.
--   
--   Compare with <a>Monad</a> instance method <a>&gt;&gt;=</a>. This
--   implementation allows stream fusion but has quadratic complexity. This
--   can fuse with other operations and can be much faster than
--   <a>Monad</a> instance for small number (less than 8) of compositions.
--   
--   <i>Pre-release</i>
concatMap :: MonadCatch m => (b -> Parser m a c) -> Parser m a b -> Parser m a c

-- | <tt>count n f p</tt> collects exactly <tt>n</tt> sequential parses of
--   parser <tt>p</tt> using the fold <tt>f</tt>. Fails if the input ends
--   or the parser fails before <tt>n</tt> results are collected.
--   
--   <i>Unimplemented</i>
count :: Int -> Parser m a b -> Fold m b c -> Parser m a c

-- | <tt>countBetween m n f p</tt> collects between <tt>m</tt> and
--   <tt>n</tt> sequential parses of parser <tt>p</tt> using the fold
--   <tt>f</tt>. Stop after collecting <tt>n</tt> results. Fails if the
--   input ends or the parser fails before <tt>m</tt> results are
--   collected.
--   
--   <i>Unimplemented</i>
countBetween :: Int -> Int -> Parser m a b -> Fold m b c -> Parser m a c

-- | Like <a>many</a> but uses a <a>Parser</a> instead of a <a>Fold</a> to
--   collect the results. Parsing stops or fails if the collecting parser
--   stops or fails.
--   
--   <i>Unimplemented</i>
manyP :: Parser m a b -> Parser m b c -> Parser m a c

-- | Collect zero or more parses. Apply the supplied parser repeatedly on
--   the input stream and push the parse results to a downstream fold.
--   
--   Stops: when the downstream fold stops or the parser fails. Fails:
--   never, produces zero or more results.
--   
--   Compare with <a>many</a>.
--   
--   <i>Pre-release</i>
many :: MonadCatch m => Parser m a b -> Fold m b c -> Parser m a c

-- | Collect one or more parses. Apply the supplied parser repeatedly on
--   the input stream and push the parse results to a downstream fold.
--   
--   Stops: when the downstream fold stops or the parser fails. Fails: if
--   it stops without producing a single result.
--   
--   <pre>
--   some fld parser = manyP (takeGE 1 fld) parser
--   </pre>
--   
--   Compare with <a>some</a>.
--   
--   <i>Pre-release</i>
some :: MonadCatch m => Parser m a b -> Fold m b c -> Parser m a c

-- | Like <a>manyTill</a> but uses a <a>Parser</a> to collect the results
--   instead of a <a>Fold</a>. Parsing stops or fails if the collecting
--   parser stops or fails.
--   
--   We can implemnent parsers like the following using <a>manyTillP</a>:
--   
--   <pre>
--   countBetweenTill m n f p = manyTillP (takeBetween m n f) p
--   </pre>
--   
--   <i>Unimplemented</i>
manyTillP :: Parser m a b -> Parser m a x -> Parser m b c -> Parser m a c

-- | <tt>manyTill f collect test</tt> tries the parser <tt>test</tt> on the
--   input, if <tt>test</tt> fails it backtracks and tries
--   <tt>collect</tt>, after <tt>collect</tt> succeeds <tt>test</tt> is
--   tried again and so on. The parser stops when <tt>test</tt> succeeds.
--   The output of <tt>test</tt> is discarded and the output of
--   <tt>collect</tt> is accumulated by the supplied fold. The parser fails
--   if <tt>collect</tt> fails.
--   
--   Stops when the fold <tt>f</tt> stops.
--   
--   <i>Pre-release</i>
manyTill :: MonadCatch m => Parser m a b -> Parser m a x -> Fold m b c -> Parser m a c

-- | <tt>manyThen f collect recover</tt> repeats the parser
--   <tt>collect</tt> on the input and collects the output in the supplied
--   fold. If the the parser <tt>collect</tt> fails, parser
--   <tt>recover</tt> is run until it stops and then we start repeating the
--   parser <tt>collect</tt> again. The parser fails if the recovery parser
--   fails.
--   
--   For example, this can be used to find a key frame in a video stream
--   after an error.
--   
--   <i>Unimplemented</i>
manyThen :: Parser m a b -> Parser m a x -> Fold m b c -> Parser m a c

-- | Apply a collection of parsers to an input stream in a round robin
--   fashion. Each parser is applied until it stops and then we repeat
--   starting with the the first parser again.
--   
--   <i>Unimplemented</i>
roundRobin :: t (Parser m a b) -> Fold m b c -> Parser m a c

-- | <tt>choice parsers</tt> applies the <tt>parsers</tt> in order and
--   returns the first successful parse.
--   
--   This is same as <tt>asum</tt> but more efficient.
--   
--   <i>Broken</i>
choice :: (Functor t, Foldable t, MonadCatch m) => t (Parser m a b) -> Parser m a b

-- | Keep trying a parser up to a maximum of <tt>n</tt> failures. When the
--   parser fails the input consumed till now is dropped and the new
--   instance is tried on the fresh input.
--   
--   <i>Unimplemented</i>
retryMaxTotal :: Int -> Parser m a b -> Fold m b c -> Parser m a c

-- | Like <a>retryMaxTotal</a> but aborts after <tt>n</tt> successive
--   failures.
--   
--   <i>Unimplemented</i>
retryMaxSuccessive :: Int -> Parser m a b -> Fold m b c -> Parser m a c

-- | Keep trying a parser until it succeeds. When the parser fails the
--   input consumed till now is dropped and the new instance is tried on
--   the fresh input.
--   
--   <i>Unimplemented</i>
retry :: Parser m a b -> Parser m a b


-- | A newtype wrapper over the <a>Fold</a> type providing distributing
--   <a>Applicative</a>, <a>Semigroup</a>, <a>Monoid</a>, <a>Num</a>,
--   <a>Floating</a> and <a>Fractional</a> instances.
module Streamly.Internal.Data.Fold.Tee

-- | <tt>Tee</tt> is a newtype wrapper over the <a>Fold</a> type providing
--   distributing <a>Applicative</a>, <a>Semigroup</a>, <a>Monoid</a>,
--   <a>Num</a>, <a>Floating</a> and <a>Fractional</a> instances.
newtype Tee m a b
Tee :: Fold m a b -> Tee m a b
[toFold] :: Tee m a b -> Fold m a b
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Fold.Tee.Tee m a)
instance GHC.Base.Monad m => GHC.Base.Applicative (Streamly.Internal.Data.Fold.Tee.Tee m a)
instance (GHC.Base.Semigroup b, GHC.Base.Monad m) => GHC.Base.Semigroup (Streamly.Internal.Data.Fold.Tee.Tee m a b)
instance (GHC.Base.Semigroup b, GHC.Base.Monoid b, GHC.Base.Monad m) => GHC.Base.Monoid (Streamly.Internal.Data.Fold.Tee.Tee m a b)
instance (GHC.Base.Monad m, GHC.Num.Num b) => GHC.Num.Num (Streamly.Internal.Data.Fold.Tee.Tee m a b)
instance (GHC.Base.Monad m, GHC.Real.Fractional b) => GHC.Real.Fractional (Streamly.Internal.Data.Fold.Tee.Tee m a b)
instance (GHC.Base.Monad m, GHC.Float.Floating b) => GHC.Float.Floating (Streamly.Internal.Data.Fold.Tee.Tee m a b)


-- | The <a>Tee</a> type is a newtype wrapper over the <a>Fold</a> type
--   providing distributive <a>Applicative</a>, <a>Semigroup</a>,
--   <a>Monoid</a>, <a>Num</a>, <a>Floating</a> and <a>Fractional</a>
--   instances. The input received by the composed <a>Tee</a> is replicated
--   and distributed to both the constituent Tees.
--   
--   For example, to compute the average of numbers in a stream without
--   going through the stream twice:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Data.Fold.Tee (Tee(..))
--   
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Data.Fold as Fold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; avg = (/) &lt;$&gt; (Tee Fold.sum) &lt;*&gt; (Tee $ fmap fromIntegral Fold.length)
--   
--   &gt;&gt;&gt; Stream.fold (toFold avg) $ Stream.fromList [1.0..100.0]
--   50.5
--   </pre>
--   
--   Similarly, the <a>Semigroup</a> and <a>Monoid</a> instances of
--   <a>Tee</a> distribute the input to both the folds and combine the
--   outputs using Monoid or Semigroup instances of the output types:
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Monoid (Sum(..))
--   
--   &gt;&gt;&gt; t = Tee Fold.head &lt;&gt; Tee Fold.last
--   
--   &gt;&gt;&gt; Stream.fold (toFold t) (fmap Sum $ Stream.enumerateFromTo 1.0 100.0)
--   Just (Sum {getSum = 101.0})
--   </pre>
--   
--   The <a>Num</a>, <a>Floating</a>, and <a>Fractional</a> instances work
--   in the same way.
module Streamly.Data.Fold.Tee

-- | <tt>Tee</tt> is a newtype wrapper over the <a>Fold</a> type providing
--   distributing <a>Applicative</a>, <a>Semigroup</a>, <a>Monoid</a>,
--   <a>Num</a>, <a>Floating</a> and <a>Fractional</a> instances.
newtype Tee m a b
Tee :: Fold m a b -> Tee m a b
[toFold] :: Tee m a b -> Fold m a b


module Streamly.Internal.Data.Fold.Async

-- | <tt>takeInterval n fold</tt> uses <tt>fold</tt> to fold the input
--   items arriving within a window of first <tt>n</tt> seconds.
--   
--   <pre>
--   &gt;&gt;&gt; input = Stream.delay 0.1 $ Stream.fromList [1..]
--   
--   &gt;&gt;&gt; Stream.fold (Fold.takeInterval 1.0 Fold.toList) input
--   [1,2,3,4,5,6,7,8,9,10,11]
--   </pre>
--   
--   Stops when <tt>fold</tt> stops or when the timeout occurs. Note that
--   the fold needs an input after the timeout to stop. For example, if no
--   input is pushed to the fold until one hour after the timeout had
--   occurred, then the fold will be done only after consuming that input.
--   
--   <i>Pre-release</i>
takeInterval :: MonadAsync m => Double -> Fold m a b -> Fold m a b

-- | Group the input stream into windows of n second each using the first
--   fold and then fold the resulting groups using the second fold.
--   
--   <pre>
--   &gt;&gt;&gt; intervals = Fold.intervalsOf 0.5 Fold.toList Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold intervals $ Stream.delay 0.2 $ Stream.fromList [1..10]
--   [[1,2,3,4],[5,6,7],[8,9,10]]
--   </pre>
--   
--   <pre>
--   intervalsOf n split = many (takeInterval n split)
--   </pre>
--   
--   <i>Pre-release</i>
intervalsOf :: MonadAsync m => Double -> Fold m a b -> Fold m b c -> Fold m a c


-- | To run the examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Data.Fold as Fold
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
module Streamly.Internal.Data.Unfold.Type

-- | An <tt>Unfold m a b</tt> is a generator of a stream of values of type
--   <tt>b</tt> from a seed of type <tt>a</tt> in <a>Monad</a> <tt>m</tt>.
data Unfold m a b

-- | <pre>
--   Unfold step inject
--   </pre>
Unfold :: (s -> m (Step s b)) -> (a -> m s) -> Unfold m a b

-- | Make an unfold from <tt>step</tt> and <tt>inject</tt> functions.
--   
--   <i>Pre-release</i>
mkUnfoldM :: (s -> m (Step s b)) -> (a -> m s) -> Unfold m a b

-- | Make an unfold from a step function.
--   
--   See also: <a>unfoldrM</a>
--   
--   <i>Pre-release</i>
mkUnfoldrM :: Applicative m => (a -> m (Step a b)) -> Unfold m a b

-- | Build a stream by unfolding a <i>monadic</i> step function starting
--   from a seed. The step function returns the next element in the stream
--   and the next seed value. When it is done it returns <a>Nothing</a> and
--   the stream ends.
--   
--   <i>Since: 0.8.0</i>
unfoldrM :: Applicative m => (a -> m (Maybe (b, a))) -> Unfold m a b

-- | Like <a>unfoldrM</a> but uses a pure step function.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    f [] = Nothing
--    f (x:xs) = Just (x, xs)
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Unfold.fold Fold.toList (Unfold.unfoldr f) [1,2,3]
--   [1,2,3]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
unfoldr :: Applicative m => (a -> Maybe (b, a)) -> Unfold m a b

-- | Lift a monadic function into an unfold. The unfold generates a
--   singleton stream.
--   
--   <i>Since: 0.8.0</i>
functionM :: Applicative m => (a -> m b) -> Unfold m a b

-- | Lift a pure function into an unfold. The unfold generates a singleton
--   stream.
--   
--   <pre>
--   function f = functionM $ return . f
--   </pre>
--   
--   <i>Since: 0.8.0</i>
function :: Applicative m => (a -> b) -> Unfold m a b

-- | Identity unfold. The unfold generates a singleton stream having the
--   input as the only element.
--   
--   <pre>
--   identity = function Prelude.id
--   </pre>
--   
--   <i>Pre-release</i>
identity :: Applicative m => Unfold m a a

-- | The unfold discards its input and generates a function stream using
--   the supplied monadic action.
--   
--   <i>Pre-release</i>
fromEffect :: Applicative m => m b -> Unfold m a b

-- | Discards the unfold input and always returns the argument of
--   <a>fromPure</a>.
--   
--   <pre>
--   fromPure = fromEffect . pure
--   </pre>
--   
--   <i>Pre-release</i>
fromPure :: Applicative m => b -> Unfold m a b

-- | Map a function on the input argument of the <a>Unfold</a>.
--   
--   <pre>
--   &gt;&gt;&gt; u = Unfold.lmap (fmap (+1)) Unfold.fromList
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..5]
--   [2,3,4,5,6]
--   </pre>
--   
--   <pre>
--   lmap f = Unfold.many (Unfold.function f)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
lmap :: (a -> c) -> Unfold m c b -> Unfold m a b

-- | Map an action on the input argument of the <a>Unfold</a>.
--   
--   <pre>
--   lmapM f = Unfold.many (Unfold.functionM f)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
lmapM :: Monad m => (a -> m c) -> Unfold m c b -> Unfold m a b

-- | Map a function on the output of the unfold (the type <tt>b</tt>).
--   
--   <i>Pre-release</i>
map :: Functor m => (b -> c) -> Unfold m a b -> Unfold m a c

-- | Supply the seed to an unfold closing the input end of the unfold.
--   
--   <pre>
--   supply a = Unfold.lmap (Prelude.const a)
--   </pre>
--   
--   <i>Pre-release</i>
supply :: a -> Unfold m a b -> Unfold m Void b

-- | Supply the first component of the tuple to an unfold that accepts a
--   tuple as a seed resulting in a fold that accepts the second component
--   of the tuple as a seed.
--   
--   <pre>
--   supplyFirst a = Unfold.lmap (a, )
--   </pre>
--   
--   <i>Pre-release</i>
supplyFirst :: a -> Unfold m (a, b) c -> Unfold m b c

-- | Supply the second component of the tuple to an unfold that accepts a
--   tuple as a seed resulting in a fold that accepts the first component
--   of the tuple as a seed.
--   
--   <pre>
--   supplySecond b = Unfold.lmap (, b)
--   </pre>
--   
--   <i>Pre-release</i>
supplySecond :: b -> Unfold m (a, b) c -> Unfold m a c
takeWhileMWithInput :: Monad m => (a -> b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | Same as <a>takeWhile</a> but with a monadic predicate.
--   
--   <i>Since: 0.8.0</i>
takeWhileM :: Monad m => (b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | End the stream generated by the <a>Unfold</a> as soon as the predicate
--   fails on an element.
--   
--   <i>Since: 0.8.0</i>
takeWhile :: Monad m => (b -> Bool) -> Unfold m a b -> Unfold m a b
data ConcatState s1 s2
ConcatOuter :: s1 -> ConcatState s1 s2
ConcatInner :: s1 -> s2 -> ConcatState s1 s2

-- | Apply the second unfold to each output element of the first unfold and
--   flatten the output in a single stream.
--   
--   <i>Since: 0.8.0</i>
many :: Monad m => Unfold m a b -> Unfold m b c -> Unfold m a c

-- | <a>unfoldManyInterleave</a> for documentation and notes.
--   
--   This is almost identical to unfoldManyInterleave in StreamD module.
--   
--   The <a>many</a> combinator is in fact <tt>manyAppend</tt> to be more
--   explicit in naming.
--   
--   <i>Internal</i>
manyInterleave :: Monad m => Unfold m a b -> Unfold m c a -> Unfold m c b

-- | Outer product discarding the first element.
--   
--   <i>Unimplemented</i>
apSequence :: Unfold m a b -> Unfold m a c -> Unfold m a c

-- | Outer product discarding the second element.
--   
--   <i>Unimplemented</i>
apDiscardSnd :: Unfold m a b -> Unfold m a c -> Unfold m a b

-- | Create a cross product (vector product or cartesian product) of the
--   output streams of two unfolds using a monadic combining function.
--   
--   <i>Pre-release</i>
crossWithM :: Monad m => (b -> c -> m d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | Like <a>crossWithM</a> but uses a pure combining function.
--   
--   <pre>
--   crossWith f = crossWithM (\b c -&gt; return $ f b c)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; u1 = Unfold.lmap fst Unfold.fromList
--   
--   &gt;&gt;&gt; u2 = Unfold.lmap snd Unfold.fromList
--   
--   &gt;&gt;&gt; u = Unfold.crossWith (,) u1 u2
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u ([1,2,3], [4,5,6])
--   [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
crossWith :: Monad m => (b -> c -> d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | See <a>crossWith</a>.
--   
--   <pre>
--   cross = crossWith (,)
--   </pre>
--   
--   To cross the streams from a tuple we can write:
--   
--   <pre>
--   crossProduct :: Monad m =&gt; Unfold m a b -&gt; Unfold m c d -&gt; Unfold m (a, c) (b, d)
--   crossProduct u1 u2 = cross (lmap fst u1) (lmap snd u2)
--   </pre>
--   
--   <i>Pre-release</i>
cross :: Monad m => Unfold m a b -> Unfold m a c -> Unfold m a (b, c)
apply :: Monad m => Unfold m a (b -> c) -> Unfold m a b -> Unfold m a c

-- | Map an unfold generating action to each element of an unfold and
--   flatten the results into a single stream.
concatMapM :: Monad m => (b -> m (Unfold m a c)) -> Unfold m a b -> Unfold m a c
concatMap :: Monad m => (b -> Unfold m a c) -> Unfold m a b -> Unfold m a c
bind :: Monad m => Unfold m a b -> (b -> Unfold m a c) -> Unfold m a c
infixl 1 `bind`

-- | Distribute the input to two unfolds and then zip the outputs to a
--   single stream using a monadic zip function.
--   
--   Stops as soon as any of the unfolds stops.
--   
--   <i>Pre-release</i>
zipWithM :: Monad m => (b -> c -> m d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | Like <a>zipWithM</a> but with a pure zip function.
--   
--   <pre>
--   &gt;&gt;&gt; square = fmap (\x -&gt; x * x) Unfold.fromList
--   
--   &gt;&gt;&gt; cube = fmap (\x -&gt; x * x * x) Unfold.fromList
--   
--   &gt;&gt;&gt; u = Unfold.zipWith (,) square cube
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..5]
--   [(1,1),(4,8),(9,27),(16,64),(25,125)]
--   </pre>
--   
--   <pre>
--   zipWith f = zipWithM (\a b -&gt; return $ f a b)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
zipWith :: Monad m => (b -> c -> d) -> Unfold m a b -> Unfold m a c -> Unfold m a d
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Unfold.Type.Unfold m a)


-- | The functions defined in this module should be rarely needed for
--   direct use, try to use the operations from the <a>Enumerable</a> type
--   class instances instead.
--   
--   This module provides an <a>Enumerable</a> type class to enumerate
--   <a>Enum</a> types into a stream. The operations in this type class
--   correspond to similar operations in the <a>Enum</a> type class, the
--   only difference is that they produce a stream instead of a list. These
--   operations cannot be defined generically based on the <a>Enum</a> type
--   class. We provide instances for commonly used types. If instances for
--   other types are needed convenience functions defined in this module
--   can be used to define them. Alternatively, these functions can be used
--   directly.
module Streamly.Internal.Data.Unfold.Enumeration

-- | Types that can be enumerated as a stream. The operations in this type
--   class are equivalent to those in the <a>Enum</a> type class, except
--   that these generate a stream instead of a list. Use the functions in
--   <a>Streamly.Internal.Data.Unfold.Enumeration</a> module to define new
--   instances.
--   
--   <i>Pre-release</i>
class Enum a => Enumerable a

-- | Unfolds <tt>from</tt> generating a stream starting with the element
--   <tt>from</tt>, enumerating up to <a>maxBound</a> when the type is
--   <a>Bounded</a> or generating an infinite stream when the type is not
--   <a>Bounded</a>.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFrom (0 :: Int)
--   [0,1,2,3]
--   </pre>
--   
--   For <a>Fractional</a> types, enumeration is numerically stable.
--   However, no overflow or underflow checks are performed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFrom 1.1
--   [1.1,2.1,3.1,4.1]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFrom :: (Enumerable a, Monad m) => Unfold m a a

-- | Unfolds <tt>(from, to)</tt> generating a finite stream starting with
--   the element <tt>from</tt>, enumerating the type up to the value
--   <tt>to</tt>. If <tt>to</tt> is smaller than <tt>from</tt> then an
--   empty stream is returned.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromTo (0, 4)
--   [0,1,2,3,4]
--   </pre>
--   
--   For <a>Fractional</a> types, the last element is equal to the
--   specified <tt>to</tt> value after rounding to the nearest integral
--   value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromTo (1.1, 4)
--   [1.1,2.1,3.1,4.1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromTo (1.1, 4.6)
--   [1.1,2.1,3.1,4.1,5.1]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFromTo :: (Enumerable a, Monad m) => Unfold m (a, a) a

-- | Unfolds <tt>(from, then)</tt> generating a stream whose first element
--   is <tt>from</tt> and the successive elements are in increments of
--   <tt>then</tt>. Enumeration can occur downwards or upwards depending on
--   whether <tt>then</tt> comes before or after <tt>from</tt>. For
--   <a>Bounded</a> types the stream ends when <a>maxBound</a> is reached,
--   for unbounded types it keeps enumerating infinitely.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFromThen (0, 2)
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFromThen (0,(-2))
--   [0,-2,-4,-6]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFromThen :: (Enumerable a, Monad m) => Unfold m (a, a) a

-- | Unfolds <tt>(from, then, to)</tt> generating a finite stream whose
--   first element is <tt>from</tt> and the successive elements are in
--   increments of <tt>then</tt> up to <tt>to</tt>. Enumeration can occur
--   downwards or upwards depending on whether <tt>then</tt> comes before
--   or after <tt>from</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromThenTo (0, 2, 6)
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromThenTo (0, (-2), (-6))
--   [0,-2,-4,-6]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFromThenTo :: (Enumerable a, Monad m) => Unfold m (a, a, a) a

-- | Unfolds <tt>(from, stride)</tt> generating an infinite stream starting
--   from <tt>from</tt> and incrementing every time by <tt>stride</tt>. For
--   <a>Bounded</a> types, after the value overflows it keeps enumerating
--   in a cycle:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 10 $ Stream.unfold Unfold.enumerateFromStepNum (255::Word8,1)
--   [255,0,1,2,3,4,5,6,7,8]
--   </pre>
--   
--   The implementation is numerically stable for floating point values.
--   
--   Note <a>enumerateFromStepIntegral</a> is faster for integrals.
--   
--   <i>Internal</i>
enumerateFromStepNum :: (Monad m, Num a) => Unfold m (a, a) a

-- | Same as <a>enumerateFromStepNum</a> using a stride of 1:
--   
--   <pre>
--   &gt;&gt;&gt; enumerateFromNum = lmap (from -&gt; (from, 1)) Unfold.enumerateFromStepNum
--   &gt;&gt;&gt; Stream.toList $ Stream.take 6 $ Stream.unfold enumerateFromNum (0.9)
--   [0.9,1.9,2.9,3.9,4.9,5.9]
--   </pre>
--   
--   Also, same as <a>enumerateFromThenNum</a> using a stride of 1 but see
--   the note in <a>enumerateFromThenNum</a> about the loss of precision:
--   
--   <pre>
--   &gt;&gt;&gt; enumerateFromNum = lmap (from -&gt; (from, from + 1)) Unfold.enumerateFromThenNum
--   &gt;&gt;&gt; Stream.toList $ Stream.take 6 $ Stream.unfold enumerateFromNum (0.9)
--   [0.9,1.9,2.9,3.8999999999999995,4.8999999999999995,5.8999999999999995]
--   </pre>
--   
--   <i>Internal</i>
enumerateFromNum :: (Monad m, Num a) => Unfold m a a

-- | Same as 'enumerateFromStepNum (from, next)' using a stride of <tt>next
--   - from</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; enumerateFromThenNum = lmap ((from, next) -&gt; (from, next - from)) Unfold.enumerateFromStepNum
--   </pre>
--   
--   Example: @ &gt;&gt;&gt; Stream.toList $ Stream.take 10 $ Stream.unfold
--   enumerateFromThenNum (255::Word8,0) [255,0,1,2,3,4,5,6,7,8]
--   
--   <pre>
--   The implementation is numerically stable for floating point values.
--   
--   Note that <a>enumerateFromThenIntegral</a> is faster for integrals.
--   
--   Note that in the strange world of floating point numbers, using
--   </pre>
--   
--   enumerateFromThenNum (from, from + 1)<tt> is almost exactly the same
--   as </tt>enumerateFromStepNum (from, 1) but not precisely the same.
--   Because <tt>(from + 1) - from</tt> is not exactly 1, it may lose some
--   precision, the loss may also be aggregated in each step, if you want
--   that precision then use <a>enumerateFromStepNum</a> instead.
--   
--   <i>Internal</i>
enumerateFromThenNum :: (Monad m, Num a) => Unfold m (a, a) a

-- | Can be used to enumerate unbounded integrals. This does not check for
--   overflow or underflow for bounded integrals.
--   
--   <i>Internal</i>
enumerateFromStepIntegral :: (Monad m, Integral a) => Unfold m (a, a) a
enumerateFromIntegral :: (Monad m, Integral a) => Unfold m a a
enumerateFromThenIntegral :: (Monad m, Integral a) => Unfold m (a, a) a
enumerateFromToIntegral :: (Monad m, Integral a) => Unfold m (a, a) a
enumerateFromThenToIntegral :: (Monad m, Integral a) => Unfold m (a, a, a) a
enumerateFromIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m a a
enumerateFromThenIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m (a, a) a
enumerateFromToIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m (a, a) a
enumerateFromThenToIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m (a, a, a) a

-- | Enumerate from given starting Enum value <tt>from</tt> with stride of
--   1 till maxBound
--   
--   <i>Internal</i>
enumerateFromSmallBounded :: (Monad m, Enum a, Bounded a) => Unfold m a a

-- | Enumerate from given starting Enum value <tt>from</tt> and next Enum
--   value <tt>next</tt> with stride of (fromEnum next - fromEnum from)
--   till maxBound.
--   
--   <i>Internal</i>
enumerateFromThenSmallBounded :: forall m a. (Monad m, Enum a, Bounded a) => Unfold m (a, a) a

-- | Enumerate from given starting Enum value <tt>from</tt> and to Enum
--   value <tt>to</tt> with stride of 1 till to value.
--   
--   <i>Internal</i>
enumerateFromToSmall :: (Monad m, Enum a) => Unfold m (a, a) a

-- | Enumerate from given starting Enum value <tt>from</tt> and then Enum
--   value <tt>next</tt> and to Enum value <tt>to</tt> with stride of
--   (fromEnum next - fromEnum from) till to value.
--   
--   <i>Internal</i>
enumerateFromThenToSmall :: (Monad m, Enum a) => Unfold m (a, a, a) a
enumerateFromFractional :: (Monad m, Fractional a) => Unfold m a a
enumerateFromThenFractional :: (Monad m, Fractional a) => Unfold m (a, a) a

-- | Same as <a>enumerateFromStepNum</a> with a step of 1 and enumerating
--   up to the specified upper limit rounded to the nearest integral value:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromToFractional (0.1, 6.3)
--   [0.1,1.1,2.1,3.1,4.1,5.1,6.1]
--   </pre>
--   
--   <i>Internal</i>
enumerateFromToFractional :: (Monad m, Fractional a, Ord a) => Unfold m (a, a) a
enumerateFromThenToFractional :: (Monad m, Fractional a, Ord a) => Unfold m (a, a, a) a
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable ()
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Types.Bool
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Types.Ordering
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Types.Char
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Types.Int
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Int.Int8
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Int.Int16
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Int.Int32
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Int.Int64
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Types.Word
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Word.Word8
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Word.Word16
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Word.Word32
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Word.Word64
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Num.Integer.Integer
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Num.Natural.Natural
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Types.Float
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable GHC.Types.Double
instance Data.Fixed.HasResolution a => Streamly.Internal.Data.Unfold.Enumeration.Enumerable (Data.Fixed.Fixed a)
instance GHC.Real.Integral a => Streamly.Internal.Data.Unfold.Enumeration.Enumerable (GHC.Real.Ratio a)
instance Streamly.Internal.Data.Unfold.Enumeration.Enumerable a => Streamly.Internal.Data.Unfold.Enumeration.Enumerable (Data.Functor.Identity.Identity a)


module Streamly.Internal.Data.Stream.StreamD.Type

-- | A stream is a succession of <a>Step</a>s. A <a>Yield</a> produces a
--   single value and the next state of the stream. <a>Stop</a> indicates
--   there are no more values in the stream.
data Step s a
Yield :: a -> s -> Step s a
Skip :: s -> Step s a
Stop :: Step s a

-- | A stream consists of a step function that generates the next step
--   given a current state, and the current state.
data Stream m a
UnStream :: (State Stream m a -> s -> m (Step s a)) -> s -> Stream m a
pattern Stream :: (State Stream m a -> s -> m (Step s a)) -> s -> Stream m a

-- | An empty <a>Stream</a> with a side effect.
nilM :: Applicative m => m b -> Stream m a
consM :: Applicative m => m a -> Stream m a -> Stream m a

-- | Does not fuse, has the same performance as the StreamK version.
uncons :: Monad m => Stream m a -> m (Maybe (a, Stream m a))

-- | Convert an <a>Unfold</a> into a <a>Stream</a> by supplying it a seed.
unfold :: Applicative m => Unfold m a b -> a -> Stream m b

-- | Create a singleton <a>Stream</a> from a pure value.
fromPure :: Applicative m => a -> Stream m a

-- | Create a singleton <a>Stream</a> from a monadic action.
fromEffect :: Applicative m => m a -> Stream m a

-- | Convert a list of pure values to a <a>Stream</a>
fromList :: Applicative m => [a] -> Stream m a

-- | Convert a CPS encoded StreamK to direct style step encoded StreamD
fromStreamK :: Applicative m => Stream m a -> Stream m a

-- | Convert a direct style step encoded StreamD to a CPS encoded StreamK
toStreamK :: Monad m => Stream m a -> Stream m a
fold :: Monad m => Fold m a b -> Stream m a -> m b
fold_ :: Monad m => Fold m a b -> Stream m a -> m (b, Stream m a)
foldOn :: Monad m => Fold m a b -> Stream m a -> Fold m a b
foldrT :: (Monad m, Monad (t m), MonadTrans t) => (a -> t m b -> t m b) -> t m b -> Stream m a -> t m b
foldrM :: Monad m => (a -> m b -> m b) -> m b -> Stream m a -> m b
foldrMx :: Monad m => (a -> m x -> m x) -> m x -> (m x -> m b) -> Stream m a -> m b
foldr :: Monad m => (a -> b -> b) -> b -> Stream m a -> m b
foldrS :: Monad m => (a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
foldl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> m b
foldlM' :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> m b
foldlx' :: Monad m => (x -> a -> x) -> x -> (x -> b) -> Stream m a -> m b
foldlMx' :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> Stream m a -> m b

-- | Run a streaming composition, discard the results.
drain :: Monad m => Stream m a -> m ()
toList :: Monad m => Stream m a -> m [a]
eqBy :: Monad m => (a -> b -> Bool) -> Stream m a -> Stream m b -> m Bool

-- | Compare two streams lexicographically
cmpBy :: Monad m => (a -> b -> Ordering) -> Stream m a -> Stream m b -> m Ordering
map :: Monad m => (a -> b) -> Stream m a -> Stream m b

-- | Map a monadic function over a <a>Stream</a>
mapM :: Monad m => (a -> m b) -> Stream m a -> Stream m b
take :: Applicative m => Int -> Stream m a -> Stream m a
takeWhile :: Monad m => (a -> Bool) -> Stream m a -> Stream m a
takeWhileM :: Monad m => (a -> m Bool) -> Stream m a -> Stream m a
data ConcatMapUState o i
ConcatMapUOuter :: o -> ConcatMapUState o i
ConcatMapUInner :: o -> i -> ConcatMapUState o i

-- | <tt>unfoldMany unfold stream</tt> uses <tt>unfold</tt> to map the
--   input stream elements to streams and then flattens the generated
--   streams into a single output stream.
unfoldMany :: Monad m => Unfold m a b -> Stream m a -> Stream m b
concatMap :: Monad m => (a -> Stream m b) -> Stream m a -> Stream m b
concatMapM :: Monad m => (a -> m (Stream m b)) -> Stream m a -> Stream m b
data FoldMany s fs b a
FoldManyStart :: s -> FoldMany s fs b a
FoldManyFirst :: fs -> s -> FoldMany s fs b a
FoldManyLoop :: s -> fs -> FoldMany s fs b a
FoldManyYield :: b -> FoldMany s fs b a -> FoldMany s fs b a
FoldManyDone :: FoldMany s fs b a
data FoldManyPost s fs b a
FoldManyPostStart :: s -> FoldManyPost s fs b a
FoldManyPostLoop :: s -> fs -> FoldManyPost s fs b a
FoldManyPostYield :: b -> FoldManyPost s fs b a -> FoldManyPost s fs b a
FoldManyPostDone :: FoldManyPost s fs b a

-- | Apply a fold multiple times until the stream ends. If the stream is
--   empty the output would be empty.
--   
--   <pre>
--   foldMany f = parseMany (fromFold f)
--   </pre>
--   
--   A terminating fold may terminate even without accepting a single
--   input. So we run the fold's initial action before evaluating the
--   stream. However, this means that if later the stream does not yield
--   anything we have to discard the fold's initial result which could have
--   generated an effect.
foldMany :: Monad m => Fold m a b -> Stream m a -> Stream m b

-- | Like foldMany but with the following differences:
--   
--   <ul>
--   <li>If the stream is empty the default value of the fold would still
--   be emitted in the output.</li>
--   <li>At the end of the stream if the last application of the fold did
--   not receive any input it would still yield the default fold
--   accumulator as the last value.</li>
--   </ul>
foldManyPost :: Monad m => Fold m a b -> Stream m a -> Stream m b

-- | Like <a>foldMany</a> but for the <a>Refold</a> type. The supplied
--   action is used as the initial value for each refold.
--   
--   <i>Internal</i>
refoldMany :: Monad m => Refold m x a b -> m x -> Stream m a -> Stream m b
chunksOf :: Monad m => Int -> Fold m a b -> Stream m a -> Stream m b
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Stream.StreamD.Type.Stream m)
instance GHC.Base.Applicative f => GHC.Base.Applicative (Streamly.Internal.Data.Stream.StreamD.Type.Stream f)
instance GHC.Base.Monad m => GHC.Base.Monad (Streamly.Internal.Data.Stream.StreamD.Type.Stream m)
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.StreamD.Type.Stream
instance Control.Monad.Catch.MonadThrow m => Control.Monad.Catch.MonadThrow (Streamly.Internal.Data.Stream.StreamD.Type.Stream m)


-- | Transform the underlying monad of a stream.
module Streamly.Internal.Data.Stream.StreamD.Lift
hoist :: Monad n => (forall x. m x -> n x) -> Stream m a -> Stream n a
generally :: Monad m => Stream Identity a -> Stream m a
liftInner :: (Monad m, MonadTrans t, Monad (t m)) => Stream m a -> Stream (t m) a
runReaderT :: Monad m => m s -> Stream (ReaderT s m) a -> Stream m a
evalStateT :: Monad m => m s -> Stream (StateT s m) a -> Stream m a
runStateT :: Monad m => m s -> Stream (StateT s m) a -> Stream m (s, a)


module Streamly.Internal.Data.Stream.StreamD.Exception

-- | Like <a>gbracket</a> but with following differences:
--   
--   <ul>
--   <li>alloc action <tt>m c</tt> runs with async exceptions enabled</li>
--   <li>cleanup action <tt>c -&gt; m d</tt> won't run if the stream is
--   garbage collected after partial evaluation.</li>
--   <li>does not require a <a>MonadAsync</a> constraint.</li>
--   </ul>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
gbracket_ :: Monad m => m c -> (forall s. m s -> m (Either e s)) -> (c -> m d) -> (c -> e -> Stream m b -> Stream m b) -> (c -> Stream m b) -> Stream m b

-- | Run the alloc action <tt>m c</tt> with async exceptions disabled but
--   keeping blocking operations interruptible (see <a>mask</a>). Use the
--   output <tt>c</tt> as input to <tt>c -&gt; Stream m b</tt> to generate
--   an output stream. When generating the stream use the supplied
--   <tt>try</tt> operation <tt>forall s. m s -&gt; m (Either e s)</tt> to
--   catch synchronous exceptions. If an exception occurs run the exception
--   handler <tt>c -&gt; e -&gt; Stream m b -&gt; m (Stream m b)</tt>. Note
--   that <a>gbracket</a> does not rethrow the exception, it has to be done
--   by the exception handler if desired.
--   
--   The cleanup action <tt>c -&gt; m d</tt>, runs whenever the stream ends
--   normally, due to a sync or async exception or if it gets garbage
--   collected after a partial lazy evaluation. See <tt>bracket</tt> for
--   the semantics of the cleanup action.
--   
--   <a>gbracket</a> can express all other exception handling combinators.
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
gbracket :: (MonadIO m, MonadBaseControl IO m) => m c -> (forall s. m s -> m (Either e s)) -> (c -> m d1) -> (c -> m d2) -> (c -> e -> Stream m b -> m (Stream m b)) -> (c -> Stream m b) -> Stream m b

-- | See <a>before</a>.
before :: Monad m => m b -> Stream m a -> Stream m a

-- | See <a>after_</a>.
after_ :: Monad m => m b -> Stream m a -> Stream m a

-- | See <a>after</a>.
after :: (MonadIO m, MonadBaseControl IO m) => m b -> Stream m a -> Stream m a

-- | See <a>bracket_</a>.
bracket_ :: MonadCatch m => m b -> (b -> m c) -> (b -> Stream m a) -> Stream m a

-- | See <a>bracket</a>.
bracket' :: (MonadAsync m, MonadCatch m) => m b -> (b -> m c) -> (b -> m d) -> (b -> m e) -> (b -> Stream m a) -> Stream m a

-- | See <a>onException</a>.
onException :: MonadCatch m => m b -> Stream m a -> Stream m a

-- | See <a>finally_</a>.
finally_ :: MonadCatch m => m b -> Stream m a -> Stream m a

-- | See <a>finally</a>.
--   
--   finally action xs = after action $ onException action xs
finally :: (MonadAsync m, MonadCatch m) => m b -> Stream m a -> Stream m a

-- | See <a>ghandle</a>.
ghandle :: (MonadCatch m, Exception e) => (e -> Stream m a -> Stream m a) -> Stream m a -> Stream m a

-- | See <a>handle</a>.
handle :: (MonadCatch m, Exception e) => (e -> Stream m a) -> Stream m a -> Stream m a

-- | See <a>retry</a>
retry :: forall e m a. (Exception e, Ord e, MonadCatch m) => Map e Int -> (e -> Stream m a) -> Stream m a -> Stream m a


-- | Low level functions using StreamK as the intermediate stream type.
--   These functions are used in SerialT<i>AsyncT</i>AheadT/ParallelT
--   stream modules to implement their instances..
module Streamly.Internal.Data.Stream.Prelude
drain :: Monad m => Stream m a -> m ()

-- | <pre>
--   fromList = <a>foldr</a> <a>cons</a> <a>nil</a>
--   </pre>
--   
--   Construct a stream from a list of pure values. This is more efficient
--   than <a>fromFoldable</a> for serial streams.
fromList :: Monad m => [a] -> Stream m a

-- | Convert a stream into a list in the underlying monad.
toList :: Monad m => Stream m a -> m [a]
foldrM :: Monad m => (a -> m b -> m b) -> m b -> Stream m a -> m b
foldrMx :: Monad m => (a -> m x -> m x) -> m x -> (m x -> m b) -> Stream m a -> m b
foldr :: Monad m => (a -> b -> b) -> b -> Stream m a -> m b

-- | Strict left fold with an extraction function. Like the standard strict
--   left fold, but applies a user supplied extraction function (the third
--   argument) to the folded value at the end. This is designed to work
--   with the <tt>foldl</tt> library. The suffix <tt>x</tt> is a mnemonic
--   for extraction.
foldlx' :: Monad m => (x -> a -> x) -> x -> (x -> b) -> Stream m a -> m b

-- | Like <a>foldlx'</a>, but with a monadic step function.
foldlMx' :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> Stream m a -> m b

-- | Strict left associative fold.
foldl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> m b
fold :: Monad m => Fold m a b -> Stream m a -> m b

-- | Compare two streams for equality
eqBy :: Monad m => (a -> b -> Bool) -> Stream m a -> Stream m b -> m Bool

-- | Compare two streams
cmpBy :: Monad m => (a -> b -> Ordering) -> Stream m a -> Stream m b -> m Ordering


-- | A mutable variable in a mutation capable monad (IO) holding a
--   <a>Prim</a> value. This allows fast modification because of unboxed
--   storage.
--   
--   <h1>Multithread Consistency Notes</h1>
--   
--   In general, any value that straddles a machine word cannot be
--   guaranteed to be consistently read from another thread without a lock.
--   GHC heap objects are always machine word aligned, therefore, a
--   <a>IORef</a> is also word aligned. On a 64-bit platform, writing a
--   64-bit aligned type from one thread and reading it from another thread
--   should give consistent old or new value. The same holds true for
--   32-bit values on a 32-bit platform.
module Streamly.Internal.Data.IORef.Prim

-- | An <a>IORef</a> holds a single <a>Prim</a> value.
data IORef a

-- | Class of types supporting primitive array operations. This includes
--   interfacing with GC-managed memory (functions suffixed with
--   <tt>ByteArray#</tt>) and interfacing with unmanaged memory (functions
--   suffixed with <tt>Addr#</tt>). Endianness is platform-dependent.
class Prim a

-- | Create a new <a>IORef</a>.
--   
--   <i>Pre-release</i>
newIORef :: forall a. Prim a => a -> IO (IORef a)

-- | Write a value to an <a>IORef</a>.
--   
--   <i>Pre-release</i>
writeIORef :: Prim a => IORef a -> a -> IO ()

-- | Modify the value of an <a>IORef</a> using a function with strict
--   application.
--   
--   <i>Pre-release</i>
modifyIORef' :: Prim a => IORef a -> (a -> a) -> IO ()

-- | Read a value from an <a>IORef</a>.
--   
--   <i>Pre-release</i>
readIORef :: Prim a => IORef a -> IO a

-- | Generate a stream by continuously reading the IORef.
--   
--   <i>Pre-release</i>
toStreamD :: (MonadIO m, Prim a) => IORef a -> Stream m a


module Streamly.Internal.Data.Time.Clock

-- | Clock types. A clock may be system-wide (that is, visible to all
--   processes) or per-process (measuring time that is meaningful only
--   within a process). All implementations shall support CLOCK_REALTIME.
--   (The only suspend-aware monotonic is CLOCK_BOOTTIME on Linux.)
data Clock

-- | The identifier for the system-wide monotonic clock, which is defined
--   as a clock measuring real time, whose value cannot be set via
--   <tt>clock_settime</tt> and which cannot have negative clock jumps. The
--   maximum possible clock jump shall be implementation defined. For this
--   clock, the value returned by <a>getTime</a> represents the amount of
--   time (in seconds and nanoseconds) since an unspecified point in the
--   past (for example, system start-up time, or the Epoch). This point
--   does not change after system start-up time. Note that the absolute
--   value of the monotonic clock is meaningless (because its origin is
--   arbitrary), and thus there is no need to set it. Furthermore, realtime
--   applications can rely on the fact that the value of this clock is
--   never set.
Monotonic :: Clock

-- | The identifier of the system-wide clock measuring real time. For this
--   clock, the value returned by <a>getTime</a> represents the amount of
--   time (in seconds and nanoseconds) since the Epoch.
Realtime :: Clock

-- | The identifier of the CPU-time clock associated with the calling
--   process. For this clock, the value returned by <a>getTime</a>
--   represents the amount of execution time of the current process.
ProcessCPUTime :: Clock

-- | The identifier of the CPU-time clock associated with the calling OS
--   thread. For this clock, the value returned by <a>getTime</a>
--   represents the amount of execution time of the current OS thread.
ThreadCPUTime :: Clock

-- | (since Linux 2.6.28; Linux and Mac OSX) Similar to CLOCK_MONOTONIC,
--   but provides access to a raw hardware-based time that is not subject
--   to NTP adjustments or the incremental adjustments performed by
--   adjtime(3).
MonotonicRaw :: Clock

-- | (since Linux 2.6.32; Linux and Mac OSX) A faster but less precise
--   version of CLOCK_MONOTONIC. Use when you need very fast, but not
--   fine-grained timestamps.
MonotonicCoarse :: Clock

-- | (since Linux 2.6.39; Linux and Mac OSX) Identical to CLOCK_MONOTONIC,
--   except it also includes any time that the system is suspended. This
--   allows applications to get a suspend-aware monotonic clock without
--   having to deal with the complications of CLOCK_REALTIME, which may
--   have discontinuities if the time is changed using settimeofday(2).
Uptime :: Clock

-- | (since Linux 2.6.32; Linux-specific) A faster but less precise version
--   of CLOCK_REALTIME. Use when you need very fast, but not fine-grained
--   timestamps.
RealtimeCoarse :: Clock
getTime :: Clock -> IO AbsTime

-- | <tt>asyncClock g</tt> starts a clock thread that updates an IORef with
--   current time as a 64-bit value in microseconds, every <tt>g</tt>
--   seconds. The IORef can be read asynchronously. The thread exits
--   automatically when the reference to the returned <a>ThreadId</a> is
--   lost.
--   
--   Minimum granularity of clock update is 1 ms. Higher is better for
--   performance.
--   
--   CAUTION! This is safe only on a 64-bit machine. On a 32-bit machine a
--   64-bit <tt>Var</tt> cannot be read consistently without a lock while
--   another thread is writing to it.
asyncClock :: Clock -> Double -> IO (ThreadId, IORef MicroSecond64)
readClock :: (ThreadId, IORef MicroSecond64) -> IO MicroSecond64


-- | Prefer unfolds (<a>Streamly.Internal.Data.Unfold</a>) over the
--   combinators in this module. They are more powerful and efficient as
--   they can be transformed and composed on the input side efficiently and
--   they can fuse in nested operations (e.g. unfoldMany). All the
--   combinators in this module can be expressed using unfolds with the
--   same efficiency.
--   
--   Operations in this module that are not in
--   <a>Streamly.Internal.Data.Unfold</a>: generate, times, fromPrimIORef.
--   
--   We should plan to replace this module with
--   <a>Streamly.Internal.Data.Unfold</a> in future.
module Streamly.Internal.Data.Stream.StreamD.Generate

-- | An empty <a>Stream</a>.
nil :: Monad m => Stream m a

-- | An empty <a>Stream</a> with a side effect.
nilM :: Applicative m => m b -> Stream m a

-- | Can fuse but has O(n^2) complexity.
cons :: Monad m => a -> Stream m a -> Stream m a
consM :: Applicative m => m a -> Stream m a -> Stream m a

-- | Convert an <a>Unfold</a> into a <a>Stream</a> by supplying it a seed.
unfold :: Applicative m => Unfold m a b -> a -> Stream m b
unfoldr :: Monad m => (s -> Maybe (a, s)) -> s -> Stream m a
unfoldrM :: Monad m => (s -> m (Maybe (a, s))) -> s -> Stream m a

-- | Create a singleton <a>Stream</a> from a pure value.
fromPure :: Applicative m => a -> Stream m a

-- | Create a singleton <a>Stream</a> from a monadic action.
fromEffect :: Applicative m => m a -> Stream m a
repeat :: Monad m => a -> Stream m a
repeatM :: Monad m => m a -> Stream m a
replicate :: Monad m => Int -> a -> Stream m a
replicateM :: forall m a. Monad m => Int -> m a -> Stream m a

-- | Can be used to enumerate unbounded integrals. This does not check for
--   overflow or underflow for bounded integrals.
enumerateFromStepIntegral :: (Integral a, Monad m) => a -> a -> Stream m a
enumerateFromIntegral :: (Monad m, Integral a, Bounded a) => a -> Stream m a
enumerateFromThenIntegral :: (Monad m, Integral a, Bounded a) => a -> a -> Stream m a

-- | Enumerate upwards from <tt>from</tt> to <tt>to</tt>. We are assuming
--   that "to" is constrained by the type to be within max/min bounds.
enumerateFromToIntegral :: (Monad m, Integral a) => a -> a -> Stream m a
enumerateFromThenToIntegral :: (Monad m, Integral a) => a -> a -> a -> Stream m a

-- | For floating point numbers if the increment is less than the precision
--   then it just gets lost. Therefore we cannot always increment it
--   correctly by just repeated addition. 9007199254740992 + 1 + 1 ::
--   Double =&gt; 9.007199254740992e15 9007199254740992 + 2 :: Double =&gt;
--   9.007199254740994e15
--   
--   Instead we accumulate the increment counter and compute the increment
--   every time before adding it to the starting number.
--   
--   This works for Integrals as well as floating point numbers, but
--   enumerateFromStepIntegral is faster for integrals.
enumerateFromStepNum :: (Monad m, Num a) => a -> a -> Stream m a
enumerateFromNum :: (Monad m, Num a) => a -> Stream m a
enumerateFromThenNum :: (Monad m, Num a) => a -> a -> Stream m a

-- | We cannot write a general function for Num. The only way to write code
--   portable between the two is to use a <a>Real</a> constraint and
--   convert between Fractional and Integral using fromRational which is
--   horribly slow.
enumerateFromToFractional :: (Monad m, Fractional a, Ord a) => a -> a -> Stream m a
enumerateFromThenToFractional :: (Monad m, Fractional a, Ord a) => a -> a -> a -> Stream m a
times :: MonadAsync m => Double -> Stream m (AbsTime, RelTime64)
fromIndices :: Monad m => (Int -> a) -> Stream m a
fromIndicesM :: Monad m => (Int -> m a) -> Stream m a
generate :: Monad m => Int -> (Int -> a) -> Stream m a
generateM :: Monad m => Int -> (Int -> m a) -> Stream m a
iterate :: Monad m => (a -> a) -> a -> Stream m a
iterateM :: Monad m => (a -> m a) -> m a -> Stream m a

-- | Convert a list of pure values to a <a>Stream</a>
fromList :: Applicative m => [a] -> Stream m a

-- | Convert a list of monadic actions to a <a>Stream</a>
fromListM :: MonadAsync m => [m a] -> Stream m a

-- | Convert a CPS encoded StreamK to direct style step encoded StreamD
fromStreamK :: Applicative m => Stream m a -> Stream m a

-- | Convert a direct style step encoded StreamD to a CPS encoded StreamK
toStreamK :: Monad m => Stream m a -> Stream m a


-- | To run examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   </pre>
module Streamly.Internal.Data.Stream.Serial

-- | For <a>SerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>serial</a> -- <a>Monad</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(1,4),(2,3),(2,4)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
newtype SerialT m a
SerialT :: Stream m a -> SerialT m a
[getSerialT] :: SerialT m a -> Stream m a

-- | A serial IO stream of elements of type <tt>a</tt>. See <a>SerialT</a>
--   documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Serial = SerialT IO
serial :: SerialT m a -> SerialT m a -> SerialT m a

-- | For <a>WSerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wSerial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wSerial</a> -- <a>Monad</a>
--   </pre>
--   
--   Note that <a>&lt;&gt;</a> is associative only if we disregard the
--   ordering of elements in the resulting stream.
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like interleaved nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   It is a result of interleaving all the nested iterations corresponding
--   to element <tt>1</tt> in the first stream with all the nested
--   iterations of element <tt>2</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromList [(1,3),(1,4)] `Stream.wSerial` Stream.fromList [(2,3),(2,4)]
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>SerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
newtype WSerialT m a
WSerialT :: Stream m a -> WSerialT m a
[getWSerialT] :: WSerialT m a -> Stream m a

-- | An interleaving serial IO stream of elements of type <tt>a</tt>. See
--   <a>WSerialT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WSerial = WSerialT IO
wSerialK :: Stream m a -> Stream m a -> Stream m a

-- | Interleaves two streams, yielding one element from each stream
--   alternately. When one stream stops the rest of the other stream is
--   used in the output stream.
wSerial :: WSerialT m a -> WSerialT m a -> WSerialT m a
infixr 6 `wSerial`
wSerialFst :: WSerialT m a -> WSerialT m a -> WSerialT m a
wSerialMin :: WSerialT m a -> WSerialT m a -> WSerialT m a
consMWSerial :: Monad m => m a -> WSerialT m a -> WSerialT m a
cons :: a -> SerialT m a -> SerialT m a
consM :: Monad m => m a -> SerialT m a -> SerialT m a

-- | Generate an infinite stream by repeating a pure value.
repeat :: Monad m => a -> SerialT m a

-- | Build a stream by unfolding a <i>monadic</i> step function starting
--   from a seed. The step function returns the next element in the stream
--   and the next seed value. When it is done it returns <a>Nothing</a> and
--   the stream ends. For example,
--   
--   <pre>
--   let f b =
--           if b &gt; 3
--           then return Nothing
--           else print b &gt;&gt; return (Just (b, b + 1))
--   in drain $ unfoldrM f 0
--   </pre>
--   
--   <pre>
--   0
--   1
--   2
--   3
--   </pre>
--   
--   <i>Pre-release</i>
unfoldrM :: Monad m => (b -> m (Maybe (a, b))) -> b -> SerialT m a

-- | The <a>fromList</a> function constructs the structure <tt>l</tt> from
--   the given list of <tt>Item l</tt>
fromList :: IsList l => [Item l] -> l

-- | The <a>toList</a> function extracts a list of <tt>Item l</tt> from the
--   structure <tt>l</tt>. It should satisfy fromList . toList = id.
toList :: IsList l => l -> [Item l]

-- | <pre>
--   map = fmap
--   </pre>
--   
--   Same as <a>fmap</a>.
--   
--   <pre>
--   &gt; S.toList $ S.map (+1) $ S.fromList [1,2,3]
--   [2,3,4]
--   </pre>
map :: Monad m => (a -> b) -> SerialT m a -> SerialT m b
mapM :: Monad m => (a -> m b) -> SerialT m a -> SerialT m b


-- | <i>Deprecated: Please use <a>SerialT</a> instead.</i>
type StreamT = SerialT


-- | <i>Deprecated: Please use <a>WSerialT</a> instead.</i>
type InterleavedT = WSerialT
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.Serial.SerialT
instance GHC.Base.Monoid (Streamly.Internal.Data.Stream.Serial.SerialT m a)
instance GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Serial.SerialT m a)
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.Serial.WSerialT
instance GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Serial.WSerialT m a)
instance GHC.Base.Monoid (Streamly.Internal.Data.Stream.Serial.WSerialT m a)
instance GHC.Base.Monad m => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance GHC.Base.Monad m => GHC.Base.Monad (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance (Control.Monad.Base.MonadBase b m, GHC.Base.Monad m) => Control.Monad.Base.MonadBase b (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance Control.Monad.IO.Class.MonadIO m => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance Control.Monad.Catch.MonadThrow m => Control.Monad.Catch.MonadThrow (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance Control.Monad.Reader.Class.MonadReader r m => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance Control.Monad.State.Class.MonadState s m => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance GHC.Exts.IsList (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity a)
instance GHC.Classes.Ord a => GHC.Classes.Ord (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity a)
instance GHC.Show.Show a => GHC.Show.Show (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity a)
instance GHC.Read.Read a => GHC.Read.Read (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity a)
instance Control.DeepSeq.NFData1 (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity)
instance (Data.Foldable.Foldable m, GHC.Base.Monad m) => Data.Foldable.Foldable (Streamly.Internal.Data.Stream.Serial.WSerialT m)
instance Data.Traversable.Traversable (Streamly.Internal.Data.Stream.Serial.WSerialT Data.Functor.Identity.Identity)
instance GHC.Base.Monad m => GHC.Base.Monad (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance GHC.Base.Monad m => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance (Control.Monad.Base.MonadBase b m, GHC.Base.Monad m) => Control.Monad.Base.MonadBase b (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance Control.Monad.IO.Class.MonadIO m => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance Control.Monad.Catch.MonadThrow m => Control.Monad.Catch.MonadThrow (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance Control.Monad.Reader.Class.MonadReader r m => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance Control.Monad.State.Class.MonadState s m => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance GHC.Exts.IsList (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity a)
instance GHC.Classes.Ord a => GHC.Classes.Ord (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity a)
instance GHC.Show.Show a => GHC.Show.Show (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity a)
instance GHC.Read.Read a => GHC.Read.Read (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity a)
instance Control.DeepSeq.NFData1 (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity)
instance (Data.Foldable.Foldable m, GHC.Base.Monad m) => Data.Foldable.Foldable (Streamly.Internal.Data.Stream.Serial.SerialT m)
instance Data.Traversable.Traversable (Streamly.Internal.Data.Stream.Serial.SerialT Data.Functor.Identity.Identity)


-- | See <a>Streamly.Data.Fold</a> for an overview and
--   <a>Streamly.Internal.Data.Fold.Types</a> for design notes.
--   
--   IMPORTANT: keep the signatures consistent with the folds in
--   Streamly.Prelude
module Streamly.Internal.Data.Fold

-- | Represents the result of the <tt>step</tt> of a <tt>Fold</tt>.
--   <a>Partial</a> returns an intermediate state of the fold, the fold
--   step can be called again with the state or the driver can use
--   <tt>extract</tt> on the state to get the result out. <a>Done</a>
--   returns the final result and the fold cannot be driven further.
--   
--   <i>Pre-release</i>
data Step s b
Partial :: !s -> Step s b
Done :: !b -> Step s b

-- | The type <tt>Fold m a b</tt> having constructor <tt>Fold step initial
--   extract</tt> represents a fold over an input stream of values of type
--   <tt>a</tt> to a final value of type <tt>b</tt> in <a>Monad</a>
--   <tt>m</tt>.
--   
--   The fold uses an intermediate state <tt>s</tt> as accumulator, the
--   type <tt>s</tt> is internal to the specific fold definition. The
--   initial value of the fold state <tt>s</tt> is returned by
--   <tt>initial</tt>. The <tt>step</tt> function consumes an input and
--   either returns the final result <tt>b</tt> if the fold is done or the
--   next intermediate state (see <a>Step</a>). At any point the fold
--   driver can extract the result from the intermediate state using the
--   <tt>extract</tt> function.
--   
--   NOTE: The constructor is not yet exposed via exposed modules, smart
--   constructors are provided to create folds. If you think you need the
--   constructor of this type please consider using the smart constructors
--   in <a>Streamly.Internal.Data.Fold</a> instead.
--   
--   <i>since 0.8.0 (type changed)</i>
data Fold m a b

-- | <tt>Fold </tt> <tt> step </tt> <tt> initial </tt> <tt> extract</tt>
Fold :: (s -> a -> m (Step s b)) -> m (Step s b) -> (s -> m b) -> Fold m a b

-- | Make a fold from a left fold style pure step function and initial
--   value of the accumulator.
--   
--   If your <a>Fold</a> returns only <a>Partial</a> (i.e. never returns a
--   <a>Done</a>) then you can use <tt>foldl'*</tt> constructors.
--   
--   A fold with an extract function can be expressed using fmap:
--   
--   <pre>
--   mkfoldlx :: Monad m =&gt; (s -&gt; a -&gt; s) -&gt; s -&gt; (s -&gt; b) -&gt; Fold m a b
--   mkfoldlx step initial extract = fmap extract (foldl' step initial)
--   </pre>
--   
--   See also: <tt>Streamly.Prelude.foldl'</tt>
foldl' :: Monad m => (b -> a -> b) -> b -> Fold m a b

-- | Make a fold from a left fold style monadic step function and initial
--   value of the accumulator.
--   
--   A fold with an extract function can be expressed using rmapM:
--   
--   <pre>
--   mkFoldlxM :: Functor m =&gt; (s -&gt; a -&gt; m s) -&gt; m s -&gt; (s -&gt; m b) -&gt; Fold m a b
--   mkFoldlxM step initial extract = rmapM extract (foldlM' step initial)
--   </pre>
--   
--   See also: <tt>Streamly.Prelude.foldlM'</tt>
foldlM' :: Monad m => (b -> a -> m b) -> m b -> Fold m a b

-- | Make a strict left fold, for non-empty streams, using first element as
--   the starting value. Returns Nothing if the stream is empty.
--   
--   See also: <tt>Streamly.Prelude.foldl1'</tt>
--   
--   <i>Pre-release</i>
foldl1' :: Monad m => (a -> a -> a) -> Fold m a (Maybe a)

-- | Make a fold using a right fold style step function and a terminal
--   value. It performs a strict right fold via a left fold using function
--   composition. Note that this is strict fold, it can only be useful for
--   constructing strict structures in memory. For reductions this will be
--   very inefficient.
--   
--   For example,
--   
--   <pre>
--   toList = foldr (:) []
--   </pre>
--   
--   See also: <a>foldr</a>
foldr :: Monad m => (a -> b -> b) -> b -> Fold m a b

-- | Like <a>foldr</a> but with a monadic step function.
--   
--   For example,
--   
--   <pre>
--   toList = foldrM (\a xs -&gt; return $ a : xs) (return [])
--   </pre>
--   
--   See also: <a>foldrM</a>
--   
--   <i>Pre-release</i>
foldrM :: Monad m => (a -> b -> m b) -> m b -> Fold m a b

-- | Make a terminating fold using a pure step function, a pure initial
--   state and a pure state extraction function.
--   
--   <i>Pre-release</i>
mkFold :: Monad m => (s -> a -> Step s b) -> Step s b -> (s -> b) -> Fold m a b

-- | Similar to <a>mkFold</a> but the final state extracted is identical to
--   the intermediate state.
--   
--   <pre>
--   mkFold_ step initial = mkFold step initial id
--   </pre>
--   
--   <i>Pre-release</i>
mkFold_ :: Monad m => (b -> a -> Step b b) -> Step b b -> Fold m a b

-- | Make a terminating fold with an effectful step function and initial
--   state, and a state extraction function.
--   
--   <pre>
--   mkFoldM = Fold
--   </pre>
--   
--   We can just use <a>Fold</a> but it is provided for completeness.
--   
--   <i>Pre-release</i>
mkFoldM :: (s -> a -> m (Step s b)) -> m (Step s b) -> (s -> m b) -> Fold m a b

-- | Similar to <a>mkFoldM</a> but the final state extracted is identical
--   to the intermediate state.
--   
--   <pre>
--   mkFoldM_ step initial = mkFoldM step initial return
--   </pre>
--   
--   <i>Pre-release</i>
mkFoldM_ :: Monad m => (b -> a -> m (Step b b)) -> m (Step b b) -> Fold m a b

-- | A fold that always yields a pure value without consuming any input.
--   
--   <i>Pre-release</i>
fromPure :: Applicative m => b -> Fold m a b

-- | A fold that always yields the result of an effectful action without
--   consuming any input.
--   
--   <i>Pre-release</i>
fromEffect :: Applicative m => m b -> Fold m a b

-- | Append the elements of an input stream to a provided starting value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.sconcat 10) (Stream.map Data.Monoid.Sum $ Stream.enumerateFromTo 1 10)
--   Sum {getSum = 65}
--   </pre>
--   
--   <pre>
--   sconcat = Fold.foldl' (&lt;&gt;)
--   </pre>
sconcat :: (Monad m, Semigroup a) => a -> Fold m a a

-- | Fold an input stream consisting of monoidal elements using
--   <a>mappend</a> and <a>mempty</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.mconcat (Stream.map Data.Monoid.Sum $ Stream.enumerateFromTo 1 10)
--   Sum {getSum = 55}
--   </pre>
--   
--   <pre>
--   mconcat = Fold.sconcat mempty
--   </pre>
mconcat :: (Monad m, Monoid a) => Fold m a a

-- | <pre>
--   foldMap f = Fold.lmap f Fold.mconcat
--   </pre>
--   
--   Make a fold from a pure function that folds the output of the function
--   using <a>mappend</a> and <a>mempty</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.foldMap Data.Monoid.Sum) $ Stream.enumerateFromTo 1 10
--   Sum {getSum = 55}
--   </pre>
foldMap :: (Monad m, Monoid b) => (a -> b) -> Fold m a b

-- | <pre>
--   foldMapM f = Fold.lmapM f Fold.mconcat
--   </pre>
--   
--   Make a fold from a monadic function that folds the output of the
--   function using <a>mappend</a> and <a>mempty</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.foldMapM (return . Data.Monoid.Sum)) $ Stream.enumerateFromTo 1 10
--   Sum {getSum = 55}
--   </pre>
foldMapM :: (Monad m, Monoid b) => (a -> m b) -> Fold m a b

-- | A fold that drains all its input, running the effects and discarding
--   the results.
--   
--   <pre>
--   drain = drainBy (const (return ()))
--   </pre>
drain :: Monad m => Fold m a ()

-- | <pre>
--   drainBy f = lmapM f drain
--   drainBy = Fold.foldMapM (void . f)
--   </pre>
--   
--   Drain all input after passing it through a monadic function. This is
--   the dual of mapM_ on stream producers.
--   
--   See also: <a>mapM_</a>
drainBy :: Monad m => (a -> m b) -> Fold m a ()

-- | Extract the last element of the input stream, if any.
--   
--   <pre>
--   last = fmap getLast $ Fold.foldMap (Last . Just)
--   </pre>
last :: Monad m => Fold m a (Maybe a)

-- | Determine the length of the input stream.
--   
--   <pre>
--   length = fmap getSum $ Fold.foldMap (Sum . const  1)
--   </pre>
length :: Monad m => Fold m a Int

-- | Compute a numerically stable arithmetic mean of all elements in the
--   input stream.
mean :: (Monad m, Fractional a) => Fold m a a

-- | Compute a numerically stable (population) variance over all elements
--   in the input stream.
variance :: (Monad m, Fractional a) => Fold m a a

-- | Compute a numerically stable (population) standard deviation over all
--   elements in the input stream.
stdDev :: (Monad m, Floating a) => Fold m a a

-- | Compute an <a>Int</a> sized polynomial rolling hash of a stream.
--   
--   <pre>
--   rollingHash = Fold.rollingHashWithSalt defaultSalt
--   </pre>
rollingHash :: (Monad m, Enum a) => Fold m a Int64

-- | Compute an <a>Int</a> sized polynomial rolling hash
--   
--   <pre>
--   H = salt * k ^ n + c1 * k ^ (n - 1) + c2 * k ^ (n - 2) + ... + cn * k ^ 0
--   </pre>
--   
--   Where <tt>c1</tt>, <tt>c2</tt>, <tt>cn</tt> are the elements in the
--   input stream and <tt>k</tt> is a constant.
--   
--   This hash is often used in Rabin-Karp string search algorithm.
--   
--   See <a>https://en.wikipedia.org/wiki/Rolling_hash</a>
rollingHashWithSalt :: (Monad m, Enum a) => Int64 -> Fold m a Int64

-- | Compute an <a>Int</a> sized polynomial rolling hash of the first n
--   elements of a stream.
--   
--   <pre>
--   rollingHashFirstN = Fold.take n Fold.rollingHash
--   </pre>
--   
--   <i>Pre-release</i>
rollingHashFirstN :: (Monad m, Enum a) => Int -> Fold m a Int64

-- | Determine the sum of all elements of a stream of numbers. Returns
--   additive identity (<tt>0</tt>) when the stream is empty. Note that
--   this is not numerically stable for floating point numbers.
--   
--   <pre>
--   sum = fmap getSum $ Fold.foldMap Sum
--   </pre>
sum :: (Monad m, Num a) => Fold m a a

-- | Determine the product of all elements of a stream of numbers. Returns
--   multiplicative identity (<tt>1</tt>) when the stream is empty. The
--   fold terminates when it encounters (<tt>0</tt>) in its input.
--   
--   Compare with <tt>Fold.foldMap Product</tt>.
--   
--   <i>Since 0.8.0 (Added <a>Eq</a> constraint)</i>
product :: (Monad m, Num a, Eq a) => Fold m a a

-- | Determine the maximum element in a stream using the supplied
--   comparison function.
maximumBy :: Monad m => (a -> a -> Ordering) -> Fold m a (Maybe a)

-- | <pre>
--   maximum = Fold.maximumBy compare
--   </pre>
--   
--   Determine the maximum element in a stream.
--   
--   Compare with <tt>Fold.foldMap Max</tt>.
maximum :: (Monad m, Ord a) => Fold m a (Maybe a)

-- | Computes the minimum element with respect to the given comparison
--   function
minimumBy :: Monad m => (a -> a -> Ordering) -> Fold m a (Maybe a)

-- | Determine the minimum element in a stream using the supplied
--   comparison function.
--   
--   <pre>
--   minimum = <a>minimumBy</a> compare
--   </pre>
--   
--   Compare with <tt>Fold.foldMap Min</tt>.
minimum :: (Monad m, Ord a) => Fold m a (Maybe a)

-- | Folds the input stream to a list.
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using
--   <a>Streamly.Data.Array.Foreign</a> instead.
--   
--   <pre>
--   toList = foldr (:) []
--   </pre>
toList :: Monad m => Fold m a [a]

-- | Buffers the input stream to a list in the reverse order of the input.
--   
--   <pre>
--   toListRev = Fold.foldl' (flip (:)) []
--   </pre>
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using <a>Streamly.Array</a>
--   instead.
toListRev :: Monad m => Fold m a [a]

-- | A fold that buffers its input to a pure stream.
--   
--   <i>Warning!</i> working on large streams accumulated as buffers in
--   memory could be very inefficient, consider using
--   <a>Streamly.Data.Array</a> instead.
--   
--   <pre>
--   &gt;&gt;&gt; toStream = fmap SerialT Fold.toStreamK
--   </pre>
--   
--   <i>Pre-release</i>
toStream :: Monad m => Fold m a (SerialT n a)

-- | Buffers the input stream to a pure stream in the reverse order of the
--   input.
--   
--   <pre>
--   &gt;&gt;&gt; toStreamRev = fmap SerialT Fold.toStreamKRev
--   </pre>
--   
--   <i>Warning!</i> working on large streams accumulated as buffers in
--   memory could be very inefficient, consider using
--   <a>Streamly.Data.Array</a> instead.
--   
--   <i>Pre-release</i>
toStreamRev :: Monad m => Fold m a (SerialT n a)

-- | A fold that drains the first n elements of its input, running the
--   effects and discarding the results.
--   
--   <pre>
--   drainN n = Fold.take n Fold.drain
--   </pre>
--   
--   <i>Pre-release</i>
drainN :: Monad m => Int -> Fold m a ()

-- | Like <a>index</a>, except with a more general <a>Integral</a> argument
--   
--   <i>Pre-release</i>
genericIndex :: (Integral i, Monad m) => i -> Fold m a (Maybe a)

-- | Lookup the element at the given index.
--   
--   See also: <a>!!</a>
index :: Monad m => Int -> Fold m a (Maybe a)

-- | Extract the first element of the stream, if any.
head :: Monad m => Fold m a (Maybe a)

-- | Returns the first element that satisfies the given predicate.
find :: Monad m => (a -> Bool) -> Fold m a (Maybe a)

-- | In a stream of (key-value) pairs <tt>(a, b)</tt>, return the value
--   <tt>b</tt> of the first pair where the key equals the given value
--   <tt>a</tt>.
--   
--   <pre>
--   lookup = snd &lt;$&gt; Fold.find ((==) . fst)
--   </pre>
lookup :: (Eq a, Monad m) => a -> Fold m (a, b) (Maybe b)

-- | Returns the first index that satisfies the given predicate.
findIndex :: Monad m => (a -> Bool) -> Fold m a (Maybe Int)

-- | Returns the first index where a given value is found in the stream.
--   
--   <pre>
--   elemIndex a = Fold.findIndex (== a)
--   </pre>
elemIndex :: (Eq a, Monad m) => a -> Fold m a (Maybe Int)

-- | Return <a>True</a> if the input stream is empty.
--   
--   <pre>
--   null = fmap isJust Fold.head
--   </pre>
null :: Monad m => Fold m a Bool

-- | Return <a>True</a> if the given element is present in the stream.
--   
--   <pre>
--   elem a = Fold.any (== a)
--   </pre>
elem :: (Eq a, Monad m) => a -> Fold m a Bool

-- | Returns <a>True</a> if the given element is not present in the stream.
--   
--   <pre>
--   notElem a = Fold.all (/= a)
--   </pre>
notElem :: (Eq a, Monad m) => a -> Fold m a Bool

-- | Returns <a>True</a> if all elements of a stream satisfy a predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.all (== 0)) $ Stream.fromList [1,0,1]
--   False
--   </pre>
--   
--   <pre>
--   all p = Fold.lmap p Fold.and
--   </pre>
all :: Monad m => (a -> Bool) -> Fold m a Bool

-- | Returns <a>True</a> if any of the elements of a stream satisfies a
--   predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.any (== 0)) $ Stream.fromList [1,0,1]
--   True
--   </pre>
--   
--   <pre>
--   any p = Fold.lmap p Fold.or
--   </pre>
any :: Monad m => (a -> Bool) -> Fold m a Bool

-- | Returns <a>True</a> if all elements are <a>True</a>, <a>False</a>
--   otherwise
--   
--   <pre>
--   and = Fold.all (== True)
--   </pre>
and :: Monad m => Fold m Bool Bool

-- | Returns <a>True</a> if any element is <a>True</a>, <a>False</a>
--   otherwise
--   
--   <pre>
--   or = Fold.any (== True)
--   </pre>
or :: Monad m => Fold m Bool Bool

-- | Change the predicate function of a Fold from <tt>a -&gt; b</tt> to
--   accept an additional state input <tt>(s, a) -&gt; b</tt>. Convenient
--   to filter with an addiitonal index or time input.
--   
--   <pre>
--   filterWithIndex = with indexed filter
--   filterWithAbsTime = with timestamped filter
--   filterWithRelTime = with timeIndexed filter
--   </pre>
--   
--   <i>Pre-release</i>
with :: (Fold m (s, a) b -> Fold m a b) -> (((s, a) -> c) -> Fold m (s, a) b -> Fold m (s, a) b) -> ((s, a) -> c) -> Fold m a b -> Fold m a b

-- | Change the underlying monad of a fold
--   
--   <i>Pre-release</i>
hoist :: (forall x. m x -> n x) -> Fold m a b -> Fold n a b

-- | Adapt a pure fold to any monad
--   
--   <pre>
--   generally = Fold.hoist (return . runIdentity)
--   </pre>
--   
--   <i>Pre-release</i>
generally :: Monad m => Fold Identity a b -> Fold m a b

-- | Map a monadic function on the output of a fold.
rmapM :: Monad m => (b -> m c) -> Fold m a b -> Fold m a c

-- | Apply a transformation on a <a>Fold</a> using a <a>Pipe</a>.
--   
--   <i>Pre-release</i>
transform :: Monad m => Pipe m a b -> Fold m b c -> Fold m a c

-- | <tt>lmap f fold</tt> maps the function <tt>f</tt> on the input of the
--   fold.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.lmap (\x -&gt; x * x) Fold.sum) (Stream.enumerateFromTo 1 100)
--   338350
--   </pre>
--   
--   <pre>
--   lmap = Fold.lmapM return
--   </pre>
lmap :: (a -> b) -> Fold m b r -> Fold m a r

-- | <tt>lmapM f fold</tt> maps the monadic function <tt>f</tt> on the
--   input of the fold.
lmapM :: Monad m => (a -> m b) -> Fold m b r -> Fold m a r

-- | Scan the input of a <a>Fold</a> to change it in a stateful manner
--   using another <a>Fold</a>. <i>Pre-release</i>
scan :: Monad m => Fold m a b -> Fold m b c -> Fold m a c

-- | Pair each element of a fold input with its index, starting from index
--   0.
--   
--   <i>Unimplemented</i>
indexed :: Fold m (Int, a) b -> Fold m a b

-- | Include only those elements that pass a predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.filter (&gt; 5) Fold.sum) $ Stream.fromList [1..10]
--   40
--   </pre>
--   
--   <pre>
--   filter f = Fold.filterM (return . f)
--   </pre>
filter :: Monad m => (a -> Bool) -> Fold m a r -> Fold m a r

-- | Like <a>filter</a> but with a monadic predicate.
filterM :: Monad m => (a -> m Bool) -> Fold m a r -> Fold m a r

-- | <tt>sampleFromthen offset stride</tt> samples the element at
--   <tt>offset</tt> index and then every element at strides of
--   <tt>stride</tt>.
--   
--   <i>Unimplemented</i>
sampleFromthen :: Monad m => Int -> Int -> Fold m a b -> Fold m a b

-- | Modify a fold to receive a <a>Maybe</a> input, the <a>Just</a> values
--   are unwrapped and sent to the original fold, <a>Nothing</a> values are
--   discarded.
catMaybes :: Monad m => Fold m a b -> Fold m (Maybe a) b

-- | <tt>mapMaybe f fold</tt> maps a <a>Maybe</a> returning function
--   <tt>f</tt> on the input of the fold, filters out <a>Nothing</a>
--   elements, and return the values extracted from <a>Just</a>.
--   
--   <pre>
--   &gt;&gt;&gt; f x = if even x then Just x else Nothing
--   
--   &gt;&gt;&gt; fld = Fold.mapMaybe f Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold fld (Stream.enumerateFromTo 1 10)
--   [2,4,6,8,10]
--   </pre>
mapMaybe :: Monad m => (a -> Maybe b) -> Fold m b r -> Fold m a r

-- | Take at most <tt>n</tt> input elements and fold them using the
--   supplied fold. A negative count is treated as 0.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.take 2 Fold.toList) $ Stream.fromList [1..10]
--   [1,2]
--   </pre>
take :: Monad m => Int -> Fold m a b -> Fold m a b

-- | Take the input, stop when the predicate succeeds taking the succeeding
--   element as well.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.takeEndBy (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   "hello\n"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany (Fold.takeEndBy (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   ["hello\n","there\n"]
--   </pre>
--   
--   <pre>
--   Stream.splitWithSuffix p f = Stream.foldMany (Fold.takeEndBy p f)
--   </pre>
--   
--   See <a>splitWithSuffix</a> for more details on splitting a stream
--   using <a>takeEndBy</a>.
takeEndBy :: Monad m => (a -> Bool) -> Fold m a b -> Fold m a b

-- | Like <a>takeEndBy</a> but drops the element on which the predicate
--   succeeds.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.takeEndBy_ (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   "hello"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany (Fold.takeEndBy_ (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   ["hello","there"]
--   </pre>
--   
--   <pre>
--   Stream.splitOnSuffix p f = Stream.foldMany (Fold.takeEndBy_ p f)
--   </pre>
--   
--   See <a>splitOnSuffix</a> for more details on splitting a stream using
--   <a>takeEndBy_</a>.
takeEndBy_ :: Monad m => (a -> Bool) -> Fold m a b -> Fold m a b

-- | Sequential fold application. Apply two folds sequentially to an input
--   stream. The input is provided to the first fold, when it is done - the
--   remaining input is provided to the second fold. When the second fold
--   is done or if the input stream is over, the outputs of the two folds
--   are combined using the supplied function.
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.serialWith (,) (Fold.take 8 Fold.toList) (Fold.takeEndBy (== '\n') Fold.toList)
--   
--   &gt;&gt;&gt; Stream.fold f $ Stream.fromList "header: hello\n"
--   ("header: ","hello\n")
--   </pre>
--   
--   Note: This is dual to appending streams using <a>serial</a>.
--   
--   Note: this implementation allows for stream fusion but has quadratic
--   time complexity, because each composition adds a new branch that each
--   subsequent fold's input element has to traverse, therefore, it cannot
--   scale to a large number of compositions. After around 100 compositions
--   the performance starts dipping rapidly compared to a CPS style
--   implementation.
--   
--   <i>Time: O(n^2) where n is the number of compositions.</i>
serialWith :: Monad m => (a -> b -> c) -> Fold m x a -> Fold m x b -> Fold m x c

-- | Same as applicative <a>*&gt;</a>. Run two folds serially one after the
--   other discarding the result of the first.
--   
--   This was written in the hope that it might be faster than implementing
--   it using serialWith, but the current benchmarks show that it has the
--   same performance. So do not expose it unless some benchmark shows
--   benefit.
serial_ :: Monad m => Fold m x a -> Fold m x b -> Fold m x b

-- | <tt>splitAt n f1 f2</tt> composes folds <tt>f1</tt> and <tt>f2</tt>
--   such that first <tt>n</tt> elements of its input are consumed by fold
--   <tt>f1</tt> and the rest of the stream is consumed by fold
--   <tt>f2</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; let splitAt_ n xs = Stream.fold (Fold.splitAt n Fold.toList Fold.toList) $ Stream.fromList xs
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitAt_ 6 "Hello World!"
--   ("Hello ","World!")
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitAt_ (-1) [1,2,3]
--   ([],[1,2,3])
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitAt_ 0 [1,2,3]
--   ([],[1,2,3])
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitAt_ 1 [1,2,3]
--   ([1],[2,3])
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitAt_ 3 [1,2,3]
--   ([1,2,3],[])
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitAt_ 4 [1,2,3]
--   ([1,2,3],[])
--   </pre>
--   
--   <pre>
--   splitAt n f1 f2 = Fold.serialWith (,) (Fold.take n f1) f2
--   </pre>
--   
--   <i>Internal</i>
splitAt :: Monad m => Int -> Fold m a b -> Fold m a c -> Fold m a (b, c)

-- | <tt>teeWith k f1 f2</tt> distributes its input to both <tt>f1</tt> and
--   <tt>f2</tt> until both of them terminate and combines their output
--   using <tt>k</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; avg = Fold.teeWith (/) Fold.sum (fmap fromIntegral Fold.length)
--   
--   &gt;&gt;&gt; Stream.fold avg $ Stream.fromList [1.0..100.0]
--   50.5
--   </pre>
--   
--   <pre>
--   teeWith k f1 f2 = fmap (uncurry k) ((Fold.tee f1 f2)
--   </pre>
--   
--   For applicative composition using this combinator see
--   <a>Streamly.Internal.Data.Fold.Tee</a>.
--   
--   See also: <a>Streamly.Internal.Data.Fold.Tee</a>
teeWith :: Monad m => (a -> b -> c) -> Fold m x a -> Fold m x b -> Fold m x c

-- | Distribute one copy of the stream to each fold and zip the results.
--   
--   <pre>
--                   |-------Fold m a b--------|
--   ---stream m a---|                         |---m (b,c)
--                   |-------Fold m a c--------|
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.tee Fold.sum Fold.length) (Stream.enumerateFromTo 1.0 100.0)
--   (5050.0,100)
--   </pre>
--   
--   <pre>
--   tee = teeWith (,)
--   </pre>
tee :: Monad m => Fold m a b -> Fold m a c -> Fold m a (b, c)

-- | Like <a>teeWith</a> but terminates as soon as the first fold
--   terminates.
--   
--   <i>Pre-release</i>
teeWithFst :: Monad m => (b -> c -> d) -> Fold m a b -> Fold m a c -> Fold m a d

-- | Like <a>teeWith</a> but terminates as soon as any one of the two folds
--   terminates.
--   
--   <i>Pre-release</i>
teeWithMin :: Monad m => (b -> c -> d) -> Fold m a b -> Fold m a c -> Fold m a d

-- | Distribute one copy of the stream to each fold and collect the results
--   in a container.
--   
--   <pre>
--                   |-------Fold m a b--------|
--   ---stream m a---|                         |---m [b]
--                   |-------Fold m a b--------|
--                   |                         |
--                              ...
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.distribute [Fold.sum, Fold.length]) (Stream.enumerateFromTo 1 5)
--   [15,5]
--   </pre>
--   
--   <pre>
--   distribute = Prelude.foldr (Fold.teeWith (:)) (Fold.fromPure [])
--   </pre>
--   
--   This is the consumer side dual of the producer side <a>sequence</a>
--   operation.
--   
--   Stops when all the folds stop.
distribute :: Monad m => [Fold m a b] -> Fold m a [b]

-- | Shortest alternative. Apply both folds in parallel but choose the
--   result from the one which consumed least input i.e. take the shortest
--   succeeding fold.
--   
--   If both the folds finish at the same time or if the result is
--   extracted before any of the folds could finish then the left one is
--   taken.
--   
--   <i>Pre-release</i>
shortest :: Monad m => Fold m x a -> Fold m x b -> Fold m x (Either a b)

-- | Longest alternative. Apply both folds in parallel but choose the
--   result from the one which consumed more input i.e. take the longest
--   succeeding fold.
--   
--   If both the folds finish at the same time or if the result is
--   extracted before any of the folds could finish then the left one is
--   taken.
--   
--   <i>Pre-release</i>
longest :: Monad m => Fold m x a -> Fold m x b -> Fold m x (Either a b)

-- | Partition the input over two folds using an <a>Either</a> partitioning
--   predicate.
--   
--   <pre>
--                                       |-------Fold b x--------|
--   -----stream m a --&gt; (Either b c)----|                       |----(x,y)
--                                       |-------Fold c y--------|
--   </pre>
--   
--   Send input to either fold randomly:
--   
--   <pre>
--   &gt; import System.Random (randomIO)
--   &gt; randomly a = randomIO &gt;&gt;= \x -&gt; return $ if x then Left a else Right a
--   &gt; Stream.fold (Fold.partitionByM randomly Fold.length Fold.length) (Stream.enumerateFromTo 1 100)
--   (59,41)
--   </pre>
--   
--   Send input to the two folds in a proportion of 2:1:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   proportionately m n = do
--    ref &lt;- newIORef $ cycle $ concat [replicate m Left, replicate n Right]
--    return $ \a -&gt; do
--        r &lt;- readIORef ref
--        writeIORef ref $ tail r
--        return $ Prelude.head r a
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   main = do
--    f &lt;- proportionately 2 1
--    r &lt;- Stream.fold (Fold.partitionByM f Fold.length Fold.length) (Stream.enumerateFromTo (1 :: Int) 100)
--    print r
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; main
--   (67,33)
--   </pre>
--   
--   This is the consumer side dual of the producer side <tt>mergeBy</tt>
--   operation.
--   
--   When one fold is done, any input meant for it is ignored until the
--   other fold is also done.
--   
--   Stops when both the folds stop.
--   
--   <i>See also: <a>partitionByFstM</a> and <a>partitionByMinM</a>.</i>
--   
--   <i>Pre-release</i>
partitionByM :: Monad m => (a -> m (Either b c)) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Similar to <a>partitionByM</a> but terminates when the first fold
--   terminates.
partitionByFstM :: Monad m => (a -> m (Either b c)) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Similar to <a>partitionByM</a> but terminates when any fold
--   terminates.
partitionByMinM :: Monad m => (a -> m (Either b c)) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Same as <a>partitionByM</a> but with a pure partition function.
--   
--   Count even and odd numbers in a stream:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    let f = Fold.partitionBy (\n -&gt; if even n then Left n else Right n)
--                        (fmap (("Even " ++) . show) Fold.length)
--                        (fmap (("Odd "  ++) . show) Fold.length)
--     in Stream.fold f (Stream.enumerateFromTo 1 100)
--   :}
--   ("Even 50","Odd 50")
--   </pre>
--   
--   <i>Pre-release</i>
partitionBy :: Monad m => (a -> Either b c) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Compose two folds such that the combined fold accepts a stream of
--   <a>Either</a> and routes the <a>Left</a> values to the first fold and
--   <a>Right</a> values to the second fold.
--   
--   <pre>
--   partition = partitionBy id
--   </pre>
partition :: Monad m => Fold m b x -> Fold m c y -> Fold m (Either b c) (x, y)

-- | Fold a stream of key value pairs using a map of specific folds for
--   each key into a map from keys to the results of fold outputs of the
--   corresponding values.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Data.Map
--   
--   &gt;&gt;&gt; :{
--    let table = Data.Map.fromList [("SUM", Fold.sum), ("PRODUCT", Fold.product)]
--        input = Stream.fromList [("SUM",1),("PRODUCT",2),("SUM",3),("PRODUCT",4)]
--     in Stream.fold (Fold.demux table) input
--   :}
--   fromList [("PRODUCT",8),("SUM",4)]
--   </pre>
--   
--   <pre>
--   demux = demuxWith id
--   </pre>
--   
--   <i>Pre-release</i>
demux :: (Monad m, Ord k) => Map k (Fold m a b) -> Fold m (k, a) (Map k b)

-- | Split the input stream based on a key field and fold each split using
--   a specific fold collecting the results in a map from the keys to the
--   results. Useful for cases like protocol handlers to handle different
--   type of packets using different handlers.
--   
--   <pre>
--                               |-------Fold m a b
--   -----stream m a-----Map-----|
--                               |-------Fold m a b
--                               |
--                                         ...
--   </pre>
--   
--   Any input that does not map to a fold in the input Map is silently
--   ignored.
--   
--   <pre>
--   demuxWith f kv = fmap fst $ demuxDefaultWith f kv drain
--   </pre>
--   
--   <i>Pre-release</i>
demuxWith :: (Monad m, Ord k) => (a -> (k, a')) -> Map k (Fold m a' b) -> Fold m a (Map k b)

-- | <pre>
--   demuxDefault = demuxDefaultWith id
--   </pre>
--   
--   <i>Pre-release</i>
demuxDefault :: (Monad m, Ord k) => Map k (Fold m a b) -> Fold m (k, a) b -> Fold m (k, a) (Map k b, b)

-- | Like <a>demuxWith</a> but uses a default catchall fold to handle
--   inputs which do not have a specific fold in the map to handle them.
--   
--   If any fold in the map stops, inputs meant for that fold are sent to
--   the catchall fold. If the catchall fold stops then inputs that do not
--   match any fold are ignored.
--   
--   Stops when all the folds, including the catchall fold, stop.
--   
--   <i>Pre-release</i>
demuxDefaultWith :: (Monad m, Ord k) => (a -> (k, a')) -> Map k (Fold m a' b) -> Fold m (k, a') c -> Fold m a (Map k b, c)

-- | Given an input stream of key value pairs and a fold for values, fold
--   all the values belonging to each key. Useful for map/reduce,
--   bucketizing the input in different bins or for generating histograms.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    let input = Stream.fromList [("ONE",1),("ONE",1.1),("TWO",2), ("TWO",2.2)]
--     in Stream.fold (Fold.classify Fold.toList) input
--   :}
--   fromList [("ONE",[1.0,1.1]),("TWO",[2.0,2.2])]
--   </pre>
--   
--   Same as:
--   
--   <pre>
--   classify fld = Fold.classifyWith fst (lmap snd fld)
--   </pre>
--   
--   <i>Pre-release</i>
classify :: (Monad m, Ord k) => Fold m a b -> Fold m (k, a) (Map k b)

-- | Split the input stream based on a key field and fold each split using
--   the given fold. Useful for map/reduce, bucketizing the input in
--   different bins or for generating histograms.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    let input = Stream.fromList [("ONE",1),("ONE",1.1),("TWO",2), ("TWO",2.2)]
--     in Stream.fold (Fold.classifyWith fst (Fold.map snd Fold.toList)) input
--   :}
--   fromList [("ONE",[1.0,1.1]),("TWO",[2.0,2.2])]
--   </pre>
--   
--   If the classifier fold stops for a particular key any further inputs
--   in that bucket are ignored.
--   
--   <i>Stops: never</i>
--   
--   <i>Pre-release</i>
classifyWith :: (Monad m, Ord k) => (a -> k) -> Fold m a b -> Fold m a (Map k b)

-- | Send the elements of tuples in a stream of tuples through two
--   different folds.
--   
--   <pre>
--                             |-------Fold m a x--------|
--   ---------stream of (a,b)--|                         |----m (x,y)
--                             |-------Fold m b y--------|
--   </pre>
--   
--   <pre>
--   unzip = Fold.unzipWith id
--   </pre>
--   
--   This is the consumer side dual of the producer side <a>zip</a>
--   operation.
unzip :: Monad m => Fold m a x -> Fold m b y -> Fold m (a, b) (x, y)

-- | Split elements in the input stream into two parts using a pure
--   splitter function, direct each part to a different fold and zip the
--   results.
--   
--   <pre>
--   unzipWith f fld1 fld2 = Fold.lmap f (Fold.unzip fld1 fld2)
--   </pre>
--   
--   This fold terminates when both the input folds terminate.
--   
--   <i>Pre-release</i>
unzipWith :: Monad m => (a -> (b, c)) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Like <a>unzipWith</a> but with a monadic splitter function.
--   
--   <pre>
--   unzipWithM k f1 f2 = lmapM k (unzip f1 f2)
--   </pre>
--   
--   <i>Pre-release</i>
unzipWithM :: Monad m => (a -> m (b, c)) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Similar to <a>unzipWithM</a> but terminates when the first fold
--   terminates.
unzipWithFstM :: Monad m => (a -> m (b, c)) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Similar to <a>unzipWithM</a> but terminates when any fold terminates.
unzipWithMinM :: Monad m => (a -> m (b, c)) -> Fold m b x -> Fold m c y -> Fold m a (x, y)

-- | Zip a stream with the input of a fold using the supplied function.
--   
--   <i>Unimplemented</i>
zipWithM :: (a -> b -> m c) -> t m a -> Fold m c x -> Fold m b x

-- | Zip a stream with the input of a fold.
--   
--   <i>Unimplemented</i>
zip :: Monad m => t m a -> Fold m (a, b) x -> Fold m b x

-- | Collect zero or more applications of a fold. <tt>many split
--   collect</tt> applies the <tt>split</tt> fold repeatedly on the input
--   stream and accumulates zero or more fold results using
--   <tt>collect</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; two = Fold.take 2 Fold.toList
--   
--   &gt;&gt;&gt; twos = Fold.many two Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold twos $ Stream.fromList [1..10]
--   [[1,2],[3,4],[5,6],[7,8],[9,10]]
--   </pre>
--   
--   Stops when <tt>collect</tt> stops.
--   
--   See also: <a>concatMap</a>, <a>foldMany</a>
many :: Monad m => Fold m a b -> Fold m b c -> Fold m a c

-- | <tt>chunksOf n split collect</tt> repeatedly applies the
--   <tt>split</tt> fold to chunks of <tt>n</tt> items in the input stream
--   and supplies the result to the <tt>collect</tt> fold.
--   
--   <pre>
--   &gt;&gt;&gt; twos = Fold.chunksOf 2 Fold.toList Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold twos $ Stream.fromList [1..10]
--   [[1,2],[3,4],[5,6],[7,8],[9,10]]
--   </pre>
--   
--   <pre>
--   chunksOf n split = many (take n split)
--   </pre>
--   
--   Stops when <tt>collect</tt> stops.
chunksOf :: Monad m => Int -> Fold m a b -> Fold m b c -> Fold m a c

-- | Group the input stream into groups of elements between <tt>low</tt>
--   and <tt>high</tt>. Collection starts in chunks of <tt>low</tt> and
--   then keeps doubling until we reach <tt>high</tt>. Each chunk is folded
--   using the provided fold function.
--   
--   This could be useful, for example, when we are folding a stream of
--   unknown size to a stream of arrays and we want to minimize the number
--   of allocations.
--   
--   NOTE: this would be an application of "many" using a terminating fold.
--   
--   <i>Unimplemented</i>
chunksBetween :: Int -> Int -> Fold m a b -> Fold m b c -> Fold m a c

-- | <tt>concatSequence f t</tt> applies folds from stream <tt>t</tt>
--   sequentially and collects the results using the fold <tt>f</tt>.
--   
--   <i>Unimplemented</i>
concatSequence :: Fold m b c -> t (Fold m a b) -> Fold m a c

-- | Map a <a>Fold</a> returning function on the result of a <a>Fold</a>
--   and run the returned fold. This operation can be used to express data
--   dependencies between fold operations.
--   
--   Let's say the first element in the stream is a count of the following
--   elements that we have to add, then:
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Maybe (fromJust)
--   
--   &gt;&gt;&gt; count = fmap fromJust Fold.head
--   
--   &gt;&gt;&gt; total n = Fold.take n Fold.sum
--   
--   &gt;&gt;&gt; Stream.fold (Fold.concatMap total count) $ Stream.fromList [10,9..1]
--   45
--   </pre>
--   
--   <i>Time: O(n^2) where <tt>n</tt> is the number of compositions.</i>
--   
--   See also: <a>foldIterateM</a>
concatMap :: Monad m => (b -> Fold m a c) -> Fold m a b -> Fold m a c

-- | Run the initialization effect of a fold. The returned fold would use
--   the value returned by this effect as its initial value.
--   
--   <i>Pre-release</i>
initialize :: Monad m => Fold m a b -> m (Fold m a b)

-- | Append a singleton value to the fold.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Data.Foldable as Foldable
--   
--   &gt;&gt;&gt; Foldable.foldlM Fold.snoc Fold.toList [1..3] &gt;&gt;= Fold.finish
--   [1,2,3]
--   </pre>
--   
--   Compare with <a>duplicate</a> which allows appending a stream to the
--   fold.
--   
--   <i>Pre-release</i>
snoc :: Monad m => Fold m a b -> a -> m (Fold m a b)

-- | <a>duplicate</a> provides the ability to run a fold in parts. The
--   duplicated fold consumes the input and returns the same fold as output
--   instead of returning the final result, the returned fold can be run
--   later to consume more input.
--   
--   We can append a stream to a fold as follows:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   foldAppend :: Monad m =&gt; Fold m a b -&gt; SerialT m a -&gt; m (Fold m a b)
--   foldAppend f = Stream.fold (Fold.duplicate f)
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   do
--    sum1 &lt;- foldAppend Fold.sum (Stream.enumerateFromTo 1 10)
--    sum2 &lt;- foldAppend sum1 (Stream.enumerateFromTo 11 20)
--    Stream.fold sum2 (Stream.enumerateFromTo 21 30)
--   :}
--   465
--   </pre>
--   
--   <a>duplicate</a> essentially appends a stream to the fold without
--   finishing the fold. Compare with <a>snoc</a> which appends a singleton
--   value to the fold.
--   
--   <i>Pre-release</i>
duplicate :: Monad m => Fold m a b -> Fold m a (Fold m a b)

-- | Finish the fold to extract the current value of the fold.
--   
--   <pre>
--   &gt;&gt;&gt; Fold.finish Fold.toList
--   []
--   </pre>
--   
--   <i>Pre-release</i>
finish :: Monad m => Fold m a b -> m b

-- | Flatten the monadic output of a fold to pure output.

-- | <i>Deprecated: Use "rmapM id" instead</i>
sequence :: Monad m => Fold m a (m b) -> Fold m a b

-- | Map a monadic function on the output of a fold.

-- | <i>Deprecated: Use rmapM instead</i>
mapM :: Monad m => (b -> m c) -> Fold m a b -> Fold m a c


-- | A <a>Fold</a> is a sink or a consumer of a stream of values. The
--   <a>Fold</a> type consists of an accumulator and an effectful action
--   that absorbs a value into the accumulator.
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Function ((&amp;))
--   
--   &gt;&gt;&gt; import qualified Streamly.Data.Fold as Fold
--   
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   </pre>
--   
--   For example, a <a>sum</a> Fold represents adding the input to the
--   accumulated sum. A fold driver e.g. <a>fold</a> pushes values from a
--   stream to the <a>Fold</a> one at a time, reducing the stream to a
--   single value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.sum $ Stream.fromList [1..100]
--   5050
--   </pre>
--   
--   Conceptually, a <a>Fold</a> is a data type that can mimic a strict
--   left fold (<a>foldl</a>) as well as lazy right fold (<a>foldr</a>).
--   The above example is similar to a left fold using <tt>(+)</tt> as the
--   step and <tt>0</tt> as the initial value of the accumulator:
--   
--   <pre>
--   &gt;&gt;&gt; Data.List.foldl' (+) 0 [1..100]
--   5050
--   </pre>
--   
--   <a>Fold</a>s have an early termination capability e.g. the <a>head</a>
--   fold would terminate on an infinite stream:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.head $ Stream.fromList [1..]
--   Just 1
--   </pre>
--   
--   The above example is similar to the following right fold:
--   
--   <pre>
--   &gt;&gt;&gt; Prelude.foldr (\x _ -&gt; Just x) Nothing [1..]
--   Just 1
--   </pre>
--   
--   <a>Fold</a>s can be combined together using combinators. For example,
--   to create a fold that sums first two elements in a stream:
--   
--   <pre>
--   &gt;&gt;&gt; sumTwo = Fold.take 2 Fold.sum
--   
--   &gt;&gt;&gt; Stream.fold sumTwo $ Stream.fromList [1..100]
--   3
--   </pre>
--   
--   Folds can be combined to run in parallel on the same input. For
--   example, to compute the average of numbers in a stream without going
--   through the stream twice:
--   
--   <pre>
--   &gt;&gt;&gt; avg = Fold.teeWith (/) Fold.sum (fmap fromIntegral Fold.length)
--   
--   &gt;&gt;&gt; Stream.fold avg $ Stream.fromList [1.0..100.0]
--   50.5
--   </pre>
--   
--   Folds can be combined so as to partition the input stream over
--   multiple folds. For example, to count even and odd numbers in a
--   stream:
--   
--   <pre>
--   &gt;&gt;&gt; split n = if even n then Left n else Right n
--   
--   &gt;&gt;&gt; stream = Stream.map split $ Stream.fromList [1..100]
--   
--   &gt;&gt;&gt; countEven = fmap (("Even " ++) . show) Fold.length
--   
--   &gt;&gt;&gt; countOdd = fmap (("Odd "  ++) . show) Fold.length
--   
--   &gt;&gt;&gt; f = Fold.partition countEven countOdd
--   
--   &gt;&gt;&gt; Stream.fold f stream
--   ("Even 50","Odd 50")
--   </pre>
--   
--   Terminating folds can be combined to parse the stream serially such
--   that the first fold consumes the input until it terminates and the
--   second fold consumes the rest of the input until it terminates:
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.serialWith (,) (Fold.take 8 Fold.toList) (Fold.takeEndBy (== '\n') Fold.toList)
--   
--   &gt;&gt;&gt; Stream.fold f $ Stream.fromList "header: hello\n"
--   ("header: ","hello\n")
--   </pre>
--   
--   A <a>Fold</a> can be applied repeatedly on a stream to transform it to
--   a stream of fold results. To split a stream on newlines:
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.takeEndBy (== '\n') Fold.toList
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany f $ Stream.fromList "Hello there!\nHow are you\n"
--   ["Hello there!\n","How are you\n"]
--   </pre>
--   
--   Similarly, we can split the input of a fold too:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.many f Fold.toList) $ Stream.fromList "Hello there!\nHow are you\n"
--   ["Hello there!\n","How are you\n"]
--   </pre>
--   
--   Please see <a>Streamly.Internal.Data.Fold</a> for additional
--   <tt>Pre-release</tt> functions.
--   
--   <h1>Folds vs. Streams</h1>
--   
--   We can often use streams or folds to achieve the same goal. However,
--   streams are more efficient in composition of producers (e.g.
--   <a>serial</a> or <a>mergeBy</a>) whereas folds are more efficient in
--   composition of consumers (e.g. <a>serialWith</a>, <a>partition</a> or
--   <a>teeWith</a>).
--   
--   Streams are producers, transformations on streams happen on the output
--   side:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    f stream =
--          Stream.filter odd stream
--        &amp; Stream.map (+1)
--        &amp; Stream.sum
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; f $ Stream.fromList [1..100 :: Int]
--   2550
--   </pre>
--   
--   Folds are stream consumers with an input stream and an output value,
--   stream transformations on folds happen on the input side:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   f =
--          Fold.filter odd
--        $ Fold.lmap (+1)
--        $ Fold.sum
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold f $ Stream.fromList [1..100 :: Int]
--   2550
--   </pre>
--   
--   Notice the similiarity in the definition of <tt>f</tt> in both cases,
--   the only difference is the composition by <tt>&amp;</tt> vs <tt>$</tt>
--   and the use <tt>lmap</tt> vs <tt>map</tt>, the difference is due to
--   output vs input side transformations.
module Streamly.Data.Fold

-- | The type <tt>Fold m a b</tt> having constructor <tt>Fold step initial
--   extract</tt> represents a fold over an input stream of values of type
--   <tt>a</tt> to a final value of type <tt>b</tt> in <a>Monad</a>
--   <tt>m</tt>.
--   
--   The fold uses an intermediate state <tt>s</tt> as accumulator, the
--   type <tt>s</tt> is internal to the specific fold definition. The
--   initial value of the fold state <tt>s</tt> is returned by
--   <tt>initial</tt>. The <tt>step</tt> function consumes an input and
--   either returns the final result <tt>b</tt> if the fold is done or the
--   next intermediate state (see <a>Step</a>). At any point the fold
--   driver can extract the result from the intermediate state using the
--   <tt>extract</tt> function.
--   
--   NOTE: The constructor is not yet exposed via exposed modules, smart
--   constructors are provided to create folds. If you think you need the
--   constructor of this type please consider using the smart constructors
--   in <a>Streamly.Internal.Data.Fold</a> instead.
--   
--   <i>since 0.8.0 (type changed)</i>
data Fold m a b

-- | Make a fold from a left fold style pure step function and initial
--   value of the accumulator.
--   
--   If your <a>Fold</a> returns only <a>Partial</a> (i.e. never returns a
--   <a>Done</a>) then you can use <tt>foldl'*</tt> constructors.
--   
--   A fold with an extract function can be expressed using fmap:
--   
--   <pre>
--   mkfoldlx :: Monad m =&gt; (s -&gt; a -&gt; s) -&gt; s -&gt; (s -&gt; b) -&gt; Fold m a b
--   mkfoldlx step initial extract = fmap extract (foldl' step initial)
--   </pre>
--   
--   See also: <tt>Streamly.Prelude.foldl'</tt>
foldl' :: Monad m => (b -> a -> b) -> b -> Fold m a b

-- | Make a fold from a left fold style monadic step function and initial
--   value of the accumulator.
--   
--   A fold with an extract function can be expressed using rmapM:
--   
--   <pre>
--   mkFoldlxM :: Functor m =&gt; (s -&gt; a -&gt; m s) -&gt; m s -&gt; (s -&gt; m b) -&gt; Fold m a b
--   mkFoldlxM step initial extract = rmapM extract (foldlM' step initial)
--   </pre>
--   
--   See also: <tt>Streamly.Prelude.foldlM'</tt>
foldlM' :: Monad m => (b -> a -> m b) -> m b -> Fold m a b

-- | Make a fold using a right fold style step function and a terminal
--   value. It performs a strict right fold via a left fold using function
--   composition. Note that this is strict fold, it can only be useful for
--   constructing strict structures in memory. For reductions this will be
--   very inefficient.
--   
--   For example,
--   
--   <pre>
--   toList = foldr (:) []
--   </pre>
--   
--   See also: <a>foldr</a>
foldr :: Monad m => (a -> b -> b) -> b -> Fold m a b

-- | Append the elements of an input stream to a provided starting value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.sconcat 10) (Stream.map Data.Monoid.Sum $ Stream.enumerateFromTo 1 10)
--   Sum {getSum = 65}
--   </pre>
--   
--   <pre>
--   sconcat = Fold.foldl' (&lt;&gt;)
--   </pre>
sconcat :: (Monad m, Semigroup a) => a -> Fold m a a

-- | Fold an input stream consisting of monoidal elements using
--   <a>mappend</a> and <a>mempty</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.mconcat (Stream.map Data.Monoid.Sum $ Stream.enumerateFromTo 1 10)
--   Sum {getSum = 55}
--   </pre>
--   
--   <pre>
--   mconcat = Fold.sconcat mempty
--   </pre>
mconcat :: (Monad m, Monoid a) => Fold m a a

-- | <pre>
--   foldMap f = Fold.lmap f Fold.mconcat
--   </pre>
--   
--   Make a fold from a pure function that folds the output of the function
--   using <a>mappend</a> and <a>mempty</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.foldMap Data.Monoid.Sum) $ Stream.enumerateFromTo 1 10
--   Sum {getSum = 55}
--   </pre>
foldMap :: (Monad m, Monoid b) => (a -> b) -> Fold m a b

-- | <pre>
--   foldMapM f = Fold.lmapM f Fold.mconcat
--   </pre>
--   
--   Make a fold from a monadic function that folds the output of the
--   function using <a>mappend</a> and <a>mempty</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.foldMapM (return . Data.Monoid.Sum)) $ Stream.enumerateFromTo 1 10
--   Sum {getSum = 55}
--   </pre>
foldMapM :: (Monad m, Monoid b) => (a -> m b) -> Fold m a b

-- | A fold that drains all its input, running the effects and discarding
--   the results.
--   
--   <pre>
--   drain = drainBy (const (return ()))
--   </pre>
drain :: Monad m => Fold m a ()

-- | <pre>
--   drainBy f = lmapM f drain
--   drainBy = Fold.foldMapM (void . f)
--   </pre>
--   
--   Drain all input after passing it through a monadic function. This is
--   the dual of mapM_ on stream producers.
--   
--   See also: <a>mapM_</a>
drainBy :: Monad m => (a -> m b) -> Fold m a ()

-- | Extract the last element of the input stream, if any.
--   
--   <pre>
--   last = fmap getLast $ Fold.foldMap (Last . Just)
--   </pre>
last :: Monad m => Fold m a (Maybe a)

-- | Determine the length of the input stream.
--   
--   <pre>
--   length = fmap getSum $ Fold.foldMap (Sum . const  1)
--   </pre>
length :: Monad m => Fold m a Int

-- | Determine the sum of all elements of a stream of numbers. Returns
--   additive identity (<tt>0</tt>) when the stream is empty. Note that
--   this is not numerically stable for floating point numbers.
--   
--   <pre>
--   sum = fmap getSum $ Fold.foldMap Sum
--   </pre>
sum :: (Monad m, Num a) => Fold m a a

-- | Determine the product of all elements of a stream of numbers. Returns
--   multiplicative identity (<tt>1</tt>) when the stream is empty. The
--   fold terminates when it encounters (<tt>0</tt>) in its input.
--   
--   Compare with <tt>Fold.foldMap Product</tt>.
--   
--   <i>Since 0.8.0 (Added <a>Eq</a> constraint)</i>
product :: (Monad m, Num a, Eq a) => Fold m a a

-- | Determine the maximum element in a stream using the supplied
--   comparison function.
maximumBy :: Monad m => (a -> a -> Ordering) -> Fold m a (Maybe a)

-- | <pre>
--   maximum = Fold.maximumBy compare
--   </pre>
--   
--   Determine the maximum element in a stream.
--   
--   Compare with <tt>Fold.foldMap Max</tt>.
maximum :: (Monad m, Ord a) => Fold m a (Maybe a)

-- | Computes the minimum element with respect to the given comparison
--   function
minimumBy :: Monad m => (a -> a -> Ordering) -> Fold m a (Maybe a)

-- | Determine the minimum element in a stream using the supplied
--   comparison function.
--   
--   <pre>
--   minimum = <a>minimumBy</a> compare
--   </pre>
--   
--   Compare with <tt>Fold.foldMap Min</tt>.
minimum :: (Monad m, Ord a) => Fold m a (Maybe a)

-- | Compute a numerically stable arithmetic mean of all elements in the
--   input stream.
mean :: (Monad m, Fractional a) => Fold m a a

-- | Compute a numerically stable (population) variance over all elements
--   in the input stream.
variance :: (Monad m, Fractional a) => Fold m a a

-- | Compute a numerically stable (population) standard deviation over all
--   elements in the input stream.
stdDev :: (Monad m, Floating a) => Fold m a a

-- | Compute an <a>Int</a> sized polynomial rolling hash of a stream.
--   
--   <pre>
--   rollingHash = Fold.rollingHashWithSalt defaultSalt
--   </pre>
rollingHash :: (Monad m, Enum a) => Fold m a Int64

-- | Compute an <a>Int</a> sized polynomial rolling hash
--   
--   <pre>
--   H = salt * k ^ n + c1 * k ^ (n - 1) + c2 * k ^ (n - 2) + ... + cn * k ^ 0
--   </pre>
--   
--   Where <tt>c1</tt>, <tt>c2</tt>, <tt>cn</tt> are the elements in the
--   input stream and <tt>k</tt> is a constant.
--   
--   This hash is often used in Rabin-Karp string search algorithm.
--   
--   See <a>https://en.wikipedia.org/wiki/Rolling_hash</a>
rollingHashWithSalt :: (Monad m, Enum a) => Int64 -> Fold m a Int64

-- | Folds the input stream to a list.
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using
--   <a>Streamly.Data.Array.Foreign</a> instead.
--   
--   <pre>
--   toList = foldr (:) []
--   </pre>
toList :: Monad m => Fold m a [a]

-- | Buffers the input stream to a list in the reverse order of the input.
--   
--   <pre>
--   toListRev = Fold.foldl' (flip (:)) []
--   </pre>
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using <a>Streamly.Array</a>
--   instead.
toListRev :: Monad m => Fold m a [a]

-- | Lookup the element at the given index.
--   
--   See also: <a>!!</a>
index :: Monad m => Int -> Fold m a (Maybe a)

-- | Extract the first element of the stream, if any.
head :: Monad m => Fold m a (Maybe a)

-- | Returns the first element that satisfies the given predicate.
find :: Monad m => (a -> Bool) -> Fold m a (Maybe a)

-- | In a stream of (key-value) pairs <tt>(a, b)</tt>, return the value
--   <tt>b</tt> of the first pair where the key equals the given value
--   <tt>a</tt>.
--   
--   <pre>
--   lookup = snd &lt;$&gt; Fold.find ((==) . fst)
--   </pre>
lookup :: (Eq a, Monad m) => a -> Fold m (a, b) (Maybe b)

-- | Returns the first index that satisfies the given predicate.
findIndex :: Monad m => (a -> Bool) -> Fold m a (Maybe Int)

-- | Returns the first index where a given value is found in the stream.
--   
--   <pre>
--   elemIndex a = Fold.findIndex (== a)
--   </pre>
elemIndex :: (Eq a, Monad m) => a -> Fold m a (Maybe Int)

-- | Return <a>True</a> if the input stream is empty.
--   
--   <pre>
--   null = fmap isJust Fold.head
--   </pre>
null :: Monad m => Fold m a Bool

-- | Return <a>True</a> if the given element is present in the stream.
--   
--   <pre>
--   elem a = Fold.any (== a)
--   </pre>
elem :: (Eq a, Monad m) => a -> Fold m a Bool

-- | Returns <a>True</a> if the given element is not present in the stream.
--   
--   <pre>
--   notElem a = Fold.all (/= a)
--   </pre>
notElem :: (Eq a, Monad m) => a -> Fold m a Bool

-- | Returns <a>True</a> if all elements of a stream satisfy a predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.all (== 0)) $ Stream.fromList [1,0,1]
--   False
--   </pre>
--   
--   <pre>
--   all p = Fold.lmap p Fold.and
--   </pre>
all :: Monad m => (a -> Bool) -> Fold m a Bool

-- | Returns <a>True</a> if any of the elements of a stream satisfies a
--   predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.any (== 0)) $ Stream.fromList [1,0,1]
--   True
--   </pre>
--   
--   <pre>
--   any p = Fold.lmap p Fold.or
--   </pre>
any :: Monad m => (a -> Bool) -> Fold m a Bool

-- | Returns <a>True</a> if all elements are <a>True</a>, <a>False</a>
--   otherwise
--   
--   <pre>
--   and = Fold.all (== True)
--   </pre>
and :: Monad m => Fold m Bool Bool

-- | Returns <a>True</a> if any element is <a>True</a>, <a>False</a>
--   otherwise
--   
--   <pre>
--   or = Fold.any (== True)
--   </pre>
or :: Monad m => Fold m Bool Bool

-- | Map a monadic function on the output of a fold.
rmapM :: Monad m => (b -> m c) -> Fold m a b -> Fold m a c

-- | <tt>lmap f fold</tt> maps the function <tt>f</tt> on the input of the
--   fold.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.lmap (\x -&gt; x * x) Fold.sum) (Stream.enumerateFromTo 1 100)
--   338350
--   </pre>
--   
--   <pre>
--   lmap = Fold.lmapM return
--   </pre>
lmap :: (a -> b) -> Fold m b r -> Fold m a r

-- | <tt>lmapM f fold</tt> maps the monadic function <tt>f</tt> on the
--   input of the fold.
lmapM :: Monad m => (a -> m b) -> Fold m b r -> Fold m a r

-- | Include only those elements that pass a predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.filter (&gt; 5) Fold.sum) $ Stream.fromList [1..10]
--   40
--   </pre>
--   
--   <pre>
--   filter f = Fold.filterM (return . f)
--   </pre>
filter :: Monad m => (a -> Bool) -> Fold m a r -> Fold m a r

-- | Like <a>filter</a> but with a monadic predicate.
filterM :: Monad m => (a -> m Bool) -> Fold m a r -> Fold m a r

-- | Modify a fold to receive a <a>Maybe</a> input, the <a>Just</a> values
--   are unwrapped and sent to the original fold, <a>Nothing</a> values are
--   discarded.
catMaybes :: Monad m => Fold m a b -> Fold m (Maybe a) b

-- | <tt>mapMaybe f fold</tt> maps a <a>Maybe</a> returning function
--   <tt>f</tt> on the input of the fold, filters out <a>Nothing</a>
--   elements, and return the values extracted from <a>Just</a>.
--   
--   <pre>
--   &gt;&gt;&gt; f x = if even x then Just x else Nothing
--   
--   &gt;&gt;&gt; fld = Fold.mapMaybe f Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold fld (Stream.enumerateFromTo 1 10)
--   [2,4,6,8,10]
--   </pre>
mapMaybe :: Monad m => (a -> Maybe b) -> Fold m b r -> Fold m a r

-- | Take at most <tt>n</tt> input elements and fold them using the
--   supplied fold. A negative count is treated as 0.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.take 2 Fold.toList) $ Stream.fromList [1..10]
--   [1,2]
--   </pre>
take :: Monad m => Int -> Fold m a b -> Fold m a b

-- | Like <a>takeEndBy</a> but drops the element on which the predicate
--   succeeds.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.takeEndBy_ (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   "hello"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany (Fold.takeEndBy_ (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   ["hello","there"]
--   </pre>
--   
--   <pre>
--   Stream.splitOnSuffix p f = Stream.foldMany (Fold.takeEndBy_ p f)
--   </pre>
--   
--   See <a>splitOnSuffix</a> for more details on splitting a stream using
--   <a>takeEndBy_</a>.
takeEndBy_ :: Monad m => (a -> Bool) -> Fold m a b -> Fold m a b

-- | Take the input, stop when the predicate succeeds taking the succeeding
--   element as well.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.takeEndBy (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   "hello\n"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany (Fold.takeEndBy (== '\n') Fold.toList) $ Stream.fromList "hello\nthere\n"
--   ["hello\n","there\n"]
--   </pre>
--   
--   <pre>
--   Stream.splitWithSuffix p f = Stream.foldMany (Fold.takeEndBy p f)
--   </pre>
--   
--   See <a>splitWithSuffix</a> for more details on splitting a stream
--   using <a>takeEndBy</a>.
takeEndBy :: Monad m => (a -> Bool) -> Fold m a b -> Fold m a b

-- | Sequential fold application. Apply two folds sequentially to an input
--   stream. The input is provided to the first fold, when it is done - the
--   remaining input is provided to the second fold. When the second fold
--   is done or if the input stream is over, the outputs of the two folds
--   are combined using the supplied function.
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.serialWith (,) (Fold.take 8 Fold.toList) (Fold.takeEndBy (== '\n') Fold.toList)
--   
--   &gt;&gt;&gt; Stream.fold f $ Stream.fromList "header: hello\n"
--   ("header: ","hello\n")
--   </pre>
--   
--   Note: This is dual to appending streams using <a>serial</a>.
--   
--   Note: this implementation allows for stream fusion but has quadratic
--   time complexity, because each composition adds a new branch that each
--   subsequent fold's input element has to traverse, therefore, it cannot
--   scale to a large number of compositions. After around 100 compositions
--   the performance starts dipping rapidly compared to a CPS style
--   implementation.
--   
--   <i>Time: O(n^2) where n is the number of compositions.</i>
serialWith :: Monad m => (a -> b -> c) -> Fold m x a -> Fold m x b -> Fold m x c

-- | <tt>teeWith k f1 f2</tt> distributes its input to both <tt>f1</tt> and
--   <tt>f2</tt> until both of them terminate and combines their output
--   using <tt>k</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; avg = Fold.teeWith (/) Fold.sum (fmap fromIntegral Fold.length)
--   
--   &gt;&gt;&gt; Stream.fold avg $ Stream.fromList [1.0..100.0]
--   50.5
--   </pre>
--   
--   <pre>
--   teeWith k f1 f2 = fmap (uncurry k) ((Fold.tee f1 f2)
--   </pre>
--   
--   For applicative composition using this combinator see
--   <a>Streamly.Internal.Data.Fold.Tee</a>.
--   
--   See also: <a>Streamly.Internal.Data.Fold.Tee</a>
teeWith :: Monad m => (a -> b -> c) -> Fold m x a -> Fold m x b -> Fold m x c

-- | Distribute one copy of the stream to each fold and zip the results.
--   
--   <pre>
--                   |-------Fold m a b--------|
--   ---stream m a---|                         |---m (b,c)
--                   |-------Fold m a c--------|
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.tee Fold.sum Fold.length) (Stream.enumerateFromTo 1.0 100.0)
--   (5050.0,100)
--   </pre>
--   
--   <pre>
--   tee = teeWith (,)
--   </pre>
tee :: Monad m => Fold m a b -> Fold m a c -> Fold m a (b, c)

-- | Distribute one copy of the stream to each fold and collect the results
--   in a container.
--   
--   <pre>
--                   |-------Fold m a b--------|
--   ---stream m a---|                         |---m [b]
--                   |-------Fold m a b--------|
--                   |                         |
--                              ...
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold (Fold.distribute [Fold.sum, Fold.length]) (Stream.enumerateFromTo 1 5)
--   [15,5]
--   </pre>
--   
--   <pre>
--   distribute = Prelude.foldr (Fold.teeWith (:)) (Fold.fromPure [])
--   </pre>
--   
--   This is the consumer side dual of the producer side <a>sequence</a>
--   operation.
--   
--   Stops when all the folds stop.
distribute :: Monad m => [Fold m a b] -> Fold m a [b]

-- | Compose two folds such that the combined fold accepts a stream of
--   <a>Either</a> and routes the <a>Left</a> values to the first fold and
--   <a>Right</a> values to the second fold.
--   
--   <pre>
--   partition = partitionBy id
--   </pre>
partition :: Monad m => Fold m b x -> Fold m c y -> Fold m (Either b c) (x, y)

-- | Send the elements of tuples in a stream of tuples through two
--   different folds.
--   
--   <pre>
--                             |-------Fold m a x--------|
--   ---------stream of (a,b)--|                         |----m (x,y)
--                             |-------Fold m b y--------|
--   </pre>
--   
--   <pre>
--   unzip = Fold.unzipWith id
--   </pre>
--   
--   This is the consumer side dual of the producer side <a>zip</a>
--   operation.
unzip :: Monad m => Fold m a x -> Fold m b y -> Fold m (a, b) (x, y)

-- | Collect zero or more applications of a fold. <tt>many split
--   collect</tt> applies the <tt>split</tt> fold repeatedly on the input
--   stream and accumulates zero or more fold results using
--   <tt>collect</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; two = Fold.take 2 Fold.toList
--   
--   &gt;&gt;&gt; twos = Fold.many two Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold twos $ Stream.fromList [1..10]
--   [[1,2],[3,4],[5,6],[7,8],[9,10]]
--   </pre>
--   
--   Stops when <tt>collect</tt> stops.
--   
--   See also: <a>concatMap</a>, <a>foldMany</a>
many :: Monad m => Fold m a b -> Fold m b c -> Fold m a c

-- | <tt>chunksOf n split collect</tt> repeatedly applies the
--   <tt>split</tt> fold to chunks of <tt>n</tt> items in the input stream
--   and supplies the result to the <tt>collect</tt> fold.
--   
--   <pre>
--   &gt;&gt;&gt; twos = Fold.chunksOf 2 Fold.toList Fold.toList
--   
--   &gt;&gt;&gt; Stream.fold twos $ Stream.fromList [1..10]
--   [[1,2],[3,4],[5,6],[7,8],[9,10]]
--   </pre>
--   
--   <pre>
--   chunksOf n split = many (take n split)
--   </pre>
--   
--   Stops when <tt>collect</tt> stops.
chunksOf :: Monad m => Int -> Fold m a b -> Fold m b c -> Fold m a c

-- | Map a <a>Fold</a> returning function on the result of a <a>Fold</a>
--   and run the returned fold. This operation can be used to express data
--   dependencies between fold operations.
--   
--   Let's say the first element in the stream is a count of the following
--   elements that we have to add, then:
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Maybe (fromJust)
--   
--   &gt;&gt;&gt; count = fmap fromJust Fold.head
--   
--   &gt;&gt;&gt; total n = Fold.take n Fold.sum
--   
--   &gt;&gt;&gt; Stream.fold (Fold.concatMap total count) $ Stream.fromList [10,9..1]
--   45
--   </pre>
--   
--   <i>Time: O(n^2) where <tt>n</tt> is the number of compositions.</i>
--   
--   See also: <a>foldIterateM</a>
concatMap :: Monad m => (b -> Fold m a c) -> Fold m a b -> Fold m a c

-- | Flatten the monadic output of a fold to pure output.

-- | <i>Deprecated: Use "rmapM id" instead</i>
sequence :: Monad m => Fold m a (m b) -> Fold m a b

-- | Map a monadic function on the output of a fold.

-- | <i>Deprecated: Use rmapM instead</i>
mapM :: Monad m => (b -> m c) -> Fold m a b -> Fold m a c


module Streamly.Internal.Data.SVar.Worker
decrementYieldLimit :: SVar t m a -> IO Bool
incrementYieldLimit :: SVar t m a -> IO ()
decrementBufferLimit :: SVar t m a -> IO ()
incrementBufferLimit :: SVar t m a -> IO ()
resetBufferLimit :: SVar t m a -> IO ()
data Work
BlockWait :: NanoSecond64 -> Work
PartialWorker :: Count -> Work
ManyWorkers :: Int -> Count -> Work
isBeyondMaxRate :: SVar t m a -> YieldRateInfo -> IO Bool
estimateWorkers :: Limit -> Count -> Count -> NanoSecond64 -> NanoSecond64 -> NanoSecond64 -> LatencyRange -> Work
updateYieldCount :: WorkerInfo -> IO Count

-- | This is a magic number and it is overloaded, and used at several
--   places to achieve batching:
--   
--   <ol>
--   <li>If we have to sleep to slowdown this is the minimum period that we
--   accumulate before we sleep. Also, workers do not stop until this much
--   sleep time is accumulated.</li>
--   <li>Collected latencies are computed and transferred to measured
--   latency after a minimum of this period.</li>
--   </ol>
minThreadDelay :: NanoSecond64
workerRateControl :: SVar t m a -> YieldRateInfo -> WorkerInfo -> IO Bool
workerUpdateLatency :: YieldRateInfo -> WorkerInfo -> IO ()

-- | This function is used by the producer threads to queue output for the
--   consumer thread to consume. Returns whether the queue has more space.
send :: SVar t m a -> ChildEvent a -> IO Int
ringDoorBell :: SVar t m a -> IO ()
sendYield :: SVar t m a -> Maybe WorkerInfo -> ChildEvent a -> IO Bool
sendToProducer :: SVar t m a -> ChildEvent a -> IO Int
sendStop :: SVar t m a -> Maybe WorkerInfo -> IO ()
sendStopToProducer :: MonadIO m => SVar t m a -> m ()
handleChildException :: SVar t m a -> SomeException -> IO ()
handleFoldException :: SVar t m a -> SomeException -> IO ()
instance GHC.Show.Show Streamly.Internal.Data.SVar.Worker.Work


module Streamly.Internal.Data.SVar.Dispatch
collectLatency :: SVar t m a -> YieldRateInfo -> Bool -> IO (Count, AbsTime, NanoSecond64)
withDiagMVar :: SVar t m a -> String -> IO () -> IO ()
dumpSVar :: SVar t m a -> IO String
printSVar :: SVar t m a -> String -> IO ()
delThread :: MonadIO m => SVar t m a -> ThreadId -> m ()
modifyThread :: MonadIO m => SVar t m a -> ThreadId -> m ()

-- | This is safe even if we are adding more threads concurrently because
--   if a child thread is adding another thread then anyway
--   <a>workerThreads</a> will not be empty.
allThreadsDone :: MonadIO m => SVar t m a -> m Bool
recordMaxWorkers :: MonadIO m => SVar t m a -> m ()
pushWorker :: MonadAsync m => Count -> SVar t m a -> m ()

-- | In contrast to pushWorker which always happens only from the consumer
--   thread, a pushWorkerPar can happen concurrently from multiple threads
--   on the producer side. So we need to use a thread safe modification of
--   workerThreads. Alternatively, we can use a CreateThread event to avoid
--   using a CAS based modification.
pushWorkerPar :: MonadAsync m => SVar t m a -> (Maybe WorkerInfo -> m ()) -> m ()
dispatchWorker :: MonadAsync m => Count -> SVar t m a -> m Bool
dispatchWorkerPaced :: MonadAsync m => SVar t m a -> m Bool
sendWorkerWait :: MonadAsync m => (SVar t m a -> IO ()) -> (SVar t m a -> m Bool) -> SVar t m a -> m ()
sendFirstWorker :: MonadAsync m => SVar t m a -> t m a -> m (SVar t m a)
sendWorkerDelay :: SVar t m a -> IO ()
sendWorkerDelayPaced :: SVar t m a -> IO ()


module Streamly.Internal.Data.SVar.Pull
readOutputQBasic :: IORef ([ChildEvent a], Int) -> IO ([ChildEvent a], Int)
readOutputQRaw :: SVar t m a -> IO ([ChildEvent a], Int)
readOutputQPaced :: MonadAsync m => SVar t m a -> m [ChildEvent a]
readOutputQBounded :: MonadAsync m => SVar t m a -> m [ChildEvent a]
postProcessPaced :: MonadAsync m => SVar t m a -> m Bool
postProcessBounded :: MonadAsync m => SVar t m a -> m Bool
cleanupSVar :: SVar t m a -> IO ()
cleanupSVarFromWorker :: SVar t m a -> IO ()


module Streamly.Internal.Data.SVar
getYieldRateInfo :: State t m a -> IO (Maybe YieldRateInfo)
newSVarStats :: IO SVarStats
newParallelVar :: MonadAsync m => SVarStopStyle -> State t m a -> m (SVar t m a)
enqueueAhead :: SVar t m a -> IORef ([t m a], Int) -> (RunInIO m, t m a) -> IO ()
reEnqueueAhead :: SVar t m a -> IORef ([t m a], Int) -> t m a -> IO ()
queueEmptyAhead :: MonadIO m => IORef ([t m a], Int) -> m Bool
dequeueAhead :: MonadIO m => IORef ([t m a], Int) -> m (Maybe (t m a, Int))
data HeapDequeueResult t m a
Clearing :: HeapDequeueResult t m a
Waiting :: Int -> HeapDequeueResult t m a
Ready :: Entry Int (AheadHeapEntry t m a) -> HeapDequeueResult t m a
dequeueFromHeap :: IORef (Heap (Entry Int (AheadHeapEntry t m a)), Maybe Int) -> IO (HeapDequeueResult t m a)
dequeueFromHeapSeq :: IORef (Heap (Entry Int (AheadHeapEntry t m a)), Maybe Int) -> Int -> IO (HeapDequeueResult t m a)
requeueOnHeapTop :: IORef (Heap (Entry Int (AheadHeapEntry t m a)), Maybe Int) -> Entry Int (AheadHeapEntry t m a) -> Int -> IO ()
updateHeapSeq :: IORef (Heap (Entry Int (AheadHeapEntry t m a)), Maybe Int) -> Int -> IO ()
withIORef :: IORef a -> (a -> IO b) -> IO b
heapIsSane :: Maybe Int -> Int -> Bool
newAheadVar :: MonadAsync m => State t m a -> t m a -> (IORef ([t m a], Int) -> IORef (Heap (Entry Int (AheadHeapEntry t m a)), Maybe Int) -> State t m a -> SVar t m a -> Maybe WorkerInfo -> m ()) -> m (SVar t m a)


module Streamly.Internal.Data.Unfold.SVar

-- | <i>Internal</i>
fromSVar :: MonadAsync m => Unfold m (SVar t m a) a

-- | <i>Internal</i>
fromProducer :: MonadAsync m => Unfold m (SVar t m a) a


module Streamly.Internal.Data.Stream.SVar.Generate

-- | Write a stream to an <a>SVar</a> in a non-blocking manner. The stream
--   can then be read back from the SVar using <a>fromSVar</a>.
toSVar :: MonadAsync m => SVar SerialT m a -> SerialT m a -> m ()

-- | Generate a stream from an SVar. An unevaluated stream can be pushed to
--   an SVar using <a>toSVar</a>. As we pull a stream from the SVar the
--   input stream gets evaluated concurrently. The evaluation depends on
--   the SVar style and the configuration parameters e.g. using the
--   maxBuffer/maxThreads combinators.
fromSVar :: MonadAsync m => SVar Stream m a -> SerialT m a

-- | Like <a>fromSVar</a> but generates a StreamD style stream instead of
--   CPS.
fromSVarD :: MonadAsync m => SVar t m a -> Stream m a


-- | To run examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; :{
--    delay n = do
--        threadDelay (n * 1000000)   -- sleep for n seconds
--        putStrLn (show n ++ " sec") -- print "n sec"
--        return n                    -- IO Int
--   :}
--   </pre>
module Streamly.Internal.Data.Stream.Async

-- | For <a>AsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>async</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>async</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>async</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>async</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>async</tt>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
newtype AsyncT m a
AsyncT :: Stream m a -> AsyncT m a
[getAsyncT] :: AsyncT m a -> Stream m a

-- | A demand driven left biased parallely composing IO stream of elements
--   of type <tt>a</tt>. See <a>AsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Async = AsyncT IO

-- | XXX we can implement it more efficienty by directly implementing
--   instead of combining streams using async.
consMAsync :: MonadAsync m => m a -> AsyncT m a -> AsyncT m a
asyncK :: MonadAsync m => Stream m a -> Stream m a -> Stream m a

-- | Generate a stream asynchronously to keep it buffered, lazily consume
--   from the buffer.
--   
--   <i>Pre-release</i>
mkAsyncK :: MonadAsync m => Stream m a -> Stream m a
mkAsyncD :: MonadAsync m => Stream m a -> Stream m a

-- | For <a>WAsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wAsync</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wAsync</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>wAsync</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>wAsync</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one <a>WAsyncT</a> output stream and all the iterations corresponding
--   to <tt>2</tt> constitute another <a>WAsyncT</a> output stream and
--   these two output streams are merged using <tt>wAsync</tt>.
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>AsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
newtype WAsyncT m a
WAsyncT :: Stream m a -> WAsyncT m a
[getWAsyncT] :: WAsyncT m a -> Stream m a

-- | A round robin parallely composing IO stream of elements of type
--   <tt>a</tt>. See <a>WAsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WAsync = WAsyncT IO

-- | XXX we can implement it more efficienty by directly implementing
--   instead of combining streams using wAsync.
consMWAsync :: MonadAsync m => m a -> WAsyncT m a -> WAsyncT m a
wAsyncK :: MonadAsync m => Stream m a -> Stream m a -> Stream m a
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.Async.AsyncT
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.Async.WAsyncT
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Async.WAsyncT m a)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monoid (Streamly.Internal.Data.Stream.Async.WAsyncT m a)
instance (GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monad (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance (Control.Monad.Base.MonadBase b m, GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Base.MonadBase b (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance (Control.Monad.IO.Class.MonadIO m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance (Control.Monad.Catch.MonadThrow m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Catch.MonadThrow (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance (Control.Monad.Reader.Class.MonadReader r m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance (Control.Monad.State.Class.MonadState s m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Stream.Async.WAsyncT m)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Async.AsyncT m a)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monoid (Streamly.Internal.Data.Stream.Async.AsyncT m a)
instance (GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Async.AsyncT m)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monad (Streamly.Internal.Data.Stream.Async.AsyncT m)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Async.AsyncT m)
instance (Control.Monad.Base.MonadBase b m, GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Base.MonadBase b (Streamly.Internal.Data.Stream.Async.AsyncT m)
instance (Control.Monad.IO.Class.MonadIO m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Stream.Async.AsyncT m)
instance (Control.Monad.Catch.MonadThrow m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Catch.MonadThrow (Streamly.Internal.Data.Stream.Async.AsyncT m)
instance (Control.Monad.Reader.Class.MonadReader r m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Stream.Async.AsyncT m)
instance (Control.Monad.State.Class.MonadState s m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Stream.Async.AsyncT m)


-- | To run examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; :{
--    delay n = do
--        threadDelay (n * 1000000)   -- sleep for n seconds
--        putStrLn (show n ++ " sec") -- print "n sec"
--        return n                    -- IO Int
--   :}
--   </pre>
module Streamly.Internal.Data.Stream.Ahead

-- | For <a>AheadT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>ahead</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>ahead</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations executed concurrently, ahead of time, producing side
--   effects of iterations out of order, but results in order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [2,1]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, ahead of time:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,5,4,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>ahead</tt>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
newtype AheadT m a
AheadT :: Stream m a -> AheadT m a
[getAheadT] :: AheadT m a -> Stream m a

-- | A serial IO stream of elements of type <tt>a</tt> with concurrent
--   lookahead. See <a>AheadT</a> documentation for more details.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
type Ahead = AheadT IO
aheadK :: MonadAsync m => Stream m a -> Stream m a -> Stream m a

-- | XXX we can implement it more efficienty by directly implementing
--   instead of combining streams using ahead.
consM :: MonadAsync m => m a -> AheadT m a -> AheadT m a
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.Ahead.AheadT
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Ahead.AheadT m a)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monoid (Streamly.Internal.Data.Stream.Ahead.AheadT m a)
instance (GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Ahead.AheadT m)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monad (Streamly.Internal.Data.Stream.Ahead.AheadT m)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Ahead.AheadT m)
instance (Control.Monad.Base.MonadBase b m, GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Base.MonadBase b (Streamly.Internal.Data.Stream.Ahead.AheadT m)
instance (Control.Monad.IO.Class.MonadIO m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Stream.Ahead.AheadT m)
instance (Control.Monad.Catch.MonadThrow m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Catch.MonadThrow (Streamly.Internal.Data.Stream.Ahead.AheadT m)
instance (Control.Monad.Reader.Class.MonadReader r m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Stream.Ahead.AheadT m)
instance (Control.Monad.State.Class.MonadState s m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Stream.Ahead.AheadT m)


module Streamly.Internal.Data.Fold.SVar

-- | A fold to write a stream to an SVar. Unlike <tt>toSVar</tt> this does
--   not allow for concurrent evaluation of the stream, as the fold
--   receives the input one element at a time, it just forwards the
--   elements to the SVar. However, we can safely execute the fold in an
--   independent thread, the SVar can act as a buffer decoupling the sender
--   from the receiver. Also, we can have multiple folds running
--   concurrently pusing the streams to the SVar.
write :: MonadIO m => SVar t m a -> Maybe WorkerInfo -> Fold m a ()

-- | Like write, but applies a yield limit.
writeLimited :: MonadIO m => SVar t m a -> Maybe WorkerInfo -> Fold m a ()


-- | Eliminate a stream by distributing it to multiple SVars concurrently.
module Streamly.Internal.Data.Stream.SVar.Eliminate

-- | Fold the supplied stream to the SVar asynchronously using Parallel
--   concurrency style. {-# INLINE [1] toSVarParallel #-}
toSVarParallel :: MonadAsync m => State t m a -> SVar t m a -> Stream m a -> m ()

-- | Create a Fold style SVar that runs a supplied fold function as the
--   consumer. Any elements sent to the SVar are consumed by the supplied
--   fold function.
newFoldSVar :: MonadAsync m => State Stream m a -> (SerialT m a -> m b) -> m (SVar Stream m a)

-- | Like <a>newFoldSVar</a> except that it uses a <a>Fold</a> instead of a
--   fold function.
newFoldSVarF :: MonadAsync m => State t m a -> Fold m a b -> m (SVar t m a)

-- | Poll for events sent by the fold consumer to the stream pusher. The
--   fold consumer can send a <a>Stop</a> event or an exception. When a
--   <a>Stop</a> is received this function returns <a>True</a>. If an
--   exception is recieved then it throws the exception.
fromConsumer :: MonadAsync m => SVar Stream m a -> m Bool

-- | Push values from a stream to a fold worker via an SVar. Before pushing
--   a value to the SVar it polls for events received from the fold
--   consumer. If a stop event is received then it returns <a>True</a>
--   otherwise false. Propagates exceptions received from the fold
--   consumer.
pushToFold :: MonadAsync m => SVar Stream m a -> a -> m Bool

-- | Tap a stream and send the elements to the specified SVar in addition
--   to yielding them again. The SVar runs a fold consumer. Elements are
--   tapped and sent to the SVar until the fold finishes. Any exceptions
--   from the fold evaluation are propagated in the current thread.
--   
--   <pre>
--   ------input stream---------output stream-----&gt;
--                      /|\   |
--           exceptions  |    |  input
--                       |   \|/
--                       ----SVar
--                            |
--                           Fold
--   </pre>
teeToSVar :: MonadAsync m => SVar Stream m a -> SerialT m a -> SerialT m a


-- | To run examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; :{
--    delay n = do
--        threadDelay (n * 1000000)   -- sleep for n seconds
--        putStrLn (show n ++ " sec") -- print "n sec"
--        return n                    -- IO Int
--   :}
--   </pre>
module Streamly.Internal.Data.Stream.Parallel

-- | For <a>ParallelT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>parallel</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>parallel</a>
--   </pre>
--   
--   See <a>AsyncT</a>, <a>ParallelT</a> is similar except that all
--   iterations are strictly concurrent while in <tt>AsyncT</tt> it depends
--   on the consumer demand and available threads. See <tt>parallel</tt>
--   for more details.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
--   
--   <i>Since: 0.7.0 (maxBuffer applies to ParallelT streams)</i>
newtype ParallelT m a
ParallelT :: Stream m a -> ParallelT m a
[getParallelT] :: ParallelT m a -> Stream m a

-- | A parallely composing IO stream of elements of type <tt>a</tt>. See
--   <a>ParallelT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Parallel = ParallelT IO

-- | XXX we can implement it more efficienty by directly implementing
--   instead of combining streams using parallel.
consM :: MonadAsync m => m a -> ParallelT m a -> ParallelT m a
parallelK :: MonadAsync m => Stream m a -> Stream m a -> Stream m a

-- | Like <tt>parallel</tt> but stops the output as soon as the first
--   stream stops.
--   
--   <i>Pre-release</i>
parallelFstK :: MonadAsync m => Stream m a -> Stream m a -> Stream m a

-- | Like <tt>parallel</tt> but stops the output as soon as any of the two
--   streams stops.
--   
--   <i>Pre-release</i>
parallelMinK :: MonadAsync m => Stream m a -> Stream m a -> Stream m a

-- | Same as <tt>mkParallel</tt> but for StreamD stream.
mkParallelD :: MonadAsync m => Stream m a -> Stream m a

-- | Like <tt>mkParallel</tt> but uses StreamK internally.
--   
--   <i>Pre-release</i>
mkParallelK :: MonadAsync m => Stream m a -> Stream m a

-- | Redirect a copy of the stream to a supplied fold and run it
--   concurrently in an independent thread. The fold may buffer some
--   elements. The buffer size is determined by the prevailing
--   <a>maxBuffer</a> setting.
--   
--   <pre>
--                 Stream m a -&gt; m b
--                         |
--   -----stream m a ---------------stream m a-----
--   </pre>
--   
--   <pre>
--   &gt; S.drain $ S.tapAsync (S.mapM_ print) (S.enumerateFromTo 1 2)
--   1
--   2
--   </pre>
--   
--   Exceptions from the concurrently running fold are propagated to the
--   current computation. Note that, because of buffering in the fold,
--   exceptions may be delayed and may not correspond to the current
--   element being processed in the parent stream, but we guarantee that
--   before the parent stream stops the tap finishes and all exceptions
--   from it are drained.
--   
--   Compare with <tt>tap</tt>.
--   
--   <i>Pre-release</i>
tapAsyncK :: MonadAsync m => (Stream m a -> m b) -> Stream m a -> Stream m a

-- | Like <tt>tapAsync</tt> but uses a <a>Fold</a> instead of a fold
--   function.
tapAsyncF :: MonadAsync m => Fold m a b -> Stream m a -> Stream m a

-- | Generates a callback and a stream pair. The callback returned is used
--   to queue values to the stream. The stream is infinite, there is no way
--   for the callback to indicate that it is done now.
--   
--   <i>Pre-release</i>
newCallbackStream :: MonadAsync m => m (a -> m (), Stream m a)
instance Control.Monad.Trans.Class.MonadTrans Streamly.Internal.Data.Stream.Parallel.ParallelT
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Parallel.ParallelT m a)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monoid (Streamly.Internal.Data.Stream.Parallel.ParallelT m a)
instance (GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Parallel.ParallelT m)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Monad (Streamly.Internal.Data.Stream.Parallel.ParallelT m)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Parallel.ParallelT m)
instance (Control.Monad.Base.MonadBase b m, GHC.Base.Monad m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Base.MonadBase b (Streamly.Internal.Data.Stream.Parallel.ParallelT m)
instance (Control.Monad.IO.Class.MonadIO m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.IO.Class.MonadIO (Streamly.Internal.Data.Stream.Parallel.ParallelT m)
instance (Control.Monad.Catch.MonadThrow m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Catch.MonadThrow (Streamly.Internal.Data.Stream.Parallel.ParallelT m)
instance (Control.Monad.Reader.Class.MonadReader r m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.Reader.Class.MonadReader r (Streamly.Internal.Data.Stream.Parallel.ParallelT m)
instance (Control.Monad.State.Class.MonadState s m, Streamly.Internal.Control.Concurrent.MonadAsync m) => Control.Monad.State.Class.MonadState s (Streamly.Internal.Data.Stream.Parallel.ParallelT m)


-- | <a>Streamly.Internal.Data.Pipe</a> might ultimately replace this
--   module.
module Streamly.Internal.Data.Stream.StreamD.Transform
transform :: Monad m => Pipe m a b -> Stream m a -> Stream m b
map :: Monad m => (a -> b) -> Stream m a -> Stream m b

-- | Map a monadic function over a <a>Stream</a>
mapM :: Monad m => (a -> m b) -> Stream m a -> Stream m b
sequence :: Monad m => Stream m (m a) -> Stream m a
tap :: Monad m => Fold m a b -> Stream m a -> Stream m a
tapOffsetEvery :: Monad m => Int -> Int -> Fold m a b -> Stream m a -> Stream m a
tapRate :: (MonadAsync m, MonadCatch m) => Double -> (Int -> m b) -> Stream m a -> Stream m a
pollCounts :: MonadAsync m => (a -> Bool) -> (Stream m Int -> Stream m Int) -> Fold m Int b -> Stream m a -> Stream m a
foldrS :: Monad m => (a -> Stream m b -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
foldrT :: (Monad m, Monad (t m), MonadTrans t) => (a -> t m b -> t m b) -> t m b -> Stream m a -> t m b
foldlS :: Monad m => (Stream m b -> a -> Stream m b) -> Stream m b -> Stream m a -> Stream m b
foldlT :: (Monad m, Monad (s m), MonadTrans s) => (s m b -> a -> s m b) -> s m b -> Stream m a -> s m b
postscanOnce :: Monad m => Fold m a b -> Stream m a -> Stream m b
scanOnce :: Monad m => Fold m a b -> Stream m a -> Stream m b
scanlM' :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> Stream m b
scanlMAfter' :: Monad m => (b -> a -> m b) -> m b -> (b -> m b) -> Stream m a -> Stream m b
scanl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> Stream m b
scanlM :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> Stream m b
scanl :: Monad m => (b -> a -> b) -> b -> Stream m a -> Stream m b
scanl1M' :: Monad m => (a -> a -> m a) -> Stream m a -> Stream m a
scanl1' :: Monad m => (a -> a -> a) -> Stream m a -> Stream m a
scanl1M :: Monad m => (a -> a -> m a) -> Stream m a -> Stream m a
scanl1 :: Monad m => (a -> a -> a) -> Stream m a -> Stream m a
prescanl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> Stream m b
prescanlM' :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> Stream m b
postscanl :: Monad m => (a -> b -> a) -> a -> Stream m b -> Stream m a
postscanlM :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> Stream m b
postscanl' :: Monad m => (a -> b -> a) -> a -> Stream m b -> Stream m a
postscanlM' :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> Stream m b
postscanlMAfter' :: Monad m => (b -> a -> m b) -> m b -> (b -> m b) -> Stream m a -> Stream m b
postscanlx' :: Monad m => (x -> a -> x) -> x -> (x -> b) -> Stream m a -> Stream m b
postscanlMx' :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> Stream m a -> Stream m b
scanlMx' :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> Stream m a -> Stream m b
scanlx' :: Monad m => (x -> a -> x) -> x -> (x -> b) -> Stream m a -> Stream m b
filter :: Monad m => (a -> Bool) -> Stream m a -> Stream m a
filterM :: Monad m => (a -> m Bool) -> Stream m a -> Stream m a
deleteBy :: Monad m => (a -> a -> Bool) -> a -> Stream m a -> Stream m a
uniq :: (Eq a, Monad m) => Stream m a -> Stream m a
take :: Applicative m => Int -> Stream m a -> Stream m a
takeByTime :: (MonadIO m, TimeUnit64 t) => t -> Stream m a -> Stream m a
takeWhile :: Monad m => (a -> Bool) -> Stream m a -> Stream m a
takeWhileM :: Monad m => (a -> m Bool) -> Stream m a -> Stream m a
drop :: Monad m => Int -> Stream m a -> Stream m a
dropByTime :: (MonadIO m, TimeUnit64 t) => t -> Stream m a -> Stream m a
dropWhile :: Monad m => (a -> Bool) -> Stream m a -> Stream m a
dropWhileM :: Monad m => (a -> m Bool) -> Stream m a -> Stream m a
insertBy :: Monad m => (a -> a -> Ordering) -> a -> Stream m a -> Stream m a
intersperse :: Monad m => a -> Stream m a -> Stream m a
intersperseM :: Monad m => m a -> Stream m a -> Stream m a
intersperseSuffix :: forall m a. Monad m => m a -> Stream m a -> Stream m a

-- | intersperse after every n items
intersperseSuffixBySpan :: forall m a. Monad m => Int -> m a -> Stream m a -> Stream m a
intersperseM_ :: Monad m => m b -> Stream m a -> Stream m a
intersperseSuffix_ :: Monad m => m b -> Stream m a -> Stream m a
reverse :: Monad m => Stream m a -> Stream m a
indexed :: Monad m => Stream m a -> Stream m (Int, a)
indexedR :: Monad m => Int -> Stream m a -> Stream m (Int, a)
findIndices :: Monad m => (a -> Bool) -> Stream m a -> Stream m Int
slicesBy :: Monad m => (a -> Bool) -> Stream m a -> Stream m (Int, Int)
rollingMap :: Monad m => (a -> a -> b) -> Stream m a -> Stream m b
rollingMapM :: Monad m => (a -> a -> m b) -> Stream m a -> Stream m b
mapMaybe :: Monad m => (a -> Maybe b) -> Stream m a -> Stream m b
mapMaybeM :: Monad m => (a -> m (Maybe b)) -> Stream m a -> Stream m b


-- | A <a>Producer</a> is an <a>Unfold</a> with an <tt>extract</tt>
--   function added to extract the state. It is more powerful but less
--   general than an Unfold.
--   
--   A <a>Producer</a> represents steps of a loop generating a sequence of
--   elements. While unfolds are closed representation of imperative loops
--   with some opaque internal state, producers are open loops with the
--   state being accessible to the user.
--   
--   Unlike an unfold, which runs a loop till completion, a producer can be
--   stopped in the middle, its state can be extracted, examined, changed,
--   and then it can be resumed later from the stopped state.
--   
--   A producer can be used in places where a CPS stream would otherwise be
--   needed, because the state of the loop can be passed around. However,
--   it can be much more efficient than CPS because it allows stream fusion
--   and unecessary function calls can be avoided.
module Streamly.Internal.Data.Producer

-- | A <tt>Producer m a b</tt> is a generator of a stream of values of type
--   <tt>b</tt> from a seed of type <tt>a</tt> in <a>Monad</a> <tt>m</tt>.
--   
--   <i>Pre-release</i>
data Producer m a b

-- | <pre>
--   Producer step inject extract
--   </pre>
Producer :: (s -> m (Step s b)) -> (a -> m s) -> (s -> m a) -> Producer m a b

-- | Simplify a producer to an unfold.
--   
--   <i>Pre-release</i>
simplify :: Producer m a b -> Unfold m a b
nil :: Monad m => Producer m a b
nilM :: Monad m => (a -> m c) -> Producer m a b
unfoldrM :: Monad m => (a -> m (Maybe (b, a))) -> Producer m a b

-- | Convert a StreamD stream into a producer.
--   
--   <i>Pre-release</i>
fromStreamD :: Monad m => Producer m (Stream m a) a

-- | Convert a list of pure values to a <tt>Stream</tt>
--   
--   <i>Pre-release</i>
fromList :: Monad m => Producer m [a] a

-- | State representing a nested loop.
data NestedLoop s1 s2
OuterLoop :: s1 -> NestedLoop s1 s2
InnerLoop :: s1 -> s2 -> NestedLoop s1 s2

-- | Apply the second unfold to each output element of the first unfold and
--   flatten the output in a single stream.
--   
--   <i>Pre-release</i>
concat :: Monad m => Producer m a b -> Producer m b c -> Producer m (NestedLoop a b) c


module Streamly.Internal.Foreign.Malloc
mallocForeignPtrAlignedBytes :: Int -> Int -> IO (ForeignPtr a)
mallocForeignPtrAlignedUnmanagedBytes :: Int -> Int -> IO (ForeignPtr a)


module Streamly.Internal.System.IO

-- | Default maximum buffer size in bytes, for reading from and writing to
--   IO devices, the value is 32KB minus GHC allocation overhead, which is
--   a few bytes, so that the actual allocation is 32KB.
defaultChunkSize :: Int

-- | When we allocate a byte array of size <tt>k</tt> the allocator
--   actually allocates memory of size <tt>k + byteArrayOverhead</tt>.
--   <tt>arrayPayloadSize n</tt> returns the size of the array in bytes
--   that would result in an allocation of <tt>n</tt> bytes.
arrayPayloadSize :: Int -> Int
unsafeInlineIO :: IO a -> a


-- | Mutable arrays and file system files are quite similar, they can grow
--   and their content is mutable. Therefore, both have similar APIs as
--   well. We strive to keep the API consistent for both. Ideally, you
--   should be able to replace one with another with little changes to the
--   code.
module Streamly.Internal.Data.Array.Foreign.Mut.Type

-- | An unboxed, pinned mutable array. An array is created with a given
--   length and capacity. Length is the number of valid elements in the
--   array. Capacity is the maximum number of elements that the array can
--   be expanded to without having to reallocate the memory.
--   
--   The elements in the array can be mutated in-place without changing the
--   reference (constructor). However, the length of the array cannot be
--   mutated in-place. A new array reference is generated when the length
--   changes. When the length is increased (upto the maximum reserved
--   capacity of the array), the array is not reallocated and the new
--   reference uses the same underlying memory as the old one.
--   
--   Several routines in this module allow the programmer to control the
--   capacity of the array. The programmer can control the trade-off
--   between memory usage and performance impact due to reallocations when
--   growing or shrinking the array.
data Array a
Array :: {-# UNPACK #-} !ArrayContents -> {-# UNPACK #-} !Ptr a -> {-# UNPACK #-} !Ptr a -> {-# UNPACK #-} !Ptr a -> Array a
[arrContents] :: Array a -> {-# UNPACK #-} !ArrayContents

-- | first address
[arrStart] :: Array a -> {-# UNPACK #-} !Ptr a

-- | first unused address
[aEnd] :: Array a -> {-# UNPACK #-} !Ptr a

-- | first address beyond allocated memory
[aBound] :: Array a -> {-# UNPACK #-} !Ptr a
data ArrayContents
arrayToFptrContents :: ArrayContents -> ForeignPtrContents
fptrToArrayContents :: ForeignPtrContents -> ArrayContents

-- | Similar to unsafeWithForeignPtr.
unsafeWithArrayContents :: MonadIO m => ArrayContents -> Ptr a -> (Ptr a -> m b) -> m b
nilArrayContents :: ArrayContents
touch :: ArrayContents -> IO ()

-- | Allocates an empty array that can hold <tt>count</tt> items. The
--   memory of the array is uninitialized and the allocation is aligned as
--   per the <a>Storable</a> instance of the type.
--   
--   <i>Pre-release</i>
newArray :: forall m a. (MonadIO m, Storable a) => Int -> m (Array a)

-- | Like <a>newArrayWith</a> but using an allocator that aligns the memory
--   to the alignment dictated by the <a>Storable</a> instance of the type.
--   
--   <i>Internal</i>
newArrayAligned :: (MonadIO m, Storable a) => Int -> Int -> m (Array a)

-- | Like <a>newArrayWith</a> but using an allocator that allocates
--   unmanaged pinned memory. The memory will never be freed by GHC. This
--   could be useful in allocate-once global data structures. Use carefully
--   as incorrect use can lead to memory leak.
--   
--   <i>Internal</i>
newArrayAlignedUnmanaged :: forall m a. (MonadIO m, Storable a) => Int -> Int -> m (Array a)

-- | <tt>newArrayWith allocator alignment count</tt> allocates a new array
--   of zero length and with a capacity to hold <tt>count</tt> elements,
--   using <tt>allocator size alignment</tt> as the memory allocator
--   function.
--   
--   Alignment must be greater than or equal to machine word size and a
--   power of 2.
--   
--   <i>Pre-release</i>
newArrayWith :: forall m a. (MonadIO m, Storable a) => (Int -> Int -> m (ArrayContents, Ptr a)) -> Int -> Int -> m (Array a)

-- | Allocate an Array of the given size and run an IO action passing the
--   array start pointer.
--   
--   <i>Internal</i>
withNewArrayUnsafe :: (MonadIO m, Storable a) => Int -> (Ptr a -> m ()) -> m (Array a)
data ArrayUnsafe a
ArrayUnsafe :: {-# UNPACK #-} !ArrayContents -> {-# UNPACK #-} !Ptr a -> {-# UNPACK #-} !Ptr a -> ArrayUnsafe a

-- | Like <a>writeNUnsafe</a> but takes a new array allocator <tt>alloc
--   size</tt> function as argument.
--   
--   <pre>
--   &gt;&gt;&gt; writeNWithUnsafe alloc n = Array.appendNUnsafe (alloc n) n
--   </pre>
--   
--   <i>Pre-release</i>
writeNWithUnsafe :: forall m a. (MonadIO m, Storable a) => (Int -> m (Array a)) -> Int -> Fold m a (Array a)

-- | <tt>writeNWith alloc n</tt> folds a maximum of <tt>n</tt> elements
--   into an array allocated using the <tt>alloc</tt> function.
--   
--   <pre>
--   &gt;&gt;&gt; writeNWith alloc n = Fold.take n (Array.writeNWithUnsafe alloc n)
--   
--   &gt;&gt;&gt; writeNWith alloc n = Array.appendN (alloc n) n
--   </pre>
writeNWith :: forall m a. (MonadIO m, Storable a) => (Int -> m (Array a)) -> Int -> Fold m a (Array a)

-- | Like <a>writeN</a> but does not check the array bounds when writing.
--   The fold driver must not call the step function more than <tt>n</tt>
--   times otherwise it will corrupt the memory and crash. This function
--   exists mainly because any conditional in the step function blocks
--   fusion causing 10x performance slowdown.
--   
--   <pre>
--   &gt;&gt;&gt; writeNUnsafe = Array.writeNWithUnsafe Array.newArray
--   </pre>
writeNUnsafe :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <pre>
--   &gt;&gt;&gt; writeN = Array.writeNWith Array.newArray
--   
--   &gt;&gt;&gt; writeN n = Fold.take n (Array.writeNUnsafe n)
--   
--   &gt;&gt;&gt; writeN n = Array.appendN (Array.newArray n) n
--   </pre>
writeN :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | <tt>writeNAligned align n</tt> folds a maximum of <tt>n</tt> elements
--   from the input stream to an <a>Array</a> aligned to the given size.
--   
--   <pre>
--   &gt;&gt;&gt; writeNAligned align = Array.writeNWith (Array.newArrayAligned align)
--   
--   &gt;&gt;&gt; writeNAligned align n = Array.appendN (Array.newArrayAligned align n) n
--   </pre>
--   
--   <i>Pre-release</i>
writeNAligned :: forall m a. (MonadIO m, Storable a) => Int -> Int -> Fold m a (Array a)

-- | <tt>writeNAlignedUnmanaged align n</tt> folds a maximum of <tt>n</tt>
--   elements from the input stream to an <a>Array</a> whose starting
--   address is aligned to <tt>align</tt> bytes and is allocated using
--   unmanaged memory (never freed). This could be useful to allocate
--   memory that we need to allocate only once in the lifetime of the
--   program.
--   
--   <pre>
--   &gt;&gt;&gt; f = Array.newArrayAlignedUnmanaged
--   
--   &gt;&gt;&gt; writeNAlignedUnmanaged a = Array.writeNWith (f a)
--   
--   &gt;&gt;&gt; writeNAlignedUnmanaged a n = Array.appendN (f a n) n
--   </pre>
--   
--   <i>Pre-release</i>
writeNAlignedUnmanaged :: forall m a. (MonadIO m, Storable a) => Int -> Int -> Fold m a (Array a)

-- | <tt>writeWith minCount</tt> folds the whole input to a single array.
--   The array starts at a size big enough to hold minCount elements, the
--   size is doubled every time the array needs to be grown.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <pre>
--   &gt;&gt;&gt; f n = Array.appendWith (* 2) (Array.newArray n)
--   
--   &gt;&gt;&gt; writeWith n = Fold.rmapM Array.rightSize (f n)
--   
--   &gt;&gt;&gt; writeWith n = Fold.rmapM Array.fromArrayStreamK (Array.writeChunks n)
--   </pre>
--   
--   <i>Pre-release</i>
writeWith :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   Same as <a>writeWith</a> using an initial array size of
--   <a>arrayChunkBytes</a> bytes rounded up to the element size.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
write :: forall m a. (MonadIO m, Storable a) => Fold m a (Array a)

-- | <tt>fromForeignPtrUnsafe foreignPtr end bound</tt> creates an
--   <a>Array</a> that starts at the memory pointed by the
--   <tt>foreignPtr</tt>, <tt>end</tt> is the first unused address, and
--   <tt>bound</tt> is the first address beyond the allocated memory.
--   
--   Unsafe: Make sure that foreignPtr &lt;= end &lt;= bound and (end -
--   start) is an integral multiple of the element size. Only PlainPtr type
--   ForeignPtr is supported.
--   
--   <i>Pre-release</i>
fromForeignPtrUnsafe :: ForeignPtr a -> Ptr a -> Ptr a -> Array a

-- | Create an <a>Array</a> from the first N elements of a list. The array
--   is allocated to size N, if the list terminates before N elements then
--   the array may hold less than N elements.
fromListN :: (MonadIO m, Storable a) => Int -> [a] -> m (Array a)

-- | Create an <a>Array</a> from a list. The list must be of finite size.
fromList :: (MonadIO m, Storable a) => [a] -> m (Array a)

-- | Use the <a>writeN</a> fold instead.
--   
--   <pre>
--   &gt;&gt;&gt; fromStreamDN n = StreamD.fold (Array.writeN n)
--   </pre>
fromStreamDN :: forall m a. (MonadIO m, Storable a) => Int -> Stream m a -> m (Array a)

-- | We could take the approach of doubling the memory allocation on each
--   overflow. This would result in more or less the same amount of copying
--   as in the chunking approach. However, if we have to shrink in the end
--   then it may result in an extra copy of the entire data.
--   
--   <pre>
--   &gt;&gt;&gt; fromStreamD = StreamD.fold Array.write
--   </pre>
fromStreamD :: (MonadIO m, Storable a) => Stream m a -> m (Array a)

-- | <i>O(1)</i> Write the given element at the given index in the array.
--   Performs in-place mutation of the array.
--   
--   <pre>
--   &gt;&gt;&gt; putIndex arr ix val = Array.modifyIndex arr ix (const (val, ()))
--   
--   &gt;&gt;&gt; f = Array.putIndices
--   
--   &gt;&gt;&gt; putIndex arr ix val = Stream.fold (f arr) (Stream.fromPure (ix, val))
--   </pre>
--   
--   <i>Pre-release</i>
putIndex :: (MonadIO m, Storable a) => Array a -> Int -> a -> m ()

-- | Write the given element to the given index of the array. Does not
--   check if the index is out of bounds of the array.
--   
--   <i>Pre-release</i>
putIndexUnsafe :: forall m a. (MonadIO m, Storable a) => Array a -> Int -> a -> m ()

-- | Write an input stream of (index, value) pairs to an array. Throws an
--   error if any index is out of bounds.
--   
--   <i>Unimplemented</i>
putIndices :: Array a -> Fold m (Int, a) ()

-- | Modify a given index of an array using a modifier function.
--   
--   <i>Pre-release</i>
modifyIndexUnsafe :: forall m a b. (MonadIO m, Storable a) => Array a -> Int -> (a -> (a, b)) -> m b

-- | Modify a given index of an array using a modifier function.
--   
--   <i>Pre-release</i>
modifyIndex :: forall m a b. (MonadIO m, Storable a) => Array a -> Int -> (a -> (a, b)) -> m b

-- | Modify the array indices generated by the supplied unfold.
--   
--   <i>Pre-release</i>
modifyIndices :: Unfold m (Array a) Int -> Array a -> (a -> a) -> m ()

-- | Modify each element of an array using the supplied modifier function.
--   
--   <i>Unimplemented</i>
modify :: Array a -> (a -> a) -> m ()

-- | Swap the elements at two indices.
--   
--   <i>Pre-release</i>
swapIndices :: Array a -> Int -> Int -> m ()

-- | <tt>snocWith sizer arr elem</tt> mutates <tt>arr</tt> to append
--   <tt>elem</tt>. The length of the array increases by 1.
--   
--   If there is no reserved space available in <tt>arr</tt> it is
--   reallocated to a size in bytes determined by the <tt>sizer
--   oldSizeBytes</tt> function, where <tt>oldSizeBytes</tt> is the
--   original size of the array in bytes.
--   
--   If the new array size is more than <a>largeObjectThreshold</a> we
--   automatically round it up to <a>blockSize</a>.
--   
--   Note that the returned array may be a mutated version of the original
--   array.
--   
--   <i>Pre-release</i>
snocWith :: forall m a. (MonadIO m, Storable a) => (Int -> Int) -> Array a -> a -> m (Array a)

-- | The array is mutated to append an additional element to it. If there
--   is no reserved space available in the array then it is reallocated to
--   double the original size.
--   
--   This is useful to reduce allocations when appending unknown number of
--   elements.
--   
--   Note that the returned array may be a mutated version of the original
--   array.
--   
--   <pre>
--   &gt;&gt;&gt; snoc = Array.snocWith (* 2)
--   </pre>
--   
--   Performs O(n * log n) copies to grow, but is liberal with memory
--   allocation.
--   
--   <i>Pre-release</i>
snoc :: forall m a. (MonadIO m, Storable a) => Array a -> a -> m (Array a)

-- | The array is mutated to append an additional element to it. If there
--   is no reserved space available in the array then it is reallocated to
--   grow it by <a>arrayChunkBytes</a> rounded up to <a>blockSize</a> when
--   the size becomes more than <a>largeObjectThreshold</a>.
--   
--   Note that the returned array may be a mutated version of the original
--   array.
--   
--   Performs O(n^2) copies to grow but is thrifty on memory.
--   
--   <i>Pre-release</i>
snocLinear :: forall m a. (MonadIO m, Storable a) => Array a -> a -> m (Array a)

-- | Like <a>snoc</a> but does not reallocate when pre-allocated array
--   capacity becomes full.
--   
--   <i>Internal</i>
snocMay :: forall m a. (MonadIO m, Storable a) => Array a -> a -> m (Maybe (Array a))

-- | Really really unsafe, appends the element into the first array, may
--   cause silent data corruption or if you are lucky a segfault if the
--   first array does not have enough space to append the element.
--   
--   <i>Internal</i>
snocUnsafe :: forall m a. (MonadIO m, Storable a) => Array a -> a -> m (Array a)

-- | Append up to <tt>n</tt> input items to the supplied array.
--   
--   Unsafe: Do not drive the fold beyond <tt>n</tt> elements, it will lead
--   to memory corruption or segfault.
--   
--   Any free space left in the array after appending <tt>n</tt> elements
--   is lost.
--   
--   <i>Internal</i>
appendNUnsafe :: forall m a. (MonadIO m, Storable a) => m (Array a) -> Int -> Fold m a (Array a)

-- | Append <tt>n</tt> elements to an existing array. Any free space left
--   in the array after appending <tt>n</tt> elements is lost.
--   
--   <pre>
--   &gt;&gt;&gt; appendN initial n = Fold.take n (Array.appendNUnsafe initial n)
--   </pre>
--   
--   <i>Pre-release</i>
appendN :: forall m a. (MonadIO m, Storable a) => m (Array a) -> Int -> Fold m a (Array a)

-- | <tt>appendWith realloc action</tt> mutates the array generated by
--   <tt>action</tt> to append the input stream. If there is no reserved
--   space available in the array it is reallocated to a size in bytes
--   determined by <tt>realloc oldSize</tt>, where <tt>oldSize</tt> is the
--   current size of the array in bytes.
--   
--   Note that the returned array may be a mutated version of original
--   array.
--   
--   <pre>
--   &gt;&gt;&gt; appendWith sizer = Fold.foldlM' (Array.snocWith sizer)
--   </pre>
--   
--   <i>Pre-release</i>
appendWith :: forall m a. (MonadIO m, Storable a) => (Int -> Int) -> m (Array a) -> Fold m a (Array a)

-- | <tt>append action</tt> mutates the array generated by <tt>action</tt>
--   to append the input stream. If there is no reserved space available in
--   the array it is reallocated to double the size.
--   
--   Note that the returned array may be a mutated version of original
--   array.
--   
--   <pre>
--   &gt;&gt;&gt; append = Array.appendWith (* 2)
--   </pre>
--   
--   <i>Pre-release</i>
append :: forall m a. (MonadIO m, Storable a) => m (Array a) -> Fold m a (Array a)

-- | Drop the last n elements of the array to reduce the length by n. The
--   capacity is reallocated using the user supplied function.
--   
--   <i>Unimplemented</i>
truncateWith :: Int -> (Int -> Int) -> Array a -> m (Array a)

-- | Drop the last n elements of the array to reduce the length by n.
--   
--   The capacity is rounded to 1K or 4K if the length is more than the GHC
--   large block threshold.
--   
--   <i>Unimplemented</i>
truncate :: Int -> Array a -> m (Array a)

-- | Like <a>truncate</a> but the capacity is rounded to the closest power
--   of 2.
--   
--   <i>Unimplemented</i>
truncateExp :: Int -> Array a -> m (Array a)
data ReadUState a
ReadUState :: {-# UNPACK #-} !ArrayContents -> !Ptr a -> !Ptr a -> ReadUState a

-- | Unfold an array into a stream.
read :: forall m a. (MonadIO m, Storable a) => Unfold m (Array a) a

-- | Unfold an array into a stream in reverse order.
--   
--   <i>Pre-release</i>
readRev :: forall m a. (MonadIO m, Storable a) => Unfold m (Array a) a

-- | Use the <a>read</a> unfold instead.
--   
--   <pre>
--   toStreamD = D.unfold read
--   </pre>
--   
--   We can try this if the unfold has any performance issues.
toStreamD :: forall m a. (MonadIO m, Storable a) => Array a -> Stream m a

-- | Use the <a>readRev</a> unfold instead.
--   
--   <pre>
--   toStreamDRev = D.unfold readRev
--   </pre>
--   
--   We can try this if the unfold has any perf issues.
toStreamDRev :: forall m a. (MonadIO m, Storable a) => Array a -> Stream m a
toStreamK :: forall m a. (MonadIO m, Storable a) => Array a -> Stream m a
toStreamKRev :: forall m a. (MonadIO m, Storable a) => Array a -> Stream m a

-- | Convert an <a>Array</a> into a list.
toList :: forall m a. (MonadIO m, Storable a) => Array a -> m [a]

-- | Resumable unfold of an array.
producer :: forall m a. (MonadIO m, Storable a) => Producer m (Array a) a

-- | <i>O(1)</i> Lookup the element at the given index. Index starts from
--   0.
getIndex :: (MonadIO m, Storable a) => Array a -> Int -> m a

-- | Return the element at the specified index without checking the bounds.
--   
--   Unsafe because it does not check the bounds of the array.
getIndexUnsafe :: forall m a. (MonadIO m, Storable a) => Array a -> Int -> m a

-- | Given an unfold that generates array indices, read the elements on
--   those indices from the supplied Array. An error is thrown if an index
--   is out of bounds.
--   
--   <i>Pre-release</i>
getIndices :: (MonadIO m, Storable a) => Unfold m (Array a) Int -> Unfold m (Array a) a

-- | <i>O(1)</i> Lookup the element at the given index from the end of the
--   array. Index starts from 0.
--   
--   Slightly faster than computing the forward index and using getIndex.
getIndexRev :: (MonadIO m, Storable a) => Array a -> Int -> m a

-- | The page or block size used by the GHC allocator. Allocator allocates
--   at least a block and then allocates smaller allocations from within a
--   block.
blockSize :: Int

-- | The default chunk size by which the array creation routines increase
--   the size of the array when the array is grown linearly.
arrayChunkBytes :: Int

-- | Given a <a>Storable</a> type (unused first arg) and real allocation
--   size (including overhead), return how many elements of that type will
--   completely fit in it, returns at least 1.
allocBytesToElemCount :: Storable a => a -> Int -> Int
realloc :: forall m a. (MonadIO m, Storable a) => Int -> Array a -> m (Array a)

-- | Change the reserved memory of the array so that it is enough to hold
--   the specified number of elements. Nothing is done if the specified
--   capacity is less than the length of the array.
--   
--   If the capacity is more than <a>largeObjectThreshold</a> then it is
--   rounded up to the block size (4K).
--   
--   <i>Unimplemented</i>
resize :: Int -> Array a -> m (Array a)

-- | Like <a>resize</a> but if the capacity is more than
--   <a>largeObjectThreshold</a> then it is rounded up to the closest power
--   of 2.
--   
--   <i>Unimplemented</i>
resizeExp :: Int -> Array a -> m (Array a)

-- | Resize the allocated memory to drop any reserved free space at the end
--   of the array and reallocate it to reduce wastage.
--   
--   Up to 25% wastage is allowed to avoid reallocations. If the capacity
--   is more than <a>largeObjectThreshold</a> then free space up to the
--   <a>blockSize</a> is retained.
--   
--   <i>Pre-release</i>
rightSize :: forall m a. (MonadIO m, Storable a) => Array a -> m (Array a)

-- | <i>O(1)</i> Get the length of the array i.e. the number of elements in
--   the array.
--   
--   Note that <a>byteLength</a> is less expensive than this operation, as
--   <a>length</a> involves a costly division operation.
length :: forall a. Storable a => Array a -> Int

-- | <i>O(1)</i> Get the byte length of the array.
byteLength :: Array a -> Int

-- | Get the total capacity of an array. An array may have space reserved
--   beyond the current used length of the array.
--   
--   <i>Pre-release</i>
byteCapacity :: Array a -> Int

-- | The remaining capacity in the array for appending more elements
--   without reallocation.
--   
--   <i>Pre-release</i>
bytesFree :: Array a -> Int

-- | You may not need to reverse an array because you can consume it in
--   reverse using <a>readRev</a>. To reverse large arrays you can read in
--   reverse and write to another array. However, in-place reverse can be
--   useful to take adavantage of cache locality and when you do not want
--   to allocate additional memory.
--   
--   <i>Unimplemented</i>
reverse :: Array a -> m Bool

-- | Generate the next permutation of the sequence, returns False if this
--   is the last permutation.
--   
--   <i>Unimplemented</i>
permute :: Array a -> m Bool

-- | Partition an array into two halves using a partitioning predicate. The
--   first half retains values where the predicate is <a>False</a> and the
--   second half retains values where the predicate is <a>True</a>.
--   
--   <i>Unimplemented</i>
partitionBy :: (a -> Bool) -> Array a -> m (Array a, Array a)

-- | Shuffle corresponding elements from two arrays using a shuffle
--   function. If the shuffle function returns <a>False</a> then do nothing
--   otherwise swap the elements. This can be used in a bottom up fold to
--   shuffle or reorder the elements.
--   
--   <i>Unimplemented</i>
shuffleBy :: (a -> a -> m Bool) -> Array a -> Array a -> m (Array a)

-- | <tt>divideBy level partition array</tt> performs a top down
--   hierarchical recursive partitioning fold of items in the container
--   using the given function as the partition function. Level indicates
--   the level in the tree where the fold would stop.
--   
--   This performs a quick sort if the partition function is 'partitionBy
--   (&lt; pivot)'.
--   
--   <i>Unimplemented</i>
divideBy :: Int -> (Array a -> Array a -> m (Array a)) -> Array a -> m (Array a)

-- | <tt>mergeBy level merge array</tt> performs a pairwise bottom up fold
--   recursively merging the pairs using the supplied merge function. Level
--   indicates the level in the tree where the fold would stop.
--   
--   This performs a random shuffle if the shuffle function is random. If
--   we stop at level 0 and repeatedly apply the function then we can do a
--   bubble sort.
--   
--   <i>Unimplemented</i>
mergeBy :: Int -> (Array a -> Array a -> m (Array a)) -> Array a -> m (Array a)

-- | Cast an array having elements of type <tt>a</tt> into an array having
--   elements of type <tt>b</tt>. The length of the array should be a
--   multiple of the size of the target element otherwise <a>Nothing</a> is
--   returned.
--   
--   <i>Pre-release</i>
cast :: forall a b. Storable b => Array a -> Maybe (Array b)

-- | Cast an array having elements of type <tt>a</tt> into an array having
--   elements of type <tt>b</tt>. The array size must be a multiple of the
--   size of type <tt>b</tt> otherwise accessing the last element of the
--   array may result into a crash or a random value.
--   
--   <i>Pre-release</i>
castUnsafe :: Array a -> Array b

-- | Cast an <tt>Array a</tt> into an <tt>Array Word8</tt>.
--   
--   <i>Pre-release</i>
asBytes :: Array a -> Array Word8

-- | Use an <tt>Array a</tt> as <tt>Ptr b</tt>.
--   
--   <i>Unsafe</i>
--   
--   <i>Pre-release</i>
asPtrUnsafe :: Array a -> (Ptr b -> IO c) -> IO c

-- | Strict left fold of an array.
foldl' :: (MonadIO m, Storable a) => (b -> a -> b) -> b -> Array a -> m b

-- | Right fold of an array.
foldr :: (MonadIO m, Storable a) => (a -> b -> b) -> b -> Array a -> m b

-- | Compare if two arrays are equal.
--   
--   <i>Pre-release</i>
cmp :: MonadIO m => Array a -> Array a -> m Bool

-- | <tt>arraysOf n stream</tt> groups the input stream into a stream of
--   arrays of size n.
--   
--   <pre>
--   arraysOf n = StreamD.foldMany (Array.writeN n)
--   </pre>
--   
--   <i>Pre-release</i>
arraysOf :: forall m a. (MonadIO m, Storable a) => Int -> Stream m a -> Stream m (Array a)

-- | Buffer the stream into arrays in memory.
arrayStreamKFromStreamD :: forall m a. (MonadIO m, Storable a) => Stream m a -> m (Stream m (Array a))

-- | Buffer a stream into a stream of arrays.
--   
--   <pre>
--   &gt;&gt;&gt; writeChunks n = Fold.many (Array.writeN n) Fold.toStreamK
--   </pre>
--   
--   Breaking an array into an array stream can be useful to consume a
--   large array sequentially such that memory of the array is released
--   incrementatlly.
--   
--   See also: <a>arrayStreamKFromStreamD</a>.
--   
--   <i>Unimplemented</i>
writeChunks :: (MonadIO m, Storable a) => Int -> Fold m a (Stream n (Array a))

-- | Use the "read" unfold instead.
--   
--   <pre>
--   flattenArrays = unfoldMany read
--   </pre>
--   
--   We can try this if there are any fusion issues in the unfold.
flattenArrays :: forall m a. (MonadIO m, Storable a) => Stream m (Array a) -> Stream m a

-- | Use the "readRev" unfold instead.
--   
--   <pre>
--   flattenArrays = unfoldMany readRev
--   </pre>
--   
--   We can try this if there are any fusion issues in the unfold.
flattenArraysRev :: forall m a. (MonadIO m, Storable a) => Stream m (Array a) -> Stream m a

-- | Convert an array stream to an array. Note that this requires peak
--   memory that is double the size of the array stream.
fromArrayStreamK :: (Storable a, MonadIO m) => Stream m (Array a) -> m (Array a)

-- | <i>O(1)</i> Slice an array in constant time.
--   
--   Unsafe: The bounds of the slice are not checked.
--   
--   <i>Unsafe</i>
--   
--   <i>Pre-release</i>
getSliceUnsafe :: forall a. Storable a => Int -> Int -> Array a -> Array a

-- | <i>O(1)</i> Slice an array in constant time. Throws an error if the
--   slice extends out of the array bounds.
--   
--   <i>Pre-release</i>
getSlice :: forall a. Storable a => Int -> Int -> Array a -> Array a

-- | Create two slices of an array without copying the original array. The
--   specified index <tt>i</tt> is the first index of the second slice.
splitAt :: forall a. Storable a => Int -> Array a -> (Array a, Array a)

-- | Drops the separator byte
breakOn :: MonadIO m => Word8 -> Array Word8 -> m (Array Word8, Maybe (Array Word8))

-- | Copy two arrays into a newly allocated array.
spliceCopy :: (MonadIO m, Storable a) => Array a -> Array a -> m (Array a)

-- | <tt>spliceWith sizer dst src</tt> mutates <tt>dst</tt> to append
--   <tt>src</tt>. If there is no reserved space available in <tt>dst</tt>
--   it is reallocated to a size determined by the <tt>sizer dstBytesn
--   srcBytes</tt> function, where <tt>dstBytes</tt> is the size of the
--   first array and <tt>srcBytes</tt> is the size of the second array, in
--   bytes.
--   
--   Note that the returned array may be a mutated version of first array.
--   
--   <i>Pre-release</i>
spliceWith :: forall m a. (MonadIO m, Storable a) => (Int -> Int -> Int) -> Array a -> Array a -> m (Array a)

-- | The first array is mutated to append the second array. If there is no
--   reserved space available in the first array a new allocation of exact
--   required size is done.
--   
--   Note that the returned array may be a mutated version of first array.
--   
--   <pre>
--   &gt;&gt;&gt; splice = Array.spliceWith (+)
--   </pre>
--   
--   <i>Pre-release</i>
splice :: (MonadIO m, Storable a) => Array a -> Array a -> m (Array a)

-- | Like <a>append</a> but the growth of the array is exponential.
--   Whenever a new allocation is required the previous array size is at
--   least doubled.
--   
--   This is useful to reduce allocations when folding many arrays
--   together.
--   
--   Note that the returned array may be a mutated version of first array.
--   
--   <pre>
--   &gt;&gt;&gt; spliceExp = Array.spliceWith (\l1 l2 -&gt; max (l1 * 2) (l1 + l2))
--   </pre>
--   
--   <i>Pre-release</i>
spliceExp :: (MonadIO m, Storable a) => Array a -> Array a -> m (Array a)
memcpy :: Ptr Word8 -> Ptr Word8 -> Int -> IO ()
memcmp :: Ptr Word8 -> Ptr Word8 -> Int -> IO Bool
c_memchr :: Ptr Word8 -> Word8 -> CSize -> IO (Ptr Word8)
instance Control.DeepSeq.NFData (Streamly.Internal.Data.Array.Foreign.Mut.Type.Array a)


-- | See notes in <a>Streamly.Internal.Data.Array.Foreign.Mut.Type</a>
module Streamly.Internal.Data.Array.Foreign.Type
data Array a
Array :: {-# UNPACK #-} !ArrayContents -> {-# UNPACK #-} !Ptr a -> {-# UNPACK #-} !Ptr a -> Array a

-- | first address
[arrContents] :: Array a -> {-# UNPACK #-} !ArrayContents
[arrStart] :: Array a -> {-# UNPACK #-} !Ptr a
[aEnd] :: Array a -> {-# UNPACK #-} !Ptr a

-- | Makes an immutable array using the underlying memory of the mutable
--   array.
--   
--   Please make sure that there are no other references to the mutable
--   array lying around, so that it is never used after freezing it using
--   <i>unsafeFreeze</i>. If the underlying array is mutated, the immutable
--   promise is lost.
--   
--   <i>Pre-release</i>
unsafeFreeze :: Array a -> Array a

-- | Similar to <a>unsafeFreeze</a> but uses <a>rightSize</a> on the
--   mutable array first.
unsafeFreezeWithShrink :: Storable a => Array a -> Array a

-- | Makes a mutable array using the underlying memory of the immutable
--   array.
--   
--   Please make sure that there are no other references to the immutable
--   array lying around, so that it is never used after thawing it using
--   <i>unsafeThaw</i>. If the resulting array is mutated, any references
--   to the older immutable array are mutated as well.
--   
--   <i>Pre-release</i>
unsafeThaw :: Array a -> Array a
splice :: (MonadIO m, Storable a) => Array a -> Array a -> m (Array a)

-- | Create an <a>Array</a> of the given number of elements of type
--   <tt>a</tt> from a read only pointer <tt>Ptr a</tt>. The pointer is not
--   freed when the array is garbage collected. This API is unsafe for the
--   following reasons:
--   
--   <ol>
--   <li>The pointer must point to static pinned memory or foreign memory
--   that does not require freeing..</li>
--   <li>The pointer must be legally accessible upto the given length.</li>
--   <li>To guarantee that the array is immutable, the contents of the
--   address must be guaranteed to not change.</li>
--   </ol>
--   
--   <i>Unsafe</i>
--   
--   <i>Pre-release</i>
fromPtr :: Int -> Ptr a -> Array a

-- | Create an <tt>Array Word8</tt> of the given length from a static, read
--   only machine address <a>Addr#</a>. See <a>fromPtr</a> for safety
--   caveats.
--   
--   A common use case for this API is to create an array from a static
--   unboxed string literal. GHC string literals are of type <a>Addr#</a>,
--   and must contain characters that can be encoded in a byte i.e.
--   characters or literal bytes in the range from 0-255.
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Word (Word8)
--   
--   &gt;&gt;&gt; Array.fromAddr# 5 "hello world!"# :: Array Word8
--   [104,101,108,108,111]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Array.fromAddr# 3 "\255\NUL\255"# :: Array Word8
--   [255,0,255]
--   </pre>
--   
--   <i>See also: <tt>fromString#</tt></i>
--   
--   <i>Unsafe</i>
--   
--   <i>Time complexity: O(1)</i>
--   
--   <i>Pre-release</i>
fromAddr# :: Int -> Addr# -> Array a

-- | Generate a byte array from an <a>Addr#</a> that contains a sequence of
--   NUL (<tt>0</tt>) terminated bytes. The array would not include the NUL
--   byte. The address must be in static read-only memory and must be
--   legally accessible up to and including the first NUL byte.
--   
--   An unboxed string literal (e.g. <tt>"hello"#</tt>) is a common example
--   of an <a>Addr#</a> in static read only memory. It represents the UTF8
--   encoded sequence of bytes terminated by a NUL byte (a <a>CString</a>)
--   corresponding to the given unicode string.
--   
--   <pre>
--   &gt;&gt;&gt; Array.fromCString# "hello world!"#
--   [104,101,108,108,111,32,119,111,114,108,100,33]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Array.fromCString# "\255\NUL\255"#
--   [255]
--   </pre>
--   
--   <i>See also: <a>fromAddr#</a></i>
--   
--   <i>Unsafe</i>
--   
--   <i>Time complexity: O(n) (computes the length of the string)</i>
--   
--   <i>Pre-release</i>
fromCString# :: Addr# -> Array Word8

-- | Create an <a>Array</a> from a list. The list must be of finite size.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromList :: Storable a => [a] -> Array a

-- | Create an <a>Array</a> from the first N elements of a list. The array
--   is allocated to size N, if the list terminates before N elements then
--   the array may hold less than N elements.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromListN :: Storable a => Int -> [a] -> Array a

-- | Create an <a>Array</a> from a list in reverse order. The list must be
--   of finite size.
--   
--   <i>Unimplemented</i>
fromListRev :: [a] -> Array a

-- | Create an <a>Array</a> from the first N elements of a list in reverse
--   order. The array is allocated to size N, if the list terminates before
--   N elements then the array may hold less than N elements.
--   
--   <i>Unimplemented</i>
fromListRevN :: Int -> [a] -> Array a
fromStreamDN :: forall m a. (MonadIO m, Storable a) => Int -> Stream m a -> m (Array a)
fromStreamD :: forall m a. (MonadIO m, Storable a) => Stream m a -> m (Array a)
breakOn :: MonadIO m => Word8 -> Array Word8 -> m (Array Word8, Maybe (Array Word8))

-- | Return element at the specified index without checking the bounds.
--   
--   Unsafe because it does not check the bounds of the array.
unsafeIndexIO :: forall a. Storable a => Array a -> Int -> IO a

-- | Return element at the specified index without checking the bounds.
unsafeIndex :: forall a. Storable a => Array a -> Int -> a

-- | <i>O(1)</i> Get the byte length of the array.
byteLength :: Array a -> Int

-- | <i>O(1)</i> Get the length of the array i.e. the number of elements in
--   the array.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
length :: forall a. Storable a => Array a -> Int
foldl' :: forall a b. Storable a => (b -> a -> b) -> b -> Array a -> b
foldr :: Storable a => (a -> b -> b) -> b -> Array a -> b

-- | Create two slices of an array without copying the original array. The
--   specified index <tt>i</tt> is the first index of the second slice.
splitAt :: forall a. Storable a => Int -> Array a -> (Array a, Array a)

-- | Unfold an array into a stream in reverse order.
readRev :: forall m a. (Monad m, Storable a) => Unfold m (Array a) a
toStreamD :: forall m a. (Monad m, Storable a) => Array a -> Stream m a
toStreamDRev :: forall m a. (Monad m, Storable a) => Array a -> Stream m a
toStreamK :: forall m a. Storable a => Array a -> Stream m a
toStreamKRev :: forall m a. Storable a => Array a -> Stream m a

-- | Convert an <a>Array</a> into a stream.
--   
--   <i>Pre-release</i>
toStream :: (Monad m, Storable a) => Array a -> SerialT m a

-- | Convert an <a>Array</a> into a stream in reverse order.
--   
--   <i>Pre-release</i>
toStreamRev :: (Monad m, Storable a) => Array a -> SerialT m a

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
toList :: Storable a => Array a -> [a]
writeWith :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
writeN :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | Like <a>writeN</a> but does not check the array bounds when writing.
--   The fold driver must not call the step function more than <tt>n</tt>
--   times otherwise it will corrupt the memory and crash. This function
--   exists mainly because any conditional in the step function blocks
--   fusion causing 10x performance slowdown.
writeNUnsafe :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)
data ArrayUnsafe a
ArrayUnsafe :: {-# UNPACK #-} !ArrayContents -> {-# UNPACK #-} !Ptr a -> {-# UNPACK #-} !Ptr a -> ArrayUnsafe a

-- | <tt>writeNAligned alignment n</tt> folds a maximum of <tt>n</tt>
--   elements from the input stream to an <a>Array</a> aligned to the given
--   size.
--   
--   <i>Pre-release</i>
writeNAligned :: forall m a. (MonadIO m, Storable a) => Int -> Int -> Fold m a (Array a)

-- | <tt>writeNAlignedUnmanaged n</tt> folds a maximum of <tt>n</tt>
--   elements from the input stream to an <a>Array</a> aligned to the given
--   size and using unmanaged memory. This could be useful to allocate
--   memory that we need to allocate only once in the lifetime of the
--   program.
--   
--   <i>Pre-release</i>
writeNAlignedUnmanaged :: forall m a. (MonadIO m, Storable a) => Int -> Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
write :: forall m a. (MonadIO m, Storable a) => Fold m a (Array a)

-- | <tt>arraysOf n stream</tt> groups the input stream into a stream of
--   arrays of size n.
arraysOf :: forall m a. (MonadIO m, Storable a) => Int -> Stream m a -> Stream m (Array a)
bufferChunks :: (MonadIO m, Storable a) => Stream m a -> m (Stream m (Array a))

-- | Use the "read" unfold instead.
--   
--   <pre>
--   flattenArrays = unfoldMany read
--   </pre>
--   
--   We can try this if there are any fusion issues in the unfold.
flattenArrays :: forall m a. (MonadIO m, Storable a) => Stream m (Array a) -> Stream m a

-- | Use the "readRev" unfold instead.
--   
--   <pre>
--   flattenArrays = unfoldMany readRev
--   </pre>
--   
--   We can try this if there are any fusion issues in the unfold.
flattenArraysRev :: forall m a. (MonadIO m, Storable a) => Stream m (Array a) -> Stream m a
instance (GHC.Show.Show a, Foreign.Storable.Storable a) => GHC.Show.Show (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance (Foreign.Storable.Storable a, GHC.Read.Read a, GHC.Show.Show a) => GHC.Read.Read (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance Foreign.Storable.Storable a => GHC.Exts.IsList (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance (Foreign.Storable.Storable a, GHC.Classes.Eq a) => GHC.Classes.Eq (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance Control.DeepSeq.NFData (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance (Foreign.Storable.Storable a, GHC.Classes.Ord a) => GHC.Classes.Ord (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance Foreign.Storable.Storable a => GHC.Base.Semigroup (Streamly.Internal.Data.Array.Foreign.Type.Array a)
instance Foreign.Storable.Storable a => GHC.Base.Monoid (Streamly.Internal.Data.Array.Foreign.Type.Array a)


-- | A ring array is a circular mutable array.
module Streamly.Internal.Ring.Foreign

-- | A ring buffer is a mutable array of fixed size. Initially the array is
--   empty, with ringStart pointing at the start of allocated memory. We
--   call the next location to be written in the ring as ringHead.
--   Initially ringHead == ringStart. When the first item is added,
--   ringHead points to ringStart + sizeof item. When the buffer becomes
--   full ringHead would wrap around to ringStart. When the buffer is full,
--   ringHead always points at the oldest item in the ring and the newest
--   item added always overwrites the oldest item.
--   
--   When using it we should keep in mind that a ringBuffer is a mutable
--   data structure. We should not leak out references to it for immutable
--   use.
data Ring a
Ring :: {-# UNPACK #-} !ForeignPtr a -> {-# UNPACK #-} !Ptr a -> Ring a
[ringStart] :: Ring a -> {-# UNPACK #-} !ForeignPtr a
[ringBound] :: Ring a -> {-# UNPACK #-} !Ptr a

-- | Create a new ringbuffer and return the ring buffer and the ringHead.
--   Returns the ring and the ringHead, the ringHead is same as ringStart.
new :: forall a. Storable a => Int -> IO (Ring a, Ptr a)

-- | <tt>newRing count</tt> allocates an empty array that can hold
--   <tt>count</tt> items. The memory of the array is uninitialized and the
--   allocation is aligned as per the <a>Storable</a> instance of the type.
--   
--   <i>Unimplemented</i>
newRing :: Int -> m (Ring a)

-- | <tt>writeN n</tt> is a rolling fold that keeps the last n elements of
--   the stream in a ring array.
--   
--   <i>Unimplemented</i>
writeN :: Int -> Fold m a (Ring a)

-- | Advance the ringHead by 1 item, wrap around if we hit the end of the
--   array.
advance :: forall a. Storable a => Ring a -> Ptr a -> Ptr a

-- | Move the ringHead by n items. The direction depends on the sign on
--   whether n is positive or negative. Wrap around if we hit the beginning
--   or end of the array.
moveBy :: forall a. Storable a => Int -> Ring a -> Ptr a -> Ptr a

-- | Get the first address of the ring as a pointer.
startOf :: Ring a -> Ptr a

-- | Insert an item at the head of the ring, when the ring is full this
--   replaces the oldest item in the ring with the new item. This is unsafe
--   beause ringHead supplied is not verified to be within the Ring. Also,
--   the ringStart foreignPtr must be guaranteed to be alive by the caller.
unsafeInsert :: Storable a => Ring a -> Ptr a -> a -> IO (Ptr a)

-- | Insert an item at the head of the ring, when the ring is full this
--   replaces the oldest item in the ring with the new item.
--   
--   <i>Unimplemented</i>
slide :: Ring a -> a -> m (Ring a)

-- | <i>O(1)</i> Write the given element at the given index in the ring
--   array. Performs in-place mutation of the array.
--   
--   <pre>
--   &gt;&gt;&gt; putIndex arr ix val = Ring.modifyIndex arr ix (const (val, ()))
--   </pre>
--   
--   <i>Unimplemented</i>
putIndex :: Ring a -> Int -> a -> m ()

-- | Modify a given index of a ring array using a modifier function.
--   
--   <i>Unimplemented</i>
modifyIndex :: Ring a -> Int -> (a -> (a, b)) -> m b

-- | Unfold a ring array into a stream.
--   
--   <i>Unimplemented</i>
read :: Unfold m (Ring a) a

-- | Unfold a ring array into a stream in reverse order.
--   
--   <i>Unimplemented</i>
readRev :: Unfold m (Array a) a

-- | <i>O(1)</i> Lookup the element at the given index. Index starts from
--   0.
getIndex :: Ring a -> Int -> m a

-- | Return the element at the specified index without checking the bounds.
--   
--   Unsafe because it does not check the bounds of the ring array.
getIndexUnsafe :: Ring a -> Int -> m a

-- | <i>O(1)</i> Lookup the element at the given index from the end of the
--   array. Index starts from 0.
--   
--   Slightly faster than computing the forward index and using getIndex.
getIndexRev :: Ring a -> Int -> m a

-- | <i>O(1)</i> Get the length of the array i.e. the number of elements in
--   the array.
--   
--   Note that <a>byteLength</a> is less expensive than this operation, as
--   <a>length</a> involves a costly division operation.
--   
--   <i>Unimplemented</i>
length :: Ring a -> Int

-- | <i>O(1)</i> Get the byte length of the array.
--   
--   <i>Unimplemented</i>
byteLength :: Ring a -> Int

-- | Get the total capacity of an array. An array may have space reserved
--   beyond the current used length of the array.
--   
--   <i>Pre-release</i>
byteCapacity :: Ring a -> Int

-- | The remaining capacity in the array for appending more elements
--   without reallocation.
--   
--   <i>Pre-release</i>
bytesFree :: Ring a -> Int

-- | Cast an array having elements of type <tt>a</tt> into an array having
--   elements of type <tt>b</tt>. The length of the array should be a
--   multiple of the size of the target element otherwise <a>Nothing</a> is
--   returned.
--   
--   <i>Pre-release</i>
cast :: forall a b. Storable b => Ring a -> Maybe (Ring b)

-- | Cast an array having elements of type <tt>a</tt> into an array having
--   elements of type <tt>b</tt>. The array size must be a multiple of the
--   size of type <tt>b</tt>.
--   
--   <i>Unimplemented</i>
castUnsafe :: Ring a -> Ring b

-- | Cast an <tt>Array a</tt> into an <tt>Array Word8</tt>.
--   
--   <i>Unimplemented</i>
asBytes :: Ring a -> Ring Word8

-- | Cast a mutable array to a ring array.
fromArray :: Array a -> Ring a

-- | Fold the buffer starting from ringStart up to the given <a>Ptr</a>
--   using a pure step function. This is useful to fold the items in the
--   ring when the ring is not full. The supplied pointer is usually the
--   end of the ring.
--   
--   Unsafe because the supplied Ptr is not checked to be in range.
unsafeFoldRing :: forall a b. Storable a => Ptr a -> (b -> a -> b) -> b -> Ring a -> b

-- | Like unsafeFoldRing but with a monadic step function.
unsafeFoldRingM :: forall m a b. (MonadIO m, Storable a) => Ptr a -> (b -> a -> m b) -> b -> Ring a -> m b

-- | Fold the entire length of a ring buffer starting at the supplied
--   ringHead pointer. Assuming the supplied ringHead pointer points to the
--   oldest item, this would fold the ring starting from the oldest item to
--   the newest item in the ring.
--   
--   Note, this will crash on ring of 0 size.
unsafeFoldRingFullM :: forall m a b. (MonadIO m, Storable a) => Ptr a -> (b -> a -> m b) -> b -> Ring a -> m b

-- | Fold <tt>Int</tt> items in the ring starting at <tt>Ptr a</tt>. Won't
--   fold more than the length of the ring.
--   
--   Note, this will crash on ring of 0 size.
unsafeFoldRingNM :: forall m a b. (MonadIO m, Storable a) => Int -> Ptr a -> (b -> a -> m b) -> b -> Ring a -> m b

-- | <tt>ringsOf n stream</tt> groups the input stream into a stream of
--   ring arrays of size n. Each ring is a sliding window of size n.
--   
--   <i>Unimplemented</i>
ringsOf :: Int -> SerialT m a -> SerialT m (Array a)

-- | Byte compare the entire length of ringBuffer with the given array,
--   starting at the supplied ringHead pointer. Returns true if the Array
--   and the ringBuffer have identical contents.
--   
--   This is unsafe because the ringHead Ptr is not checked to be in range.
--   The supplied array must be equal to or bigger than the ringBuffer,
--   ARRAY BOUNDS ARE NOT CHECKED.
unsafeEqArray :: Ring a -> Ptr a -> Array a -> Bool

-- | Like <a>unsafeEqArray</a> but compares only N bytes instead of entire
--   length of the ring buffer. This is unsafe because the ringHead Ptr is
--   not checked to be in range.
unsafeEqArrayN :: Ring a -> Ptr a -> Array a -> Int -> Bool


-- | This module contains transformations involving multiple streams,
--   unfolds or folds. There are two types of transformations generational
--   or eliminational. Generational transformations are like the
--   <a>Generate</a> module but they generate a stream by combining streams
--   instead of elements. Eliminational transformations are like the
--   <a>Eliminate</a> module but they transform a stream by eliminating
--   parts of the stream instead of eliminating the whole stream.
--   
--   These combinators involve transformation, generation, elimination so
--   can be classified under any of those.
--   
--   Ultimately these operations should be supported by Unfolds, Pipes and
--   Folds, and this module may become redundant.
module Streamly.Internal.Data.Stream.StreamD.Nesting
data AppendState s1 s2
AppendFirst :: s1 -> AppendState s1 s2
AppendSecond :: s2 -> AppendState s1 s2
append :: Monad m => Stream m a -> Stream m a -> Stream m a
data InterleaveState s1 s2
InterleaveFirst :: s1 -> s2 -> InterleaveState s1 s2
InterleaveSecond :: s1 -> s2 -> InterleaveState s1 s2
InterleaveSecondOnly :: s2 -> InterleaveState s1 s2
InterleaveFirstOnly :: s1 -> InterleaveState s1 s2
interleave :: Monad m => Stream m a -> Stream m a -> Stream m a
interleaveMin :: Monad m => Stream m a -> Stream m a -> Stream m a
interleaveSuffix :: Monad m => Stream m a -> Stream m a -> Stream m a
interleaveInfix :: Monad m => Stream m a -> Stream m a -> Stream m a
roundRobin :: Monad m => Stream m a -> Stream m a -> Stream m a
zipWith :: Monad m => (a -> b -> c) -> Stream m a -> Stream m b -> Stream m c
zipWithM :: Monad m => (a -> b -> m c) -> Stream m a -> Stream m b -> Stream m c
mergeBy :: Monad m => (a -> a -> Ordering) -> Stream m a -> Stream m a -> Stream m a
mergeByM :: Monad m => (a -> a -> m Ordering) -> Stream m a -> Stream m a -> Stream m a
concatMap :: Monad m => (a -> Stream m b) -> Stream m a -> Stream m b
concatMapM :: Monad m => (a -> m (Stream m b)) -> Stream m a -> Stream m b

-- | <tt>unfoldMany unfold stream</tt> uses <tt>unfold</tt> to map the
--   input stream elements to streams and then flattens the generated
--   streams into a single output stream.
unfoldMany :: Monad m => Unfold m a b -> Stream m a -> Stream m b
data ConcatUnfoldInterleaveState o i
ConcatUnfoldInterleaveOuter :: o -> [i] -> ConcatUnfoldInterleaveState o i
ConcatUnfoldInterleaveInner :: o -> [i] -> ConcatUnfoldInterleaveState o i
ConcatUnfoldInterleaveInnerL :: [i] -> [i] -> ConcatUnfoldInterleaveState o i
ConcatUnfoldInterleaveInnerR :: [i] -> [i] -> ConcatUnfoldInterleaveState o i

-- | This does not pair streams like concatPairsWith, instead, it goes
--   through each stream one by one and yields one element from each
--   stream. After it goes to the last stream it reverses the traversal to
--   come back to the first stream yielding elements from each stream on
--   its way back to the first stream and so on.
--   
--   <pre>
--   &gt;&gt;&gt; input = Stream.fromList [[1,1],[2,2],[3,3],[4,4],[5,5]]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfoldManyInterleave Unfold.fromList input
--   [1,2,3,4,5,5,4,3,2,1]
--   </pre>
--   
--   Note that this is order of magnitude more efficient than
--   "concatPairsWith wSerial"
unfoldManyInterleave :: Monad m => Unfold m a b -> Stream m a -> Stream m b
unfoldManyRoundRobin :: Monad m => Unfold m a b -> Stream m a -> Stream m b
interpose :: Monad m => m c -> Unfold m b c -> Stream m b -> Stream m c
interposeSuffix :: Monad m => m c -> Unfold m b c -> Stream m b -> Stream m c

-- | Interleave streams (full streams, not the elements) unfolded from two
--   input streams and concat. Stop when the first stream stops. If the
--   second stream ends before the first one then first stream still keeps
--   running alone without any interleaving with the second stream.
--   
--   <ul>
--   <li><i>a1, a2, ... an</i> [b1, b2 ...] =&gt; [streamA1, streamA2, ...
--   streamAn] [streamB1, streamB2, ...] =&gt; [streamA1, streamB1,
--   streamA2...StreamAn, streamBn] =&gt; [a11, a12, ...a1j, b11, b12,
--   ...b1k, a21, a22, ...]</li>
--   </ul>
gintercalate :: Monad m => Unfold m a c -> Stream m a -> Unfold m b c -> Stream m b -> Stream m c

-- | Interleave streams (full streams, not the elements) unfolded from two
--   input streams and concat. Stop when the first stream stops. If the
--   second stream ends before the first one then first stream still keeps
--   running alone without any interleaving with the second stream.
--   
--   <ul>
--   <li><i>a1, a2, ... an</i> [b1, b2 ...] =&gt; [streamA1, streamA2, ...
--   streamAn] [streamB1, streamB2, ...] =&gt; [streamA1, streamB1,
--   streamA2...StreamAn, streamBn] =&gt; [a11, a12, ...a1j, b11, b12,
--   ...b1k, a21, a22, ...]</li>
--   </ul>
gintercalateSuffix :: Monad m => Unfold m a c -> Stream m a -> Unfold m b c -> Stream m b -> Stream m c

-- | Apply a fold multiple times until the stream ends. If the stream is
--   empty the output would be empty.
--   
--   <pre>
--   foldMany f = parseMany (fromFold f)
--   </pre>
--   
--   A terminating fold may terminate even without accepting a single
--   input. So we run the fold's initial action before evaluating the
--   stream. However, this means that if later the stream does not yield
--   anything we have to discard the fold's initial result which could have
--   generated an effect.
foldMany :: Monad m => Fold m a b -> Stream m a -> Stream m b

-- | Like <a>foldMany</a> but for the <a>Refold</a> type. The supplied
--   action is used as the initial value for each refold.
--   
--   <i>Internal</i>
refoldMany :: Monad m => Refold m x a b -> m x -> Stream m a -> Stream m b
foldIterateM :: Monad m => (b -> m (Fold m a b)) -> m b -> Stream m a -> Stream m b

-- | Like <a>foldIterateM</a> but using the <a>Refold</a> type instead.
--   This could be much more efficient due to stream fusion.
--   
--   <i>Internal</i>
refoldIterateM :: Monad m => Refold m b a b -> m b -> Stream m a -> Stream m b
parseMany :: MonadThrow m => Parser m a b -> Stream m a -> Stream m b
parseIterate :: MonadThrow m => (b -> Parser m a b) -> b -> Stream m a -> Stream m b
chunksOf :: Monad m => Int -> Fold m a b -> Stream m a -> Stream m b
groupsBy :: Monad m => (a -> a -> Bool) -> Fold m a b -> Stream m a -> Stream m b
groupsRollingBy :: Monad m => (a -> a -> Bool) -> Fold m a b -> Stream m a -> Stream m b
wordsBy :: Monad m => (a -> Bool) -> Fold m a b -> Stream m a -> Stream m b
splitOnSeq :: forall m a b. (MonadIO m, Storable a, Enum a, Eq a) => Array a -> Fold m a b -> Stream m a -> Stream m b
splitOnSuffixSeq :: forall m a b. (MonadIO m, Storable a, Enum a, Eq a) => Bool -> Array a -> Fold m a b -> Stream m a -> Stream m b
sliceOnSuffix :: Monad m => (a -> Bool) -> Stream m a -> Stream m (Int, Int)

-- | Performs infix separator style splitting.
splitInnerBy :: Monad m => (f a -> m (f a, Maybe (f a))) -> (f a -> f a -> m (f a)) -> Stream m (f a) -> Stream m (f a)

-- | Performs infix separator style splitting.
splitInnerBySuffix :: (Monad m, Eq (f a), Monoid (f a)) => (f a -> m (f a, Maybe (f a))) -> (f a -> f a -> m (f a)) -> Stream m (f a) -> Stream m (f a)


module Streamly.Internal.Data.Stream.StreamD.Eliminate
fold :: Monad m => Fold m a b -> Stream m a -> m b

-- | Run a <tt>Parse</tt> over a stream.
parse :: MonadThrow m => Parser m a b -> Stream m a -> m b

-- | Run a <tt>Parse</tt> over a stream and return rest of the Stream.
parse_ :: MonadThrow m => Parser m a b -> Stream m a -> m (b, Stream m a)

-- | Does not fuse, has the same performance as the StreamK version.
uncons :: Monad m => Stream m a -> m (Maybe (a, Stream m a))
foldrM :: Monad m => (a -> m b -> m b) -> m b -> Stream m a -> m b
foldr :: Monad m => (a -> b -> b) -> b -> Stream m a -> m b
foldrMx :: Monad m => (a -> m x -> m x) -> m x -> (m x -> m b) -> Stream m a -> m b
foldr1 :: Monad m => (a -> a -> a) -> Stream m a -> m (Maybe a)
foldlM' :: Monad m => (b -> a -> m b) -> m b -> Stream m a -> m b
foldl' :: Monad m => (b -> a -> b) -> b -> Stream m a -> m b
foldlMx' :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> Stream m a -> m b
foldlx' :: Monad m => (x -> a -> x) -> x -> (x -> b) -> Stream m a -> m b

-- | Run a streaming composition, discard the results.
drain :: Monad m => Stream m a -> m ()

-- | Execute a monadic action for each element of the <a>Stream</a>
mapM_ :: Monad m => (a -> m b) -> Stream m a -> m ()
null :: Monad m => Stream m a -> m Bool
head :: Monad m => Stream m a -> m (Maybe a)
headElse :: Monad m => a -> Stream m a -> m a
tail :: Monad m => Stream m a -> m (Maybe (Stream m a))
last :: Monad m => Stream m a -> m (Maybe a)
elem :: (Monad m, Eq a) => a -> Stream m a -> m Bool
notElem :: (Monad m, Eq a) => a -> Stream m a -> m Bool
all :: Monad m => (a -> Bool) -> Stream m a -> m Bool
any :: Monad m => (a -> Bool) -> Stream m a -> m Bool
maximum :: (Monad m, Ord a) => Stream m a -> m (Maybe a)
maximumBy :: Monad m => (a -> a -> Ordering) -> Stream m a -> m (Maybe a)
minimum :: (Monad m, Ord a) => Stream m a -> m (Maybe a)
minimumBy :: Monad m => (a -> a -> Ordering) -> Stream m a -> m (Maybe a)
lookup :: (Monad m, Eq a) => a -> Stream m (a, b) -> m (Maybe b)
findM :: Monad m => (a -> m Bool) -> Stream m a -> m (Maybe a)
find :: Monad m => (a -> Bool) -> Stream m a -> m (Maybe a)
(!!) :: Monad m => Stream m a -> Int -> m (Maybe a)
the :: (Eq a, Monad m) => Stream m a -> m (Maybe a)
toList :: Monad m => Stream m a -> m [a]
toListRev :: Monad m => Stream m a -> m [a]
eqBy :: Monad m => (a -> b -> Bool) -> Stream m a -> Stream m b -> m Bool

-- | Compare two streams lexicographically
cmpBy :: Monad m => (a -> b -> Ordering) -> Stream m a -> Stream m b -> m Ordering
isPrefixOf :: (Eq a, Monad m) => Stream m a -> Stream m a -> m Bool
isSubsequenceOf :: (Eq a, Monad m) => Stream m a -> Stream m a -> m Bool
stripPrefix :: (Eq a, Monad m) => Stream m a -> Stream m a -> m (Maybe (Stream m a))


-- | Direct style re-implementation of CPS stream in
--   <a>Streamly.Internal.Data.Stream.StreamK</a>. The symbol or suffix
--   <tt>D</tt> in this module denotes the <a>Direct</a> style. GHC is able
--   to INLINE and fuse direct style better, providing better performance
--   than CPS implementation.
--   
--   <pre>
--   import qualified Streamly.Internal.Data.Stream.StreamD as D
--   </pre>
module Streamly.Internal.Data.Stream.StreamD


-- | To run examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   </pre>
module Streamly.Internal.Data.Stream.Zip

-- | For <a>ZipSerialM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped serially:
--   
--   <pre>
--   &gt;&gt;&gt; s1 = Stream.fromFoldable [1, 2]
--   
--   &gt;&gt;&gt; s2 = Stream.fromFoldable [3, 4]
--   
--   &gt;&gt;&gt; s3 = Stream.fromFoldable [5, 6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipSerial $ (,,) &lt;$&gt; s1 &lt;*&gt; s2 &lt;*&gt; s3
--   [(1,3,5),(2,4,6)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
newtype ZipSerialM m a
ZipSerialM :: Stream m a -> ZipSerialM m a
[getZipSerialM] :: ZipSerialM m a -> Stream m a

-- | An IO stream whose applicative instance zips streams serially.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipSerial = ZipSerialM IO
consMZip :: Monad m => m a -> ZipSerialM m a -> ZipSerialM m a
zipWithK :: Monad m => (a -> b -> c) -> Stream m a -> Stream m b -> Stream m c
zipWithMK :: Monad m => (a -> b -> m c) -> Stream m a -> Stream m b -> Stream m c

-- | For <a>ZipAsyncM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipAsyncWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped concurrently, the
--   following would take half the time that it would take in serial
--   zipping:
--   
--   <pre>
--   &gt;&gt;&gt; s = Stream.fromFoldableM $ Prelude.map delay [1, 1, 1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipAsync $ (,) &lt;$&gt; s &lt;*&gt; s
--   ...
--   [(1,1),(1,1),(1,1)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
newtype ZipAsyncM m a
ZipAsyncM :: Stream m a -> ZipAsyncM m a
[getZipAsyncM] :: ZipAsyncM m a -> Stream m a

-- | An IO stream whose applicative instance zips streams wAsyncly.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipAsync = ZipAsyncM IO
consMZipAsync :: Monad m => m a -> ZipAsyncM m a -> ZipAsyncM m a

-- | Like <tt>zipWith</tt> but zips concurrently i.e. both the streams
--   being zipped are evaluated concurrently using the <tt>ParallelT</tt>
--   concurrent evaluation style. The maximum number of elements of each
--   stream evaluated in advance can be controlled by <tt>maxBuffer</tt>.
--   
--   The stream ends if stream <tt>a</tt> or stream <tt>b</tt> ends.
--   However, if stream <tt>b</tt> ends while we are still evaluating
--   stream <tt>a</tt> and waiting for a result then stream will not end
--   until after the evaluation of stream <tt>a</tt> finishes. This
--   behavior can potentially be changed in future to end the stream
--   immediately as soon as any of the stream end is detected.
zipAsyncWithK :: MonadAsync m => (a -> b -> c) -> Stream m a -> Stream m b -> Stream m c

-- | Like <tt>zipAsyncWith</tt> but with a monadic zipping function.
zipAsyncWithMK :: MonadAsync m => (a -> b -> m c) -> Stream m a -> Stream m b -> Stream m c


-- | <i>Deprecated: Please use <a>ZipSerialM</a> instead.</i>
type ZipStream = ZipSerialM
instance GHC.Base.Monoid (Streamly.Internal.Data.Stream.Zip.ZipSerialM m a)
instance GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Zip.ZipSerialM m a)
instance GHC.Base.Monoid (Streamly.Internal.Data.Stream.Zip.ZipAsyncM m a)
instance GHC.Base.Semigroup (Streamly.Internal.Data.Stream.Zip.ZipAsyncM m a)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Zip.ZipAsyncM m)
instance Streamly.Internal.Control.Concurrent.MonadAsync m => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Zip.ZipAsyncM m)
instance GHC.Exts.IsList (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity a)
instance GHC.Classes.Ord a => GHC.Classes.Ord (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity a)
instance GHC.Show.Show a => GHC.Show.Show (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity a)
instance GHC.Read.Read a => GHC.Read.Read (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity a)
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity a)
instance Control.DeepSeq.NFData1 (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity)
instance GHC.Base.Monad m => GHC.Base.Functor (Streamly.Internal.Data.Stream.Zip.ZipSerialM m)
instance GHC.Base.Monad m => GHC.Base.Applicative (Streamly.Internal.Data.Stream.Zip.ZipSerialM m)
instance (Data.Foldable.Foldable m, GHC.Base.Monad m) => Data.Foldable.Foldable (Streamly.Internal.Data.Stream.Zip.ZipSerialM m)
instance Data.Traversable.Traversable (Streamly.Internal.Data.Stream.Zip.ZipSerialM Data.Functor.Identity.Identity)


module Streamly.Internal.Data.Stream.IsStream.Type

-- | Class of types that can represent a stream of elements of some type
--   <tt>a</tt> in some monad <tt>m</tt>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
class (forall m a. MonadAsync m => Semigroup (t m a), forall m a. MonadAsync m => Monoid (t m a), forall m. Monad m => Functor (t m), forall m. MonadAsync m => Applicative (t m)) => IsStream t
toStream :: IsStream t => t m a -> Stream m a
fromStream :: IsStream t => Stream m a -> t m a

-- | Constructs a stream by adding a monadic action at the head of an
--   existing stream. For example:
--   
--   <pre>
--   &gt; toList $ getLine `consM` getLine `consM` nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
consM :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a

-- | Operator equivalent of <a>consM</a>. We can read it as "<tt>parallel
--   colon</tt>" to remember that <tt>|</tt> comes before <tt>:</tt>.
--   
--   <pre>
--   &gt; toList $ getLine |: getLine |: nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <pre>
--   let delay = threadDelay 1000000 &gt;&gt; print 1
--   drain $ fromSerial  $ delay |: delay |: delay |: nil
--   drain $ fromParallel $ delay |: delay |: delay |: nil
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
(|:) :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a
infixr 5 `consM`
infixr 5 |:

-- | The type <tt>Stream m a</tt> represents a monadic stream of values of
--   type <tt>a</tt> constructed using actions in monad <tt>m</tt>. It uses
--   stop, singleton and yield continuations equivalent to the following
--   direct style type:
--   
--   <pre>
--   data Stream m a = Stop | Singleton a | Yield a (Stream m a)
--   </pre>
--   
--   To facilitate parallel composition we maintain a local state in an
--   <tt>SVar</tt> that is shared across and is used for synchronization of
--   the streams being composed.
--   
--   The singleton case can be expressed in terms of stop and yield but we
--   have it as a separate case to optimize composition operations for
--   streams with single element. We build singleton streams in the
--   implementation of <a>pure</a> for Applicative and Monad, and in
--   <a>lift</a> for MonadTrans.
newtype Stream m a
MkStream :: (forall r. State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> m r) -> Stream m a

-- | Same as <a>IsStream</a>.

-- | <i>Deprecated: Please use IsStream instead.</i>
type Streaming = IsStream
fromStreamS :: (IsStream t, Monad m) => Stream m a -> t m a
toStreamS :: (IsStream t, Monad m) => t m a -> Stream m a
fromStreamD :: (IsStream t, Monad m) => Stream m a -> t m a
toStreamD :: (IsStream t, Monad m) => t m a -> Stream m a

-- | Adapt any specific stream type to any other specific stream type.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
adapt :: (IsStream t1, IsStream t2) => t1 m a -> t2 m a

-- | Adapt a polymorphic consM operation to a StreamK cons operation
toConsK :: IsStream t => (m a -> t m a -> t m a) -> m a -> Stream m a -> Stream m a

-- | Build a stream from an <tt>SVar</tt>, a stop continuation, a singleton
--   stream continuation and a yield continuation.
mkStream :: IsStream t => (forall r. State Stream m a -> (a -> t m a -> m r) -> (a -> m r) -> m r -> m r) -> t m a

-- | Fold a stream by providing an SVar, a stop continuation, a singleton
--   continuation and a yield continuation. The stream would share the
--   current SVar passed via the State.
foldStreamShared :: IsStream t => State Stream m a -> (a -> t m a -> m r) -> (a -> m r) -> m r -> t m a -> m r

-- | Fold a stream by providing a State, stop continuation, a singleton
--   continuation and a yield continuation. The stream will not use the
--   SVar passed via State.
foldStream :: IsStream t => State Stream m a -> (a -> t m a -> m r) -> (a -> m r) -> m r -> t m a -> m r

-- | For <a>SerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>serial</a> -- <a>Monad</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(1,4),(2,3),(2,4)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data SerialT m a

-- | A serial IO stream of elements of type <tt>a</tt>. See <a>SerialT</a>
--   documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Serial = SerialT IO

-- | Fix the type of a polymorphic stream as <a>SerialT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromSerial :: IsStream t => SerialT m a -> t m a

-- | For <a>WSerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wSerial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wSerial</a> -- <a>Monad</a>
--   </pre>
--   
--   Note that <a>&lt;&gt;</a> is associative only if we disregard the
--   ordering of elements in the resulting stream.
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like interleaved nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   It is a result of interleaving all the nested iterations corresponding
--   to element <tt>1</tt> in the first stream with all the nested
--   iterations of element <tt>2</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromList [(1,3),(1,4)] `Stream.wSerial` Stream.fromList [(2,3),(2,4)]
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>SerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WSerialT m a

-- | An interleaving serial IO stream of elements of type <tt>a</tt>. See
--   <a>WSerialT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WSerial = WSerialT IO

-- | Fix the type of a polymorphic stream as <a>WSerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromWSerial :: IsStream t => WSerialT m a -> t m a

-- | For <a>AsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>async</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>async</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>async</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>async</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>async</tt>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
data AsyncT m a

-- | A demand driven left biased parallely composing IO stream of elements
--   of type <tt>a</tt>. See <a>AsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Async = AsyncT IO

-- | Fix the type of a polymorphic stream as <a>AsyncT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromAsync :: IsStream t => AsyncT m a -> t m a

-- | For <a>WAsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wAsync</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wAsync</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>wAsync</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>wAsync</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one <a>WAsyncT</a> output stream and all the iterations corresponding
--   to <tt>2</tt> constitute another <a>WAsyncT</a> output stream and
--   these two output streams are merged using <tt>wAsync</tt>.
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>AsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WAsyncT m a

-- | A round robin parallely composing IO stream of elements of type
--   <tt>a</tt>. See <a>WAsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WAsync = WAsyncT IO

-- | Fix the type of a polymorphic stream as <a>WAsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromWAsync :: IsStream t => WAsyncT m a -> t m a

-- | For <a>AheadT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>ahead</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>ahead</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations executed concurrently, ahead of time, producing side
--   effects of iterations out of order, but results in order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [2,1]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, ahead of time:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,5,4,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>ahead</tt>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
data AheadT m a

-- | A serial IO stream of elements of type <tt>a</tt> with concurrent
--   lookahead. See <a>AheadT</a> documentation for more details.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
type Ahead = AheadT IO

-- | Fix the type of a polymorphic stream as <a>AheadT</a>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
fromAhead :: IsStream t => AheadT m a -> t m a

-- | For <a>ParallelT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>parallel</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>parallel</a>
--   </pre>
--   
--   See <a>AsyncT</a>, <a>ParallelT</a> is similar except that all
--   iterations are strictly concurrent while in <tt>AsyncT</tt> it depends
--   on the consumer demand and available threads. See <tt>parallel</tt>
--   for more details.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
--   
--   <i>Since: 0.7.0 (maxBuffer applies to ParallelT streams)</i>
data ParallelT m a

-- | A parallely composing IO stream of elements of type <tt>a</tt>. See
--   <a>ParallelT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Parallel = ParallelT IO

-- | Fix the type of a polymorphic stream as <a>ParallelT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromParallel :: IsStream t => ParallelT m a -> t m a

-- | For <a>ZipSerialM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped serially:
--   
--   <pre>
--   &gt;&gt;&gt; s1 = Stream.fromFoldable [1, 2]
--   
--   &gt;&gt;&gt; s2 = Stream.fromFoldable [3, 4]
--   
--   &gt;&gt;&gt; s3 = Stream.fromFoldable [5, 6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipSerial $ (,,) &lt;$&gt; s1 &lt;*&gt; s2 &lt;*&gt; s3
--   [(1,3,5),(2,4,6)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipSerialM m a

-- | An IO stream whose applicative instance zips streams serially.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipSerial = ZipSerialM IO

-- | Fix the type of a polymorphic stream as <a>ZipSerialM</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromZipSerial :: IsStream t => ZipSerialM m a -> t m a

-- | For <a>ZipAsyncM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipAsyncWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped concurrently, the
--   following would take half the time that it would take in serial
--   zipping:
--   
--   <pre>
--   &gt;&gt;&gt; s = Stream.fromFoldableM $ Prelude.map delay [1, 1, 1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipAsync $ (,) &lt;$&gt; s &lt;*&gt; s
--   ...
--   [(1,1),(1,1),(1,1)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipAsyncM m a

-- | An IO stream whose applicative instance zips streams wAsyncly.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipAsync = ZipAsyncM IO

-- | Fix the type of a polymorphic stream as <a>ZipAsyncM</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromZipAsync :: IsStream t => ZipAsyncM m a -> t m a

-- | Construct a stream by adding a pure value at the head of an existing
--   stream. For serial streams this is the same as <tt>(return a) `consM`
--   r</tt> but more efficient. For concurrent streams this is not
--   concurrent whereas <a>consM</a> is concurrent. For example:
--   
--   <pre>
--   &gt; toList $ 1 `cons` 2 `cons` 3 `cons` nil
--   [1,2,3]
--   </pre>
cons :: IsStream t => a -> t m a -> t m a
infixr 5 `cons`

-- | Operator equivalent of <a>cons</a>.
--   
--   <pre>
--   &gt; toList $ 1 .: 2 .: 3 .: nil
--   [1,2,3]
--   </pre>
(.:) :: IsStream t => a -> t m a -> t m a
infixr 5 .:
nil :: IsStream t => t m a
nilM :: (IsStream t, Monad m) => m b -> t m a
fromPure :: IsStream t => a -> t m a
fromEffect :: (Monad m, IsStream t) => m a -> t m a
repeat :: IsStream t => a -> t m a
bindWith :: IsStream t => (t m b -> t m b -> t m b) -> t m a -> (a -> t m b) -> t m b

-- | <tt>concatMapWith mixer generator stream</tt> is a two dimensional
--   looping combinator. The <tt>generator</tt> function is used to
--   generate streams from the elements in the input <tt>stream</tt> and
--   the <tt>mixer</tt> function is used to merge those streams.
--   
--   Note we can merge streams concurrently by using a concurrent merge
--   function.
--   
--   <i>Since: 0.7.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
concatMapWith :: IsStream t => (t m b -> t m b -> t m b) -> (a -> t m b) -> t m a -> t m b

-- | A variant of <a>fold</a> that allows you to fold a <a>Foldable</a>
--   container of streams using the specified stream sum operation.
--   
--   <pre>
--   concatFoldableWith <tt>async</tt> $ map return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatFoldableWith f = Prelude.foldr f S.nil
--   concatFoldableWith f = S.concatMapFoldableWith f id
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldWith to concatFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatFoldableWith :: (IsStream t, Foldable f) => (t m a -> t m a -> t m a) -> f (t m a) -> t m a

-- | A variant of <a>foldMap</a> that allows you to map a monadic streaming
--   action on a <a>Foldable</a> container and then fold it using the
--   specified stream merge operation.
--   
--   <pre>
--   concatMapFoldableWith <tt>async</tt> return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatMapFoldableWith f g = Prelude.foldr (f . g) S.nil
--   concatMapFoldableWith f g xs = S.concatMapWith f g (S.fromFoldable xs)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldMapWith to concatMapFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatMapFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> (a -> t m b) -> f a -> t m b

-- | Like <a>concatMapFoldableWith</a> but with the last two arguments
--   reversed i.e. the monadic streaming function is the last argument.
--   
--   Equivalent to:
--   
--   <pre>
--   concatForFoldableWith f xs g = Prelude.foldr (f . g) S.nil xs
--   concatForFoldableWith f = flip (S.concatMapFoldableWith f)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed forEachWith to concatForFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatForFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> f a -> (a -> t m b) -> t m b
drain :: (IsStream t, Monad m) => t m a -> m ()

-- | <pre>
--   fromList = <a>foldr</a> <a>cons</a> <a>nil</a>
--   </pre>
--   
--   Construct a stream from a list of pure values. This is more efficient
--   than <a>fromFoldable</a> for serial streams.
fromList :: (Monad m, IsStream t) => [a] -> t m a

-- | Convert a stream into a list in the underlying monad.
toList :: (IsStream t, Monad m) => t m a -> m [a]
foldrM :: (IsStream t, Monad m) => (a -> m b -> m b) -> m b -> t m a -> m b
foldrMx :: (IsStream t, Monad m) => (a -> m x -> m x) -> m x -> (m x -> m b) -> t m a -> m b
foldr :: (IsStream t, Monad m) => (a -> b -> b) -> b -> t m a -> m b

-- | Strict left fold with an extraction function. Like the standard strict
--   left fold, but applies a user supplied extraction function (the third
--   argument) to the folded value at the end. This is designed to work
--   with the <tt>foldl</tt> library. The suffix <tt>x</tt> is a mnemonic
--   for extraction.
foldlx' :: (IsStream t, Monad m) => (x -> a -> x) -> x -> (x -> b) -> t m a -> m b

-- | Like <a>foldlx'</a>, but with a monadic step function.
foldlMx' :: (IsStream t, Monad m) => (x -> a -> m x) -> m x -> (x -> m b) -> t m a -> m b

-- | Strict left associative fold.
foldl' :: (IsStream t, Monad m) => (b -> a -> b) -> b -> t m a -> m b
fold :: (IsStream t, Monad m) => Fold m a b -> t m a -> m b

-- | Compare two streams for equality
eqBy :: (IsStream t, Monad m) => (a -> b -> Bool) -> t m a -> t m b -> m Bool

-- | Compare two streams
cmpBy :: (IsStream t, Monad m) => (a -> b -> Ordering) -> t m a -> t m b -> m Ordering

-- | Same as <a>fromWSerial</a>.

-- | <i>Deprecated: Please use fromWSerial instead.</i>
interleaving :: IsStream t => WSerialT m a -> t m a

-- | Same as <a>fromZipSerial</a>.

-- | <i>Deprecated: Please use fromZipSerial instead.</i>
zipping :: IsStream t => ZipSerialM m a -> t m a

-- | Same as <a>fromZipAsync</a>.

-- | <i>Deprecated: Please use fromZipAsync instead.</i>
zippingAsync :: IsStream t => ZipAsyncM m a -> t m a
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Serial.SerialT
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Serial.WSerialT
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Async.AsyncT
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Async.WAsyncT
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Ahead.AheadT
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Parallel.ParallelT
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Zip.ZipSerialM
instance Streamly.Internal.Data.Stream.IsStream.Type.IsStream Streamly.Internal.Data.Stream.Zip.ZipAsyncM


-- | To run the examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Data.Fold as Fold
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <h1>Unfolds and Streams</h1>
--   
--   An <a>Unfold</a> type is the same as the direct style <a>Stream</a>
--   type except that it uses an inject function to determine the initial
--   state of the stream based on an input. A stream is a special case of
--   Unfold when the static input is unit or Void.
--   
--   This allows an important optimization to occur in several cases,
--   making the <a>Unfold</a> a more efficient abstraction. Consider the
--   <a>concatMap</a> and <tt>unfoldMany</tt> operations, the latter is
--   more efficient. <a>concatMap</a> generates a new stream object from
--   each element in the stream by applying the supplied function to the
--   element, the stream object includes the "step" function as well as the
--   initial "state" of the stream. Since the stream is generated
--   dynamically the compiler does not know the step function or the state
--   type statically at compile time, therefore, it cannot inline it. On
--   the other hand in case of <tt>unfoldMany</tt> the compiler has
--   visibility into the unfold's state generation function, therefore, the
--   compiler knows all the types statically and it can inline the inject
--   as well as the step functions, generating efficient code. Essentially,
--   the stream is not opaque to the consumer in case of unfolds, the
--   consumer knows how to generate the stream from a seed using a known
--   "inject" and "step" functions.
--   
--   A Stream is like a data object whereas unfold is like a function.
--   Being function like, an Unfold is an instance of <tt>Category</tt> and
--   <tt>Arrow</tt> type classes.
--   
--   <h1>Unfolds and Folds</h1>
--   
--   Streams forcing a closed control flow loop can be categorized under
--   two types, unfolds and folds, both of these are duals of each other.
--   
--   Unfold streams are really generators of a sequence of elements, we can
--   also call them pull style streams. These are lazy producers of
--   streams. On each evaluation the producer generates the next element. A
--   consumer can therefore pull elements from the stream whenever it wants
--   to. A stream consumer can multiplex pull streams by pulling elements
--   from the chosen streams, therefore, pull streams allow merging or
--   multiplexing. On the other hand, with this representation we cannot
--   split or demultiplex a stream. So really these are stream sources that
--   can be generated from a seed and can be merged or zipped into a single
--   stream.
--   
--   The dual of Unfolds are Folds. Folds can also be called as push style
--   streams or reducers. These are strict consumers of streams. We keep
--   pushing elements to a fold and we can extract the result at any point.
--   A driver can choose which fold to push to and can also push the same
--   element to multiple folds. Therefore, folds allow splitting or
--   demultiplexing a stream. On the other hand, we cannot merge streams
--   using this representation. So really these are stream consumers that
--   reduce the stream to a single value, these consumers can be composed
--   such that a stream can be split over multiple consumers.
--   
--   Performance:
--   
--   Composing a tree or graph of computations with unfolds can be much
--   more efficient compared to composing with the Monad instance. The
--   reason is that unfolds allow the compiler to statically know the state
--   and optimize it using stream fusion whereas it is not possible with
--   the monad bind because the state is determined dynamically.
module Streamly.Internal.Data.Unfold

-- | A stream is a succession of <a>Step</a>s. A <a>Yield</a> produces a
--   single value and the next state of the stream. <a>Stop</a> indicates
--   there are no more values in the stream.
data Step s a
Yield :: a -> s -> Step s a
Skip :: s -> Step s a
Stop :: Step s a

-- | An <tt>Unfold m a b</tt> is a generator of a stream of values of type
--   <tt>b</tt> from a seed of type <tt>a</tt> in <a>Monad</a> <tt>m</tt>.
data Unfold m a b

-- | Make an unfold from <tt>step</tt> and <tt>inject</tt> functions.
--   
--   <i>Pre-release</i>
mkUnfoldM :: (s -> m (Step s b)) -> (a -> m s) -> Unfold m a b

-- | Make an unfold from a step function.
--   
--   See also: <a>unfoldrM</a>
--   
--   <i>Pre-release</i>
mkUnfoldrM :: Applicative m => (a -> m (Step a b)) -> Unfold m a b

-- | Build a stream by unfolding a <i>monadic</i> step function starting
--   from a seed. The step function returns the next element in the stream
--   and the next seed value. When it is done it returns <a>Nothing</a> and
--   the stream ends.
--   
--   <i>Since: 0.8.0</i>
unfoldrM :: Applicative m => (a -> m (Maybe (b, a))) -> Unfold m a b

-- | Like <a>unfoldrM</a> but uses a pure step function.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    f [] = Nothing
--    f (x:xs) = Just (x, xs)
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Unfold.fold Fold.toList (Unfold.unfoldr f) [1,2,3]
--   [1,2,3]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
unfoldr :: Applicative m => (a -> Maybe (b, a)) -> Unfold m a b

-- | Lift a monadic function into an unfold. The unfold generates a
--   singleton stream.
--   
--   <i>Since: 0.8.0</i>
functionM :: Applicative m => (a -> m b) -> Unfold m a b

-- | Lift a pure function into an unfold. The unfold generates a singleton
--   stream.
--   
--   <pre>
--   function f = functionM $ return . f
--   </pre>
--   
--   <i>Since: 0.8.0</i>
function :: Applicative m => (a -> b) -> Unfold m a b

-- | Identity unfold. The unfold generates a singleton stream having the
--   input as the only element.
--   
--   <pre>
--   identity = function Prelude.id
--   </pre>
--   
--   <i>Pre-release</i>
identity :: Applicative m => Unfold m a a

-- | Lift a monadic function into an unfold generating a nil stream with a
--   side effect.
nilM :: Applicative m => (a -> m c) -> Unfold m a b

-- | Prepend a monadic single element generator function to an
--   <a>Unfold</a>. The same seed is used in the action as well as the
--   unfold.
--   
--   <i>Pre-release</i>
consM :: Applicative m => (a -> m b) -> Unfold m a b -> Unfold m a b

-- | The unfold discards its input and generates a function stream using
--   the supplied monadic action.
--   
--   <i>Pre-release</i>
fromEffect :: Applicative m => m b -> Unfold m a b

-- | Discards the unfold input and always returns the argument of
--   <a>fromPure</a>.
--   
--   <pre>
--   fromPure = fromEffect . pure
--   </pre>
--   
--   <i>Pre-release</i>
fromPure :: Applicative m => b -> Unfold m a b

-- | Generates an infinite stream repeating the seed.
--   
--   <i>Since: 0.8.0</i>
repeatM :: Monad m => Unfold m (m a) a

-- | Generates a stream replicating the seed <tt>n</tt> times.
--   
--   <i>Since: 0.8.0</i>
replicateM :: Monad m => Int -> Unfold m (m a) a

-- | <tt>fromIndicesM gen</tt> generates an infinite stream of values using
--   <tt>gen</tt> starting from the seed.
--   
--   <pre>
--   fromIndicesM f = Unfold.mapM f $ Unfold.enumerateFrom 0
--   </pre>
--   
--   <i>Pre-release</i>
fromIndicesM :: Applicative m => (Int -> m a) -> Unfold m Int a

-- | Generates an infinite stream starting with the given seed and applying
--   the given function repeatedly.
--   
--   <i>Since: 0.8.0</i>
iterateM :: Monad m => (a -> m a) -> Unfold m (m a) a

-- | Types that can be enumerated as a stream. The operations in this type
--   class are equivalent to those in the <a>Enum</a> type class, except
--   that these generate a stream instead of a list. Use the functions in
--   <a>Streamly.Internal.Data.Unfold.Enumeration</a> module to define new
--   instances.
--   
--   <i>Pre-release</i>
class Enum a => Enumerable a

-- | Unfolds <tt>from</tt> generating a stream starting with the element
--   <tt>from</tt>, enumerating up to <a>maxBound</a> when the type is
--   <a>Bounded</a> or generating an infinite stream when the type is not
--   <a>Bounded</a>.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFrom (0 :: Int)
--   [0,1,2,3]
--   </pre>
--   
--   For <a>Fractional</a> types, enumeration is numerically stable.
--   However, no overflow or underflow checks are performed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFrom 1.1
--   [1.1,2.1,3.1,4.1]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFrom :: (Enumerable a, Monad m) => Unfold m a a

-- | Unfolds <tt>(from, to)</tt> generating a finite stream starting with
--   the element <tt>from</tt>, enumerating the type up to the value
--   <tt>to</tt>. If <tt>to</tt> is smaller than <tt>from</tt> then an
--   empty stream is returned.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromTo (0, 4)
--   [0,1,2,3,4]
--   </pre>
--   
--   For <a>Fractional</a> types, the last element is equal to the
--   specified <tt>to</tt> value after rounding to the nearest integral
--   value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromTo (1.1, 4)
--   [1.1,2.1,3.1,4.1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromTo (1.1, 4.6)
--   [1.1,2.1,3.1,4.1,5.1]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFromTo :: (Enumerable a, Monad m) => Unfold m (a, a) a

-- | Unfolds <tt>(from, then)</tt> generating a stream whose first element
--   is <tt>from</tt> and the successive elements are in increments of
--   <tt>then</tt>. Enumeration can occur downwards or upwards depending on
--   whether <tt>then</tt> comes before or after <tt>from</tt>. For
--   <a>Bounded</a> types the stream ends when <a>maxBound</a> is reached,
--   for unbounded types it keeps enumerating infinitely.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFromThen (0, 2)
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.unfold Unfold.enumerateFromThen (0,(-2))
--   [0,-2,-4,-6]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFromThen :: (Enumerable a, Monad m) => Unfold m (a, a) a

-- | Unfolds <tt>(from, then, to)</tt> generating a finite stream whose
--   first element is <tt>from</tt> and the successive elements are in
--   increments of <tt>then</tt> up to <tt>to</tt>. Enumeration can occur
--   downwards or upwards depending on whether <tt>then</tt> comes before
--   or after <tt>from</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Unfold as Unfold
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromThenTo (0, 2, 6)
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromThenTo (0, (-2), (-6))
--   [0,-2,-4,-6]
--   </pre>
--   
--   <i>Pre-release</i>
enumerateFromThenTo :: (Enumerable a, Monad m) => Unfold m (a, a, a) a

-- | Same as <a>enumerateFromStepNum</a> using a stride of 1:
--   
--   <pre>
--   &gt;&gt;&gt; enumerateFromNum = lmap (from -&gt; (from, 1)) Unfold.enumerateFromStepNum
--   &gt;&gt;&gt; Stream.toList $ Stream.take 6 $ Stream.unfold enumerateFromNum (0.9)
--   [0.9,1.9,2.9,3.9,4.9,5.9]
--   </pre>
--   
--   Also, same as <a>enumerateFromThenNum</a> using a stride of 1 but see
--   the note in <a>enumerateFromThenNum</a> about the loss of precision:
--   
--   <pre>
--   &gt;&gt;&gt; enumerateFromNum = lmap (from -&gt; (from, from + 1)) Unfold.enumerateFromThenNum
--   &gt;&gt;&gt; Stream.toList $ Stream.take 6 $ Stream.unfold enumerateFromNum (0.9)
--   [0.9,1.9,2.9,3.8999999999999995,4.8999999999999995,5.8999999999999995]
--   </pre>
--   
--   <i>Internal</i>
enumerateFromNum :: (Monad m, Num a) => Unfold m a a

-- | Same as 'enumerateFromStepNum (from, next)' using a stride of <tt>next
--   - from</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; enumerateFromThenNum = lmap ((from, next) -&gt; (from, next - from)) Unfold.enumerateFromStepNum
--   </pre>
--   
--   Example: @ &gt;&gt;&gt; Stream.toList $ Stream.take 10 $ Stream.unfold
--   enumerateFromThenNum (255::Word8,0) [255,0,1,2,3,4,5,6,7,8]
--   
--   <pre>
--   The implementation is numerically stable for floating point values.
--   
--   Note that <a>enumerateFromThenIntegral</a> is faster for integrals.
--   
--   Note that in the strange world of floating point numbers, using
--   </pre>
--   
--   enumerateFromThenNum (from, from + 1)<tt> is almost exactly the same
--   as </tt>enumerateFromStepNum (from, 1) but not precisely the same.
--   Because <tt>(from + 1) - from</tt> is not exactly 1, it may lose some
--   precision, the loss may also be aggregated in each step, if you want
--   that precision then use <a>enumerateFromStepNum</a> instead.
--   
--   <i>Internal</i>
enumerateFromThenNum :: (Monad m, Num a) => Unfold m (a, a) a

-- | Unfolds <tt>(from, stride)</tt> generating an infinite stream starting
--   from <tt>from</tt> and incrementing every time by <tt>stride</tt>. For
--   <a>Bounded</a> types, after the value overflows it keeps enumerating
--   in a cycle:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 10 $ Stream.unfold Unfold.enumerateFromStepNum (255::Word8,1)
--   [255,0,1,2,3,4,5,6,7,8]
--   </pre>
--   
--   The implementation is numerically stable for floating point values.
--   
--   Note <a>enumerateFromStepIntegral</a> is faster for integrals.
--   
--   <i>Internal</i>
enumerateFromStepNum :: (Monad m, Num a) => Unfold m (a, a) a
enumerateFromIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m a a
enumerateFromThenIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m (a, a) a
enumerateFromToIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m (a, a) a
enumerateFromThenToIntegralBounded :: (Monad m, Integral a, Bounded a) => Unfold m (a, a, a) a
enumerateFromIntegral :: (Monad m, Integral a) => Unfold m a a
enumerateFromThenIntegral :: (Monad m, Integral a) => Unfold m (a, a) a
enumerateFromToIntegral :: (Monad m, Integral a) => Unfold m (a, a) a
enumerateFromThenToIntegral :: (Monad m, Integral a) => Unfold m (a, a, a) a

-- | Enumerate from given starting Enum value <tt>from</tt> with stride of
--   1 till maxBound
--   
--   <i>Internal</i>
enumerateFromSmallBounded :: (Monad m, Enum a, Bounded a) => Unfold m a a

-- | Enumerate from given starting Enum value <tt>from</tt> and next Enum
--   value <tt>next</tt> with stride of (fromEnum next - fromEnum from)
--   till maxBound.
--   
--   <i>Internal</i>
enumerateFromThenSmallBounded :: forall m a. (Monad m, Enum a, Bounded a) => Unfold m (a, a) a

-- | Enumerate from given starting Enum value <tt>from</tt> and to Enum
--   value <tt>to</tt> with stride of 1 till to value.
--   
--   <i>Internal</i>
enumerateFromToSmall :: (Monad m, Enum a) => Unfold m (a, a) a

-- | Enumerate from given starting Enum value <tt>from</tt> and then Enum
--   value <tt>next</tt> and to Enum value <tt>to</tt> with stride of
--   (fromEnum next - fromEnum from) till to value.
--   
--   <i>Internal</i>
enumerateFromThenToSmall :: (Monad m, Enum a) => Unfold m (a, a, a) a
enumerateFromFractional :: (Monad m, Fractional a) => Unfold m a a
enumerateFromThenFractional :: (Monad m, Fractional a) => Unfold m (a, a) a

-- | Same as <a>enumerateFromStepNum</a> with a step of 1 and enumerating
--   up to the specified upper limit rounded to the nearest integral value:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold Unfold.enumerateFromToFractional (0.1, 6.3)
--   [0.1,1.1,2.1,3.1,4.1,5.1,6.1]
--   </pre>
--   
--   <i>Internal</i>
enumerateFromToFractional :: (Monad m, Fractional a, Ord a) => Unfold m (a, a) a
enumerateFromThenToFractional :: (Monad m, Fractional a, Ord a) => Unfold m (a, a, a) a

-- | Convert a list of pure values to a <a>Stream</a>
--   
--   <i>Since: 0.8.0</i>
fromList :: Monad m => Unfold m [a] a

-- | Convert a list of monadic values to a <a>Stream</a>
--   
--   <i>Since: 0.8.0</i>
fromListM :: Monad m => Unfold m [m a] a

-- | Convert a stream into an <a>Unfold</a>. Note that a stream converted
--   to an <a>Unfold</a> may not be as efficient as an <a>Unfold</a> in
--   some situations.
--   
--   <i>Since: 0.8.0</i>
fromStream :: (IsStream t, Monad m) => Unfold m (t m a) a
fromStreamK :: Applicative m => Unfold m (Stream m a) a
fromStreamD :: Applicative m => Unfold m (Stream m a) a

-- | Map a function on the input argument of the <a>Unfold</a>.
--   
--   <pre>
--   &gt;&gt;&gt; u = Unfold.lmap (fmap (+1)) Unfold.fromList
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..5]
--   [2,3,4,5,6]
--   </pre>
--   
--   <pre>
--   lmap f = Unfold.many (Unfold.function f)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
lmap :: (a -> c) -> Unfold m c b -> Unfold m a b

-- | Map an action on the input argument of the <a>Unfold</a>.
--   
--   <pre>
--   lmapM f = Unfold.many (Unfold.functionM f)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
lmapM :: Monad m => (a -> m c) -> Unfold m c b -> Unfold m a b

-- | Supply the seed to an unfold closing the input end of the unfold.
--   
--   <pre>
--   supply a = Unfold.lmap (Prelude.const a)
--   </pre>
--   
--   <i>Pre-release</i>
supply :: a -> Unfold m a b -> Unfold m Void b

-- | Supply the first component of the tuple to an unfold that accepts a
--   tuple as a seed resulting in a fold that accepts the second component
--   of the tuple as a seed.
--   
--   <pre>
--   supplyFirst a = Unfold.lmap (a, )
--   </pre>
--   
--   <i>Pre-release</i>
supplyFirst :: a -> Unfold m (a, b) c -> Unfold m b c

-- | Supply the second component of the tuple to an unfold that accepts a
--   tuple as a seed resulting in a fold that accepts the first component
--   of the tuple as a seed.
--   
--   <pre>
--   supplySecond b = Unfold.lmap (, b)
--   </pre>
--   
--   <i>Pre-release</i>
supplySecond :: b -> Unfold m (a, b) c -> Unfold m a c

-- | Convert an <a>Unfold</a> into an unfold accepting a tuple as an
--   argument, using the argument of the original fold as the second
--   element of tuple and discarding the first element of the tuple.
--   
--   <pre>
--   discardFirst = Unfold.lmap snd
--   </pre>
--   
--   <i>Pre-release</i>
discardFirst :: Unfold m a b -> Unfold m (c, a) b

-- | Convert an <a>Unfold</a> into an unfold accepting a tuple as an
--   argument, using the argument of the original fold as the first element
--   of tuple and discarding the second element of the tuple.
--   
--   <pre>
--   discardSecond = Unfold.lmap fst
--   </pre>
--   
--   <i>Pre-release</i>
discardSecond :: Unfold m a b -> Unfold m (a, c) b

-- | Convert an <a>Unfold</a> that accepts a tuple as an argument into an
--   unfold that accepts a tuple with elements swapped.
--   
--   <pre>
--   swap = Unfold.lmap Tuple.swap
--   </pre>
--   
--   <i>Pre-release</i>
swap :: Unfold m (a, c) b -> Unfold m (c, a) b

-- | Compose an <a>Unfold</a> and a <a>Fold</a>. Given an <tt>Unfold m a
--   b</tt> and a <tt>Fold m b c</tt>, returns a monadic action <tt>a -&gt;
--   m c</tt> representing the application of the fold on the unfolded
--   stream.
--   
--   <pre>
--   &gt;&gt;&gt; Unfold.fold Fold.sum Unfold.fromList [1..100]
--   5050
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; fold f u = Stream.fold f . Stream.unfold u
--   </pre>
--   
--   <i>Pre-release</i>
fold :: Monad m => Fold m b c -> Unfold m a b -> a -> m c

-- | Map a function on the output of the unfold (the type <tt>b</tt>).
--   
--   <i>Pre-release</i>
map :: Functor m => (b -> c) -> Unfold m a b -> Unfold m a c

-- | Apply a monadic function to each element of the stream and replace it
--   with the output of the resulting action.
--   
--   <i>Since: 0.8.0</i>
mapM :: Monad m => (b -> m c) -> Unfold m a b -> Unfold m a c
mapMWithInput :: Monad m => (a -> b -> m c) -> Unfold m a b -> Unfold m a c

-- | Scan the output of an <a>Unfold</a> to change it in a stateful manner.
--   
--   <i>Unimplemented</i>
scanlM' :: Monad m => (b -> a -> m b) -> m b -> Unfold m c a -> Unfold m c b

-- | Scan the output of an <a>Unfold</a> to change it in a stateful manner.
--   
--   <i>Pre-release</i>
scan :: Monad m => Fold m b c -> Unfold m a b -> Unfold m a c

-- | Apply a fold multiple times on the output of an unfold.
--   
--   <i>Unimplemented</i>
foldMany :: Fold m b c -> Unfold m a b -> Unfold m a c

-- | Make an unfold operate on values wrapped in an <tt>Either a a</tt>
--   type. 'Right a' translates to 'Right b' and 'Left a' translates to
--   'Left b'.
--   
--   <i>Internal</i>
either :: Applicative m => Unfold m a b -> Unfold m (Either a a) (Either b b)

-- | Same as <a>takeWhile</a> but with a monadic predicate.
--   
--   <i>Since: 0.8.0</i>
takeWhileM :: Monad m => (b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | End the stream generated by the <a>Unfold</a> as soon as the predicate
--   fails on an element.
--   
--   <i>Since: 0.8.0</i>
takeWhile :: Monad m => (b -> Bool) -> Unfold m a b -> Unfold m a b

-- | <pre>
--   &gt;&gt;&gt; u = Unfold.take 2 Unfold.fromList
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..100]
--   [1,2]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
take :: Monad m => Int -> Unfold m a b -> Unfold m a b

-- | Include only those elements that pass a predicate.
--   
--   <i>Since: 0.8.0</i>
filter :: Monad m => (b -> Bool) -> Unfold m a b -> Unfold m a b

-- | Same as <a>filter</a> but with a monadic predicate.
--   
--   <i>Since: 0.8.0</i>
filterM :: Monad m => (b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | <tt>drop n unf</tt> drops <tt>n</tt> elements from the stream
--   generated by <tt>unf</tt>.
--   
--   <i>Since: 0.8.0</i>
drop :: Monad m => Int -> Unfold m a b -> Unfold m a b

-- | Similar to <a>dropWhileM</a> but with a pure condition function.
--   
--   <i>Since: 0.8.0</i>
dropWhile :: Monad m => (b -> Bool) -> Unfold m a b -> Unfold m a b

-- | <tt>dropWhileM f unf</tt> drops elements from the stream generated by
--   <tt>unf</tt> while the condition holds true. The condition function
--   <tt>f</tt> is <i>monadic</i> in nature.
--   
--   <i>Since: 0.8.0</i>
dropWhileM :: Monad m => (b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | Distribute the input to two unfolds and then zip the outputs to a
--   single stream using a monadic zip function.
--   
--   Stops as soon as any of the unfolds stops.
--   
--   <i>Pre-release</i>
zipWithM :: Monad m => (b -> c -> m d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | Like <a>zipWithM</a> but with a pure zip function.
--   
--   <pre>
--   &gt;&gt;&gt; square = fmap (\x -&gt; x * x) Unfold.fromList
--   
--   &gt;&gt;&gt; cube = fmap (\x -&gt; x * x * x) Unfold.fromList
--   
--   &gt;&gt;&gt; u = Unfold.zipWith (,) square cube
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..5]
--   [(1,1),(4,8),(9,27),(16,64),(25,125)]
--   </pre>
--   
--   <pre>
--   zipWith f = zipWithM (\a b -&gt; return $ f a b)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
zipWith :: Monad m => (b -> c -> d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | Create a cross product (vector product or cartesian product) of the
--   output streams of two unfolds using a monadic combining function.
--   
--   <i>Pre-release</i>
crossWithM :: Monad m => (b -> c -> m d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | Like <a>crossWithM</a> but uses a pure combining function.
--   
--   <pre>
--   crossWith f = crossWithM (\b c -&gt; return $ f b c)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; u1 = Unfold.lmap fst Unfold.fromList
--   
--   &gt;&gt;&gt; u2 = Unfold.lmap snd Unfold.fromList
--   
--   &gt;&gt;&gt; u = Unfold.crossWith (,) u1 u2
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u ([1,2,3], [4,5,6])
--   [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
crossWith :: Monad m => (b -> c -> d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | See <a>crossWith</a>.
--   
--   <pre>
--   cross = crossWith (,)
--   </pre>
--   
--   To cross the streams from a tuple we can write:
--   
--   <pre>
--   crossProduct :: Monad m =&gt; Unfold m a b -&gt; Unfold m c d -&gt; Unfold m (a, c) (b, d)
--   crossProduct u1 u2 = cross (lmap fst u1) (lmap snd u2)
--   </pre>
--   
--   <i>Pre-release</i>
cross :: Monad m => Unfold m a b -> Unfold m a c -> Unfold m a (b, c)
apply :: Monad m => Unfold m a (b -> c) -> Unfold m a b -> Unfold m a c
data ConcatState s1 s2
ConcatOuter :: s1 -> ConcatState s1 s2
ConcatInner :: s1 -> s2 -> ConcatState s1 s2

-- | Apply the second unfold to each output element of the first unfold and
--   flatten the output in a single stream.
--   
--   <i>Since: 0.8.0</i>
many :: Monad m => Unfold m a b -> Unfold m b c -> Unfold m a c

-- | Map an unfold generating action to each element of an unfold and
--   flatten the results into a single stream.
concatMapM :: Monad m => (b -> m (Unfold m a c)) -> Unfold m a b -> Unfold m a c
bind :: Monad m => Unfold m a b -> (b -> Unfold m a c) -> Unfold m a c
infixl 1 `bind`

-- | Like <a>gbracket</a> but with following differences:
--   
--   <ul>
--   <li>alloc action <tt>a -&gt; m c</tt> runs with async exceptions
--   enabled</li>
--   <li>cleanup action <tt>c -&gt; m d</tt> won't run if the stream is
--   garbage collected after partial evaluation.</li>
--   <li>does not require a <a>MonadAsync</a> constraint.</li>
--   </ul>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
gbracket_ :: Monad m => (a -> m c) -> (forall s. m s -> m (Either e s)) -> (c -> m d) -> Unfold m (c, e) b -> Unfold m c b -> Unfold m a b

-- | Run the alloc action <tt>a -&gt; m c</tt> with async exceptions
--   disabled but keeping blocking operations interruptible (see
--   <a>mask</a>). Use the output <tt>c</tt> as input to <tt>Unfold m c
--   b</tt> to generate an output stream. When unfolding use the supplied
--   <tt>try</tt> operation <tt>forall s. m s -&gt; m (Either e s)</tt> to
--   catch synchronous exceptions. If an exception occurs run the exception
--   handling unfold <tt>Unfold m (c, e) b</tt>.
--   
--   The cleanup action <tt>c -&gt; m d</tt>, runs whenever the stream ends
--   normally, due to a sync or async exception or if it gets garbage
--   collected after a partial lazy evaluation. See <a>bracket</a> for the
--   semantics of the cleanup action.
--   
--   <a>gbracket</a> can express all other exception handling combinators.
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
gbracket :: (MonadIO m, MonadBaseControl IO m) => (a -> m c) -> (forall s. m s -> m (Either e s)) -> (c -> m d) -> Unfold m (c, e) b -> Unfold m c b -> Unfold m a b

-- | Run a side effect <tt>a -&gt; m c</tt> on the input <tt>a</tt> before
--   unfolding it using <tt>Unfold m a b</tt>.
--   
--   <pre>
--   before f = lmapM (\a -&gt; f a &gt;&gt; return a)
--   </pre>
--   
--   <i>Pre-release</i>
before :: (a -> m c) -> Unfold m a b -> Unfold m a b

-- | Unfold the input <tt>a</tt> using <tt>Unfold m a b</tt>, run an action
--   on <tt>a</tt> whenever the unfold stops normally, or if it is garbage
--   collected after a partial lazy evaluation.
--   
--   The semantics of the action <tt>a -&gt; m c</tt> are similar to the
--   cleanup action semantics in <a>bracket</a>.
--   
--   <i>See also <a>after_</a></i>
--   
--   <i>Pre-release</i>
after :: (MonadIO m, MonadBaseControl IO m) => (a -> m c) -> Unfold m a b -> Unfold m a b

-- | Like <a>after</a> with following differences:
--   
--   <ul>
--   <li>action <tt>a -&gt; m c</tt> won't run if the stream is garbage
--   collected after partial evaluation.</li>
--   <li>Monad <tt>m</tt> does not require any other constraints.</li>
--   </ul>
--   
--   <i>Pre-release</i>
after_ :: Monad m => (a -> m c) -> Unfold m a b -> Unfold m a b

-- | Unfold the input <tt>a</tt> using <tt>Unfold m a b</tt>, run an action
--   on <tt>a</tt> whenever the unfold stops normally, aborts due to an
--   exception or if it is garbage collected after a partial lazy
--   evaluation.
--   
--   The semantics of the action <tt>a -&gt; m c</tt> are similar to the
--   cleanup action semantics in <a>bracket</a>.
--   
--   <pre>
--   finally release = bracket return release
--   </pre>
--   
--   <i>See also <a>finally_</a></i>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
finally :: (MonadAsync m, MonadCatch m) => (a -> m c) -> Unfold m a b -> Unfold m a b

-- | Like <a>finally</a> with following differences:
--   
--   <ul>
--   <li>action <tt>a -&gt; m c</tt> won't run if the stream is garbage
--   collected after partial evaluation.</li>
--   <li>does not require a <a>MonadAsync</a> constraint.</li>
--   </ul>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
finally_ :: MonadCatch m => (a -> m c) -> Unfold m a b -> Unfold m a b

-- | Run the alloc action <tt>a -&gt; m c</tt> with async exceptions
--   disabled but keeping blocking operations interruptible (see
--   <a>mask</a>). Use the output <tt>c</tt> as input to <tt>Unfold m c
--   b</tt> to generate an output stream.
--   
--   <tt>c</tt> is usually a resource under the state of monad <tt>m</tt>,
--   e.g. a file handle, that requires a cleanup after use. The cleanup
--   action <tt>c -&gt; m d</tt>, runs whenever the stream ends normally,
--   due to a sync or async exception or if it gets garbage collected after
--   a partial lazy evaluation.
--   
--   <a>bracket</a> only guarantees that the cleanup action runs, and it
--   runs with async exceptions enabled. The action must ensure that it can
--   successfully cleanup the resource in the face of sync or async
--   exceptions.
--   
--   When the stream ends normally or on a sync exception, cleanup action
--   runs immediately in the current thread context, whereas in other cases
--   it runs in the GC context, therefore, cleanup may be delayed until the
--   GC gets to run.
--   
--   <i>See also: <a>bracket_</a>, <a>gbracket</a></i>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
bracket :: (MonadAsync m, MonadCatch m) => (a -> m c) -> (c -> m d) -> Unfold m c b -> Unfold m a b

-- | Like <a>bracket</a> but with following differences:
--   
--   <ul>
--   <li>alloc action <tt>a -&gt; m c</tt> runs with async exceptions
--   enabled</li>
--   <li>cleanup action <tt>c -&gt; m d</tt> won't run if the stream is
--   garbage collected after partial evaluation.</li>
--   <li>does not require a <a>MonadAsync</a> constraint.</li>
--   </ul>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
bracket_ :: MonadCatch m => (a -> m c) -> (c -> m d) -> Unfold m c b -> Unfold m a b

-- | Unfold the input <tt>a</tt> using <tt>Unfold m a b</tt>, run the
--   action <tt>a -&gt; m c</tt> on <tt>a</tt> if the unfold aborts due to
--   an exception.
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
onException :: MonadCatch m => (a -> m c) -> Unfold m a b -> Unfold m a b

-- | When unfolding <tt>Unfold m a b</tt> if an exception <tt>e</tt>
--   occurs, unfold <tt>e</tt> using <tt>Unfold m e b</tt>.
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
handle :: (MonadCatch m, Exception e) => Unfold m e b -> Unfold m a b -> Unfold m a b


-- | An <a>Unfold</a> is a source or a producer of a stream of values. It
--   takes a seed value as an input and unfolds it into a sequence of
--   values.
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Data.Fold as Fold
--   
--   &gt;&gt;&gt; import qualified Streamly.Data.Unfold as Unfold
--   
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   </pre>
--   
--   For example, the <a>fromList</a> Unfold generates a stream of values
--   from a supplied list. Unfolds can be converted to <a>SerialT</a>
--   stream using the Stream.unfold operation.
--   
--   <pre>
--   &gt;&gt;&gt; stream = Stream.unfold Unfold.fromList [1..100]
--   
--   &gt;&gt;&gt; Stream.sum stream
--   5050
--   </pre>
--   
--   All the serial stream generation operations in <a>Streamly.Prelude</a>
--   can be expressed using unfolds:
--   
--   <pre>
--   Stream.fromList = Stream.unfold Unfold.fromList [1..100]
--   </pre>
--   
--   Conceptually, an <a>Unfold</a> is just like "Data.List.unfoldr". Let
--   us write a step function to unfold a list using "Data.List.unfoldr":
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    f [] = Nothing
--    f (x:xs) = Just (x, xs)
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Data.List.unfoldr f [1,2,3]
--   [1,2,3]
--   </pre>
--   
--   Unfold.unfoldr is just the same, it uses the same step function:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold (Unfold.unfoldr f) [1,2,3]
--   [1,2,3]
--   </pre>
--   
--   The input of an unfold can be transformed using <a>lmap</a>:
--   
--   <pre>
--   &gt;&gt;&gt; u = Unfold.lmap (fmap (+1)) Unfold.fromList
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold u [1..5]
--   [2,3,4,5,6]
--   </pre>
--   
--   <a>Unfold</a> streams can be transformed using transformation
--   combinators. For example, to retain only the first two elements of an
--   unfold:
--   
--   <pre>
--   &gt;&gt;&gt; u = Unfold.take 2 Unfold.fromList
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold u [1..100]
--   [1,2]
--   </pre>
--   
--   Multiple unfolds can be combined in several interesting ways. For
--   example, to generate nested looping as in imperative languages (also
--   known as cross product of the two streams):
--   
--   <pre>
--   &gt;&gt;&gt; u1 = Unfold.lmap fst Unfold.fromList
--   
--   &gt;&gt;&gt; u2 = Unfold.lmap snd Unfold.fromList
--   
--   &gt;&gt;&gt; u = Unfold.crossWith (,) u1 u2
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.unfold u ([1,2,3], [4,5,6])
--   [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)]
--   </pre>
--   
--   Nested loops using unfolds provide C like performance due to complete
--   stream fusion.
--   
--   Please see <a>Streamly.Internal.Data.Unfold</a> for additional
--   <tt>Pre-release</tt> functions.
--   
--   <h1>Unfolds vs. Streams</h1>
--   
--   Unfolds' raison d'etre is their efficiency in nested stream operations
--   due to complete stream fusion. <a>concatMap</a> or the <a>Monad</a>
--   instance of streams use stream generation operations of the shape
--   <tt>a -&gt; t m b</tt> and then flatten the resulting stream. This
--   implementation is more powerful but does not allow for complete stream
--   fusion. Unfolds provide less powerful but more efficient
--   <a>unfoldMany</a>, <a>many</a> and <a>crossWith</a> operations as an
--   alternative to a subset of use cases of <a>concatMap</a> and
--   <a>Applicative</a> stream operations.
--   
--   <a>Streamly.Prelude</a> exports polymorphic stream generation
--   operations that provide the same functionality as unfolds in this
--   module. Since unfolds can be easily converted to streams, several
--   modules in streamly provide only unfolds for serial stream generation.
--   We cannot use unfolds exclusively for stream generation as they do not
--   support concurrency.
module Streamly.Data.Unfold

-- | An <tt>Unfold m a b</tt> is a generator of a stream of values of type
--   <tt>b</tt> from a seed of type <tt>a</tt> in <a>Monad</a> <tt>m</tt>.
data Unfold m a b

-- | Build a stream by unfolding a <i>monadic</i> step function starting
--   from a seed. The step function returns the next element in the stream
--   and the next seed value. When it is done it returns <a>Nothing</a> and
--   the stream ends.
--   
--   <i>Since: 0.8.0</i>
unfoldrM :: Applicative m => (a -> m (Maybe (b, a))) -> Unfold m a b

-- | Like <a>unfoldrM</a> but uses a pure step function.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--    f [] = Nothing
--    f (x:xs) = Just (x, xs)
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Unfold.fold Fold.toList (Unfold.unfoldr f) [1,2,3]
--   [1,2,3]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
unfoldr :: Applicative m => (a -> Maybe (b, a)) -> Unfold m a b

-- | Lift a pure function into an unfold. The unfold generates a singleton
--   stream.
--   
--   <pre>
--   function f = functionM $ return . f
--   </pre>
--   
--   <i>Since: 0.8.0</i>
function :: Applicative m => (a -> b) -> Unfold m a b

-- | Lift a monadic function into an unfold. The unfold generates a
--   singleton stream.
--   
--   <i>Since: 0.8.0</i>
functionM :: Applicative m => (a -> m b) -> Unfold m a b

-- | Generates an infinite stream repeating the seed.
--   
--   <i>Since: 0.8.0</i>
repeatM :: Monad m => Unfold m (m a) a

-- | Generates a stream replicating the seed <tt>n</tt> times.
--   
--   <i>Since: 0.8.0</i>
replicateM :: Monad m => Int -> Unfold m (m a) a

-- | Generates an infinite stream starting with the given seed and applying
--   the given function repeatedly.
--   
--   <i>Since: 0.8.0</i>
iterateM :: Monad m => (a -> m a) -> Unfold m (m a) a

-- | Convert a list of pure values to a <a>Stream</a>
--   
--   <i>Since: 0.8.0</i>
fromList :: Monad m => Unfold m [a] a

-- | Convert a list of monadic values to a <a>Stream</a>
--   
--   <i>Since: 0.8.0</i>
fromListM :: Monad m => Unfold m [m a] a

-- | Convert a stream into an <a>Unfold</a>. Note that a stream converted
--   to an <a>Unfold</a> may not be as efficient as an <a>Unfold</a> in
--   some situations.
--   
--   <i>Since: 0.8.0</i>
fromStream :: (IsStream t, Monad m) => Unfold m (t m a) a

-- | Map a function on the input argument of the <a>Unfold</a>.
--   
--   <pre>
--   &gt;&gt;&gt; u = Unfold.lmap (fmap (+1)) Unfold.fromList
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..5]
--   [2,3,4,5,6]
--   </pre>
--   
--   <pre>
--   lmap f = Unfold.many (Unfold.function f)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
lmap :: (a -> c) -> Unfold m c b -> Unfold m a b

-- | Map an action on the input argument of the <a>Unfold</a>.
--   
--   <pre>
--   lmapM f = Unfold.many (Unfold.functionM f)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
lmapM :: Monad m => (a -> m c) -> Unfold m c b -> Unfold m a b

-- | Apply a monadic function to each element of the stream and replace it
--   with the output of the resulting action.
--   
--   <i>Since: 0.8.0</i>
mapM :: Monad m => (b -> m c) -> Unfold m a b -> Unfold m a c

-- | Same as <a>takeWhile</a> but with a monadic predicate.
--   
--   <i>Since: 0.8.0</i>
takeWhileM :: Monad m => (b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | End the stream generated by the <a>Unfold</a> as soon as the predicate
--   fails on an element.
--   
--   <i>Since: 0.8.0</i>
takeWhile :: Monad m => (b -> Bool) -> Unfold m a b -> Unfold m a b

-- | <pre>
--   &gt;&gt;&gt; u = Unfold.take 2 Unfold.fromList
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..100]
--   [1,2]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
take :: Monad m => Int -> Unfold m a b -> Unfold m a b

-- | Include only those elements that pass a predicate.
--   
--   <i>Since: 0.8.0</i>
filter :: Monad m => (b -> Bool) -> Unfold m a b -> Unfold m a b

-- | Same as <a>filter</a> but with a monadic predicate.
--   
--   <i>Since: 0.8.0</i>
filterM :: Monad m => (b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | <tt>drop n unf</tt> drops <tt>n</tt> elements from the stream
--   generated by <tt>unf</tt>.
--   
--   <i>Since: 0.8.0</i>
drop :: Monad m => Int -> Unfold m a b -> Unfold m a b

-- | Similar to <a>dropWhileM</a> but with a pure condition function.
--   
--   <i>Since: 0.8.0</i>
dropWhile :: Monad m => (b -> Bool) -> Unfold m a b -> Unfold m a b

-- | <tt>dropWhileM f unf</tt> drops elements from the stream generated by
--   <tt>unf</tt> while the condition holds true. The condition function
--   <tt>f</tt> is <i>monadic</i> in nature.
--   
--   <i>Since: 0.8.0</i>
dropWhileM :: Monad m => (b -> m Bool) -> Unfold m a b -> Unfold m a b

-- | Like <a>zipWithM</a> but with a pure zip function.
--   
--   <pre>
--   &gt;&gt;&gt; square = fmap (\x -&gt; x * x) Unfold.fromList
--   
--   &gt;&gt;&gt; cube = fmap (\x -&gt; x * x * x) Unfold.fromList
--   
--   &gt;&gt;&gt; u = Unfold.zipWith (,) square cube
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u [1..5]
--   [(1,1),(4,8),(9,27),(16,64),(25,125)]
--   </pre>
--   
--   <pre>
--   zipWith f = zipWithM (\a b -&gt; return $ f a b)
--   </pre>
--   
--   <i>Since: 0.8.0</i>
zipWith :: Monad m => (b -> c -> d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | Like <a>crossWithM</a> but uses a pure combining function.
--   
--   <pre>
--   crossWith f = crossWithM (\b c -&gt; return $ f b c)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; u1 = Unfold.lmap fst Unfold.fromList
--   
--   &gt;&gt;&gt; u2 = Unfold.lmap snd Unfold.fromList
--   
--   &gt;&gt;&gt; u = Unfold.crossWith (,) u1 u2
--   
--   &gt;&gt;&gt; Unfold.fold Fold.toList u ([1,2,3], [4,5,6])
--   [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)]
--   </pre>
--   
--   <i>Since: 0.8.0</i>
crossWith :: Monad m => (b -> c -> d) -> Unfold m a b -> Unfold m a c -> Unfold m a d

-- | Apply the second unfold to each output element of the first unfold and
--   flatten the output in a single stream.
--   
--   <i>Since: 0.8.0</i>
many :: Monad m => Unfold m a b -> Unfold m b c -> Unfold m a c


-- | The functions defined in this module should be rarely needed for
--   direct use, try to use the operations from the <a>Enumerable</a> type
--   class instances instead.
--   
--   This module provides an <a>Enumerable</a> type class to enumerate
--   <a>Enum</a> types into a stream. The operations in this type class
--   correspond to similar perations in the <a>Enum</a> type class, the
--   only difference is that they produce a stream instead of a list. These
--   operations cannot be defined generically based on the <a>Enum</a> type
--   class. We provide instances for commonly used types. If instances for
--   other types are needed convenience functions defined in this module
--   can be used to define them. Alternatively, these functions can be used
--   directly.
module Streamly.Internal.Data.Stream.IsStream.Enumeration

-- | Types that can be enumerated as a stream. The operations in this type
--   class are equivalent to those in the <a>Enum</a> type class, except
--   that these generate a stream instead of a list. Use the functions in
--   <a>Streamly.Internal.Data.Stream.Enumeration</a> module to define new
--   instances.
class Enum a => Enumerable a

-- | <tt>enumerateFrom from</tt> generates a stream starting with the
--   element <tt>from</tt>, enumerating up to <a>maxBound</a> when the type
--   is <a>Bounded</a> or generating an infinite stream when the type is
--   not <a>Bounded</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFrom (0 :: Int)
--   [0,1,2,3]
--   </pre>
--   
--   For <a>Fractional</a> types, enumeration is numerically stable.
--   However, no overflow or underflow checks are performed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFrom 1.1
--   [1.1,2.1,3.1,4.1]
--   </pre>
enumerateFrom :: (Enumerable a, IsStream t, Monad m) => a -> t m a

-- | Generate a finite stream starting with the element <tt>from</tt>,
--   enumerating the type up to the value <tt>to</tt>. If <tt>to</tt> is
--   smaller than <tt>from</tt> then an empty stream is returned.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 0 4
--   [0,1,2,3,4]
--   </pre>
--   
--   For <a>Fractional</a> types, the last element is equal to the
--   specified <tt>to</tt> value after rounding to the nearest integral
--   value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 1.1 4
--   [1.1,2.1,3.1,4.1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 1.1 4.6
--   [1.1,2.1,3.1,4.1,5.1]
--   </pre>
enumerateFromTo :: (Enumerable a, IsStream t, Monad m) => a -> a -> t m a

-- | <tt>enumerateFromThen from then</tt> generates a stream whose first
--   element is <tt>from</tt>, the second element is <tt>then</tt> and the
--   successive elements are in increments of <tt>then - from</tt>.
--   Enumeration can occur downwards or upwards depending on whether
--   <tt>then</tt> comes before or after <tt>from</tt>. For <a>Bounded</a>
--   types the stream ends when <a>maxBound</a> is reached, for unbounded
--   types it keeps enumerating infinitely.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThen 0 2
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThen 0 (-2)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThen :: (Enumerable a, IsStream t, Monad m) => a -> a -> t m a

-- | <tt>enumerateFromThenTo from then to</tt> generates a finite stream
--   whose first element is <tt>from</tt>, the second element is
--   <tt>then</tt> and the successive elements are in increments of
--   <tt>then - from</tt> up to <tt>to</tt>. Enumeration can occur
--   downwards or upwards depending on whether <tt>then</tt> comes before
--   or after <tt>from</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenTo 0 2 6
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenTo 0 (-2) (-6)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThenTo :: (Enumerable a, IsStream t, Monad m) => a -> a -> a -> t m a

-- | <pre>
--   enumerate = enumerateFrom minBound
--   </pre>
--   
--   Enumerate a <a>Bounded</a> type from its <a>minBound</a> to
--   <a>maxBound</a>
enumerate :: (IsStream t, Monad m, Bounded a, Enumerable a) => t m a

-- | <pre>
--   enumerateTo = enumerateFromTo minBound
--   </pre>
--   
--   Enumerate a <a>Bounded</a> type from its <a>minBound</a> to specified
--   value.
enumerateTo :: (IsStream t, Monad m, Bounded a, Enumerable a) => a -> t m a

-- | <pre>
--   enumerateFromBounded = enumerateFromTo from maxBound
--   </pre>
--   
--   <a>enumerateFrom</a> for <a>Bounded</a> <a>Enum</a> types.
enumerateFromBounded :: (IsStream t, Monad m, Enumerable a, Bounded a) => a -> t m a

-- | <a>enumerateFromTo</a> for <a>Enum</a> types not larger than
--   <a>Int</a>.
enumerateFromToSmall :: (IsStream t, Monad m, Enum a) => a -> a -> t m a

-- | <a>enumerateFromThenTo</a> for <a>Enum</a> types not larger than
--   <a>Int</a>.
enumerateFromThenToSmall :: (IsStream t, Monad m, Enum a) => a -> a -> a -> t m a

-- | <a>enumerateFromThen</a> for <a>Enum</a> types not larger than
--   <a>Int</a>.
--   
--   Note: We convert the <a>Enum</a> to <a>Int</a> and enumerate the
--   <a>Int</a>. If a type is bounded but does not have a <a>Bounded</a>
--   instance then we can go on enumerating it beyond the legal values of
--   the type, resulting in the failure of <a>toEnum</a> when converting
--   back to <a>Enum</a>. Therefore we require a <a>Bounded</a> instance
--   for this function to be safely used.
enumerateFromThenSmallBounded :: (IsStream t, Monad m, Enumerable a, Bounded a) => a -> a -> t m a

-- | Enumerate an <a>Integral</a> type. <tt>enumerateFromIntegral from</tt>
--   generates a stream whose first element is <tt>from</tt> and the
--   successive elements are in increments of <tt>1</tt>. The stream is
--   bounded by the size of the <a>Integral</a> type.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromIntegral (0 :: Int)
--   [0,1,2,3]
--   </pre>
enumerateFromIntegral :: (IsStream t, Monad m, Integral a, Bounded a) => a -> t m a

-- | Enumerate an <a>Integral</a> type in steps.
--   <tt>enumerateFromThenIntegral from then</tt> generates a stream whose
--   first element is <tt>from</tt>, the second element is <tt>then</tt>
--   and the successive elements are in increments of <tt>then - from</tt>.
--   The stream is bounded by the size of the <a>Integral</a> type.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThenIntegral (0 :: Int) 2
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThenIntegral (0 :: Int) (-2)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThenIntegral :: (IsStream t, Monad m, Integral a, Bounded a) => a -> a -> t m a

-- | Enumerate an <a>Integral</a> type up to a given limit.
--   <tt>enumerateFromToIntegral from to</tt> generates a finite stream
--   whose first element is <tt>from</tt> and successive elements are in
--   increments of <tt>1</tt> up to <tt>to</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromToIntegral 0 4
--   [0,1,2,3,4]
--   </pre>
enumerateFromToIntegral :: (IsStream t, Monad m, Integral a) => a -> a -> t m a

-- | Enumerate an <a>Integral</a> type in steps up to a given limit.
--   <tt>enumerateFromThenToIntegral from then to</tt> generates a finite
--   stream whose first element is <tt>from</tt>, the second element is
--   <tt>then</tt> and the successive elements are in increments of
--   <tt>then - from</tt> up to <tt>to</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenToIntegral 0 2 6
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenToIntegral 0 (-2) (-6)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThenToIntegral :: (IsStream t, Monad m, Integral a) => a -> a -> a -> t m a

-- | <tt>enumerateFromStepIntegral from step</tt> generates an infinite
--   stream whose first element is <tt>from</tt> and the successive
--   elements are in increments of <tt>step</tt>.
--   
--   CAUTION: This function is not safe for finite integral types. It does
--   not check for overflow, underflow or bounds.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromStepIntegral 0 2
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 3 $ Stream.enumerateFromStepIntegral 0 (-2)
--   [0,-2,-4]
--   </pre>
enumerateFromStepIntegral :: (IsStream t, Monad m, Integral a) => a -> a -> t m a

-- | Numerically stable enumeration from a <a>Fractional</a> number in
--   steps of size <tt>1</tt>. <tt>enumerateFromFractional from</tt>
--   generates a stream whose first element is <tt>from</tt> and the
--   successive elements are in increments of <tt>1</tt>. No overflow or
--   underflow checks are performed.
--   
--   This is the equivalent to <a>enumFrom</a> for <a>Fractional</a> types.
--   For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromFractional 1.1
--   [1.1,2.1,3.1,4.1]
--   </pre>
enumerateFromFractional :: (IsStream t, Monad m, Fractional a) => a -> t m a

-- | Numerically stable enumeration from a <a>Fractional</a> number to a
--   given limit. <tt>enumerateFromToFractional from to</tt> generates a
--   finite stream whose first element is <tt>from</tt> and successive
--   elements are in increments of <tt>1</tt> up to <tt>to</tt>.
--   
--   This is the equivalent of <a>enumFromTo</a> for <a>Fractional</a>
--   types. For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromToFractional 1.1 4
--   [1.1,2.1,3.1,4.1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromToFractional 1.1 4.6
--   [1.1,2.1,3.1,4.1,5.1]
--   </pre>
--   
--   Notice that the last element is equal to the specified <tt>to</tt>
--   value after rounding to the nearest integer.
enumerateFromToFractional :: (IsStream t, Monad m, Fractional a, Ord a) => a -> a -> t m a

-- | Numerically stable enumeration from a <a>Fractional</a> number in
--   steps. <tt>enumerateFromThenFractional from then</tt> generates a
--   stream whose first element is <tt>from</tt>, the second element is
--   <tt>then</tt> and the successive elements are in increments of
--   <tt>then - from</tt>. No overflow or underflow checks are performed.
--   
--   This is the equivalent of <a>enumFromThen</a> for <a>Fractional</a>
--   types. For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThenFractional 1.1 2.1
--   [1.1,2.1,3.1,4.1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThenFractional 1.1 (-2.1)
--   [1.1,-2.1,-5.300000000000001,-8.500000000000002]
--   </pre>
enumerateFromThenFractional :: (IsStream t, Monad m, Fractional a) => a -> a -> t m a

-- | Numerically stable enumeration from a <a>Fractional</a> number in
--   steps up to a given limit. <tt>enumerateFromThenToFractional from then
--   to</tt> generates a finite stream whose first element is
--   <tt>from</tt>, the second element is <tt>then</tt> and the successive
--   elements are in increments of <tt>then - from</tt> up to <tt>to</tt>.
--   
--   This is the equivalent of <a>enumFromThenTo</a> for <a>Fractional</a>
--   types. For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenToFractional 0.1 2 6
--   [0.1,2.0,3.9,5.799999999999999]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenToFractional 0.1 (-2) (-6)
--   [0.1,-2.0,-4.1000000000000005,-6.200000000000001]
--   </pre>
enumerateFromThenToFractional :: (IsStream t, Monad m, Fractional a, Ord a) => a -> a -> a -> t m a
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable ()
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Types.Bool
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Types.Ordering
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Types.Char
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Types.Int
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Int.Int8
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Int.Int16
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Int.Int32
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Int.Int64
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Types.Word
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Word.Word8
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Word.Word16
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Word.Word32
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Word.Word64
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Num.Integer.Integer
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Num.Natural.Natural
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Types.Float
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable GHC.Types.Double
instance Data.Fixed.HasResolution a => Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable (Data.Fixed.Fixed a)
instance GHC.Real.Integral a => Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable (GHC.Real.Ratio a)
instance Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable a => Streamly.Internal.Data.Stream.IsStream.Enumeration.Enumerable (Data.Functor.Identity.Identity a)


module Streamly.Internal.Data.Stream.IsStream.Combinators

-- | Specify the maximum number of threads that can be spawned concurrently
--   for any concurrent combinator in a stream. A value of 0 resets the
--   thread limit to default, a negative value means there is no limit. The
--   default value is 1500. <a>maxThreads</a> does not affect
--   <tt>ParallelT</tt> streams as they can use unbounded number of
--   threads.
--   
--   When the actions in a stream are IO bound, having blocking IO calls,
--   this option can be used to control the maximum number of in-flight IO
--   requests. When the actions are CPU bound this option can be used to
--   control the amount of CPU used by the stream.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxThreads :: IsStream t => Int -> t m a -> t m a

-- | Specify the maximum size of the buffer for storing the results from
--   concurrent computations. If the buffer becomes full we stop spawning
--   more concurrent tasks until there is space in the buffer. A value of 0
--   resets the buffer size to default, a negative value means there is no
--   limit. The default value is 1500.
--   
--   CAUTION! using an unbounded <a>maxBuffer</a> value (i.e. a negative
--   value) coupled with an unbounded <a>maxThreads</a> value is a recipe
--   for disaster in presence of infinite streams, or very large streams.
--   Especially, it must not be used when <a>pure</a> is used in
--   <tt>ZipAsyncM</tt> streams as <a>pure</a> in applicative zip streams
--   generates an infinite stream causing unbounded concurrent generation
--   with no limit on the buffer or threads.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxBuffer :: IsStream t => Int -> t m a -> t m a
maxYields :: IsStream t => Maybe Int64 -> t m a -> t m a

-- | Specify the pull rate of a stream. A <a>Nothing</a> value resets the
--   rate to default which is unlimited. When the rate is specified,
--   concurrent production may be ramped up or down automatically to
--   achieve the specified yield rate. The specific behavior for different
--   styles of <a>Rate</a> specifications is documented under <a>Rate</a>.
--   The effective maximum production rate achieved by a stream is governed
--   by:
--   
--   <ul>
--   <li>The <a>maxThreads</a> limit</li>
--   <li>The <a>maxBuffer</a> limit</li>
--   <li>The maximum rate that the stream producer can achieve</li>
--   <li>The maximum rate that the stream consumer can achieve</li>
--   </ul>
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
rate :: IsStream t => Maybe Rate -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r (2*r) maxBound)</tt>
--   
--   Specifies the average production rate of a stream in number of yields
--   per second (i.e. <tt>Hertz</tt>). Concurrent production is ramped up
--   or down automatically to achieve the specified average yield rate. The
--   rate can go down to half of the specified rate on the lower side and
--   double of the specified rate on the higher side.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
avgRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r (2*r) maxBound)</tt>
--   
--   Specifies the minimum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go below the
--   specified rate, even though it may possibly go above it at times, the
--   upper limit is double of the specified rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
minRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r r maxBound)</tt>
--   
--   Specifies the maximum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go above the
--   specified rate, even though it may possibly go below it at times, the
--   lower limit is half of the specified rate. This can be useful in
--   applications where certain resource usage must not be allowed to go
--   beyond certain limits.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
maxRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r r 0)</tt>
--   
--   Specifies a constant yield rate. If for some reason the actual rate
--   goes above or below the specified rate we do not try to recover it by
--   increasing or decreasing the rate in future. This can be useful in
--   applications like graphics frame refresh where we need to maintain a
--   constant refresh rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
constRate :: IsStream t => Double -> t m a -> t m a

-- | Print debug information about an SVar when the stream ends
--   
--   <i>Pre-release</i>
inspectMode :: IsStream t => t m a -> t m a
printState :: MonadIO m => State Stream m a -> m ()


-- | Lists are just a special case of monadic streams. The stream type
--   <tt>SerialT Identity a</tt> can be used as a replacement for
--   <tt>[a]</tt>. The <a>List</a> type in this module is just a newtype
--   wrapper around <tt>SerialT Identity</tt> for better type inference
--   when using the <tt>OverloadedLists</tt> GHC extension. <tt>List a</tt>
--   provides better performance compared to <tt>[a]</tt>. Standard list,
--   string and list comprehension syntax can be used with the <a>List</a>
--   type by enabling <tt>OverloadedLists</tt>, <tt>OverloadedStrings</tt>
--   and <tt>MonadComprehensions</tt> GHC extensions. There would be a
--   slight difference in the <a>Show</a> and <a>Read</a> strings of
--   streamly list as compared to regular lists.
--   
--   Conversion to stream types is free, any stream combinator can be used
--   on lists by converting them to streams. However, for convenience, this
--   module provides combinators that work directly on the <a>List</a>
--   type.
--   
--   <pre>
--   List $ S.map (+ 1) $ toSerial (1 `Cons` Nil)
--   </pre>
--   
--   To convert a <a>List</a> to regular lists, you can use any of the
--   following:
--   
--   <ul>
--   <li><tt>toList . toSerial</tt> and <tt>toSerial . fromList</tt></li>
--   <li><a>toList</a> from <a>Data.Foldable</a></li>
--   <li><a>toList</a> and <a>fromList</a> from <a>IsList</a> in
--   <a>GHC.Exts</a></li>
--   </ul>
--   
--   If you have made use of <a>Nil</a> and <a>Cons</a> constructors in the
--   code and you want to replace streamly lists with standard lists, all
--   you need to do is import these definitions:
--   
--   <pre>
--   type List = []
--   pattern Nil &lt;- [] where Nil = []
--   pattern Cons x xs = x : xs
--   infixr 5 <a>Cons</a>
--   {-# COMPLETE Cons, Nil #-}
--   </pre>
--   
--   See <a>src/docs/streamly-vs-lists.md</a> for more details and
--   <a>src/test/PureStreams.hs</a> for comprehensive usage examples.
module Streamly.Internal.Data.List

-- | <tt>List a</tt> is a replacement for <tt>[a]</tt>.
newtype List a
List :: SerialT Identity a -> List a
[toSerial] :: List a -> SerialT Identity a

-- | An empty list constructor and pattern that matches an empty
--   <a>List</a>. Corresponds to '[]' for Haskell lists.
pattern Nil :: List a

-- | A list constructor and pattern that deconstructs a <a>List</a> into
--   its head and tail. Corresponds to <tt>:</tt> for Haskell lists.
pattern Cons :: a -> List a -> List a
infixr 5 `Cons`

-- | Just like <a>List</a> except that it has a zipping <a>Applicative</a>
--   instance and no <a>Monad</a> instance.
newtype ZipList a
ZipList :: ZipSerialM Identity a -> ZipList a
[toZipSerial] :: ZipList a -> ZipSerialM Identity a

-- | Convert a <a>ZipList</a> to a regular <a>List</a>
fromZipList :: ZipList a -> List a

-- | Convert a regular <a>List</a> to a <a>ZipList</a>
toZipList :: List a -> ZipList a
instance GHC.Base.Monad Streamly.Internal.Data.List.List
instance Data.Traversable.Traversable Streamly.Internal.Data.List.List
instance GHC.Base.Applicative Streamly.Internal.Data.List.List
instance Data.Foldable.Foldable Streamly.Internal.Data.List.List
instance GHC.Base.Functor Streamly.Internal.Data.List.List
instance GHC.Base.Monoid (Streamly.Internal.Data.List.List a)
instance GHC.Base.Semigroup (Streamly.Internal.Data.List.List a)
instance Control.DeepSeq.NFData1 Streamly.Internal.Data.List.List
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Streamly.Internal.Data.List.List a)
instance GHC.Classes.Ord a => GHC.Classes.Ord (Streamly.Internal.Data.List.List a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Streamly.Internal.Data.List.List a)
instance GHC.Read.Read a => GHC.Read.Read (Streamly.Internal.Data.List.List a)
instance GHC.Show.Show a => GHC.Show.Show (Streamly.Internal.Data.List.List a)
instance Data.Traversable.Traversable Streamly.Internal.Data.List.ZipList
instance GHC.Base.Applicative Streamly.Internal.Data.List.ZipList
instance Data.Foldable.Foldable Streamly.Internal.Data.List.ZipList
instance GHC.Base.Functor Streamly.Internal.Data.List.ZipList
instance GHC.Base.Monoid (Streamly.Internal.Data.List.ZipList a)
instance GHC.Base.Semigroup (Streamly.Internal.Data.List.ZipList a)
instance Control.DeepSeq.NFData1 Streamly.Internal.Data.List.ZipList
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Streamly.Internal.Data.List.ZipList a)
instance GHC.Classes.Ord a => GHC.Classes.Ord (Streamly.Internal.Data.List.ZipList a)
instance GHC.Classes.Eq a => GHC.Classes.Eq (Streamly.Internal.Data.List.ZipList a)
instance GHC.Read.Read a => GHC.Read.Read (Streamly.Internal.Data.List.ZipList a)
instance GHC.Show.Show a => GHC.Show.Show (Streamly.Internal.Data.List.ZipList a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.List.ZipList a)
instance GHC.Exts.IsList (Streamly.Internal.Data.List.ZipList a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.List.List a)
instance GHC.Exts.IsList (Streamly.Internal.Data.List.List a)


module Streamly.Internal.Data.Stream.IsStream.Lift

-- | Transform the inner monad of a stream using a natural transformation.
--   
--   <i> Internal</i>
hoist :: (Monad m, Monad n) => (forall x. m x -> n x) -> SerialT m a -> SerialT n a

-- | Generalize the inner monad of the stream from <a>Identity</a> to any
--   monad.
--   
--   <i> Internal</i>
generally :: (IsStream t, Monad m) => t Identity a -> t m a

-- | Lift the inner monad <tt>m</tt> of a stream <tt>t m a</tt> to <tt>tr
--   m</tt> using the monad transformer <tt>tr</tt>.
liftInner :: (Monad m, IsStream t, MonadTrans tr, Monad (tr m)) => t m a -> t (tr m) a

-- | Run a stream transformation using a given environment.
--   
--   See also: <a>map</a>
--   
--   <i> Internal</i>
usingReaderT :: (Monad m, IsStream t) => m r -> (t (ReaderT r m) a -> t (ReaderT r m) a) -> t m a -> t m a

-- | Evaluate the inner monad of a stream as <a>ReaderT</a>.
runReaderT :: (IsStream t, Monad m) => m s -> t (ReaderT s m) a -> t m a

-- | Evaluate the inner monad of a stream as <a>StateT</a>.
--   
--   This is supported only for <a>SerialT</a> as concurrent state updation
--   may not be safe.
--   
--   <pre>
--   evalStateT s = Stream.map snd . Stream.runStateT s
--   </pre>
--   
--   <i> Internal</i>
evalStateT :: Monad m => m s -> SerialT (StateT s m) a -> SerialT m a

-- | Run a stateful (StateT) stream transformation using a given state.
--   
--   This is supported only for <a>SerialT</a> as concurrent state updation
--   may not be safe.
--   
--   <pre>
--   usingStateT s f = evalStateT s . f . liftInner
--   </pre>
--   
--   See also: <tt>scanl'</tt>
--   
--   <i> Internal</i>
usingStateT :: Monad m => m s -> (SerialT (StateT s m) a -> SerialT (StateT s m) a) -> SerialT m a -> SerialT m a

-- | Evaluate the inner monad of a stream as <a>StateT</a> and emit the
--   resulting state and value pair after each step.
--   
--   This is supported only for <a>SerialT</a> as concurrent state updation
--   may not be safe.
runStateT :: Monad m => m s -> SerialT (StateT s m) a -> SerialT m (s, a)


module Streamly.Internal.Data.Stream.IsStream.Exception

-- | Run the action <tt>m b</tt> before the stream yields its first
--   element.
--   
--   Same as the following but more efficient due to fusion:
--   
--   <pre>
--   &gt;&gt;&gt; before action xs = Stream.nilM action &lt;&gt; xs
--   
--   &gt;&gt;&gt; before action xs = Stream.concatMap (const xs) (Stream.fromEffect action)
--   </pre>
before :: (IsStream t, Monad m) => m b -> t m a -> t m a

-- | Like <a>after</a>, with following differences:
--   
--   <ul>
--   <li>action <tt>m b</tt> won't run if the stream is garbage collected
--   after partial evaluation.</li>
--   <li>Monad <tt>m</tt> does not require any other constraints.</li>
--   <li>has slightly better performance than <a>after</a>.</li>
--   </ul>
--   
--   Same as the following, but with stream fusion:
--   
--   <pre>
--   after_ action xs = xs &lt;&gt; 'nilM' action
--   </pre>
--   
--   <i>Pre-release</i>
after_ :: (IsStream t, Monad m) => m b -> t m a -> t m a

-- | Run the action <tt>m b</tt> whenever the stream <tt>t m a</tt> stops
--   normally, or if it is garbage collected after a partial lazy
--   evaluation.
--   
--   The semantics of the action <tt>m b</tt> are similar to the semantics
--   of cleanup action in <a>bracket</a>.
--   
--   <i>See also <a>after_</a></i>
after :: (IsStream t, MonadIO m, MonadBaseControl IO m) => m b -> t m a -> t m a

-- | Like <a>bracket</a> but with following differences:
--   
--   <ul>
--   <li>alloc action <tt>m b</tt> runs with async exceptions enabled</li>
--   <li>cleanup action <tt>b -&gt; m c</tt> won't run if the stream is
--   garbage collected after partial evaluation.</li>
--   <li>does not require a <a>MonadAsync</a> constraint.</li>
--   <li>has slightly better performance than <a>bracket</a>.</li>
--   </ul>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
bracket_ :: (IsStream t, MonadCatch m) => m b -> (b -> m c) -> (b -> t m a) -> t m a

-- | Run the alloc action <tt>m b</tt> with async exceptions disabled but
--   keeping blocking operations interruptible (see <a>mask</a>). Use the
--   output <tt>b</tt> as input to <tt>b -&gt; t m a</tt> to generate an
--   output stream.
--   
--   <tt>b</tt> is usually a resource under the state of monad <tt>m</tt>,
--   e.g. a file handle, that requires a cleanup after use. The cleanup
--   action <tt>b -&gt; m c</tt>, runs whenever the stream ends normally,
--   due to a sync or async exception or if it gets garbage collected after
--   a partial lazy evaluation.
--   
--   <a>bracket</a> only guarantees that the cleanup action runs, and it
--   runs with async exceptions enabled. The action must ensure that it can
--   successfully cleanup the resource in the face of sync or async
--   exceptions.
--   
--   When the stream ends normally or on a sync exception, cleanup action
--   runs immediately in the current thread context, whereas in other cases
--   it runs in the GC context, therefore, cleanup may be delayed until the
--   GC gets to run.
--   
--   <i>See also: <a>bracket_</a></i>
--   
--   <i>Inhibits stream fusion</i>
bracket :: (IsStream t, MonadAsync m, MonadCatch m) => m b -> (b -> m c) -> (b -> t m a) -> t m a

-- | Like <a>bracket</a> but can use separate cleanup actions depending on
--   the mode of termination. <tt>bracket' before onStop onGC onException
--   action</tt> runs <tt>action</tt> using the result of <tt>before</tt>.
--   If the stream stops, <tt>onStop</tt> action is executed, if the stream
--   is abandoned <tt>onGC</tt> is executed, if the stream encounters an
--   exception <tt>onException</tt> is executed.
--   
--   <i>Pre-release</i>
bracket' :: (IsStream t, MonadAsync m, MonadCatch m) => m b -> (b -> m c) -> (b -> m d) -> (b -> m e) -> (b -> t m a) -> t m a

-- | Run the action <tt>m b</tt> if the stream aborts due to an exception.
--   The exception is not caught, simply rethrown.
--   
--   <i>Inhibits stream fusion</i>
onException :: (IsStream t, MonadCatch m) => m b -> t m a -> t m a

-- | Like <a>finally</a> with following differences:
--   
--   <ul>
--   <li>action <tt>m b</tt> won't run if the stream is garbage collected
--   after partial evaluation.</li>
--   <li>does not require a <a>MonadAsync</a> constraint.</li>
--   <li>has slightly better performance than <a>finally</a>.</li>
--   </ul>
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
finally_ :: (IsStream t, MonadCatch m) => m b -> t m a -> t m a

-- | Run the action <tt>m b</tt> whenever the stream <tt>t m a</tt> stops
--   normally, aborts due to an exception or if it is garbage collected
--   after a partial lazy evaluation.
--   
--   The semantics of running the action <tt>m b</tt> are similar to the
--   cleanup action semantics described in <a>bracket</a>.
--   
--   <pre>
--   finally release = bracket (return ()) (const release)
--   </pre>
--   
--   <i>See also <a>finally_</a></i>
--   
--   <i>Inhibits stream fusion</i>
finally :: (IsStream t, MonadAsync m, MonadCatch m) => m b -> t m a -> t m a

-- | Like <a>handle</a> but the exception handler is also provided with the
--   stream that generated the exception as input. The exception handler
--   can thus re-evaluate the stream to retry the action that failed. The
--   exception handler can again call <a>ghandle</a> on it to retry the
--   action multiple times.
--   
--   This is highly experimental. In a stream of actions we can map the
--   stream with a retry combinator to retry each action on failure.
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Pre-release</i>
ghandle :: (IsStream t, MonadCatch m, Exception e) => (e -> t m a -> t m a) -> t m a -> t m a

-- | When evaluating a stream if an exception occurs, stream evaluation
--   aborts and the specified exception handler is run with the exception
--   as argument.
--   
--   <i>Inhibits stream fusion</i>
handle :: (IsStream t, MonadCatch m, Exception e) => (e -> t m a) -> t m a -> t m a

-- | <tt>retry</tt> takes 3 arguments
--   
--   <ol>
--   <li>A map <tt>m</tt> whose keys are exceptions and values are the
--   number of times to retry the action given that the exception
--   occurs.</li>
--   <li>A handler <tt>han</tt> that decides how to handle an exception
--   when the exception cannot be retried.</li>
--   <li>The stream itself that we want to run this mechanism on.</li>
--   </ol>
--   
--   When evaluating a stream if an exception occurs,
--   
--   <ol>
--   <li>The stream evaluation aborts</li>
--   <li>The exception is looked up in <tt>m</tt></li>
--   </ol>
--   
--   a. If the exception exists and the mapped value is &gt; 0 then,
--   
--   i. The value is decreased by 1.
--   
--   ii. The stream is resumed from where the exception was called,
--   retrying the action.
--   
--   b. If the exception exists and the mapped value is == 0 then the
--   stream evaluation stops.
--   
--   c. If the exception does not exist then we handle the exception using
--   <tt>han</tt>.
--   
--   <i>Internal</i>
retry :: (IsStream t, MonadCatch m, Exception e, Ord e) => Map e Int -> (e -> t m a) -> t m a -> t m a


module Streamly.Internal.Data.SmallArray
data SmallArray a
SmallArray :: SmallArray# a -> SmallArray a
foldl' :: (b -> a -> b) -> b -> SmallArray a -> b
foldr :: (a -> b -> b) -> b -> SmallArray a -> b
length :: SmallArray a -> Int

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>SmallArray</a>.
--   
--   Since we are folding to a <a>SmallArray</a> <tt>n</tt> should be &lt;=
--   128, for larger number of elements use an <tt>Array</tt> from either
--   <a>Streamly.Data.Array</a> or <a>Streamly.Data.Array.Foreign</a>.
writeN :: MonadIO m => Int -> Fold m a (SmallArray a)
toStreamD :: Monad m => SmallArray a -> Stream m a
toStreamDRev :: Monad m => SmallArray a -> Stream m a
toStream :: Monad m => SmallArray a -> SerialT m a
toStreamRev :: Monad m => SmallArray a -> SerialT m a
read :: Monad m => Unfold m (SmallArray a) a

-- | Create a <a>SmallArray</a> from the first <tt>n</tt> elements of a
--   list. The array may hold less than <tt>n</tt> elements if the length
--   of the list &lt;= <tt>n</tt>.
--   
--   It is recommended to use a value of <tt>n</tt> &lt;= 128. For larger
--   sized arrays, use an <tt>Array</tt> from <a>Streamly.Data.Array</a> or
--   <a>Streamly.Data.Array.Foreign</a>
fromListN :: Int -> [a] -> SmallArray a
fromStreamDN :: MonadIO m => Int -> Stream m a -> m (SmallArray a)

-- | Create a <a>SmallArray</a> from the first <tt>n</tt> elements of a
--   stream. The array is allocated to size <tt>n</tt>, if the stream
--   terminates before <tt>n</tt> elements then the array may hold less
--   than <tt>n</tt> elements.
--   
--   For optimal performance use this with <tt>n</tt> &lt;= 128.
fromStreamN :: MonadIO m => Int -> SerialT m a -> m (SmallArray a)
streamFold :: Monad m => (SerialT m a -> m b) -> SmallArray a -> m b
fold :: Monad m => Fold m a b -> SmallArray a -> m b
instance Control.DeepSeq.NFData a => Control.DeepSeq.NFData (Streamly.Internal.Data.SmallArray.Type.SmallArray a)


-- | Combinators to efficiently manipulate streams of mutable arrays.
module Streamly.Internal.Data.Array.Stream.Mut.Foreign

-- | <tt>arraysOf n stream</tt> groups the elements in the input stream
--   into arrays of <tt>n</tt> elements each.
--   
--   Same as the following but may be more efficient:
--   
--   <pre>
--   arraysOf n = Stream.foldMany (MArray.writeN n)
--   </pre>
--   
--   <i>Pre-release</i>
arraysOf :: (IsStream t, MonadIO m, Storable a) => Int -> t m a -> t m (Array a)

-- | This mutates the first array (if it has space) to append values from
--   the second one. This would work for immutable arrays as well because
--   an immutable array never has space so a new array is allocated instead
--   of mutating it.
--   
--   | Coalesce adjacent arrays in incoming stream to form bigger arrays of
--   a maximum specified size. Note that if a single array is bigger than
--   the specified size we do not split it to fit. When we coalesce
--   multiple arrays if the size would exceed the specified size we do not
--   coalesce therefore the actual array size may be less than the
--   specified chunk size.
packArraysChunksOf :: (MonadIO m, Storable a) => Int -> Stream m (Array a) -> Stream m (Array a)
data SpliceState s arr
SpliceInitial :: s -> SpliceState s arr
SpliceBuffering :: s -> arr -> SpliceState s arr
SpliceYielding :: arr -> SpliceState s arr -> SpliceState s arr
SpliceFinish :: SpliceState s arr
lpackArraysChunksOf :: (MonadIO m, Storable a) => Int -> Fold m (Array a) () -> Fold m (Array a) ()

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes.
--   
--   <i>Internal</i>
compact :: (MonadIO m, Storable a) => Int -> SerialT m (Array a) -> SerialT m (Array a)

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes.
--   
--   <i>Internal</i>
compactLE :: MonadIO m => Int -> SerialT m (Array a) -> SerialT m (Array a)

-- | Like <a>compactLE</a> but generates arrays of exactly equal to the
--   size specified except for the last array in the stream which could be
--   shorter.
--   
--   <i>Unimplemented</i>
compactEQ :: Int -> SerialT m (Array a) -> SerialT m (Array a)

-- | Like <a>compactLE</a> but generates arrays of size greater than or
--   equal to the specified except for the last array in the stream which
--   could be shorter.
--   
--   <i>Unimplemented</i>
compactGE :: Int -> SerialT m (Array a) -> SerialT m (Array a)


module Streamly.Internal.Data.Array.Prim.Pinned.Mut.Type
data Array a
Array :: MutableByteArray# RealWorld -> Array a

-- | Allocate an array that is pinned and can hold <tt>count</tt> items.
--   The memory of the array is uninitialized.
--   
--   Note that this is internal routine, the reference to this array cannot
--   be given out until the array has been written to and frozen.
newArray :: forall m a. (MonadIO m, Prim a) => Int -> m (Array a)

-- | Allocate a new array aligned to the specified alignment and using
--   pinned memory.
newAlignedArray :: forall m a. (MonadIO m, Prim a) => Int -> Int -> m (Array a)
unsafeWriteIndex :: (MonadIO m, Prim a) => Array a -> Int -> a -> m ()
spliceTwo :: (MonadIO m, Prim a) => Array a -> Array a -> m (Array a)

-- | Copy a range of the first array to the specified region in the second
--   array. Both arrays must fully contain the specified ranges, but this
--   is not checked. The regions are allowed to overlap, although this is
--   only possible when the same array is provided as both the source and
--   the destination.
unsafeCopy :: forall m a. (MonadIO m, Prim a) => Array a -> Int -> Array a -> Int -> Int -> m ()
fromListM :: (MonadIO m, Prim a) => [a] -> m (Array a)
fromListNM :: (MonadIO m, Prim a) => Int -> [a] -> m (Array a)
fromStreamDN :: (MonadIO m, Prim a) => Int -> Stream m a -> m (Array a)
fromStreamD :: (MonadIO m, Prim a) => Stream m a -> m (Array a)

-- | <tt>fromStreamArraysOf n stream</tt> groups the input stream into a
--   stream of arrays of size n.
fromStreamDArraysOf :: (MonadIO m, Prim a) => Int -> Stream m a -> Stream m (Array a)

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes. Note that if a single array is bigger
--   than the specified size we do not split it to fit. When we coalesce
--   multiple arrays if the size would exceed the specified size we do not
--   coalesce therefore the actual array size may be less than the
--   specified chunk size.
--   
--   <i>Pre-release</i>
packArraysChunksOf :: (MonadIO m, Prim a) => Int -> Stream m (Array a) -> Stream m (Array a)
lpackArraysChunksOf :: (MonadIO m, Prim a) => Int -> Fold m (Array a) () -> Fold m (Array a) ()
unsafeReadIndex :: (MonadIO m, Prim a) => Array a -> Int -> m a
length :: forall m a. (MonadIO m, Prim a) => Array a -> m Int
byteLength :: MonadIO m => Array a -> m Int

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Pre-release</i>
writeN :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)
data ArrayUnsafe a
ArrayUnsafe :: {-# UNPACK #-} !Array a -> {-# UNPACK #-} !Int -> ArrayUnsafe a

-- | Like <a>writeN</a> but does not check the array bounds when writing.
--   The fold driver must not call the step function more than <tt>n</tt>
--   times otherwise it will corrupt the memory and crash. This function
--   exists mainly because any conditional in the step function blocks
--   fusion causing 10x performance slowdown.
--   
--   <i>Pre-release</i>
writeNUnsafe :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)
writeNAligned :: (MonadIO m, Prim a) => Int -> Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Pre-release</i>
write :: (MonadIO m, Prim a) => Fold m a (Array a)

-- | Resize (pinned) mutable byte array to new specified size (in elem
--   count). The returned array is either the original array resized
--   in-place or, if not possible, a newly allocated (pinned) array (with
--   the original content copied over).
resizeArray :: (MonadIO m, Prim a) => Array a -> Int -> m (Array a)
shrinkArray :: forall m a. (MonadIO m, Prim a) => Array a -> Int -> m ()
touchArray :: Array a -> IO ()
withArrayAsPtr :: Array a -> (Ptr a -> IO b) -> IO b


module Streamly.Internal.Data.Array.Prim.Pinned.Type
data Array a
Array :: ByteArray# -> Int -> Int -> Array a
unsafeFreeze :: (Prim a, MonadIO m) => Array a -> m (Array a)
unsafeFreezeWithShrink :: (Prim a, MonadIO m) => Array a -> Int -> m (Array a)

-- | Default maximum buffer size in bytes, for reading from and writing to
--   IO devices, the value is 32KB minus GHC allocation overhead, which is
--   a few bytes, so that the actual allocation is 32KB.
defaultChunkSize :: Int
nil :: Prim a => Array a

-- | Splice two immutable arrays creating a new immutable array.
spliceTwo :: (MonadIO m, Prim a) => Array a -> Array a -> m (Array a)
fromList :: Prim a => [a] -> Array a
fromListN :: Prim a => Int -> [a] -> Array a
fromStreamDN :: (MonadIO m, Prim a) => Int -> Stream m a -> m (Array a)
fromStreamD :: (MonadIO m, Prim a) => Stream m a -> m (Array a)

-- | <tt>fromStreamArraysOf n stream</tt> groups the input stream into a
--   stream of arrays of size n.
fromStreamDArraysOf :: (MonadIO m, Prim a) => Int -> Stream m a -> Stream m (Array a)
data FlattenState s a
OuterLoop :: s -> FlattenState s a
InnerLoop :: s -> !Array a -> !Int -> !Int -> FlattenState s a
flattenArrays :: (MonadIO m, Prim a) => Stream m (Array a) -> Stream m a
flattenArraysRev :: (MonadIO m, Prim a) => Stream m (Array a) -> Stream m a
data SpliceState s arr1 arr2
SpliceInitial :: s -> SpliceState s arr1 arr2
SpliceBuffering :: s -> arr2 -> SpliceState s arr1 arr2
SpliceYielding :: arr1 -> SpliceState s arr1 arr2 -> SpliceState s arr1 arr2
SpliceFinish :: SpliceState s arr1 arr2

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes. Note that if a single array is bigger
--   than the specified size we do not split it to fit. When we coalesce
--   multiple arrays if the size would exceed the specified size we do not
--   coalesce therefore the actual array size may be less than the
--   specified chunk size.
--   
--   <i>Pre-release</i>
packArraysChunksOf :: forall m a. (MonadIO m, Prim a) => Int -> Stream m (Array a) -> Stream m (Array a)
lpackArraysChunksOf :: forall m a. (MonadIO m, Prim a) => Int -> Fold m (Array a) () -> Fold m (Array a) ()

-- | Split a stream of arrays on a given separator byte, dropping the
--   separator and coalescing all the arrays between two separators into a
--   single array.
--   
--   <i>Pre-release</i>
splitOn :: MonadIO m => Word8 -> Stream m (Array Word8) -> Stream m (Array Word8)
breakOn :: MonadIO m => Word8 -> Array Word8 -> m (Array Word8, Maybe (Array Word8))
unsafeIndex :: Prim a => Array a -> Int -> a
byteLength :: forall a. Prim a => Array a -> Int
length :: Array a -> Int

-- | Strict left-associated fold over the elements of an <a>Array</a>.
foldl' :: Prim a => (b -> a -> b) -> b -> Array a -> b
foldr :: Prim a => (a -> b -> b) -> b -> Array a -> b

-- | Strict right-associated fold over the elements of an <a>Array</a>.
foldr' :: Prim a => (a -> b -> b) -> b -> Array a -> b

-- | Strict left-associated fold over the elements of an <a>Array</a>.
foldlM' :: (Prim a, Monad m) => (b -> a -> m b) -> b -> Array a -> m b

-- | <a>splitAt</a> <tt>n xs</tt> returns a tuple where first element is
--   <tt>xs</tt> prefix of length <tt>n</tt> and second element is the
--   remainder of the list:
--   
--   <pre>
--   &gt;&gt;&gt; splitAt 6 "Hello World!"
--   ("Hello ","World!")
--   
--   &gt;&gt;&gt; splitAt 3 [1,2,3,4,5]
--   ([1,2,3],[4,5])
--   
--   &gt;&gt;&gt; splitAt 1 [1,2,3]
--   ([1],[2,3])
--   
--   &gt;&gt;&gt; splitAt 3 [1,2,3]
--   ([1,2,3],[])
--   
--   &gt;&gt;&gt; splitAt 4 [1,2,3]
--   ([1,2,3],[])
--   
--   &gt;&gt;&gt; splitAt 0 [1,2,3]
--   ([],[1,2,3])
--   
--   &gt;&gt;&gt; splitAt (-1) [1,2,3]
--   ([],[1,2,3])
--   </pre>
--   
--   It is equivalent to <tt>(<a>take</a> n xs, <a>drop</a> n xs)</tt> when
--   <tt>n</tt> is not <tt>_|_</tt> (<tt>splitAt _|_ xs = _|_</tt>).
--   <a>splitAt</a> is an instance of the more general
--   <a>genericSplitAt</a>, in which <tt>n</tt> may be of any integral
--   type.
splitAt :: Int -> [a] -> ([a], [a])
toStreamD :: (Prim a, Monad m) => Array a -> Stream m a
toStreamDRev :: (Prim a, Monad m) => Array a -> Stream m a
toStreamK :: Prim a => Array a -> Stream m a
toStreamKRev :: Prim a => Array a -> Stream m a

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Pre-release</i>
toList :: Prim a => Array a -> [a]

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Pre-release</i>
writeN :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)
data ArrayUnsafe a
ArrayUnsafe :: {-# UNPACK #-} !Array a -> {-# UNPACK #-} !Int -> ArrayUnsafe a

-- | Like <a>writeN</a> but does not check the array bounds when writing.
--   The fold driver must not call the step function more than <tt>n</tt>
--   times otherwise it will corrupt the memory and crash. This function
--   exists mainly because any conditional in the step function blocks
--   fusion causing 10x performance slowdown.
--   
--   <i>Pre-release</i>
writeNUnsafe :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Pre-release</i>
write :: (MonadIO m, Prim a) => Fold m a (Array a)
unlines :: (MonadIO m, Prim a) => a -> Stream m (Array a) -> Stream m a
toPtr :: Array a -> Ptr a
touchArray :: Array a -> IO ()
withArrayAsPtr :: Array a -> (Ptr a -> IO b) -> IO b
instance (GHC.Classes.Eq a, Data.Primitive.Types.Prim a) => GHC.Classes.Eq (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance (GHC.Classes.Ord a, Data.Primitive.Types.Prim a) => GHC.Classes.Ord (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance Data.Primitive.Types.Prim a => GHC.Base.Semigroup (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance Data.Primitive.Types.Prim a => GHC.Base.Monoid (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance Control.DeepSeq.NFData (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance (GHC.Show.Show a, Data.Primitive.Types.Prim a) => GHC.Show.Show (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance Data.Primitive.Types.Prim a => GHC.Exts.IsList (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)
instance (Data.Primitive.Types.Prim a, GHC.Read.Read a, GHC.Show.Show a) => GHC.Read.Read (Streamly.Internal.Data.Array.Prim.Pinned.Type.Array a)


module Streamly.Internal.Data.Array.Prim.Pinned
data Array a
fromListN :: Prim a => Int -> [a] -> Array a
fromList :: Prim a => [a] -> Array a

-- | Create an <a>Array</a> from the first N elements of a stream. The
--   array is allocated to size N, if the stream terminates before N
--   elements then the array may hold less than N elements.
--   
--   <i>Pre-release</i>
fromStreamN :: (MonadIO m, Prim a) => Int -> SerialT m a -> m (Array a)

-- | Create an <a>Array</a> from a stream. This is useful when we want to
--   create a single array from a stream of unknown size. <tt>writeN</tt>
--   is at least twice as efficient when the size is already known.
--   
--   Note that if the input stream is too large memory allocation for the
--   array may fail. When the stream size is not known, <tt>arraysOf</tt>
--   followed by processing of indvidual arrays in the resulting stream
--   should be preferred.
--   
--   <i>Pre-release</i>
fromStream :: (MonadIO m, Prim a) => SerialT m a -> m (Array a)

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Pre-release</i>
writeN :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Pre-release</i>
write :: (MonadIO m, Prim a) => Fold m a (Array a)

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Pre-release</i>
toList :: Prim a => Array a -> [a]

-- | Convert an <a>Array</a> into a stream.
--   
--   <i>Pre-release</i>
toStream :: (MonadIO m, Prim a) => Array a -> SerialT m a

-- | Convert an <a>Array</a> into a stream in reverse order.
--   
--   <i>Pre-release</i>
toStreamRev :: (MonadIO m, Prim a) => Array a -> SerialT m a

-- | Unfold an array into a stream.
read :: (MonadIO m, Prim a) => Unfold m (Array a) a

-- | Unfold an array into a stream, does not check the end of the array,
--   the user is responsible for terminating the stream within the array
--   bounds. For high performance application where the end condition can
--   be determined by a terminating fold.
--   
--   The following might not be true, not that the representation changed.
--   Written in the hope that it may be faster than "read", however, in the
--   case for which this was written, "read" proves to be faster even
--   though the core generated with unsafeRead looks simpler.
--   
--   <i>Pre-release</i>
unsafeRead :: (MonadIO m, Prim a) => Unfold m (Array a) a
length :: Array a -> Int

-- | <pre>
--   null arr = length arr == 0
--   </pre>
--   
--   <i>Pre-release</i>
null :: Array a -> Bool

-- | <pre>
--   last arr = readIndex arr (length arr - 1)
--   </pre>
--   
--   <i>Pre-release</i>
last :: Prim a => Array a -> Maybe a

-- | <i>O(1)</i> Lookup the element at the given index, starting from 0.
--   
--   <i>Pre-release</i>
readIndex :: Prim a => Array a -> Int -> Maybe a
unsafeIndex :: Prim a => Array a -> Int -> a

-- | Fold an array using a stream fold operation.
--   
--   <i>Pre-release</i>
streamFold :: (MonadIO m, Prim a) => (SerialT m a -> m b) -> Array a -> m b

-- | Fold an array using a <a>Fold</a>.
--   
--   <i>Pre-release</i>
fold :: forall m a b. (MonadIO m, Prim a) => Fold m a b -> Array a -> m b

-- | Convert a stream of arrays into a stream of their elements.
--   
--   Same as the following but more efficient:
--   
--   <pre>
--   concat = S.concatMap A.read
--   </pre>
--   
--   <i>Pre-release</i>
concat :: (MonadIO m, Prim a) => SerialT m (Array a) -> SerialT m a

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes.
--   
--   <i>Pre-release</i>
compact :: (MonadIO m, Prim a) => Int -> SerialT m (Array a) -> SerialT m (Array a)


module Streamly.Internal.Data.Array.Prim.Mut.Type
data Array a
Array :: MutableByteArray# RealWorld -> Array a

-- | Allocate an array that is unpinned and can hold <tt>count</tt> items.
--   The memory of the array is uninitialized.
--   
--   Note that this is internal routine, the reference to this array cannot
--   be given out until the array has been written to and frozen.
newArray :: forall m a. (MonadIO m, Prim a) => Int -> m (Array a)
unsafeWriteIndex :: (MonadIO m, Prim a) => Array a -> Int -> a -> m ()
spliceTwo :: (MonadIO m, Prim a) => Array a -> Array a -> m (Array a)

-- | Copy a range of the first array to the specified region in the second
--   array. Both arrays must fully contain the specified ranges, but this
--   is not checked. The regions are allowed to overlap, although this is
--   only possible when the same array is provided as both the source and
--   the destination.
unsafeCopy :: forall m a. (MonadIO m, Prim a) => Array a -> Int -> Array a -> Int -> Int -> m ()
fromListM :: (MonadIO m, Prim a) => [a] -> m (Array a)
fromListNM :: (MonadIO m, Prim a) => Int -> [a] -> m (Array a)
fromStreamDN :: (MonadIO m, Prim a) => Int -> Stream m a -> m (Array a)
fromStreamD :: (MonadIO m, Prim a) => Stream m a -> m (Array a)

-- | <tt>fromStreamArraysOf n stream</tt> groups the input stream into a
--   stream of arrays of size n.
fromStreamDArraysOf :: (MonadIO m, Prim a) => Int -> Stream m a -> Stream m (Array a)

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes. Note that if a single array is bigger
--   than the specified size we do not split it to fit. When we coalesce
--   multiple arrays if the size would exceed the specified size we do not
--   coalesce therefore the actual array size may be less than the
--   specified chunk size.
--   
--   <i>Pre-release</i>
packArraysChunksOf :: (MonadIO m, Prim a) => Int -> Stream m (Array a) -> Stream m (Array a)
lpackArraysChunksOf :: (MonadIO m, Prim a) => Int -> Fold m (Array a) () -> Fold m (Array a) ()
unsafeReadIndex :: (MonadIO m, Prim a) => Array a -> Int -> m a
length :: forall m a. (MonadIO m, Prim a) => Array a -> m Int
byteLength :: MonadIO m => Array a -> m Int

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Pre-release</i>
writeN :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)
data ArrayUnsafe a
ArrayUnsafe :: {-# UNPACK #-} !Array a -> {-# UNPACK #-} !Int -> ArrayUnsafe a

-- | Like <a>writeN</a> but does not check the array bounds when writing.
--   The fold driver must not call the step function more than <tt>n</tt>
--   times otherwise it will corrupt the memory and crash. This function
--   exists mainly because any conditional in the step function blocks
--   fusion causing 10x performance slowdown.
--   
--   <i>Pre-release</i>
writeNUnsafe :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Pre-release</i>
write :: (MonadIO m, Prim a) => Fold m a (Array a)

-- | Resize (unpinned) mutable byte array to new specified size (in elem
--   count). The returned array is either the original array resized
--   in-place or, if not possible, a newly allocated (unpinned) array (with
--   the original content copied over).
resizeArray :: forall m a. (MonadIO m, Prim a) => Array a -> Int -> m (Array a)
shrinkArray :: forall m a. (MonadIO m, Prim a) => Array a -> Int -> m ()


module Streamly.Internal.Data.Array.Prim.Type
data Array a
Array :: ByteArray# -> Int -> Int -> Array a
unsafeFreeze :: (Prim a, MonadIO m) => Array a -> m (Array a)
unsafeFreezeWithShrink :: (Prim a, MonadIO m) => Array a -> Int -> m (Array a)

-- | Default maximum buffer size in bytes, for reading from and writing to
--   IO devices, the value is 32KB minus GHC allocation overhead, which is
--   a few bytes, so that the actual allocation is 32KB.
defaultChunkSize :: Int
nil :: Prim a => Array a

-- | Splice two immutable arrays creating a new immutable array.
spliceTwo :: (MonadIO m, Prim a) => Array a -> Array a -> m (Array a)
fromList :: Prim a => [a] -> Array a
fromListN :: Prim a => Int -> [a] -> Array a
fromStreamDN :: (MonadIO m, Prim a) => Int -> Stream m a -> m (Array a)
fromStreamD :: (MonadIO m, Prim a) => Stream m a -> m (Array a)

-- | <tt>fromStreamArraysOf n stream</tt> groups the input stream into a
--   stream of arrays of size n.
fromStreamDArraysOf :: (MonadIO m, Prim a) => Int -> Stream m a -> Stream m (Array a)
data FlattenState s a
OuterLoop :: s -> FlattenState s a
InnerLoop :: s -> !Array a -> !Int -> !Int -> FlattenState s a
flattenArrays :: (MonadIO m, Prim a) => Stream m (Array a) -> Stream m a
flattenArraysRev :: (MonadIO m, Prim a) => Stream m (Array a) -> Stream m a
data SpliceState s arr1 arr2
SpliceInitial :: s -> SpliceState s arr1 arr2
SpliceBuffering :: s -> arr2 -> SpliceState s arr1 arr2
SpliceYielding :: arr1 -> SpliceState s arr1 arr2 -> SpliceState s arr1 arr2
SpliceFinish :: SpliceState s arr1 arr2

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes. Note that if a single array is bigger
--   than the specified size we do not split it to fit. When we coalesce
--   multiple arrays if the size would exceed the specified size we do not
--   coalesce therefore the actual array size may be less than the
--   specified chunk size.
--   
--   <i>Pre-release</i>
packArraysChunksOf :: forall m a. (MonadIO m, Prim a) => Int -> Stream m (Array a) -> Stream m (Array a)
lpackArraysChunksOf :: forall m a. (MonadIO m, Prim a) => Int -> Fold m (Array a) () -> Fold m (Array a) ()

-- | Split a stream of arrays on a given separator byte, dropping the
--   separator and coalescing all the arrays between two separators into a
--   single array.
--   
--   <i>Pre-release</i>
splitOn :: MonadIO m => Word8 -> Stream m (Array Word8) -> Stream m (Array Word8)
breakOn :: MonadIO m => Word8 -> Array Word8 -> m (Array Word8, Maybe (Array Word8))
unsafeIndex :: Prim a => Array a -> Int -> a
byteLength :: forall a. Prim a => Array a -> Int
length :: Array a -> Int

-- | Strict left-associated fold over the elements of an <a>Array</a>.
foldl' :: Prim a => (b -> a -> b) -> b -> Array a -> b
foldr :: Prim a => (a -> b -> b) -> b -> Array a -> b

-- | Strict right-associated fold over the elements of an <a>Array</a>.
foldr' :: Prim a => (a -> b -> b) -> b -> Array a -> b

-- | Strict left-associated fold over the elements of an <a>Array</a>.
foldlM' :: (Prim a, Monad m) => (b -> a -> m b) -> b -> Array a -> m b

-- | <a>splitAt</a> <tt>n xs</tt> returns a tuple where first element is
--   <tt>xs</tt> prefix of length <tt>n</tt> and second element is the
--   remainder of the list:
--   
--   <pre>
--   &gt;&gt;&gt; splitAt 6 "Hello World!"
--   ("Hello ","World!")
--   
--   &gt;&gt;&gt; splitAt 3 [1,2,3,4,5]
--   ([1,2,3],[4,5])
--   
--   &gt;&gt;&gt; splitAt 1 [1,2,3]
--   ([1],[2,3])
--   
--   &gt;&gt;&gt; splitAt 3 [1,2,3]
--   ([1,2,3],[])
--   
--   &gt;&gt;&gt; splitAt 4 [1,2,3]
--   ([1,2,3],[])
--   
--   &gt;&gt;&gt; splitAt 0 [1,2,3]
--   ([],[1,2,3])
--   
--   &gt;&gt;&gt; splitAt (-1) [1,2,3]
--   ([],[1,2,3])
--   </pre>
--   
--   It is equivalent to <tt>(<a>take</a> n xs, <a>drop</a> n xs)</tt> when
--   <tt>n</tt> is not <tt>_|_</tt> (<tt>splitAt _|_ xs = _|_</tt>).
--   <a>splitAt</a> is an instance of the more general
--   <a>genericSplitAt</a>, in which <tt>n</tt> may be of any integral
--   type.
splitAt :: Int -> [a] -> ([a], [a])
toStreamD :: (Prim a, Monad m) => Array a -> Stream m a
toStreamDRev :: (Prim a, Monad m) => Array a -> Stream m a
toStreamK :: Prim a => Array a -> Stream m a
toStreamKRev :: Prim a => Array a -> Stream m a

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Pre-release</i>
toList :: Prim a => Array a -> [a]

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Pre-release</i>
writeN :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)
data ArrayUnsafe a
ArrayUnsafe :: {-# UNPACK #-} !Array a -> {-# UNPACK #-} !Int -> ArrayUnsafe a

-- | Like <a>writeN</a> but does not check the array bounds when writing.
--   The fold driver must not call the step function more than <tt>n</tt>
--   times otherwise it will corrupt the memory and crash. This function
--   exists mainly because any conditional in the step function blocks
--   fusion causing 10x performance slowdown.
--   
--   <i>Pre-release</i>
writeNUnsafe :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Pre-release</i>
write :: (MonadIO m, Prim a) => Fold m a (Array a)
unlines :: (MonadIO m, Prim a) => a -> Stream m (Array a) -> Stream m a
instance (GHC.Classes.Eq a, Data.Primitive.Types.Prim a) => GHC.Classes.Eq (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance (GHC.Classes.Ord a, Data.Primitive.Types.Prim a) => GHC.Classes.Ord (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance Data.Primitive.Types.Prim a => GHC.Base.Semigroup (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance Data.Primitive.Types.Prim a => GHC.Base.Monoid (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance Control.DeepSeq.NFData (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance (GHC.Show.Show a, Data.Primitive.Types.Prim a) => GHC.Show.Show (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance (a GHC.Types.~ GHC.Types.Char) => Data.String.IsString (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance Data.Primitive.Types.Prim a => GHC.Exts.IsList (Streamly.Internal.Data.Array.Prim.Type.Array a)
instance (Data.Primitive.Types.Prim a, GHC.Read.Read a, GHC.Show.Show a) => GHC.Read.Read (Streamly.Internal.Data.Array.Prim.Type.Array a)


module Streamly.Internal.Data.Array.Prim
data Array a
fromListN :: Prim a => Int -> [a] -> Array a
fromList :: Prim a => [a] -> Array a

-- | Create an <a>Array</a> from the first N elements of a stream. The
--   array is allocated to size N, if the stream terminates before N
--   elements then the array may hold less than N elements.
--   
--   <i>Pre-release</i>
fromStreamN :: (MonadIO m, Prim a) => Int -> SerialT m a -> m (Array a)

-- | Create an <a>Array</a> from a stream. This is useful when we want to
--   create a single array from a stream of unknown size. <tt>writeN</tt>
--   is at least twice as efficient when the size is already known.
--   
--   Note that if the input stream is too large memory allocation for the
--   array may fail. When the stream size is not known, <tt>arraysOf</tt>
--   followed by processing of indvidual arrays in the resulting stream
--   should be preferred.
--   
--   <i>Pre-release</i>
fromStream :: (MonadIO m, Prim a) => SerialT m a -> m (Array a)

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Pre-release</i>
writeN :: (MonadIO m, Prim a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Pre-release</i>
write :: (MonadIO m, Prim a) => Fold m a (Array a)

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Pre-release</i>
toList :: Prim a => Array a -> [a]

-- | Convert an <a>Array</a> into a stream.
--   
--   <i>Pre-release</i>
toStream :: (MonadIO m, Prim a) => Array a -> SerialT m a

-- | Convert an <a>Array</a> into a stream in reverse order.
--   
--   <i>Pre-release</i>
toStreamRev :: (MonadIO m, Prim a) => Array a -> SerialT m a

-- | Unfold an array into a stream.
read :: (MonadIO m, Prim a) => Unfold m (Array a) a

-- | Unfold an array into a stream, does not check the end of the array,
--   the user is responsible for terminating the stream within the array
--   bounds. For high performance application where the end condition can
--   be determined by a terminating fold.
--   
--   The following might not be true, not that the representation changed.
--   Written in the hope that it may be faster than "read", however, in the
--   case for which this was written, "read" proves to be faster even
--   though the core generated with unsafeRead looks simpler.
--   
--   <i>Pre-release</i>
unsafeRead :: (MonadIO m, Prim a) => Unfold m (Array a) a
length :: Array a -> Int

-- | <pre>
--   null arr = length arr == 0
--   </pre>
--   
--   <i>Pre-release</i>
null :: Array a -> Bool

-- | <pre>
--   last arr = readIndex arr (length arr - 1)
--   </pre>
--   
--   <i>Pre-release</i>
last :: Prim a => Array a -> Maybe a

-- | <i>O(1)</i> Lookup the element at the given index, starting from 0.
--   
--   <i>Pre-release</i>
readIndex :: Prim a => Array a -> Int -> Maybe a
unsafeIndex :: Prim a => Array a -> Int -> a

-- | Fold an array using a stream fold operation.
--   
--   <i>Pre-release</i>
streamFold :: (MonadIO m, Prim a) => (SerialT m a -> m b) -> Array a -> m b

-- | Fold an array using a <a>Fold</a>.
--   
--   <i>Pre-release</i>
fold :: forall m a b. (MonadIO m, Prim a) => Fold m a b -> Array a -> m b

-- | Convert a stream of arrays into a stream of their elements.
--   
--   Same as the following but more efficient:
--   
--   <pre>
--   concat = S.concatMap A.read
--   </pre>
--   
--   <i>Pre-release</i>
concat :: (MonadIO m, Prim a) => SerialT m (Array a) -> SerialT m a

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes.
--   
--   <i>Pre-release</i>
compact :: (MonadIO m, Prim a) => Int -> SerialT m (Array a) -> SerialT m (Array a)


module Streamly.Internal.Data.Array

-- | Boxed arrays.
data Array a
Array :: Array# a -> Array a
[array#] :: Array a -> Array# a
nil :: Array a
writeN :: MonadIO m => Int -> Fold m a (Array a)
write :: MonadIO m => Fold m a (Array a)
writeLastN :: MonadIO m => Int -> Fold m a (Array a)
fromStreamDN :: MonadIO m => Int -> Stream m a -> m (Array a)
fromStreamD :: MonadIO m => Stream m a -> m (Array a)
fromStreamN :: MonadIO m => Int -> SerialT m a -> m (Array a)
fromStream :: MonadIO m => SerialT m a -> m (Array a)
fromListN :: Int -> [a] -> Array a
fromList :: [a] -> Array a
length :: Array a -> Int
read :: Monad m => Unfold m (Array a) a
toStreamD :: Monad m => Array a -> Stream m a
toStreamDRev :: Monad m => Array a -> Stream m a
toStream :: Monad m => Array a -> SerialT m a
toStreamRev :: Monad m => Array a -> SerialT m a
foldl' :: (b -> a -> b) -> b -> Array a -> b
foldr :: (a -> b -> b) -> b -> Array a -> b
streamFold :: Monad m => (SerialT m a -> m b) -> Array a -> m b
fold :: Monad m => Fold m a b -> Array a -> m b

-- | <i>O(1)</i> Lookup the element at the given index. Index starts from
--   0. Does not check the bounds.
getIndexUnsafe :: Array a -> Int -> a

-- | Truncate the array at the beginning and end as long as the predicate
--   holds true.
strip :: (a -> Bool) -> Array a -> Array a


-- | Bottom level IsStream module that can be used by all other upper level
--   IsStream modules.
module Streamly.Internal.Data.Stream.IsStream.Common

-- | <pre>
--   fromPure a = a `cons` nil
--   </pre>
--   
--   Create a singleton stream from a pure value.
--   
--   The following holds in monadic streams, but not in Zip streams:
--   
--   <pre>
--   fromPure = pure
--   fromPure = fromEffect . pure
--   </pre>
--   
--   In Zip applicative streams <a>fromPure</a> is not the same as
--   <a>pure</a> because in that case <a>pure</a> is equivalent to
--   <a>repeat</a> instead. <a>fromPure</a> and <a>pure</a> are equally
--   efficient, in other cases <a>fromPure</a> may be slightly more
--   efficient than the other equivalent definitions.
--   
--   <i>Since: 0.8.0 (Renamed yield to fromPure)</i>
fromPure :: IsStream t => a -> t m a

-- | <pre>
--   fromEffect m = m `consM` nil
--   </pre>
--   
--   Create a singleton stream from a monadic action.
--   
--   <pre>
--   &gt; Stream.toList $ Stream.fromEffect getLine
--   hello
--   ["hello"]
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed yieldM to fromEffect)</i>
fromEffect :: (Monad m, IsStream t) => m a -> t m a

-- | <pre>
--   &gt;&gt;&gt; repeatM = fix . consM
--   
--   &gt;&gt;&gt; repeatM = cycle1 . fromEffect
--   </pre>
--   
--   Generate a stream by repeatedly executing a monadic action forever.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   repeatAsync =
--          Stream.repeatM (threadDelay 1000000 &gt;&gt; print 1)
--        &amp; Stream.take 10
--        &amp; Stream.fromAsync
--        &amp; Stream.drain
--   :}
--   </pre>
--   
--   <i>Concurrent, infinite (do not use with <tt>fromParallel</tt>)</i>
repeatM :: (IsStream t, MonadAsync m) => m a -> t m a

-- | <tt>timesWith g</tt> returns a stream of time value tuples. The first
--   component of the tuple is an absolute time reference (epoch) denoting
--   the start of the stream and the second component is a time relative to
--   the reference.
--   
--   The argument <tt>g</tt> specifies the granularity of the relative time
--   in seconds. A lower granularity clock gives higher precision but is
--   more expensive in terms of CPU usage. Any granularity lower than 1 ms
--   is treated as 1 ms.
--   
--   <pre>
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; import Streamly.Internal.Data.Stream.IsStream.Common as Stream (timesWith)
--   
--   &gt;&gt;&gt; Stream.mapM_ (\x -&gt; print x &gt;&gt; threadDelay 1000000) $ Stream.take 3 $ Stream.timesWith 0.01
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),RelTime64 (NanoSecond64 ...))
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),RelTime64 (NanoSecond64 ...))
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),RelTime64 (NanoSecond64 ...))
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
timesWith :: (IsStream t, MonadAsync m) => Double -> t m (AbsTime, RelTime64)

-- | <tt>absTimesWith g</tt> returns a stream of absolute timestamps using
--   a clock of granularity <tt>g</tt> specified in seconds. A low
--   granularity clock is more expensive in terms of CPU usage. Any
--   granularity lower than 1 ms is treated as 1 ms.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.delayPre 1 $ Stream.take 3 $ absTimesWith 0.01
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
absTimesWith :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m AbsTime

-- | <tt>relTimesWith g</tt> returns a stream of relative time values
--   starting from 0, using a clock of granularity <tt>g</tt> specified in
--   seconds. A low granularity clock is more expensive in terms of CPU
--   usage. Any granularity lower than 1 ms is treated as 1 ms.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.delayPre 1 $ Stream.take 3 $ Stream.relTimesWith 0.01
--   RelTime64 (NanoSecond64 ...)
--   RelTime64 (NanoSecond64 ...)
--   RelTime64 (NanoSecond64 ...)
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
relTimesWith :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m RelTime64

-- | We can create higher order folds using <a>foldOn</a>. We can fold a
--   number of streams to a given fold efficiently with full stream fusion.
--   For example, to fold a list of streams on the same sum fold:
--   
--   <pre>
--   &gt;&gt;&gt; concatFold = Prelude.foldl Stream.foldOn Fold.sum
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; fold f = Fold.finish . Stream.foldOn f
--   </pre>
--   
--   <i>Internal</i>
foldOn :: Monad m => Fold m a b -> SerialT m a -> Fold m a b

-- | Fold a stream using the supplied left <a>Fold</a> and reducing the
--   resulting expression strictly at each step. The behavior is similar to
--   <tt>foldl'</tt>. A <a>Fold</a> can terminate early without consuming
--   the full stream. See the documentation of individual <a>Fold</a>s for
--   termination behavior.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.sum (Stream.enumerateFromTo 1 100)
--   5050
--   </pre>
--   
--   Folds never fail, therefore, they produce a default value even when no
--   input is provided. It means we can always fold an empty stream and get
--   a valid result. For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.sum Stream.nil
--   0
--   </pre>
--   
--   However, <tt>foldMany</tt> on an empty stream results in an empty
--   stream. Therefore, <tt>Stream.fold f</tt> is not the same as
--   <tt>Stream.head . Stream.foldMany f</tt>.
--   
--   <pre>
--   fold f = Stream.parse (Parser.fromFold f)
--   </pre>
fold :: Monad m => Fold m a b -> SerialT m a -> m b
fold_ :: Monad m => Fold m a b -> SerialT m a -> m (b, SerialT m a)

-- | <pre>
--   map = fmap
--   </pre>
--   
--   Same as <a>fmap</a>.
--   
--   <pre>
--   &gt; S.toList $ S.map (+1) $ S.fromList [1,2,3]
--   [2,3,4]
--   </pre>
map :: (IsStream t, Monad m) => (a -> b) -> t m a -> t m b

-- | <tt>scanlMAfter' accumulate initial done stream</tt> is like
--   <tt>scanlM'</tt> except that it provides an additional <tt>done</tt>
--   function to be applied on the accumulator when the stream stops. The
--   result of <tt>done</tt> is also emitted in the stream.
--   
--   This function can be used to allocate a resource in the beginning of
--   the scan and release it when the stream ends or to flush the internal
--   state of the scan at the end.
--   
--   <i>Pre-release</i>
scanlMAfter' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> (b -> m b) -> t m a -> t m b

-- | Like <tt>postscanl'</tt> but with a monadic step function and a
--   monadic seed.
--   
--   <pre>
--   &gt;&gt;&gt; postscanlM' f z xs = Stream.drop 1 $ Stream.scanlM' f z xs
--   </pre>
--   
--   <i>Since: 0.7.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
postscanlM' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> t m a -> t m b

-- | A stateful <a>mapM</a>, equivalent to a left scan, more like
--   mapAccumL. Hopefully, this is a better alternative to <tt>scan</tt>.
--   Separation of state from the output makes it easier to think in terms
--   of a shared state, and also makes it easier to keep the state fully
--   strict and the output lazy.
--   
--   See also: <tt>scanlM'</tt>
--   
--   <i>Pre-release</i>
smapM :: (IsStream t, Monad m) => (s -> a -> m (s, b)) -> m s -> t m a -> t m b

-- | Take first <tt>n</tt> elements from the stream and discard the rest.
take :: (IsStream t, Monad m) => Int -> t m a -> t m a

-- | End the stream as soon as the predicate fails on an element.
takeWhile :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m a

-- | Discard first <tt>n</tt> elements from the stream and take the rest.
drop :: (IsStream t, Monad m) => Int -> t m a -> t m a

-- | Find all the indices where the element in the stream satisfies the
--   given predicate.
--   
--   <pre>
--   findIndices = fold Fold.findIndices
--   </pre>
findIndices :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m Int

-- | Insert an effect and its output before consuming an element of a
--   stream except the first one.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.trace putChar $ Stream.intersperseM (putChar '.' &gt;&gt; return ',') $ Stream.fromList "hello"
--   h.,e.,l.,l.,o"h,e,l,l,o"
--   </pre>
intersperseM :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a

-- | Intersperse a monadic action into the input stream after every
--   <tt>n</tt> seconds.
--   
--   <pre>
--   &gt; import Control.Concurrent (threadDelay)
--   &gt; Stream.drain $ Stream.interjectSuffix 1 (putChar ',') $ Stream.mapM (x -&gt; threadDelay 1000000 &gt;&gt; putChar x) $ Stream.fromList "hello"
--   h,e,l,l,o
--   </pre>
--   
--   <i>Pre-release</i>
interjectSuffix :: (IsStream t, MonadAsync m) => Double -> m a -> t m a -> t m a

-- | Returns the elements of the stream in reverse order. The stream must
--   be finite. Note that this necessarily buffers the entire stream in
--   memory.
--   
--   <pre>
--   &gt;&gt;&gt; reverse = Stream.foldlT (flip Stream.cons) Stream.nil
--   </pre>
--   
--   <i>Since 0.7.0 (Monad m constraint)</i>
--   
--   <i>Since: 0.1.1</i>
reverse :: (IsStream t, Monad m) => t m a -> t m a

-- | Like <a>reverse</a> but several times faster, requires a
--   <a>Storable</a> instance.
--   
--   <i>Pre-release</i>
reverse' :: (IsStream t, MonadIO m, Storable a) => t m a -> t m a

-- | Make the stream producer and consumer run concurrently by introducing
--   a buffer between them. The producer thread evaluates the input stream
--   until the buffer fills, it terminates if the buffer is full and a
--   worker thread is kicked off again to evaluate the remaining stream
--   when there is space in the buffer. The consumer consumes the stream
--   lazily from the buffer.
--   
--   <i>Since: 0.2.0 (Streamly)</i>
mkAsync :: (IsStream t, MonadAsync m) => t m a -> t m a

-- | Make the stream producer and consumer run concurrently by introducing
--   a buffer between them. The producer thread evaluates the input stream
--   until the buffer fills, it blocks if the buffer is full until there is
--   space in the buffer. The consumer consumes the stream lazily from the
--   buffer.
--   
--   <pre>
--   mkParallel = IsStream.fromStreamD . mkParallelD . IsStream.toStreamD
--   </pre>
--   
--   <i>Pre-release</i>
mkParallel :: (IsStream t, MonadAsync m) => t m a -> t m a

-- | Like <tt>parallel</tt> but stops the output as soon as the first
--   stream stops.
--   
--   <i>Pre-release</i>
parallelFst :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a

-- | Given a stream value in the underlying monad, lift and join the
--   underlying monad with the stream monad.
--   
--   <pre>
--   &gt;&gt;&gt; concatM = Stream.concat . Stream.fromEffect
--   
--   &gt;&gt;&gt; concatM = Stream.concat . lift    -- requires (MonadTrans t)
--   
--   &gt;&gt;&gt; concatM = join . lift             -- requires (MonadTrans t, Monad (t m))
--   </pre>
--   
--   See also: <a>concat</a>, <a>sequence</a>
--   
--   <i>Internal</i>
concatM :: (IsStream t, Monad m) => m (t m a) -> t m a

-- | Map a stream producing monadic function on each element of the stream
--   and then flatten the results into a single stream. Since the stream
--   generation function is monadic, unlike <a>concatMap</a>, it can
--   produce an effect at the beginning of each iteration of the inner
--   loop.
concatMapM :: (IsStream t, Monad m) => (a -> m (t m b)) -> t m a -> t m b

-- | Map a stream producing function on each element of the stream and then
--   flatten the results into a single stream.
--   
--   <pre>
--   &gt;&gt;&gt; concatMap f = Stream.concatMapM (return . f)
--   
--   &gt;&gt;&gt; concatMap f = Stream.concatMapWith Stream.serial f
--   
--   &gt;&gt;&gt; concatMap f = Stream.concat . Stream.map f
--   
--   &gt;&gt;&gt; concatMap f = Stream.unfoldMany (Unfold.lmap f Unfold.fromStream)
--   </pre>
concatMap :: (IsStream t, Monad m) => (a -> t m b) -> t m a -> t m b

-- | Like <tt>splitOn</tt> but the separator is a sequence of elements
--   instead of a single element.
--   
--   For illustration, let's define a function that operates on pure lists:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' pat xs = Stream.toList $ Stream.splitOnSeq (Array.fromList pat) Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "" "hello"
--   ["h","e","l","l","o"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "hello" ""
--   [""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "hello" "hello"
--   ["",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "x" "hello"
--   ["hello"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "h" "hello"
--   ["","ello"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "o" "hello"
--   ["hell",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "e" "hello"
--   ["h","llo"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "l" "hello"
--   ["he","","o"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "ll" "hello"
--   ["he","o"]
--   </pre>
--   
--   <a>splitOnSeq</a> is an inverse of <tt>intercalate</tt>. The following
--   law always holds:
--   
--   <pre>
--   intercalate . splitOnSeq == id
--   </pre>
--   
--   The following law holds when the separator is non-empty and contains
--   none of the elements present in the input lists:
--   
--   <pre>
--   splitOnSeq . intercalate == id
--   </pre>
--   
--   <i>Pre-release</i>
splitOnSeq :: (IsStream t, MonadIO m, Storable a, Enum a, Eq a) => Array a -> Fold m a b -> t m a -> t m b

-- | Like <a>zipWith</a> but using a monadic zipping function.
zipWithM :: (IsStream t, Monad m) => (a -> b -> m c) -> t m a -> t m b -> t m c

-- | Stream <tt>a</tt> is evaluated first, followed by stream <tt>b</tt>,
--   the resulting elements <tt>a</tt> and <tt>b</tt> are then zipped using
--   the supplied zip function and the result <tt>c</tt> is yielded to the
--   consumer.
--   
--   If stream <tt>a</tt> or stream <tt>b</tt> ends, the zipped stream
--   ends. If stream <tt>b</tt> ends first, the element <tt>a</tt> from
--   previous evaluation of stream <tt>a</tt> is discarded.
--   
--   <pre>
--   &gt; S.toList $ S.zipWith (+) (S.fromList [1,2,3]) (S.fromList [4,5,6])
--   [5,7,9]
--   </pre>
zipWith :: (IsStream t, Monad m) => (a -> b -> c) -> t m a -> t m b -> t m c

-- | Same as <a>fromPure</a>

-- | <i>Deprecated: Please use fromPure instead.</i>
yield :: IsStream t => a -> t m a

-- | Same as <a>fromEffect</a>

-- | <i>Deprecated: Please use fromEffect instead.</i>
yieldM :: (Monad m, IsStream t) => m a -> t m a


module Streamly.Internal.Data.Stream.IsStream.Transform

-- | Use a <a>Pipe</a> to transform a stream.
--   
--   <i>Pre-release</i>
transform :: (IsStream t, Monad m) => Pipe m a b -> t m a -> t m b

-- | Right fold to a streaming monad.
--   
--   <pre>
--   foldrS Stream.cons Stream.nil === id
--   </pre>
--   
--   <a>foldrS</a> can be used to perform stateless stream to stream
--   transformations like map and filter in general. It can be coupled with
--   a scan to perform stateful transformations. However, note that the
--   custom map and filter routines can be much more efficient than this
--   due to better stream fusion.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldrS Stream.cons Stream.nil $ Stream.fromList [1..5]
--   [1,2,3,4,5]
--   </pre>
--   
--   Find if any element in the stream is <a>True</a>:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldrS (\x xs -&gt; if odd x then return True else xs) (return False) $ (Stream.fromList (2:4:5:undefined) :: Stream.SerialT IO Int)
--   [True]
--   </pre>
--   
--   Map (+2) on odd elements and filter out the even elements:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldrS (\x xs -&gt; if odd x then (x + 2) `Stream.cons` xs else xs) Stream.nil $ (Stream.fromList [1..5] :: Stream.SerialT IO Int)
--   [3,5,7]
--   </pre>
--   
--   <tt>foldrM</tt> can also be represented in terms of <a>foldrS</a>,
--   however, the former is much more efficient:
--   
--   <pre>
--   foldrM f z s = runIdentityT $ foldrS (\x xs -&gt; lift $ f x (runIdentityT xs)) (lift z) s
--   </pre>
--   
--   <i>Pre-release</i>
foldrS :: IsStream t => (a -> t m b -> t m b) -> t m b -> t m a -> t m b
foldrSShared :: IsStream t => (a -> t m b -> t m b) -> t m b -> t m a -> t m b

-- | Right fold to a transformer monad. This is the most general right fold
--   function. <a>foldrS</a> is a special case of <a>foldrT</a>, however
--   <a>foldrS</a> implementation can be more efficient:
--   
--   <pre>
--   foldrS = foldrT
--   foldrM f z s = runIdentityT $ foldrT (\x xs -&gt; lift $ f x (runIdentityT xs)) (lift z) s
--   </pre>
--   
--   <a>foldrT</a> can be used to translate streamly streams to other
--   transformer monads e.g. to a different streaming type.
--   
--   <i>Pre-release</i>
foldrT :: (IsStream t, Monad m, Monad (s m), MonadTrans s) => (a -> s m b -> s m b) -> s m b -> t m a -> s m b

-- | <pre>
--   map = fmap
--   </pre>
--   
--   Same as <a>fmap</a>.
--   
--   <pre>
--   &gt; S.toList $ S.map (+1) $ S.fromList [1,2,3]
--   [2,3,4]
--   </pre>
map :: (IsStream t, Monad m) => (a -> b) -> t m a -> t m b

-- | <pre>
--   sequence = mapM id
--   </pre>
--   
--   Replace the elements of a stream of monadic actions with the outputs
--   of those actions.
--   
--   <pre>
--   &gt;&gt;&gt; drain $ Stream.sequence $ Stream.fromList [putStr "a", putStr "b", putStrLn "c"]
--   abc
--   
--   &gt;&gt;&gt; :{
--   drain $ Stream.replicateM 3 (return $ threadDelay 1000000 &gt;&gt; print 1)
--    &amp; (fromSerial . Stream.sequence)
--   :}
--   1
--   1
--   1
--   
--   &gt;&gt;&gt; :{
--   drain $ Stream.replicateM 3 (return $ threadDelay 1000000 &gt;&gt; print 1)
--    &amp; (fromAsync . Stream.sequence)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   streams)</i>
sequence :: (IsStream t, MonadAsync m) => t m (m a) -> t m a

-- | <pre>
--   mapM f = sequence . map f
--   </pre>
--   
--   Apply a monadic function to each element of the stream and replace it
--   with the output of the resulting action.
--   
--   <pre>
--   &gt;&gt;&gt; drain $ Stream.mapM putStr $ Stream.fromList ["a", "b", "c"]
--   abc
--   
--   &gt;&gt;&gt; :{
--      drain $ Stream.replicateM 10 (return 1)
--        &amp; (fromSerial . Stream.mapM (x -&gt; threadDelay 1000000 &gt;&gt; print x))
--   :}
--   1
--   ...
--   1
--   
--   &gt; drain $ Stream.replicateM 10 (return 1)
--    &amp; (fromAsync . Stream.mapM (x -&gt; threadDelay 1000000 &gt;&gt; print x))
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   streams)</i>
mapM :: forall t m a b. (IsStream t, MonadAsync m) => (a -> m b) -> t m a -> t m b

-- | A stateful <a>mapM</a>, equivalent to a left scan, more like
--   mapAccumL. Hopefully, this is a better alternative to <tt>scan</tt>.
--   Separation of state from the output makes it easier to think in terms
--   of a shared state, and also makes it easier to keep the state fully
--   strict and the output lazy.
--   
--   See also: <tt>scanlM'</tt>
--   
--   <i>Pre-release</i>
smapM :: (IsStream t, Monad m) => (s -> a -> m (s, b)) -> m s -> t m a -> t m b

-- | Apply a monadic function to each element flowing through the stream
--   and discard the results.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.trace print (Stream.enumerateFromTo 1 2)
--   1
--   2
--   </pre>
--   
--   Compare with <a>tap</a>.
trace :: (IsStream t, MonadAsync m) => (a -> m b) -> t m a -> t m a

-- | Perform a side effect before yielding each element of the stream and
--   discard the results.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.trace_ (print "got here") (Stream.enumerateFromTo 1 2)
--   "got here"
--   "got here"
--   </pre>
--   
--   Same as <a>interspersePrefix_</a> but always serial.
--   
--   See also: <a>trace</a>
--   
--   <i>Pre-release</i>
trace_ :: (IsStream t, Monad m) => m b -> t m a -> t m a

-- | Tap the data flowing through a stream into a <a>Fold</a>. For example,
--   you may add a tap to log the contents flowing through the stream. The
--   fold is used only for effects, its result is discarded.
--   
--   <pre>
--                     Fold m a b
--                         |
--   -----stream m a ---------------stream m a-----
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.tap (Fold.drainBy print) (Stream.enumerateFromTo 1 2)
--   1
--   2
--   </pre>
--   
--   Compare with <a>trace</a>.
tap :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m a

-- | <tt>tapOffsetEvery offset n</tt> taps every <tt>n</tt>th element in
--   the stream starting at <tt>offset</tt>. <tt>offset</tt> can be between
--   <tt>0</tt> and <tt>n - 1</tt>. Offset 0 means start at the first
--   element in the stream. If the offset is outside this range then
--   <tt>offset <a>mod</a> n</tt> is used as offset.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.tapOffsetEvery 0 2 (Fold.rmapM print Fold.toList) $ Stream.enumerateFromTo 0 10
--   [0,2,4,6,8,10]
--   </pre>
tapOffsetEvery :: (IsStream t, Monad m) => Int -> Int -> Fold m a b -> t m a -> t m a

-- | Redirect a copy of the stream to a supplied fold and run it
--   concurrently in an independent thread. The fold may buffer some
--   elements. The buffer size is determined by the prevailing
--   <a>maxBuffer</a> setting.
--   
--   <pre>
--                 Stream m a -&gt; m b
--                         |
--   -----stream m a ---------------stream m a-----
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.tapAsync (Fold.drainBy print) (Stream.enumerateFromTo 1 2)
--   1
--   2
--   </pre>
--   
--   Exceptions from the concurrently running fold are propagated to the
--   current computation. Note that, because of buffering in the fold,
--   exceptions may be delayed and may not correspond to the current
--   element being processed in the parent stream, but we guarantee that
--   before the parent stream stops the tap finishes and all exceptions
--   from it are drained.
--   
--   Compare with <a>tap</a>.
--   
--   <i>Pre-release</i>
tapAsync :: (IsStream t, MonadAsync m) => Fold m a b -> t m a -> t m a

-- | Redirect a copy of the stream to a supplied fold and run it
--   concurrently in an independent thread. The fold may buffer some
--   elements. The buffer size is determined by the prevailing
--   <a>maxBuffer</a> setting.
--   
--   <pre>
--                 Stream m a -&gt; m b
--                         |
--   -----stream m a ---------------stream m a-----
--   </pre>
--   
--   <pre>
--   &gt; S.drain $ S.tapAsync (S.mapM_ print) (S.enumerateFromTo 1 2)
--   1
--   2
--   </pre>
--   
--   Exceptions from the concurrently running fold are propagated to the
--   current computation. Note that, because of buffering in the fold,
--   exceptions may be delayed and may not correspond to the current
--   element being processed in the parent stream, but we guarantee that
--   before the parent stream stops the tap finishes and all exceptions
--   from it are drained.
--   
--   Compare with <a>tap</a>.
--   
--   <i>Pre-release</i>
tapAsyncK :: (IsStream t, MonadAsync m) => (t m a -> m b) -> t m a -> t m a

-- | Concurrently distribute a stream to a collection of fold functions,
--   discarding the outputs of the folds.
--   
--   <pre>
--   &gt; Stream.drain $ Stream.distributeAsync_ [Stream.mapM_ print, Stream.mapM_ print] (Stream.enumerateFromTo 1 2)
--   1
--   2
--   1
--   2
--   </pre>
--   
--   <pre>
--   distributeAsync_ = flip (foldr tapAsync)
--   </pre>
--   
--   <i>Pre-release</i>
distributeAsync_ :: (Foldable f, IsStream t, MonadAsync m) => f (t m a -> m b) -> t m a -> t m a

-- | Calls the supplied function with the number of elements consumed every
--   <tt>n</tt> seconds. The given function is run in a separate thread
--   until the end of the stream. In case there is an exception in the
--   stream the thread is killed during the next major GC.
--   
--   Note: The action is not guaranteed to run if the main thread exits.
--   
--   <pre>
--   &gt; delay n = threadDelay (round $ n * 1000000) &gt;&gt; return n
--   &gt; Stream.toList $ Stream.tapRate 2 (n -&gt; print $ show n ++ " elements processed") (delay 1 Stream.|: delay 0.5 Stream.|: delay 0.5 Stream.|: Stream.nil)
--   "2 elements processed"
--   [1.0,0.5,0.5]
--   "1 elements processed"
--   </pre>
--   
--   Note: This may not work correctly on 32-bit machines.
--   
--   <i>Pre-release</i>
tapRate :: (IsStream t, MonadAsync m, MonadCatch m) => Double -> (Int -> m b) -> t m a -> t m a

-- | <tt>pollCounts predicate transform fold stream</tt> counts those
--   elements in the stream that pass the <tt>predicate</tt>. The resulting
--   count stream is sent to another thread which transforms it using
--   <tt>transform</tt> and then folds it using <tt>fold</tt>. The thread
--   is automatically cleaned up if the stream stops or aborts due to
--   exception.
--   
--   For example, to print the count of elements processed every second:
--   
--   <pre>
--   &gt; Stream.drain $ Stream.pollCounts (const True) (Stream.rollingMap (-) . Stream.delayPost 1) (FLold.drainBy print)
--             $ Stream.enumerateFrom 0
--   </pre>
--   
--   Note: This may not work correctly on 32-bit machines.
--   
--   <i>Pre-release</i>
pollCounts :: (IsStream t, MonadAsync m) => (a -> Bool) -> (t m Int -> t m Int) -> Fold m Int b -> t m a -> t m a

-- | Scan a stream using the given monadic fold.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.takeWhile (&lt; 10) $ Stream.scan Fold.sum (Stream.fromList [1..10])
--   [0,1,3,6]
--   </pre>
scan :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m b

-- | Postscan a stream using the given monadic fold.
--   
--   The following example extracts the input stream up to a point where
--   the running average of elements is no more than 10:
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Maybe (fromJust)
--   
--   &gt;&gt;&gt; let avg = Fold.teeWith (/) Fold.sum (fmap fromIntegral Fold.length)
--   
--   &gt;&gt;&gt; :{
--    Stream.toList
--     $ Stream.map (fromJust . fst)
--     $ Stream.takeWhile (\(_,x) -&gt; x &lt;= 10)
--     $ Stream.postscan (Fold.tee Fold.last avg) (Stream.enumerateFromTo 1.0 100.0)
--   :}
--   [1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0]
--   </pre>
postscan :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m b

-- | Strict left scan. Like <a>map</a>, <a>scanl'</a> too is a one to one
--   transformation, however it adds an extra element.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.scanl' (+) 0 $ fromList [1,2,3,4]
--   [0,1,3,6,10]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.scanl' (flip (:)) [] $ Stream.fromList [1,2,3,4]
--   [[],[1],[2,1],[3,2,1],[4,3,2,1]]
--   </pre>
--   
--   The output of <a>scanl'</a> is the initial value of the accumulator
--   followed by all the intermediate steps and the final result of
--   <tt>foldl'</tt>.
--   
--   By streaming the accumulated state after each fold step, we can share
--   the state across multiple stages of stream composition. Each stage can
--   modify or extend the state, do some processing with it and emit it for
--   the next stage, thus modularizing the stream processing. This can be
--   useful in stateful or event-driven programming.
--   
--   Consider the following monolithic example, computing the sum and the
--   product of the elements in a stream in one go using a <tt>foldl'</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.foldl' ((s, p) x -&gt; (s + x, p * x)) (0,1) $ Stream.fromList <a>1,2,3,4</a>
--   </pre>
--   
--   Using <tt>scanl'</tt> we can make it modular by computing the sum in
--   the first stage and passing it down to the next stage for computing
--   the product:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--     Stream.foldl' ((_, p) (s, x) -&gt; (s, p * x)) (0,1)
--     $ Stream.scanl' ((s, _) x -&gt; (s + x, x)) (0,1)
--     $ Stream.fromList [1,2,3,4]
--   :}
--   (10,24)
--   </pre>
--   
--   IMPORTANT: <a>scanl'</a> evaluates the accumulator to WHNF. To avoid
--   building lazy expressions inside the accumulator, it is recommended
--   that a strict data structure is used for accumulator.
--   
--   <pre>
--   &gt;&gt;&gt; scanl' f z xs = scanlM' (\a b -&gt; return (f a b)) (return z) xs
--   
--   &gt;&gt;&gt; scanl' f z xs = z `Stream.cons` postscanl' f z xs
--   </pre>
--   
--   See also: <tt>usingStateT</tt>
scanl' :: (IsStream t, Monad m) => (b -> a -> b) -> b -> t m a -> t m b

-- | Like <a>scanl'</a> but with a monadic step function and a monadic
--   seed.
--   
--   <i>Since: 0.4.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
scanlM' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> t m a -> t m b

-- | <tt>scanlMAfter' accumulate initial done stream</tt> is like
--   <tt>scanlM'</tt> except that it provides an additional <tt>done</tt>
--   function to be applied on the accumulator when the stream stops. The
--   result of <tt>done</tt> is also emitted in the stream.
--   
--   This function can be used to allocate a resource in the beginning of
--   the scan and release it when the stream ends or to flush the internal
--   state of the scan at the end.
--   
--   <i>Pre-release</i>
scanlMAfter' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> (b -> m b) -> t m a -> t m b

-- | Like <a>scanl'</a> but does not stream the initial value of the
--   accumulator.
--   
--   <pre>
--   &gt;&gt;&gt; postscanl' f z = postscanlM' (\a b -&gt; return (f a b)) (return z)
--   
--   &gt;&gt;&gt; postscanl' f z xs = Stream.drop 1 $ Stream.scanl' f z xs
--   </pre>
postscanl' :: (IsStream t, Monad m) => (b -> a -> b) -> b -> t m a -> t m b

-- | Like <tt>postscanl'</tt> but with a monadic step function and a
--   monadic seed.
--   
--   <pre>
--   &gt;&gt;&gt; postscanlM' f z xs = Stream.drop 1 $ Stream.scanlM' f z xs
--   </pre>
--   
--   <i>Since: 0.7.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
postscanlM' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> t m a -> t m b

-- | Like scanl' but does not stream the final value of the accumulator.
--   
--   <i>Pre-release</i>
prescanl' :: (IsStream t, Monad m) => (b -> a -> b) -> b -> t m a -> t m b

-- | Like prescanl' but with a monadic step function and a monadic seed.
--   
--   <i>Pre-release</i>
prescanlM' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> t m a -> t m b

-- | Like <a>scanl'</a> but for a non-empty stream. The first element of
--   the stream is used as the initial value of the accumulator. Does
--   nothing if the stream is empty.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.scanl1' (+) $ fromList [1,2,3,4]
--   [1,3,6,10]
--   </pre>
scanl1' :: (IsStream t, Monad m) => (a -> a -> a) -> t m a -> t m a

-- | Like <a>scanl1'</a> but with a monadic step function.
scanl1M' :: (IsStream t, Monad m) => (a -> a -> m a) -> t m a -> t m a

-- | Modify a <tt>t m a -&gt; t m a</tt> stream transformation that accepts
--   a predicate <tt>(a -&gt; b)</tt> to accept <tt>((s, a) -&gt; b)</tt>
--   instead, provided a transformation <tt>t m a -&gt; t m (s, a)</tt>.
--   Convenient to filter with index or time.
--   
--   <pre>
--   filterWithIndex = with indexed filter
--   filterWithAbsTime = with timestamped filter
--   filterWithRelTime = with timeIndexed filter
--   </pre>
--   
--   <i>Pre-release</i>
with :: forall (t :: (Type -> Type) -> Type -> Type) m a b s. Functor (t m) => (t m a -> t m (s, a)) -> (((s, a) -> b) -> t m (s, a) -> t m (s, a)) -> ((s, a) -> b) -> t m a -> t m a

-- | Deletes the first occurrence of the element in the stream that
--   satisfies the given equality predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.deleteBy (==) 3 $ Stream.fromList [1,3,3,5]
--   [1,3,5]
--   </pre>
deleteBy :: (IsStream t, Monad m) => (a -> a -> Bool) -> a -> t m a -> t m a

-- | Include only those elements that pass a predicate.
filter :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m a

-- | Same as <a>filter</a> but with a monadic predicate.
filterM :: (IsStream t, Monad m) => (a -> m Bool) -> t m a -> t m a

-- | Drop repeated elements that are adjacent to each other.
uniq :: (Eq a, IsStream t, Monad m) => t m a -> t m a

-- | Drop repeated elements that are adjacent to each other using the
--   supplied comparison function.
--   
--   @uniq = uniqBy (==)
--   
--   To strip duplicate path separators:
--   
--   <pre>
--   f x y = x == <a>/</a> &amp;&amp; x == y
--   Stream.toList $ Stream.uniqBy f $ Stream.fromList "/<i>a</i>/b"
--   "<i>a</i>b"
--   </pre>
--   
--   Space: <tt>O(1)</tt>
--   
--   See also: <a>nubBy</a>.
--   
--   <i>Pre-release</i>
uniqBy :: (IsStream t, Monad m, Functor (t m)) => (a -> a -> Bool) -> t m a -> t m a

-- | Drop repeated elements anywhere in the stream.
--   
--   <i>Caution: not scalable for infinite streams</i>
--   
--   <i>See also: nubWindowBy</i>
--   
--   <i>Unimplemented</i>
nubBy :: (a -> a -> Bool) -> t m a -> t m a

-- | Drop repeated elements within the specified tumbling window in the
--   stream.
--   
--   <pre>
--   nubBy = nubWindowBy maxBound
--   </pre>
--   
--   <i>Unimplemented</i>
nubWindowBy :: Int -> (a -> a -> Bool) -> t m a -> t m a

-- | Strip all leading and trailing occurrences of an element passing a
--   predicate and make all other consecutive occurrences uniq.
--   
--   <pre>
--   prune p = dropWhileAround p $ uniqBy (x y -&gt; p x &amp;&amp; p y)
--   </pre>
--   
--   <pre>
--   &gt; Stream.prune isSpace (Stream.fromList "  hello      world!   ")
--   "hello world!"
--   </pre>
--   
--   Space: <tt>O(1)</tt>
--   
--   <i>Unimplemented</i>
prune :: (a -> Bool) -> t m a -> t m a

-- | Emit only repeated elements, once.
--   
--   <i>Unimplemented</i>
repeated :: t m a -> t m a

-- | Take first <tt>n</tt> elements from the stream and discard the rest.
take :: (IsStream t, Monad m) => Int -> t m a -> t m a

-- | <tt>takeInterval duration</tt> yields stream elements upto specified
--   time <tt>duration</tt>. The duration starts when the stream is
--   evaluated for the first time, before the first element is yielded. The
--   time duration is checked before generating each element, if the
--   duration has expired the stream stops.
--   
--   The total time taken in executing the stream is guaranteed to be <i>at
--   least</i> <tt>duration</tt>, however, because the duration is checked
--   before generating an element, the upper bound is indeterminate and
--   depends on the time taken in generating and processing the last
--   element.
--   
--   No element is yielded if the duration is zero. At least one element is
--   yielded if the duration is non-zero.
--   
--   <i>Pre-release</i>
takeInterval :: (MonadIO m, IsStream t, TimeUnit64 d) => d -> t m a -> t m a

-- | Take <tt>n</tt> elements at the end of the stream.
--   
--   O(n) space, where n is the number elements taken.
--   
--   <i>Unimplemented</i>
takeLast :: Int -> t m a -> t m a

-- | Take time interval <tt>i</tt> seconds at the end of the stream.
--   
--   O(n) space, where n is the number elements taken.
--   
--   <i>Unimplemented</i>
takeLastInterval :: Double -> t m a -> t m a

-- | End the stream as soon as the predicate fails on an element.
takeWhile :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m a

-- | Same as <a>takeWhile</a> but with a monadic predicate.
takeWhileM :: (IsStream t, Monad m) => (a -> m Bool) -> t m a -> t m a

-- | Take all consecutive elements at the end of the stream for which the
--   predicate is true.
--   
--   O(n) space, where n is the number elements taken.
--   
--   <i>Unimplemented</i>
takeWhileLast :: (a -> Bool) -> t m a -> t m a

-- | Like <a>takeWhile</a> and <a>takeWhileLast</a> combined.
--   
--   O(n) space, where n is the number elements taken from the end.
--   
--   <i>Unimplemented</i>
takeWhileAround :: (a -> Bool) -> t m a -> t m a

-- | Discard first <tt>n</tt> elements from the stream and take the rest.
drop :: (IsStream t, Monad m) => Int -> t m a -> t m a

-- | <tt>dropInterval duration</tt> drops stream elements until specified
--   <tt>duration</tt> has passed. The duration begins when the stream is
--   evaluated for the first time. The time duration is checked
--   <i>after</i> generating a stream element, the element is yielded if
--   the duration has expired otherwise it is dropped.
--   
--   The time elapsed before starting to generate the first element is
--   <i>at most</i> <tt>duration</tt>, however, because the duration expiry
--   is checked after the element is generated, the lower bound is
--   indeterminate and depends on the time taken in generating an element.
--   
--   All elements are yielded if the duration is zero.
--   
--   <i>Pre-release</i>
dropInterval :: (MonadIO m, IsStream t, TimeUnit64 d) => d -> t m a -> t m a

-- | Drop <tt>n</tt> elements at the end of the stream.
--   
--   O(n) space, where n is the number elements dropped.
--   
--   <i>Unimplemented</i>
dropLast :: Int -> t m a -> t m a

-- | Drop time interval <tt>i</tt> seconds at the end of the stream.
--   
--   O(n) space, where n is the number elements dropped.
--   
--   <i>Unimplemented</i>
dropLastInterval :: Int -> t m a -> t m a

-- | Drop elements in the stream as long as the predicate succeeds and then
--   take the rest of the stream.
dropWhile :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m a

-- | Same as <a>dropWhile</a> but with a monadic predicate.
dropWhileM :: (IsStream t, Monad m) => (a -> m Bool) -> t m a -> t m a

-- | Drop all consecutive elements at the end of the stream for which the
--   predicate is true.
--   
--   O(n) space, where n is the number elements dropped.
--   
--   <i>Unimplemented</i>
dropWhileLast :: (a -> Bool) -> t m a -> t m a

-- | Like <a>dropWhile</a> and <a>dropWhileLast</a> combined.
--   
--   O(n) space, where n is the number elements dropped from the end.
--   
--   <i>Unimplemented</i>
dropWhileAround :: (a -> Bool) -> t m a -> t m a

-- | Insert a pure value between successive elements of a stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intersperse ',' $ Stream.fromList "hello"
--   "h,e,l,l,o"
--   </pre>
intersperse :: (IsStream t, MonadAsync m) => a -> t m a -> t m a

-- | Insert an effect and its output before consuming an element of a
--   stream except the first one.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.trace putChar $ Stream.intersperseM (putChar '.' &gt;&gt; return ',') $ Stream.fromList "hello"
--   h.,e.,l.,l.,o"h,e,l,l,o"
--   </pre>
intersperseM :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a

-- | Intersperse a monadic action into the input stream after every
--   <tt>n</tt> elements.
--   
--   <pre>
--   &gt; Stream.toList $ Stream.intersperseBySpan 2 (return ',') $ Stream.fromList "hello"
--   "he,ll,o"
--   </pre>
--   
--   <i>Unimplemented</i>
intersperseBySpan :: Int -> m a -> t m a -> t m a

-- | Insert an effect and its output after consuming an element of a
--   stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.trace putChar $ intersperseSuffix (putChar '.' &gt;&gt; return ',') $ Stream.fromList "hello"
--   h.,e.,l.,l.,o.,"h,e,l,l,o,"
--   </pre>
--   
--   <i>Pre-release</i>
intersperseSuffix :: (IsStream t, Monad m) => m a -> t m a -> t m a

-- | Like <a>intersperseSuffix</a> but intersperses an effectful action
--   into the input stream after every <tt>n</tt> elements and after the
--   last element.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intersperseSuffixBySpan 2 (return ',') $ Stream.fromList "hello"
--   "he,ll,o,"
--   </pre>
--   
--   <i>Pre-release</i>
intersperseSuffixBySpan :: (IsStream t, Monad m) => Int -> m a -> t m a -> t m a

-- | Intersperse a monadic action into the input stream after every
--   <tt>n</tt> seconds.
--   
--   <pre>
--   &gt; import Control.Concurrent (threadDelay)
--   &gt; Stream.drain $ Stream.interjectSuffix 1 (putChar ',') $ Stream.mapM (x -&gt; threadDelay 1000000 &gt;&gt; putChar x) $ Stream.fromList "hello"
--   h,e,l,l,o
--   </pre>
--   
--   <i>Pre-release</i>
interjectSuffix :: (IsStream t, MonadAsync m) => Double -> m a -> t m a -> t m a

-- | Insert a side effect before consuming an element of a stream except
--   the first one.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.trace putChar $ Stream.intersperseM_ (putChar '.') $ Stream.fromList "hello"
--   h.e.l.l.o
--   </pre>
--   
--   <i>Pre-release</i>
intersperseM_ :: (IsStream t, Monad m) => m b -> t m a -> t m a

-- | Introduce a delay of specified seconds before consuming an element of
--   the stream except the first one.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.timestamped $ Stream.delay 1 $ Stream.enumerateFromTo 1 3
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),1)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),2)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),3)
--   </pre>
delay :: (IsStream t, MonadIO m) => Double -> t m a -> t m a

-- | Insert a side effect after consuming an element of a stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ putChar $ Stream.intersperseSuffix_ (threadDelay 1000000) $ Stream.fromList "hello"
--   hello
--   </pre>
--   
--   <i>Pre-release</i>
intersperseSuffix_ :: (IsStream t, Monad m) => m b -> t m a -> t m a

-- | Introduce a delay of specified seconds after consuming an element of a
--   stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.timestamped $ Stream.delayPost 1 $ Stream.enumerateFromTo 1 3
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),1)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),2)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),3)
--   </pre>
--   
--   <i>Pre-release</i>
delayPost :: (IsStream t, MonadIO m) => Double -> t m a -> t m a

-- | Insert a side effect before consuming an element of a stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.trace putChar $ Stream.interspersePrefix_ (putChar '.' &gt;&gt; return ',') $ Stream.fromList "hello"
--   .h.e.l.l.o"hello"
--   </pre>
--   
--   Same as <a>trace_</a> but may be concurrent.
--   
--   <i>Concurrent</i>
--   
--   <i>Pre-release</i>
interspersePrefix_ :: (IsStream t, MonadAsync m) => m b -> t m a -> t m a

-- | Introduce a delay of specified seconds before consuming an element of
--   a stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.timestamped $ Stream.delayPre 1 $ Stream.enumerateFromTo 1 3
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),1)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),2)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),3)
--   </pre>
--   
--   <i>Pre-release</i>
delayPre :: (IsStream t, MonadIO m) => Double -> t m a -> t m a

-- | <tt>insertBy cmp elem stream</tt> inserts <tt>elem</tt> before the
--   first element in <tt>stream</tt> that is less than <tt>elem</tt> when
--   compared using <tt>cmp</tt>.
--   
--   <pre>
--   insertBy cmp x = <tt>mergeBy</tt> cmp (<tt>fromPure</tt> x)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.insertBy compare 2 $ Stream.fromList [1,3,5]
--   [1,2,3,5]
--   </pre>
insertBy :: (IsStream t, Monad m) => (a -> a -> Ordering) -> a -> t m a -> t m a

-- | Returns the elements of the stream in reverse order. The stream must
--   be finite. Note that this necessarily buffers the entire stream in
--   memory.
--   
--   <pre>
--   &gt;&gt;&gt; reverse = Stream.foldlT (flip Stream.cons) Stream.nil
--   </pre>
--   
--   <i>Since 0.7.0 (Monad m constraint)</i>
--   
--   <i>Since: 0.1.1</i>
reverse :: (IsStream t, Monad m) => t m a -> t m a

-- | Like <a>reverse</a> but several times faster, requires a
--   <a>Storable</a> instance.
--   
--   <i>Pre-release</i>
reverse' :: (IsStream t, MonadIO m, Storable a) => t m a -> t m a

-- | Buffer until the next element in sequence arrives. The function
--   argument determines the difference in sequence numbers. This could be
--   useful in implementing sequenced streams, for example, TCP reassembly.
--   
--   <i>Unimplemented</i>
reassembleBy :: Fold m a b -> (a -> a -> Int) -> t m a -> t m b

-- | <pre>
--   indexed = Stream.postscanl' (\(i, _) x -&gt; (i + 1, x)) (-1,undefined)
--   indexed = Stream.zipWith (,) (Stream.enumerateFrom 0)
--   </pre>
--   
--   Pair each element in a stream with its index, starting from index 0.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.indexed $ Stream.fromList "hello"
--   [(0,'h'),(1,'e'),(2,'l'),(3,'l'),(4,'o')]
--   </pre>
indexed :: (IsStream t, Monad m) => t m a -> t m (Int, a)

-- | <pre>
--   indexedR n = Stream.postscanl' (\(i, _) x -&gt; (i - 1, x)) (n + 1,undefined)
--   indexedR n = Stream.zipWith (,) (Stream.enumerateFromThen n (n - 1))
--   </pre>
--   
--   Pair each element in a stream with its index, starting from the given
--   index <tt>n</tt> and counting down.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.indexedR 10 $ Stream.fromList "hello"
--   [(10,'h'),(9,'e'),(8,'l'),(7,'l'),(6,'o')]
--   </pre>
indexedR :: (IsStream t, Monad m) => Int -> t m a -> t m (Int, a)
timestamped :: (IsStream t, MonadAsync m, Functor (t m)) => t m a -> t m (AbsTime, a)

-- | Pair each element in a stream with an absolute timestamp, using a
--   clock of specified granularity. The timestamp is generated just before
--   the element is consumed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.timestampWith 0.01 $ Stream.delay 1 $ Stream.enumerateFromTo 1 3
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),1)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),2)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),3)
--   </pre>
--   
--   <i>Pre-release</i>
timestampWith :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m a -> t m (AbsTime, a)

-- | Pair each element in a stream with relative times starting from 0,
--   using a 10 ms granularity clock. The time is measured just before the
--   element is consumed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.timeIndexed $ Stream.delay 1 $ Stream.enumerateFromTo 1 3
--   (RelTime64 (NanoSecond64 ...),1)
--   (RelTime64 (NanoSecond64 ...),2)
--   (RelTime64 (NanoSecond64 ...),3)
--   </pre>
--   
--   <i>Pre-release</i>
timeIndexed :: (IsStream t, MonadAsync m, Functor (t m)) => t m a -> t m (RelTime64, a)

-- | Pair each element in a stream with relative times starting from 0,
--   using a clock with the specified granularity. The time is measured
--   just before the element is consumed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.timeIndexWith 0.01 $ Stream.delay 1 $ Stream.enumerateFromTo 1 3
--   (RelTime64 (NanoSecond64 ...),1)
--   (RelTime64 (NanoSecond64 ...),2)
--   (RelTime64 (NanoSecond64 ...),3)
--   </pre>
--   
--   <i>Pre-release</i>
timeIndexWith :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m a -> t m (RelTime64, a)

-- | Find all the indices where the element in the stream satisfies the
--   given predicate.
--   
--   <pre>
--   findIndices = fold Fold.findIndices
--   </pre>
findIndices :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m Int

-- | Find all the indices where the value of the element in the stream is
--   equal to the given value.
--   
--   <pre>
--   elemIndices a = findIndices (== a)
--   </pre>
elemIndices :: (IsStream t, Eq a, Monad m) => a -> t m a -> t m Int

-- | Like <a>rollingMap</a> but with an effectful map function.
--   
--   <i>Pre-release</i>
rollingMapM :: (IsStream t, Monad m) => (a -> a -> m b) -> t m a -> t m b

-- | Apply a function on every two successive elements of a stream. If the
--   stream consists of a single element the output is an empty stream.
--   
--   This is the stream equivalent of the list idiom <tt>zipWith f xs (tail
--   xs)</tt>.
--   
--   <i>Pre-release</i>
rollingMap :: (IsStream t, Monad m) => (a -> a -> b) -> t m a -> t m b

-- | In a stream of <a>Maybe</a>s, discard <a>Nothing</a>s and unwrap
--   <a>Just</a>s.
--   
--   <i>Pre-release</i>
catMaybes :: (IsStream t, Monad m, Functor (t m)) => t m (Maybe a) -> t m a

-- | Map a <a>Maybe</a> returning function to a stream, filter out the
--   <a>Nothing</a> elements, and return a stream of values extracted from
--   <a>Just</a>.
--   
--   Equivalent to:
--   
--   <pre>
--   mapMaybe f = Stream.map <a>fromJust</a> . Stream.filter <a>isJust</a> . Stream.map f
--   </pre>
mapMaybe :: (IsStream t, Monad m) => (a -> Maybe b) -> t m a -> t m b

-- | Like <a>mapMaybe</a> but maps a monadic function.
--   
--   Equivalent to:
--   
--   <pre>
--   mapMaybeM f = Stream.map <a>fromJust</a> . Stream.filter <a>isJust</a> . Stream.mapM f
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   streams)</i>
mapMaybeM :: (IsStream t, MonadAsync m, Functor (t m)) => (a -> m (Maybe b)) -> t m a -> t m b

-- | Discard <a>Right</a>s and unwrap <a>Left</a>s in an <a>Either</a>
--   stream.
--   
--   <i>Pre-release</i>
lefts :: (IsStream t, Monad m, Functor (t m)) => t m (Either a b) -> t m a

-- | Discard <a>Left</a>s and unwrap <a>Right</a>s in an <a>Either</a>
--   stream.
--   
--   <i>Pre-release</i>
rights :: (IsStream t, Monad m, Functor (t m)) => t m (Either a b) -> t m b

-- | Remove the either wrapper and flatten both lefts and as well as rights
--   in the output stream.
--   
--   <i>Pre-release</i>
both :: Functor (t m) => t m (Either a a) -> t m a

-- | Make the stream producer and consumer run concurrently by introducing
--   a buffer between them. The producer thread evaluates the input stream
--   until the buffer fills, it terminates if the buffer is full and a
--   worker thread is kicked off again to evaluate the remaining stream
--   when there is space in the buffer. The consumer consumes the stream
--   lazily from the buffer.
--   
--   <i>Since: 0.2.0 (Streamly)</i>
mkAsync :: (IsStream t, MonadAsync m) => t m a -> t m a

-- | Make the stream producer and consumer run concurrently by introducing
--   a buffer between them. The producer thread evaluates the input stream
--   until the buffer fills, it blocks if the buffer is full until there is
--   space in the buffer. The consumer consumes the stream lazily from the
--   buffer.
--   
--   <pre>
--   mkParallel = IsStream.fromStreamD . mkParallelD . IsStream.toStreamD
--   </pre>
--   
--   <i>Pre-release</i>
mkParallel :: (IsStream t, MonadAsync m) => t m a -> t m a

-- | Same as <a>|$</a>.
--   
--   <i>Internal</i>
applyAsync :: (IsStream t, MonadAsync m) => (t m a -> t m b) -> t m a -> t m b

-- | Parallel transform application operator; applies a stream
--   transformation function <tt>t m a -&gt; t m b</tt> to a stream <tt>t m
--   a</tt> concurrently; the input stream is evaluated asynchronously in
--   an independent thread yielding elements to a buffer and the
--   transformation function runs in another thread consuming the input
--   from the buffer. <a>|$</a> is just like regular function application
--   operator <a>$</a> except that it is concurrent.
--   
--   If you read the signature as <tt>(t m a -&gt; t m b) -&gt; (t m a
--   -&gt; t m b)</tt> you can look at it as a transformation that converts
--   a transform function to a buffered concurrent transform function.
--   
--   The following code prints a value every second even though each stage
--   adds a 1 second delay.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.drain $
--      Stream.mapM (\x -&gt; threadDelay 1000000 &gt;&gt; print x)
--        |$ Stream.replicateM 3 (threadDelay 1000000 &gt;&gt; return 1)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|$) :: (IsStream t, MonadAsync m) => (t m a -> t m b) -> t m a -> t m b
infixr 0 |$

-- | Same as <a>|$</a> but with arguments reversed.
--   
--   (|&amp;) = flip (|$)
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|&) :: (IsStream t, MonadAsync m) => t m a -> (t m a -> t m b) -> t m b
infixl 1 |&

-- | Specify the maximum number of threads that can be spawned concurrently
--   for any concurrent combinator in a stream. A value of 0 resets the
--   thread limit to default, a negative value means there is no limit. The
--   default value is 1500. <a>maxThreads</a> does not affect
--   <tt>ParallelT</tt> streams as they can use unbounded number of
--   threads.
--   
--   When the actions in a stream are IO bound, having blocking IO calls,
--   this option can be used to control the maximum number of in-flight IO
--   requests. When the actions are CPU bound this option can be used to
--   control the amount of CPU used by the stream.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxThreads :: IsStream t => Int -> t m a -> t m a

-- | Specify the maximum size of the buffer for storing the results from
--   concurrent computations. If the buffer becomes full we stop spawning
--   more concurrent tasks until there is space in the buffer. A value of 0
--   resets the buffer size to default, a negative value means there is no
--   limit. The default value is 1500.
--   
--   CAUTION! using an unbounded <a>maxBuffer</a> value (i.e. a negative
--   value) coupled with an unbounded <a>maxThreads</a> value is a recipe
--   for disaster in presence of infinite streams, or very large streams.
--   Especially, it must not be used when <a>pure</a> is used in
--   <tt>ZipAsyncM</tt> streams as <a>pure</a> in applicative zip streams
--   generates an infinite stream causing unbounded concurrent generation
--   with no limit on the buffer or threads.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxBuffer :: IsStream t => Int -> t m a -> t m a

-- | Evaluate the input stream continuously and keep only the oldest
--   <tt>n</tt> elements in the buffer, discard the new ones when the
--   buffer is full. When the output stream is evaluated it consumes the
--   values from the buffer in a FIFO manner.
--   
--   <i>Unimplemented</i>
sampleOld :: Int -> t m a -> t m a

-- | Evaluate the input stream continuously and keep only the latest
--   <tt>n</tt> elements in a ring buffer, keep discarding the older ones
--   to make space for the new ones. When the output stream is evaluated it
--   consumes the values from the buffer in a FIFO manner.
--   
--   <i>Unimplemented</i>
sampleNew :: Int -> t m a -> t m a

-- | Like <a>sampleNew</a> but samples at uniform intervals to match the
--   consumer rate. Note that <a>sampleNew</a> leads to non-uniform
--   sampling depending on the consumer pattern.
--   
--   <i>Unimplemented</i>
sampleRate :: Double -> t m a -> t m a

-- | Specifies the stream yield rate in yields per second (<tt>Hertz</tt>).
--   We keep accumulating yield credits at <a>rateGoal</a>. At any point of
--   time we allow only as many yields as we have accumulated as per
--   <a>rateGoal</a> since the start of time. If the consumer or the
--   producer is slower or faster, the actual rate may fall behind or
--   exceed <a>rateGoal</a>. We try to recover the gap between the two by
--   increasing or decreasing the pull rate from the producer. However, if
--   the gap becomes more than <a>rateBuffer</a> we try to recover only as
--   much as <a>rateBuffer</a>.
--   
--   <a>rateLow</a> puts a bound on how low the instantaneous rate can go
--   when recovering the rate gap. In other words, it determines the
--   maximum yield latency. Similarly, <a>rateHigh</a> puts a bound on how
--   high the instantaneous rate can go when recovering the rate gap. In
--   other words, it determines the minimum yield latency. We reduce the
--   latency by increasing concurrency, therefore we can say that it puts
--   an upper bound on concurrency.
--   
--   If the <a>rateGoal</a> is 0 or negative the stream never yields a
--   value. If the <a>rateBuffer</a> is 0 or negative we do not attempt to
--   recover.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
data Rate
Rate :: Double -> Double -> Double -> Int -> Rate

-- | The lower rate limit
[rateLow] :: Rate -> Double

-- | The target rate we want to achieve
[rateGoal] :: Rate -> Double

-- | The upper rate limit
[rateHigh] :: Rate -> Double

-- | Maximum slack from the goal
[rateBuffer] :: Rate -> Int

-- | Specify the pull rate of a stream. A <a>Nothing</a> value resets the
--   rate to default which is unlimited. When the rate is specified,
--   concurrent production may be ramped up or down automatically to
--   achieve the specified yield rate. The specific behavior for different
--   styles of <a>Rate</a> specifications is documented under <a>Rate</a>.
--   The effective maximum production rate achieved by a stream is governed
--   by:
--   
--   <ul>
--   <li>The <a>maxThreads</a> limit</li>
--   <li>The <a>maxBuffer</a> limit</li>
--   <li>The maximum rate that the stream producer can achieve</li>
--   <li>The maximum rate that the stream consumer can achieve</li>
--   </ul>
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
rate :: IsStream t => Maybe Rate -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r (2*r) maxBound)</tt>
--   
--   Specifies the average production rate of a stream in number of yields
--   per second (i.e. <tt>Hertz</tt>). Concurrent production is ramped up
--   or down automatically to achieve the specified average yield rate. The
--   rate can go down to half of the specified rate on the lower side and
--   double of the specified rate on the higher side.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
avgRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r (2*r) maxBound)</tt>
--   
--   Specifies the minimum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go below the
--   specified rate, even though it may possibly go above it at times, the
--   upper limit is double of the specified rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
minRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r r maxBound)</tt>
--   
--   Specifies the maximum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go above the
--   specified rate, even though it may possibly go below it at times, the
--   lower limit is half of the specified rate. This can be useful in
--   applications where certain resource usage must not be allowed to go
--   beyond certain limits.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
maxRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r r 0)</tt>
--   
--   Specifies a constant yield rate. If for some reason the actual rate
--   goes above or below the specified rate we do not try to recover it by
--   increasing or decreasing the rate in future. This can be useful in
--   applications like graphics frame refresh where we need to maintain a
--   constant refresh rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
constRate :: IsStream t => Double -> t m a -> t m a

-- | Print debug information about an SVar when the stream ends
--   
--   <i>Pre-release</i>
inspectMode :: IsStream t => t m a -> t m a

-- | Strict left scan with an extraction function. Like <a>scanl'</a>, but
--   applies a user supplied extraction function (the third argument) at
--   each step. This is designed to work with the <tt>foldl</tt> library.
--   The suffix <tt>x</tt> is a mnemonic for extraction.
--   
--   <i>Since 0.2.0</i>
--   
--   <i>Since: 0.7.0 (Monad m constraint)</i>

-- | <i>Deprecated: Please use scanl followed by map instead.</i>
scanx :: (IsStream t, Monad m) => (x -> a -> x) -> x -> (x -> b) -> t m a -> t m b


-- | Reduce streams by streams, folds or parsers.
module Streamly.Internal.Data.Stream.IsStream.Reduce

-- | Drop prefix from the input stream if present.
--   
--   Space: <tt>O(1)</tt>
--   
--   <i>Unimplemented</i> - Help wanted.
dropPrefix :: t m a -> t m a -> t m a

-- | Drop all matching infix from the input stream if present. Infix stream
--   may be consumed multiple times.
--   
--   Space: <tt>O(n)</tt> where n is the length of the infix.
--   
--   <i>Unimplemented</i> - Help wanted.
dropInfix :: t m a -> t m a -> t m a

-- | Drop suffix from the input stream if present. Suffix stream may be
--   consumed multiple times.
--   
--   Space: <tt>O(n)</tt> where n is the length of the suffix.
--   
--   <i>Unimplemented</i> - Help wanted.
dropSuffix :: t m a -> t m a -> t m a

-- | Apply a <a>Fold</a> repeatedly on a stream and emit the fold outputs
--   in the output stream.
--   
--   To sum every two contiguous elements in a stream:
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.take 2 Fold.sum
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany f $ Stream.fromList [1..10]
--   [3,7,11,15,19]
--   </pre>
--   
--   On an empty stream the output is empty:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany f $ Stream.fromList []
--   []
--   </pre>
--   
--   Note <tt>Stream.foldMany (Fold.take 0)</tt> would result in an
--   infinite loop in a non-empty stream.
foldMany :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m b

-- | Like <a>foldMany</a> but appends empty fold output if the fold and
--   stream termination aligns:
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.take 2 Fold.sum
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.foldManyPost f $ Stream.fromList []
--   [0]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.foldManyPost f $ Stream.fromList [1..9]
--   [3,7,11,15,9]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.foldManyPost f $ Stream.fromList [1..10]
--   [3,7,11,15,19,0]
--   </pre>
--   
--   <i>Pre-release</i>
foldManyPost :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m b

-- | Like <a>foldMany</a> but using the <a>Refold</a> type instead of
--   <a>Fold</a>.
--   
--   <i>Pre-release</i>
refoldMany :: (IsStream t, Monad m) => Refold m c a b -> m c -> t m a -> t m b

-- | Apply a stream of folds to an input stream and emit the results in the
--   output stream.
--   
--   <i>Unimplemented</i>
foldSequence :: t m (Fold m a b) -> t m a -> t m b

-- | Iterate a fold generator on a stream. The initial value <tt>b</tt> is
--   used to generate the first fold, the fold is applied on the stream and
--   the result of the fold is used to generate the next fold and so on.
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Monoid (Sum(..))
--   &gt;&gt;&gt; f x = return (Fold.take 2 (Fold.sconcat x))
--   &gt;&gt;&gt; s = Stream.map Sum $ Stream.fromList [1..10]
--   &gt;&gt;&gt; Stream.toList $ Stream.map getSum $ Stream.foldIterateM f (pure 0) s
--   [3,10,21,36,55,55]
--   </pre>
--   
--   This is the streaming equivalent of monad like sequenced application
--   of folds where next fold is dependent on the previous fold.
--   
--   <i>Pre-release</i>
foldIterateM :: (IsStream t, Monad m) => (b -> m (Fold m a b)) -> m b -> t m a -> t m b

-- | Like <a>foldIterateM</a> but using the <a>Refold</a> type instead.
--   This could be much more efficient due to stream fusion.
--   
--   <i>Internal</i>
refoldIterateM :: (IsStream t, Monad m) => Refold m b a b -> m b -> t m a -> t m b

-- | Group the input stream into groups of <tt>n</tt> elements each and
--   then fold each group using the provided fold function.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.chunksOf 2 Fold.sum (Stream.enumerateFromTo 1 10)
--   [3,7,11,15,19]
--   </pre>
--   
--   This can be considered as an n-fold version of <a>take</a> where we
--   apply <a>take</a> repeatedly on the leftover stream until the stream
--   exhausts.
--   
--   <pre>
--   chunksOf n f = foldMany (FL.take n f)
--   </pre>
chunksOf :: (IsStream t, Monad m) => Int -> Fold m a b -> t m a -> t m b

-- | <tt>arraysOf n stream</tt> groups the elements in the input stream
--   into arrays of <tt>n</tt> elements each.
--   
--   Same as the following but may be more efficient:
--   
--   <pre>
--   arraysOf n = Stream.foldMany (A.writeN n)
--   </pre>
--   
--   <i>Pre-release</i>
arraysOf :: (IsStream t, MonadIO m, Storable a) => Int -> t m a -> t m (Array a)

-- | Group the input stream into windows of <tt>n</tt> second each and then
--   fold each group using the provided fold function.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 5 $ Stream.intervalsOf 1 Fold.sum $ Stream.constRate 2 $ Stream.enumerateFrom 1
--   [...,...,...,...,...]
--   </pre>
intervalsOf :: (IsStream t, MonadAsync m) => Double -> Fold m a b -> t m a -> t m b

-- | Like <a>chunksOf</a> but if the chunk is not completed within the
--   specified time interval then emit whatever we have collected till now.
--   The chunk timeout is reset whenever a chunk is emitted.
--   
--   <pre>
--   &gt;&gt;&gt; s = Stream.delayPost 0.3 $ Stream.fromList [1..1000]
--   
--   &gt;&gt;&gt; f = Stream.mapM_ print $ Stream.chunksOfTimeout 5 1 Fold.toList s
--   </pre>
--   
--   <i>Pre-release</i>
chunksOfTimeout :: (IsStream t, MonadAsync m, Functor (t m)) => Int -> Double -> Fold m a b -> t m a -> t m b

-- | Split on an infixed separator element, dropping the separator. The
--   supplied <a>Fold</a> is applied on the split segments. Splits the
--   stream on separator elements determined by the supplied predicate,
--   separator is considered as infixed between two segments:
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' p xs = Stream.toList $ Stream.splitOn p Fold.toList (Stream.fromList xs)
--   
--   &gt;&gt;&gt; splitOn' (== '.') "a.b"
--   ["a","b"]
--   </pre>
--   
--   An empty stream is folded to the default value of the fold:
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') ""
--   [""]
--   </pre>
--   
--   If one or both sides of the separator are missing then the empty
--   segment on that side is folded to the default output of the fold:
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') "."
--   ["",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') ".a"
--   ["","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') "a."
--   ["a",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') "a..b"
--   ["a","","b"]
--   </pre>
--   
--   splitOn is an inverse of intercalating single element:
--   
--   <pre>
--   Stream.intercalate (Stream.fromPure '.') Unfold.fromList . Stream.splitOn (== '.') Fold.toList === id
--   </pre>
--   
--   Assuming the input stream does not contain the separator:
--   
--   <pre>
--   Stream.splitOn (== '.') Fold.toList . Stream.intercalate (Stream.fromPure '.') Unfold.fromList === id
--   </pre>
splitOn :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Split on a suffixed separator element, dropping the separator. The
--   supplied <a>Fold</a> is applied on the split segments.
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' p xs = Stream.toList $ Stream.splitOnSuffix p Fold.toList (Stream.fromList xs)
--   
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a.b."
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a."
--   ["a"]
--   </pre>
--   
--   An empty stream results in an empty output stream:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') ""
--   []
--   </pre>
--   
--   An empty segment consisting of only a suffix is folded to the default
--   output of the fold:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "."
--   [""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a..b.."
--   ["a","","b",""]
--   </pre>
--   
--   A suffix is optional at the end of the stream:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a"
--   ["a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') ".a"
--   ["","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a.b"
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   lines = splitOnSuffix (== '\n')
--   </pre>
--   
--   <a>splitOnSuffix</a> is an inverse of <tt>intercalateSuffix</tt> with
--   a single element:
--   
--   <pre>
--   Stream.intercalateSuffix (Stream.fromPure '.') Unfold.fromList . Stream.splitOnSuffix (== '.') Fold.toList === id
--   </pre>
--   
--   Assuming the input stream does not contain the separator:
--   
--   <pre>
--   Stream.splitOnSuffix (== '.') Fold.toList . Stream.intercalateSuffix (Stream.fromPure '.') Unfold.fromList === id
--   </pre>
splitOnSuffix :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Split on a prefixed separator element, dropping the separator. The
--   supplied <a>Fold</a> is applied on the split segments.
--   
--   <pre>
--   &gt; splitOnPrefix' p xs = Stream.toList $ Stream.splitOnPrefix p (Fold.toList) (Stream.fromList xs)
--   &gt; splitOnPrefix' (== <a>.</a>) ".a.b"
--   ["a","b"]
--   </pre>
--   
--   An empty stream results in an empty output stream: <tt> &gt;
--   splitOnPrefix' (== <a>.</a>) "" [] </tt>
--   
--   An empty segment consisting of only a prefix is folded to the default
--   output of the fold:
--   
--   <pre>
--   &gt; splitOnPrefix' (== <a>.</a>) "."
--   [""]
--   
--   &gt; splitOnPrefix' (== <a>.</a>) ".a.b."
--   ["a","b",""]
--   
--   &gt; splitOnPrefix' (== <a>.</a>) ".a..b"
--   ["a","","b"]
--   </pre>
--   
--   A prefix is optional at the beginning of the stream:
--   
--   <pre>
--   &gt; splitOnPrefix' (== <a>.</a>) "a"
--   ["a"]
--   
--   &gt; splitOnPrefix' (== <a>.</a>) "a.b"
--   ["a","b"]
--   </pre>
--   
--   <a>splitOnPrefix</a> is an inverse of <tt>intercalatePrefix</tt> with
--   a single element:
--   
--   <pre>
--   Stream.intercalatePrefix (Stream.fromPure '.') Unfold.fromList . Stream.splitOnPrefix (== '.') Fold.toList === id
--   </pre>
--   
--   Assuming the input stream does not contain the separator:
--   
--   <pre>
--   Stream.splitOnPrefix (== '.') Fold.toList . Stream.intercalatePrefix (Stream.fromPure '.') Unfold.fromList === id
--   </pre>
--   
--   <i>Unimplemented</i>
splitOnPrefix :: (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Like <a>splitOnSuffix</a> but keeps the suffix attached to the
--   resulting splits.
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' p xs = Stream.toList $ splitWithSuffix p Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') ""
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "."
--   ["."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a"
--   ["a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') ".a"
--   [".","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a."
--   ["a."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a.b"
--   ["a.","b"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a.b."
--   ["a.","b."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a..b.."
--   ["a.",".","b.","."]
--   </pre>
splitWithSuffix :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Like <a>splitOnSeq</a> but splits the separator as well, as an infix
--   token.
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ pat xs = Stream.toList $ Stream.splitBySeq (Array.fromList pat) Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "" "hello"
--   ["h","","e","","l","","l","","o"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "hello" ""
--   [""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "hello" "hello"
--   ["","hello",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "x" "hello"
--   ["hello"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "h" "hello"
--   ["","h","ello"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "o" "hello"
--   ["hell","o",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "e" "hello"
--   ["h","e","llo"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "l" "hello"
--   ["he","l","","l","o"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn'_ "ll" "hello"
--   ["he","ll","o"]
--   </pre>
--   
--   <i>Pre-release</i>
splitBySeq :: (IsStream t, MonadAsync m, Storable a, Enum a, Eq a) => Array a -> Fold m a b -> t m a -> t m b

-- | Like <tt>splitOn</tt> but the separator is a sequence of elements
--   instead of a single element.
--   
--   For illustration, let's define a function that operates on pure lists:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' pat xs = Stream.toList $ Stream.splitOnSeq (Array.fromList pat) Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "" "hello"
--   ["h","e","l","l","o"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "hello" ""
--   [""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "hello" "hello"
--   ["",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "x" "hello"
--   ["hello"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "h" "hello"
--   ["","ello"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "o" "hello"
--   ["hell",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "e" "hello"
--   ["h","llo"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "l" "hello"
--   ["he","","o"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSeq' "ll" "hello"
--   ["he","o"]
--   </pre>
--   
--   <a>splitOnSeq</a> is an inverse of <tt>intercalate</tt>. The following
--   law always holds:
--   
--   <pre>
--   intercalate . splitOnSeq == id
--   </pre>
--   
--   The following law holds when the separator is non-empty and contains
--   none of the elements present in the input lists:
--   
--   <pre>
--   splitOnSeq . intercalate == id
--   </pre>
--   
--   <i>Pre-release</i>
splitOnSeq :: (IsStream t, MonadIO m, Storable a, Enum a, Eq a) => Array a -> Fold m a b -> t m a -> t m b

-- | Like <tt>splitSuffixBy</tt> but the separator is a sequence of
--   elements, instead of a predicate for a single element.
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ pat xs = Stream.toList $ Stream.splitOnSuffixSeq (Array.fromList pat) Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." ""
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." "."
--   [""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." "a"
--   ["a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." ".a"
--   ["","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." "a."
--   ["a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." "a.b"
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." "a.b."
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffixSeq_ "." "a..b.."
--   ["a","","b",""]
--   </pre>
--   
--   <pre>
--   lines = splitOnSuffixSeq "\n"
--   </pre>
--   
--   <a>splitOnSuffixSeq</a> is an inverse of <tt>intercalateSuffix</tt>.
--   The following law always holds:
--   
--   <pre>
--   intercalateSuffix . splitOnSuffixSeq == id
--   </pre>
--   
--   The following law holds when the separator is non-empty and contains
--   none of the elements present in the input lists:
--   
--   <pre>
--   splitSuffixOn . intercalateSuffix == id
--   </pre>
--   
--   <i>Pre-release</i>
splitOnSuffixSeq :: (IsStream t, MonadIO m, Storable a, Enum a, Eq a) => Array a -> Fold m a b -> t m a -> t m b

-- | Like <a>splitOnSuffixSeq</a> but keeps the suffix intact in the
--   splits.
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' pat xs = Stream.toList $ Stream.splitWithSuffixSeq (Array.fromList pat) Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." ""
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." "."
--   ["."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." "a"
--   ["a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." ".a"
--   [".","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." "a."
--   ["a."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." "a.b"
--   ["a.","b"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." "a.b."
--   ["a.","b."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffixSeq' "." "a..b.."
--   ["a.",".","b.","."]
--   </pre>
--   
--   <i>Pre-release</i>
splitWithSuffixSeq :: (IsStream t, MonadIO m, Storable a, Enum a, Eq a) => Array a -> Fold m a b -> t m a -> t m b

-- | <tt>classifySessionsBy tick keepalive predicate timeout fold
--   stream</tt> classifies an input event <tt>stream</tt> consisting of
--   <tt>(timestamp, (key, value))</tt> into sessions based on the
--   <tt>key</tt>, folding all the values corresponding to the same key
--   into a session using the supplied <tt>fold</tt>.
--   
--   When the fold terminates or a <tt>timeout</tt> occurs, a tuple
--   consisting of the session key and the folded value is emitted in the
--   output stream. The timeout is measured from the first event in the
--   session. If the <tt>keepalive</tt> option is set to <a>True</a> the
--   timeout is reset to 0 whenever an event is received.
--   
--   The <tt>timestamp</tt> in the input stream is an absolute time from
--   some epoch, characterizing the time when the input event was
--   generated. The notion of current time is maintained by a monotonic
--   event time clock using the timestamps seen in the input stream. The
--   latest timestamp seen till now is used as the base for the current
--   time. When no new events are seen, a timer is started with a clock
--   resolution of <tt>tick</tt> seconds. This timer is used to detect
--   session timeouts in the absence of new events.
--   
--   To ensure an upper bound on the memory used the number of sessions can
--   be limited to an upper bound. If the ejection <tt>predicate</tt>
--   returns <a>True</a>, the oldest session is ejected before inserting a
--   new session.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.mapM_ print
--       $ Stream.classifySessionsBy 1 False (const (return False)) 3 (Fold.take 3 Fold.toList)
--       $ Stream.timestamped
--       $ Stream.delay 0.1
--       $ (,) &lt;$&gt; Stream.fromList [1,2,3] &lt;*&gt; Stream.fromList ['a','b','c']
--   :}
--   (1,"abc")
--   (2,"abc")
--   (3,"abc")
--   </pre>
--   
--   <i>Pre-release</i>
classifySessionsBy :: (IsStream t, MonadAsync m, Ord k) => Double -> Bool -> (Int -> m Bool) -> Double -> Fold m a b -> t m (AbsTime, (k, a)) -> t m (k, b)

-- | Same as <a>classifySessionsBy</a> with a timer tick of 1 second and
--   keepalive option set to <a>False</a>.
--   
--   <pre>
--   classifySessionsOf = classifySessionsBy 1 False
--   </pre>
--   
--   <i>Pre-release</i>
classifySessionsOf :: (IsStream t, MonadAsync m, Ord k) => (Int -> m Bool) -> Double -> Fold m a b -> t m (AbsTime, (k, a)) -> t m (k, b)

-- | Same as <a>classifySessionsBy</a> with a timer tick of 1 second and
--   keepalive option set to <a>True</a>.
--   
--   <pre>
--   classifyKeepAliveSessions = classifySessionsBy 1 True
--   </pre>
--   
--   <i>Pre-release</i>
classifyKeepAliveSessions :: (IsStream t, MonadAsync m, Ord k) => (Int -> m Bool) -> Double -> Fold m a b -> t m (AbsTime, (k, a)) -> t m (k, b)

-- | Apply a <a>Parser</a> repeatedly on a stream and emit the parsed
--   values in the output stream.
--   
--   This is the streaming equivalent of the <a>many</a> parse combinator.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.parseMany (Parser.takeBetween 0 2 Fold.sum) $ Stream.fromList [1..10]
--   [3,7,11,15,19]
--   </pre>
--   
--   <pre>
--   &gt; Stream.toList $ Stream.parseMany (Parser.line Fold.toList) $ Stream.fromList "hello\nworld"
--   ["hello\n","world"]
--   </pre>
--   
--   <pre>
--   foldMany f = parseMany (fromFold f)
--   </pre>
--   
--   Known Issues: When the parser fails there is no way to get the
--   remaining stream.
--   
--   <i>Pre-release</i>
parseMany :: (IsStream t, MonadThrow m) => Parser m a b -> t m a -> t m b
parseManyD :: (IsStream t, MonadThrow m) => Parser m a b -> t m a -> t m b

-- | <tt>parseManyTill collect test stream</tt> tries the parser
--   <tt>test</tt> on the input, if <tt>test</tt> fails it backtracks and
--   tries <tt>collect</tt>, after <tt>collect</tt> succeeds <tt>test</tt>
--   is tried again and so on. The parser stops when <tt>test</tt>
--   succeeds. The output of <tt>test</tt> is discarded and the output of
--   <tt>collect</tt> is emitted in the output stream. The parser fails if
--   <tt>collect</tt> fails.
--   
--   <i>Unimplemented</i>
parseManyTill :: Parser m a b -> Parser m a x -> t m a -> t m b

-- | Apply a stream of parsers to an input stream and emit the results in
--   the output stream.
--   
--   <i>Pre-release</i>
parseSequence :: t m (Parser m a b) -> t m a -> t m b

-- | Iterate a parser generating function on a stream. The initial value
--   <tt>b</tt> is used to generate the first parser, the parser is applied
--   on the stream and the result is used to generate the next parser and
--   so on.
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Monoid (Sum(..))
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.map getSum $ Stream.parseIterate (\b -&gt; Parser.takeBetween 0 2 (Fold.sconcat b)) 0 $ Stream.map Sum $ Stream.fromList [1..10]
--   [3,10,21,36,55,55]
--   </pre>
--   
--   This is the streaming equivalent of monad like sequenced application
--   of parsers where next parser is dependent on the previous parser.
--   
--   <i>Pre-release</i>
parseIterate :: (IsStream t, MonadThrow m) => (b -> Parser m a b) -> b -> t m a -> t m b

-- | Like <a>splitOn</a> after stripping leading, trailing, and repeated
--   separators. Therefore, <tt>".a..b."</tt> with <a>.</a> as the
--   separator would be parsed as <tt>["a","b"]</tt>. In other words, its
--   like parsing words from whitespace separated text.
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' p xs = Stream.toList $ Stream.wordsBy p Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' (== ',') ""
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' (== ',') ","
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' (== ',') ",a,,b,"
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   words = wordsBy isSpace
--   </pre>
wordsBy :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | <pre>
--   groups = groupsBy (==)
--   groups = groupsByRolling (==)
--   </pre>
--   
--   Groups contiguous spans of equal elements together in individual
--   groups.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.groups Fold.toList $ Stream.fromList [1,1,2,2]
--   [[1,1],[2,2]]
--   </pre>
groups :: (IsStream t, Monad m, Eq a) => Fold m a b -> t m a -> t m b

-- | <tt>groupsBy cmp f $ S.fromList [a,b,c,...]</tt> assigns the element
--   <tt>a</tt> to the first group, if <tt>b `cmp` a</tt> is <a>True</a>
--   then <tt>b</tt> is also assigned to the same group. If <tt>c `cmp`
--   a</tt> is <a>True</a> then <tt>c</tt> is also assigned to the same
--   group and so on. When the comparison fails a new group is started.
--   Each group is folded using the fold <tt>f</tt> and the result of the
--   fold is emitted in the output stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.groupsBy (&gt;) Fold.toList $ Stream.fromList [1,3,7,0,2,5]
--   [[1,3,7],[0,2,5]]
--   </pre>
groupsBy :: (IsStream t, Monad m) => (a -> a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Unlike <tt>groupsBy</tt> this function performs a rolling comparison
--   of two successive elements in the input stream. <tt>groupsByRolling
--   cmp f $ S.fromList [a,b,c,...]</tt> assigns the element <tt>a</tt> to
--   the first group, if <tt>a `cmp` b</tt> is <a>True</a> then <tt>b</tt>
--   is also assigned to the same group. If <tt>b `cmp` c</tt> is
--   <a>True</a> then <tt>c</tt> is also assigned to the same group and so
--   on. When the comparison fails a new group is started. Each group is
--   folded using the fold <tt>f</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.groupsByRolling (\a b -&gt; a + 1 == b) Fold.toList $ Stream.fromList [1,2,3,7,8,9]
--   [[1,2,3],[7,8,9]]
--   </pre>
groupsByRolling :: (IsStream t, Monad m) => (a -> a -> Bool) -> Fold m a b -> t m a -> t m b

-- | <tt>splitInnerBy splitter joiner stream</tt> splits the inner
--   containers <tt>f a</tt> of an input stream <tt>t m (f a)</tt> using
--   the <tt>splitter</tt> function. Container elements <tt>f a</tt> are
--   collected until a split occurs, then all the elements before the split
--   are joined using the <tt>joiner</tt> function.
--   
--   For example, if we have a stream of <tt>Array Word8</tt>, we may want
--   to split the stream into arrays representing lines separated by 'n'
--   byte such that the resulting stream after a split would be one array
--   for each line.
--   
--   CAUTION! This is not a true streaming function as the container size
--   after the split and merge may not be bounded.
--   
--   <i>Pre-release</i>
splitInnerBy :: (IsStream t, Monad m) => (f a -> m (f a, Maybe (f a))) -> (f a -> f a -> m (f a)) -> t m (f a) -> t m (f a)

-- | Like <a>splitInnerBy</a> but splits assuming the separator joins the
--   segment in a suffix style.
--   
--   <i>Pre-release</i>
splitInnerBySuffix :: (IsStream t, Monad m, Eq (f a), Monoid (f a)) => (f a -> m (f a, Maybe (f a))) -> (f a -> f a -> m (f a)) -> t m (f a) -> t m (f a)


-- | Most of the combinators in this module can be implemented as unfolds.
--   Some of them however can only be expressed in terms StreamK e.g.
--   cons/consM, fromFoldable, mfix. We can possibly remove those from this
--   module which can be expressed as unfolds. Unless we want to use
--   rewrite rules to rewrite them as StreamK when StreamK is used,
--   avoiding conversion to StreamD. Will that help? Are there any other
--   reasons to keep these and not use unfolds?
module Streamly.Internal.Data.Stream.IsStream.Generate
nil :: IsStream t => t m a
nilM :: (IsStream t, Monad m) => m b -> t m a

-- | Construct a stream by adding a pure value at the head of an existing
--   stream. For serial streams this is the same as <tt>(return a) `consM`
--   r</tt> but more efficient. For concurrent streams this is not
--   concurrent whereas <a>consM</a> is concurrent. For example:
--   
--   <pre>
--   &gt; toList $ 1 `cons` 2 `cons` 3 `cons` nil
--   [1,2,3]
--   </pre>
cons :: IsStream t => a -> t m a -> t m a
infixr 5 `cons`

-- | Operator equivalent of <a>cons</a>.
--   
--   <pre>
--   &gt; toList $ 1 .: 2 .: 3 .: nil
--   [1,2,3]
--   </pre>
(.:) :: IsStream t => a -> t m a -> t m a
infixr 5 .:

-- | Constructs a stream by adding a monadic action at the head of an
--   existing stream. For example:
--   
--   <pre>
--   &gt; toList $ getLine `consM` getLine `consM` nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
consM :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a
infixr 5 `consM`

-- | Operator equivalent of <a>consM</a>. We can read it as "<tt>parallel
--   colon</tt>" to remember that <tt>|</tt> comes before <tt>:</tt>.
--   
--   <pre>
--   &gt; toList $ getLine |: getLine |: nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <pre>
--   let delay = threadDelay 1000000 &gt;&gt; print 1
--   drain $ fromSerial  $ delay |: delay |: delay |: nil
--   drain $ fromParallel $ delay |: delay |: delay |: nil
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
(|:) :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a
infixr 5 |:

-- | Convert an <a>Unfold</a> into a stream by supplying it an input seed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.unfold (Unfold.replicateM 3) (putStrLn "hello")
--   hello
--   hello
--   hello
--   </pre>
--   
--   <i>Since: 0.7.0</i>
unfold :: (IsStream t, Monad m) => Unfold m a b -> a -> t m b

-- | Convert an <a>Unfold</a> with a closed input end into a stream.
--   
--   <i>Pre-release</i>
unfold0 :: (IsStream t, Monad m) => Unfold m Void b -> t m b

-- | <pre>
--   &gt;&gt;&gt; :{
--   unfoldr step s =
--       case step s of
--           Nothing -&gt; Stream.nil
--           Just (a, b) -&gt; a `Stream.cons` unfoldr step b
--   :}
--   </pre>
--   
--   Build a stream by unfolding a <i>pure</i> step function <tt>step</tt>
--   starting from a seed <tt>s</tt>. The step function returns the next
--   element in the stream and the next seed value. When it is done it
--   returns <a>Nothing</a> and the stream ends. For example,
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   let f b =
--           if b &gt; 2
--           then Nothing
--           else Just (b, b + 1)
--   in Stream.toList $ Stream.unfoldr f 0
--   :}
--   [0,1,2]
--   </pre>
unfoldr :: (Monad m, IsStream t) => (b -> Maybe (a, b)) -> b -> t m a

-- | Build a stream by unfolding a <i>monadic</i> step function starting
--   from a seed. The step function returns the next element in the stream
--   and the next seed value. When it is done it returns <a>Nothing</a> and
--   the stream ends. For example,
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   let f b =
--           if b &gt; 2
--           then return Nothing
--           else return (Just (b, b + 1))
--   in Stream.toList $ Stream.unfoldrM f 0
--   :}
--   [0,1,2]
--   </pre>
--   
--   When run concurrently, the next unfold step can run concurrently with
--   the processing of the output of the previous step. Note that more than
--   one step cannot run concurrently as the next step depends on the
--   output of the previous step.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   let f b =
--           if b &gt; 2
--           then return Nothing
--           else threadDelay 1000000 &gt;&gt; return (Just (b, b + 1))
--   in Stream.toList $ Stream.delay 1 $ Stream.fromAsync $ Stream.unfoldrM f 0
--   :}
--   [0,1,2]
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.1.0</i>
unfoldrM :: forall t m b a. (IsStream t, MonadAsync m) => (b -> m (Maybe (a, b))) -> b -> t m a

-- | <pre>
--   fromPure a = a `cons` nil
--   </pre>
--   
--   Create a singleton stream from a pure value.
--   
--   The following holds in monadic streams, but not in Zip streams:
--   
--   <pre>
--   fromPure = pure
--   fromPure = fromEffect . pure
--   </pre>
--   
--   In Zip applicative streams <a>fromPure</a> is not the same as
--   <a>pure</a> because in that case <a>pure</a> is equivalent to
--   <a>repeat</a> instead. <a>fromPure</a> and <a>pure</a> are equally
--   efficient, in other cases <a>fromPure</a> may be slightly more
--   efficient than the other equivalent definitions.
--   
--   <i>Since: 0.8.0 (Renamed yield to fromPure)</i>
fromPure :: IsStream t => a -> t m a

-- | <pre>
--   fromEffect m = m `consM` nil
--   </pre>
--   
--   Create a singleton stream from a monadic action.
--   
--   <pre>
--   &gt; Stream.toList $ Stream.fromEffect getLine
--   hello
--   ["hello"]
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed yieldM to fromEffect)</i>
fromEffect :: (Monad m, IsStream t) => m a -> t m a

-- | Generate an infinite stream by repeating a pure value.
repeat :: (IsStream t, Monad m) => a -> t m a

-- | <pre>
--   &gt;&gt;&gt; repeatM = fix . consM
--   
--   &gt;&gt;&gt; repeatM = cycle1 . fromEffect
--   </pre>
--   
--   Generate a stream by repeatedly executing a monadic action forever.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   repeatAsync =
--          Stream.repeatM (threadDelay 1000000 &gt;&gt; print 1)
--        &amp; Stream.take 10
--        &amp; Stream.fromAsync
--        &amp; Stream.drain
--   :}
--   </pre>
--   
--   <i>Concurrent, infinite (do not use with <tt>fromParallel</tt>)</i>
repeatM :: (IsStream t, MonadAsync m) => m a -> t m a

-- | <pre>
--   &gt;&gt;&gt; replicate n = Stream.take n . Stream.repeat
--   </pre>
--   
--   Generate a stream of length <tt>n</tt> by repeating a value <tt>n</tt>
--   times.
replicate :: (IsStream t, Monad m) => Int -> a -> t m a

-- | <pre>
--   &gt;&gt;&gt; replicateM n = Stream.take n . Stream.repeatM
--   </pre>
--   
--   Generate a stream by performing a monadic action <tt>n</tt> times.
--   Same as:
--   
--   <pre>
--   &gt;&gt;&gt; pr n = threadDelay 1000000 &gt;&gt; print n
--   </pre>
--   
--   This runs serially and takes 3 seconds:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromSerial $ Stream.replicateM 3 $ pr 1
--   1
--   1
--   1
--   </pre>
--   
--   This runs concurrently and takes just 1 second:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromAsync  $ Stream.replicateM 3 $ pr 1
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
replicateM :: forall t m a. (IsStream t, MonadAsync m) => Int -> m a -> t m a

-- | Types that can be enumerated as a stream. The operations in this type
--   class are equivalent to those in the <a>Enum</a> type class, except
--   that these generate a stream instead of a list. Use the functions in
--   <a>Streamly.Internal.Data.Stream.Enumeration</a> module to define new
--   instances.
class Enum a => Enumerable a

-- | <tt>enumerateFrom from</tt> generates a stream starting with the
--   element <tt>from</tt>, enumerating up to <a>maxBound</a> when the type
--   is <a>Bounded</a> or generating an infinite stream when the type is
--   not <a>Bounded</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFrom (0 :: Int)
--   [0,1,2,3]
--   </pre>
--   
--   For <a>Fractional</a> types, enumeration is numerically stable.
--   However, no overflow or underflow checks are performed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFrom 1.1
--   [1.1,2.1,3.1,4.1]
--   </pre>
enumerateFrom :: (Enumerable a, IsStream t, Monad m) => a -> t m a

-- | Generate a finite stream starting with the element <tt>from</tt>,
--   enumerating the type up to the value <tt>to</tt>. If <tt>to</tt> is
--   smaller than <tt>from</tt> then an empty stream is returned.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 0 4
--   [0,1,2,3,4]
--   </pre>
--   
--   For <a>Fractional</a> types, the last element is equal to the
--   specified <tt>to</tt> value after rounding to the nearest integral
--   value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 1.1 4
--   [1.1,2.1,3.1,4.1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 1.1 4.6
--   [1.1,2.1,3.1,4.1,5.1]
--   </pre>
enumerateFromTo :: (Enumerable a, IsStream t, Monad m) => a -> a -> t m a

-- | <tt>enumerateFromThen from then</tt> generates a stream whose first
--   element is <tt>from</tt>, the second element is <tt>then</tt> and the
--   successive elements are in increments of <tt>then - from</tt>.
--   Enumeration can occur downwards or upwards depending on whether
--   <tt>then</tt> comes before or after <tt>from</tt>. For <a>Bounded</a>
--   types the stream ends when <a>maxBound</a> is reached, for unbounded
--   types it keeps enumerating infinitely.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThen 0 2
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThen 0 (-2)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThen :: (Enumerable a, IsStream t, Monad m) => a -> a -> t m a

-- | <tt>enumerateFromThenTo from then to</tt> generates a finite stream
--   whose first element is <tt>from</tt>, the second element is
--   <tt>then</tt> and the successive elements are in increments of
--   <tt>then - from</tt> up to <tt>to</tt>. Enumeration can occur
--   downwards or upwards depending on whether <tt>then</tt> comes before
--   or after <tt>from</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenTo 0 2 6
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenTo 0 (-2) (-6)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThenTo :: (Enumerable a, IsStream t, Monad m) => a -> a -> a -> t m a

-- | <pre>
--   enumerate = enumerateFrom minBound
--   </pre>
--   
--   Enumerate a <a>Bounded</a> type from its <a>minBound</a> to
--   <a>maxBound</a>
enumerate :: (IsStream t, Monad m, Bounded a, Enumerable a) => t m a

-- | <pre>
--   enumerateTo = enumerateFromTo minBound
--   </pre>
--   
--   Enumerate a <a>Bounded</a> type from its <a>minBound</a> to specified
--   value.
enumerateTo :: (IsStream t, Monad m, Bounded a, Enumerable a) => a -> t m a

-- | <tt>times</tt> returns a stream of time value tuples with clock of 10
--   ms granularity. The first component of the tuple is an absolute time
--   reference (epoch) denoting the start of the stream and the second
--   component is a time relative to the reference.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ (\x -&gt; print x &gt;&gt; threadDelay 1000000) $ Stream.take 3 $ Stream.times
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),RelTime64 (NanoSecond64 ...))
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),RelTime64 (NanoSecond64 ...))
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),RelTime64 (NanoSecond64 ...))
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
times :: (IsStream t, MonadAsync m) => t m (AbsTime, RelTime64)

-- | <tt>absTimes</tt> returns a stream of absolute timestamps using a
--   clock of 10 ms granularity.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.delayPre 1 $ Stream.take 3 $ Stream.absTimes
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
absTimes :: (IsStream t, MonadAsync m, Functor (t m)) => t m AbsTime

-- | <tt>absTimesWith g</tt> returns a stream of absolute timestamps using
--   a clock of granularity <tt>g</tt> specified in seconds. A low
--   granularity clock is more expensive in terms of CPU usage. Any
--   granularity lower than 1 ms is treated as 1 ms.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.delayPre 1 $ Stream.take 3 $ absTimesWith 0.01
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   AbsTime (TimeSpec {sec = ..., nsec = ...})
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
absTimesWith :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m AbsTime

-- | <tt>relTimes</tt> returns a stream of relative time values starting
--   from 0, using a clock of granularity 10 ms.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.delayPre 1 $ Stream.take 3 $ Stream.relTimes
--   RelTime64 (NanoSecond64 ...)
--   RelTime64 (NanoSecond64 ...)
--   RelTime64 (NanoSecond64 ...)
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
relTimes :: (IsStream t, MonadAsync m, Functor (t m)) => t m RelTime64

-- | <tt>relTimesWith g</tt> returns a stream of relative time values
--   starting from 0, using a clock of granularity <tt>g</tt> specified in
--   seconds. A low granularity clock is more expensive in terms of CPU
--   usage. Any granularity lower than 1 ms is treated as 1 ms.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.delayPre 1 $ Stream.take 3 $ Stream.relTimesWith 0.01
--   RelTime64 (NanoSecond64 ...)
--   RelTime64 (NanoSecond64 ...)
--   RelTime64 (NanoSecond64 ...)
--   </pre>
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Pre-release</i>
relTimesWith :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m RelTime64

-- | <tt>durations g</tt> returns a stream of relative time values
--   measuring the time elapsed since the immediate predecessor element of
--   the stream was generated. The first element of the stream is always 0.
--   <tt>durations</tt> uses a clock of granularity <tt>g</tt> specified in
--   seconds. A low granularity clock is more expensive in terms of CPU
--   usage. The minimum granularity is 1 millisecond. Durations lower than
--   1 ms will be 0.
--   
--   Note: This API is not safe on 32-bit machines.
--   
--   <i>Unimplemented</i>
durations :: Double -> t m RelTime64

-- | Generate ticks at the specified rate. The rate is adaptive, the tick
--   generation speed can be increased or decreased at different times to
--   achieve the specified rate. The specific behavior for different styles
--   of <a>Rate</a> specifications is documented under <a>Rate</a>. The
--   effective maximum rate achieved by a stream is governed by the
--   processor speed.
--   
--   <i>Unimplemented</i>
ticks :: Rate -> t m ()

-- | Generate a singleton event at or after the specified absolute time.
--   Note that this is different from a threadDelay, a threadDelay starts
--   from the time when the action is evaluated, whereas if we use AbsTime
--   based timeout it will immediately expire if the action is evaluated
--   too late.
--   
--   <i>Unimplemented</i>
timeout :: AbsTime -> t m ()

-- | <pre>
--   &gt;&gt;&gt; fromIndices f = fmap f $ Stream.enumerateFrom 0
--   
--   &gt;&gt;&gt; fromIndices f = let g i = f i `Stream.cons` g (i + 1) in g 0
--   </pre>
--   
--   Generate an infinite stream, whose values are the output of a function
--   <tt>f</tt> applied on the corresponding index. Index starts at 0.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 5 $ Stream.fromIndices id
--   [0,1,2,3,4]
--   </pre>
fromIndices :: (IsStream t, Monad m) => (Int -> a) -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromIndicesM f = Stream.mapM f $ Stream.enumerateFrom 0
--   
--   &gt;&gt;&gt; fromIndicesM f = let g i = f i `Stream.consM` g (i + 1) in g 0
--   </pre>
--   
--   Generate an infinite stream, whose values are the output of a monadic
--   function <tt>f</tt> applied on the corresponding index. Index starts
--   at 0.
--   
--   <i>Concurrent</i>
fromIndicesM :: forall t m a. (IsStream t, MonadAsync m) => (Int -> m a) -> t m a

-- | <pre>
--   &gt;&gt;&gt; iterate f x = x `Stream.cons` iterate f x
--   </pre>
--   
--   Generate an infinite stream with <tt>x</tt> as the first element and
--   each successive element derived by applying the function <tt>f</tt> on
--   the previous element.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 5 $ Stream.iterate (+1) 1
--   [1,2,3,4,5]
--   </pre>
iterate :: (IsStream t, Monad m) => (a -> a) -> a -> t m a

-- | <pre>
--   &gt;&gt;&gt; iterateM f m = m &gt;&gt;= \a -&gt; return a `Stream.consM` iterateM f (f a)
--   </pre>
--   
--   Generate an infinite stream with the first element generated by the
--   action <tt>m</tt> and each successive element derived by applying the
--   monadic function <tt>f</tt> on the previous element.
--   
--   <pre>
--   &gt;&gt;&gt; pr n = threadDelay 1000000 &gt;&gt; print n
--   
--   &gt;&gt;&gt; :{
--   Stream.iterateM (\x -&gt; pr x &gt;&gt; return (x + 1)) (return 0)
--       &amp; Stream.take 3
--       &amp; Stream.fromSerial
--       &amp; Stream.toList
--   :}
--   0
--   1
--   [0,1,2]
--   </pre>
--   
--   When run concurrently, the next iteration can run concurrently with
--   the processing of the previous iteration. Note that more than one
--   iteration cannot run concurrently as the next iteration depends on the
--   output of the previous iteration.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.iterateM (\x -&gt; pr x &gt;&gt; return (x + 1)) (return 0)
--       &amp; Stream.delay 1
--       &amp; Stream.take 3
--       &amp; Stream.fromAsync
--       &amp; Stream.toList
--   :}
--   0
--   1
--   ...
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.1.2</i>
--   
--   <i>Since: 0.7.0 (signature change)</i>
iterateM :: forall t m a. (IsStream t, MonadAsync m) => (a -> m a) -> m a -> t m a

-- | We can define cyclic structures using <tt>let</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; let (a, b) = ([1, b], head a) in (a, b)
--   ([1,1],1)
--   </pre>
--   
--   The function <tt>fix</tt> defined as:
--   
--   <pre>
--   &gt;&gt;&gt; fix f = let x = f x in x
--   </pre>
--   
--   ensures that the argument of a function and its output refer to the
--   same lazy value <tt>x</tt> i.e. the same location in memory. Thus
--   <tt>x</tt> can be defined in terms of itself, creating structures with
--   cyclic references.
--   
--   <pre>
--   &gt;&gt;&gt; f ~(a, b) = ([1, b], head a)
--   
--   &gt;&gt;&gt; fix f
--   ([1,1],1)
--   </pre>
--   
--   <a>mfix</a> is essentially the same as <tt>fix</tt> but for monadic
--   values.
--   
--   Using <a>mfix</a> for streams we can construct a stream in which each
--   element of the stream is defined in a cyclic fashion. The argument of
--   the function being fixed represents the current element of the stream
--   which is being returned by the stream monad. Thus, we can use the
--   argument to construct itself.
--   
--   In the following example, the argument <tt>action</tt> of the function
--   <tt>f</tt> represents the tuple <tt>(x,y)</tt> returned by it in a
--   given iteration. We define the first element of the tuple in terms of
--   the second.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Internal.Data.Stream.IsStream as Stream
--   
--   &gt;&gt;&gt; import System.IO.Unsafe (unsafeInterleaveIO)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   main = Stream.mapM_ print $ Stream.mfix f
--       where
--       f action = do
--           let incr n act = fmap ((+n) . snd) $ unsafeInterleaveIO act
--           x &lt;- Stream.fromListM [incr 1 action, incr 2 action]
--           y &lt;- Stream.fromList [4,5]
--           return (x, y)
--   :}
--   </pre>
--   
--   Note: you cannot achieve this by just changing the order of the monad
--   statements because that would change the order in which the stream
--   elements are generated.
--   
--   Note that the function <tt>f</tt> must be lazy in its argument, that's
--   why we use <tt>unsafeInterleaveIO</tt> on <tt>action</tt> because IO
--   monad is strict.
--   
--   <i>Pre-release</i>
mfix :: (IsStream t, Monad m) => (m a -> t m a) -> t m a

-- | <pre>
--   fromList = <a>foldr</a> <a>cons</a> <a>nil</a>
--   </pre>
--   
--   Construct a stream from a list of pure values. This is more efficient
--   than <a>fromFoldable</a> for serial streams.
fromList :: (Monad m, IsStream t) => [a] -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromListM = Stream.fromFoldableM
--   
--   &gt;&gt;&gt; fromListM = Stream.sequence . Stream.fromList
--   
--   &gt;&gt;&gt; fromListM = Stream.mapM id . Stream.fromList
--   
--   &gt;&gt;&gt; fromListM = Prelude.foldr Stream.consM Stream.nil
--   </pre>
--   
--   Construct a stream from a list of monadic actions. This is more
--   efficient than <a>fromFoldableM</a> for serial streams.
fromListM :: (MonadAsync m, IsStream t) => [m a] -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromFoldable = Prelude.foldr Stream.cons Stream.nil
--   </pre>
--   
--   Construct a stream from a <a>Foldable</a> containing pure values:
fromFoldable :: (IsStream t, Foldable f) => f a -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromFoldableM = Prelude.foldr Stream.consM Stream.nil
--   </pre>
--   
--   Construct a stream from a <a>Foldable</a> containing monadic actions.
--   
--   <pre>
--   &gt;&gt;&gt; pr n = threadDelay 1000000 &gt;&gt; print n
--   
--   &gt;&gt;&gt; Stream.drain $ Stream.fromSerial $ Stream.fromFoldableM $ map pr [1,2,3]
--   1
--   2
--   3
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromAsync $ Stream.fromFoldableM $ map pr [1,2,3]
--   ...
--   ...
--   ...
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   containers)</i>
fromFoldableM :: (IsStream t, MonadAsync m, Foldable f) => f (m a) -> t m a

-- | Takes a callback setter function and provides it with a callback. The
--   callback when invoked adds a value at the tail of the stream. Returns
--   a stream of values generated by the callback.
--   
--   <i>Pre-release</i>
fromCallback :: MonadAsync m => ((a -> m ()) -> m ()) -> SerialT m a

-- | Construct a stream by reading a <a>Prim</a> <tt>IORef</tt> repeatedly.
--   
--   <i>Pre-release</i>
fromPrimIORef :: (IsStream t, MonadIO m, Prim a) => IORef a -> t m a

-- | Same as fromEffect

-- | <i>Deprecated: Please use fromEffect instead.</i>
once :: (Monad m, IsStream t) => m a -> t m a

-- | Same as <a>fromPure</a>

-- | <i>Deprecated: Please use fromPure instead.</i>
yield :: IsStream t => a -> t m a

-- | Same as <a>fromEffect</a>

-- | <i>Deprecated: Please use fromEffect instead.</i>
yieldM :: (Monad m, IsStream t) => m a -> t m a

-- | Same as <a>fromFoldable</a>.

-- | <i>Deprecated: Please use fromFoldable instead.</i>
each :: (IsStream t, Foldable f) => f a -> t m a

-- | Read lines from an IO Handle into a stream of Strings.

-- | <i>Deprecated: Please use Streamly.FileSystem.Handle module (see the
--   changelog)</i>
fromHandle :: (IsStream t, MonadIO m) => Handle -> t m String

-- | <i>Deprecated: Please use absTimes instead</i>
currentTime :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m AbsTime


-- | Expand a stream by combining two or more streams or by combining
--   streams with unfolds.
module Streamly.Internal.Data.Stream.IsStream.Expand

-- | Appends two streams sequentially, yielding all elements from the first
--   stream, and then all elements from the second stream.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (serial)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [3,4]
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `serial` stream2
--   [1,2,3,4]
--   </pre>
--   
--   This operation can be used to fold an infinite lazy container of
--   streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
serial :: IsStream t => t m a -> t m a -> t m a
infixr 6 `serial`

-- | Appends two streams, both the streams may be evaluated concurrently
--   but the outputs are used in the same order as the corresponding
--   actions in the original streams, side effects will happen in the order
--   in which the streams are evaluated:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (ahead, SerialT)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromEffect (delay 4) :: SerialT IO Int
--   
--   &gt;&gt;&gt; stream2 = Stream.fromEffect (delay 2) :: SerialT IO Int
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `ahead` stream2 :: IO [Int]
--   2 sec
--   4 sec
--   [4,2]
--   </pre>
--   
--   Multiple streams can be combined. With enough threads, all of them can
--   be scheduled simultaneously:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `ahead` stream2 `ahead` stream3
--   1 sec
--   2 sec
--   4 sec
--   [4,2,1]
--   </pre>
--   
--   With 2 threads, only two can be scheduled at a time, when one of those
--   finishes, the third one gets scheduled:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 2 $ stream1 `ahead` stream2 `ahead` stream3
--   2 sec
--   1 sec
--   4 sec
--   [4,2,1]
--   </pre>
--   
--   Only streams are scheduled for ahead evaluation, how actions within a
--   stream are evaluated depends on the stream type. If it is a concurrent
--   stream they will be evaluated concurrently. It may not make much sense
--   combining serial streams using <a>ahead</a>.
--   
--   <a>ahead</a> can be safely used to fold an infinite lazy container of
--   streams.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
ahead :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `ahead`

-- | Merges two streams, both the streams may be evaluated concurrently,
--   outputs from both are used as they arrive:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (async)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromEffect (delay 4)
--   
--   &gt;&gt;&gt; stream2 = Stream.fromEffect (delay 2)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2
--   2 sec
--   4 sec
--   [2,4]
--   </pre>
--   
--   Multiple streams can be combined. With enough threads, all of them can
--   be scheduled simultaneously:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2 `async` stream3
--   ...
--   [1,2,4]
--   </pre>
--   
--   With 2 threads, only two can be scheduled at a time, when one of those
--   finishes, the third one gets scheduled:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3
--   ...
--   [2,1,4]
--   </pre>
--   
--   With a single thread, it becomes serial:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 1 $ stream1 `async` stream2 `async` stream3
--   ...
--   [4,2,1]
--   </pre>
--   
--   Only streams are scheduled for async evaluation, how actions within a
--   stream are evaluated depends on the stream type. If it is a concurrent
--   stream they will be evaluated concurrently.
--   
--   In the following example, both the streams are scheduled for
--   concurrent evaluation but each individual stream is evaluated
--   serially:
--   
--   <pre>
--   &gt;&gt;&gt; stream1 = Stream.fromListM $ Prelude.map delay [3,3] -- SerialT IO Int
--   
--   &gt;&gt;&gt; stream2 = Stream.fromListM $ Prelude.map delay [1,1] -- SerialT IO Int
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2 -- IO [Int]
--   ...
--   [1,1,3,3]
--   </pre>
--   
--   If total threads are 2, the third stream is scheduled only after one
--   of the first two has finished:
--   
--   <pre>
--   stream3 = Stream.fromListM $ Prelude.map delay [2,2] -- SerialT IO Int
--   Stream.toList $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3 -- IO [Int]
--   </pre>
--   
--   ... [1,1,3,2,3,2]
--   
--   Thus <a>async</a> goes deep in first few streams rather than going
--   wide in all streams. It prefers to evaluate the leftmost streams as
--   much as possible. Because of this behavior, <a>async</a> can be safely
--   used to fold an infinite lazy container of streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
async :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `async`

-- | For singleton streams, <a>wAsync</a> is the same as <a>async</a>. See
--   <a>async</a> for singleton stream behavior. For multi-element streams,
--   while <a>async</a> is left biased i.e. it tries to evaluate the left
--   side stream as much as possible, <a>wAsync</a> tries to schedule them
--   both fairly. In other words, <a>async</a> goes deep while
--   <a>wAsync</a> goes wide. However, outputs are always used as they
--   arrive.
--   
--   With a single thread, <a>async</a> starts behaving like <a>serial</a>
--   while <a>wAsync</a> starts behaving like <a>wSerial</a>.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (async, wAsync)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2,3]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [4,5,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAsync $ Stream.maxThreads 1 $ stream1 `async` stream2
--   [1,2,3,4,5,6]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWAsync $ Stream.maxThreads 1 $ stream1 `wAsync` stream2
--   [1,4,2,5,3,6]
--   </pre>
--   
--   With two threads available, and combining three streams:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromList [7,8,9]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAsync $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3
--   [1,2,3,4,5,6,7,8,9]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWAsync $ Stream.maxThreads 2 $ stream1 `wAsync` stream2 `wAsync` stream3
--   [1,4,2,7,5,3,8,6,9]
--   </pre>
--   
--   This operation cannot be used to fold an infinite lazy container of
--   streams, because it schedules all the streams in a round robin manner.
--   
--   Note that <tt>WSerialT</tt> and single threaded <tt>WAsyncT</tt> both
--   interleave streams but the exact scheduling is slightly different in
--   both cases.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
wAsync :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `wAsync`

-- | Like <a>async</a> except that the execution is much more strict. There
--   is no limit on the number of threads. While <a>async</a> may not
--   schedule a stream if there is no demand from the consumer,
--   <a>parallel</a> always evaluates both the streams immediately. The
--   only limit that applies to <a>parallel</a> is <a>maxBuffer</a>.
--   Evaluation may block if the output buffer becomes full.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (parallel)
--   
--   &gt;&gt;&gt; stream = Stream.fromEffect (delay 2) `parallel` Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList stream -- IO [Int]
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   <a>parallel</a> guarantees that all the streams are scheduled for
--   execution immediately, therefore, we could use things like starting
--   timers inside the streams and relying on the fact that all timers were
--   started at the same time.
--   
--   Unlike <a>async</a> this operation cannot be used to fold an infinite
--   lazy container of streams, because it schedules all the streams
--   strictly concurrently.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
parallel :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `parallel`

-- | Like <tt>parallel</tt> but stops the output as soon as the first
--   stream stops.
--   
--   <i>Pre-release</i>
parallelFst :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a

-- | Like <a>parallel</a> but stops the output as soon as any of the two
--   streams stops.
--   
--   <i>Pre-release</i>
parallelMin :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a

-- | Append the outputs of two streams, yielding all the elements from the
--   first stream and then yielding all the elements from the second
--   stream.
--   
--   IMPORTANT NOTE: This could be 100x faster than
--   <tt>serial/&lt;&gt;</tt> for appending a few (say 100) streams because
--   it can fuse via stream fusion. However, it does not scale for a large
--   number of streams (say 1000s) and becomes qudartically slow. Therefore
--   use this for custom appending of a few streams but use
--   <a>concatMap</a> or 'concatMapWith serial' for appending <tt>n</tt>
--   streams or infinite containers of streams.
--   
--   <i>Pre-release</i>
append :: (IsStream t, Monad m) => t m b -> t m b -> t m b

-- | Interleaves two streams, yielding one element from each stream
--   alternately. When one stream stops the rest of the other stream is
--   used in the output stream.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [3,4]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWSerial $ stream1 `wSerial` stream2
--   [1,3,2,4]
--   </pre>
--   
--   Note, for singleton streams <a>wSerial</a> and <a>serial</a> are
--   identical.
--   
--   Note that this operation cannot be used to fold a container of
--   infinite streams but it can be used for very large streams as the
--   state that it needs to maintain is proportional to the logarithm of
--   the number of streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
wSerial :: IsStream t => t m a -> t m a -> t m a
infixr 6 `wSerial`
wSerialFst :: WSerialT m a -> WSerialT m a -> WSerialT m a
wSerialMin :: WSerialT m a -> WSerialT m a -> WSerialT m a

-- | Interleaves the outputs of two streams, yielding elements from each
--   stream alternately, starting from the first stream. If any of the
--   streams finishes early the other stream continues alone until it too
--   finishes.
--   
--   <pre>
--   &gt;&gt;&gt; :set -XOverloadedStrings
--   
--   &gt;&gt;&gt; import Data.Functor.Identity (Identity)
--   
--   &gt;&gt;&gt; Stream.interleave "ab" ",,,," :: Stream.SerialT Identity Char
--   fromList "a,b,,,"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.interleave "abcd" ",," :: Stream.SerialT Identity Char
--   fromList "a,b,cd"
--   </pre>
--   
--   <a>interleave</a> is dual to <a>interleaveMin</a>, it can be called
--   <tt>interleaveMax</tt>.
--   
--   Do not use at scale in concatMapWith.
--   
--   <i>Pre-release</i>
interleave :: (IsStream t, Monad m) => t m b -> t m b -> t m b

-- | Interleaves the outputs of two streams, yielding elements from each
--   stream alternately, starting from the first stream. The output stops
--   as soon as any of the two streams finishes, discarding the remaining
--   part of the other stream. The last element of the resulting stream
--   would be from the longer stream.
--   
--   <pre>
--   &gt;&gt;&gt; :set -XOverloadedStrings
--   
--   &gt;&gt;&gt; import Data.Functor.Identity (Identity)
--   
--   &gt;&gt;&gt; Stream.interleaveMin "ab" ",,,," :: Stream.SerialT Identity Char
--   fromList "a,b,"
--   
--   &gt;&gt;&gt; Stream.interleaveMin "abcd" ",," :: Stream.SerialT Identity Char
--   fromList "a,b,c"
--   </pre>
--   
--   <a>interleaveMin</a> is dual to <a>interleave</a>.
--   
--   Do not use at scale in concatMapWith.
--   
--   <i>Pre-release</i>
interleaveMin :: (IsStream t, Monad m) => t m b -> t m b -> t m b

-- | Interleaves the outputs of two streams, yielding elements from each
--   stream alternately, starting from the first stream. As soon as the
--   first stream finishes, the output stops, discarding the remaining part
--   of the second stream. In this case, the last element in the resulting
--   stream would be from the second stream. If the second stream finishes
--   early then the first stream still continues to yield elements until it
--   finishes.
--   
--   <pre>
--   &gt;&gt;&gt; :set -XOverloadedStrings
--   
--   &gt;&gt;&gt; import Data.Functor.Identity (Identity)
--   
--   &gt;&gt;&gt; Stream.interleaveSuffix "abc" ",,,," :: Stream.SerialT Identity Char
--   fromList "a,b,c,"
--   
--   &gt;&gt;&gt; Stream.interleaveSuffix "abc" "," :: Stream.SerialT Identity Char
--   fromList "a,bc"
--   </pre>
--   
--   <a>interleaveSuffix</a> is a dual of <a>interleaveInfix</a>.
--   
--   Do not use at scale in concatMapWith.
--   
--   <i>Pre-release</i>
interleaveSuffix :: (IsStream t, Monad m) => t m b -> t m b -> t m b

-- | Interleaves the outputs of two streams, yielding elements from each
--   stream alternately, starting from the first stream and ending at the
--   first stream. If the second stream is longer than the first, elements
--   from the second stream are infixed with elements from the first
--   stream. If the first stream is longer then it continues yielding
--   elements even after the second stream has finished.
--   
--   <pre>
--   &gt;&gt;&gt; :set -XOverloadedStrings
--   
--   &gt;&gt;&gt; import Data.Functor.Identity (Identity)
--   
--   &gt;&gt;&gt; Stream.interleaveInfix "abc" ",,,," :: Stream.SerialT Identity Char
--   fromList "a,b,c"
--   
--   &gt;&gt;&gt; Stream.interleaveInfix "abc" "," :: Stream.SerialT Identity Char
--   fromList "a,bc"
--   </pre>
--   
--   <a>interleaveInfix</a> is a dual of <a>interleaveSuffix</a>.
--   
--   Do not use at scale in concatMapWith.
--   
--   <i>Pre-release</i>
interleaveInfix :: (IsStream t, Monad m) => t m b -> t m b -> t m b

-- | Schedule the execution of two streams in a fair round-robin manner,
--   executing each stream once, alternately. Execution of a stream may not
--   necessarily result in an output, a stream may chose to <tt>Skip</tt>
--   producing an element until later giving the other stream a chance to
--   run. Therefore, this combinator fairly interleaves the execution of
--   two streams rather than fairly interleaving the output of the two
--   streams. This can be useful in co-operative multitasking without using
--   explicit threads. This can be used as an alternative to <a>async</a>.
--   
--   Do not use at scale in concatMapWith.
--   
--   <i>Pre-release</i>
roundrobin :: (IsStream t, Monad m) => t m b -> t m b -> t m b

-- | Stream <tt>a</tt> is evaluated first, followed by stream <tt>b</tt>,
--   the resulting elements <tt>a</tt> and <tt>b</tt> are then zipped using
--   the supplied zip function and the result <tt>c</tt> is yielded to the
--   consumer.
--   
--   If stream <tt>a</tt> or stream <tt>b</tt> ends, the zipped stream
--   ends. If stream <tt>b</tt> ends first, the element <tt>a</tt> from
--   previous evaluation of stream <tt>a</tt> is discarded.
--   
--   <pre>
--   &gt; S.toList $ S.zipWith (+) (S.fromList [1,2,3]) (S.fromList [4,5,6])
--   [5,7,9]
--   </pre>
zipWith :: (IsStream t, Monad m) => (a -> b -> c) -> t m a -> t m b -> t m c

-- | Like <a>zipWith</a> but using a monadic zipping function.
zipWithM :: (IsStream t, Monad m) => (a -> b -> m c) -> t m a -> t m b -> t m c

-- | Like <a>zipWith</a> but zips concurrently i.e. both the streams being
--   zipped are evaluated concurrently using the <tt>ParallelT</tt>
--   concurrent evaluation style. The maximum number of elements of each
--   stream evaluated in advance can be controlled by <tt>maxBuffer</tt>.
--   
--   The stream ends if stream <tt>a</tt> or stream <tt>b</tt> ends.
--   However, if stream <tt>b</tt> ends while we are still evaluating
--   stream <tt>a</tt> and waiting for a result then stream will not end
--   until after the evaluation of stream <tt>a</tt> finishes. This
--   behavior can potentially be changed in future to end the stream
--   immediately as soon as any of the stream end is detected.
zipAsyncWith :: (IsStream t, MonadAsync m) => (a -> b -> c) -> t m a -> t m b -> t m c

-- | Like <a>zipAsyncWith</a> but with a monadic zipping function.
zipAsyncWithM :: (IsStream t, MonadAsync m) => (a -> b -> m c) -> t m a -> t m b -> t m c

-- | Merge two streams using a comparison function. The head elements of
--   both the streams are compared and the smaller of the two elements is
--   emitted, if both elements are equal then the element from the first
--   stream is used first.
--   
--   If the streams are sorted in ascending order, the resulting stream
--   would also remain sorted in ascending order.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.mergeBy compare (Stream.fromList [1,3,5]) (Stream.fromList [2,4,6,8])
--   [1,2,3,4,5,6,8]
--   </pre>
--   
--   See also: <a>mergeByMFused</a>
mergeBy :: (IsStream t, Monad m) => (a -> a -> Ordering) -> t m a -> t m a -> t m a

-- | Like <a>mergeBy</a> but with a monadic comparison function.
--   
--   Merge two streams randomly:
--   
--   <pre>
--   &gt; randomly _ _ = randomIO &gt;&gt;= x -&gt; return $ if x then LT else GT
--   &gt; Stream.toList $ Stream.mergeByM randomly (Stream.fromList [1,1,1,1]) (Stream.fromList [2,2,2,2])
--   [2,1,2,2,2,1,1,1]
--   </pre>
--   
--   Merge two streams in a proportion of 2:1:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   do
--    let proportionately m n = do
--         ref &lt;- newIORef $ cycle $ Prelude.concat [Prelude.replicate m LT, Prelude.replicate n GT]
--         return $ _ _ -&gt; do
--            r &lt;- readIORef ref
--            writeIORef ref $ Prelude.tail r
--            return $ Prelude.head r
--    f &lt;- proportionately 2 1
--    xs &lt;- Stream.toList $ Stream.mergeByM f (Stream.fromList [1,1,1,1,1,1]) (Stream.fromList [2,2,2])
--    print xs
--   :}
--   [1,1,2,1,1,2,1,1,2]
--   </pre>
--   
--   See also: <a>mergeByMFused</a>
mergeByM :: (IsStream t, Monad m) => (a -> a -> m Ordering) -> t m a -> t m a -> t m a

-- | Like <a>mergeByM</a> but much faster, works best when merging
--   statically known number of streams. When merging more than two streams
--   try to merge pairs and pair pf pairs in a tree like
--   structure.<a>mergeByM</a> works better with variable number of streams
--   being merged using <a>concatPairsWith</a>.
--   
--   <i>Internal</i>
mergeByMFused :: (IsStream t, Monad m) => (a -> a -> m Ordering) -> t m a -> t m a -> t m a

-- | Like <a>mergeBy</a> but merges concurrently (i.e. both the elements
--   being merged are generated concurrently).
mergeAsyncBy :: (IsStream t, MonadAsync m) => (a -> a -> Ordering) -> t m a -> t m a -> t m a

-- | Like <a>mergeByM</a> but merges concurrently (i.e. both the elements
--   being merged are generated concurrently).
mergeAsyncByM :: (IsStream t, MonadAsync m) => (a -> a -> m Ordering) -> t m a -> t m a -> t m a

-- | Like <a>concatMap</a> but uses an <a>Unfold</a> for stream generation.
--   Unlike <a>concatMap</a> this can fuse the <a>Unfold</a> code with the
--   inner loop and therefore provide many times better performance.
unfoldMany :: (IsStream t, Monad m) => Unfold m a b -> t m a -> t m b

-- | Like <a>unfoldMany</a> but interleaves the streams in the same way as
--   <a>interleave</a> behaves instead of appending them.
--   
--   <i>Pre-release</i>
unfoldManyInterleave :: (IsStream t, Monad m) => Unfold m a b -> t m a -> t m b

-- | Like <a>unfoldMany</a> but executes the streams in the same way as
--   <a>roundrobin</a>.
--   
--   <i>Pre-release</i>
unfoldManyRoundRobin :: (IsStream t, Monad m) => Unfold m a b -> t m a -> t m b

-- | Unfold the elements of a stream, intersperse the given element between
--   the unfolded streams and then concat them into a single stream.
--   
--   <pre>
--   unwords = S.interpose ' '
--   </pre>
--   
--   <i>Pre-release</i>
interpose :: (IsStream t, Monad m) => c -> Unfold m b c -> t m b -> t m c

-- | Unfold the elements of a stream, append the given element after each
--   unfolded stream and then concat them into a single stream.
--   
--   <pre>
--   unlines = S.interposeSuffix '\n'
--   </pre>
--   
--   <i>Pre-release</i>
interposeSuffix :: (IsStream t, Monad m) => c -> Unfold m b c -> t m b -> t m c

-- | <tt>intersperse</tt> followed by unfold and concat.
--   
--   <pre>
--   intercalate unf a str = unfoldMany unf $ intersperse a str
--   intersperse = intercalate (Unfold.function id)
--   unwords = intercalate Unfold.fromList " "
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intercalate Unfold.fromList " " $ Stream.fromList ["abc", "def", "ghi"]
--   "abc def ghi"
--   </pre>
intercalate :: (IsStream t, Monad m) => Unfold m b c -> b -> t m b -> t m c

-- | <tt>intersperseSuffix</tt> followed by unfold and concat.
--   
--   <pre>
--   intercalateSuffix unf a str = unfoldMany unf $ intersperseSuffix a str
--   intersperseSuffix = intercalateSuffix (Unfold.function id)
--   unlines = intercalateSuffix Unfold.fromList "\n"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intercalateSuffix Unfold.fromList "\n" $ Stream.fromList ["abc", "def", "ghi"]
--   "abc\ndef\nghi\n"
--   </pre>
intercalateSuffix :: (IsStream t, Monad m) => Unfold m b c -> b -> t m b -> t m c

-- | <a>interleaveInfix</a> followed by unfold and concat.
--   
--   <i>Pre-release</i>
gintercalate :: (IsStream t, Monad m) => Unfold m a c -> t m a -> Unfold m b c -> t m b -> t m c

-- | <a>interleaveSuffix</a> followed by unfold and concat.
--   
--   <i>Pre-release</i>
gintercalateSuffix :: (IsStream t, Monad m) => Unfold m a c -> t m a -> Unfold m b c -> t m b -> t m c

-- | Map a stream producing monadic function on each element of the stream
--   and then flatten the results into a single stream. Since the stream
--   generation function is monadic, unlike <a>concatMap</a>, it can
--   produce an effect at the beginning of each iteration of the inner
--   loop.
concatMapM :: (IsStream t, Monad m) => (a -> m (t m b)) -> t m a -> t m b

-- | Map a stream producing function on each element of the stream and then
--   flatten the results into a single stream.
--   
--   <pre>
--   &gt;&gt;&gt; concatMap f = Stream.concatMapM (return . f)
--   
--   &gt;&gt;&gt; concatMap f = Stream.concatMapWith Stream.serial f
--   
--   &gt;&gt;&gt; concatMap f = Stream.concat . Stream.map f
--   
--   &gt;&gt;&gt; concatMap f = Stream.unfoldMany (Unfold.lmap f Unfold.fromStream)
--   </pre>
concatMap :: (IsStream t, Monad m) => (a -> t m b) -> t m a -> t m b

-- | Given a stream value in the underlying monad, lift and join the
--   underlying monad with the stream monad.
--   
--   <pre>
--   &gt;&gt;&gt; concatM = Stream.concat . Stream.fromEffect
--   
--   &gt;&gt;&gt; concatM = Stream.concat . lift    -- requires (MonadTrans t)
--   
--   &gt;&gt;&gt; concatM = join . lift             -- requires (MonadTrans t, Monad (t m))
--   </pre>
--   
--   See also: <a>concat</a>, <a>sequence</a>
--   
--   <i>Internal</i>
concatM :: (IsStream t, Monad m) => m (t m a) -> t m a

-- | Flatten a stream of streams to a single stream.
--   
--   <pre>
--   concat = concatMap id
--   </pre>
--   
--   <i>Pre-release</i>
concat :: (IsStream t, Monad m) => t m (t m a) -> t m a

-- | A variant of <a>fold</a> that allows you to fold a <a>Foldable</a>
--   container of streams using the specified stream sum operation.
--   
--   <pre>
--   concatFoldableWith <tt>async</tt> $ map return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatFoldableWith f = Prelude.foldr f S.nil
--   concatFoldableWith f = S.concatMapFoldableWith f id
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldWith to concatFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatFoldableWith :: (IsStream t, Foldable f) => (t m a -> t m a -> t m a) -> f (t m a) -> t m a

-- | A variant of <a>foldMap</a> that allows you to map a monadic streaming
--   action on a <a>Foldable</a> container and then fold it using the
--   specified stream merge operation.
--   
--   <pre>
--   concatMapFoldableWith <tt>async</tt> return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatMapFoldableWith f g = Prelude.foldr (f . g) S.nil
--   concatMapFoldableWith f g xs = S.concatMapWith f g (S.fromFoldable xs)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldMapWith to concatMapFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatMapFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> (a -> t m b) -> f a -> t m b

-- | Like <a>concatMapFoldableWith</a> but with the last two arguments
--   reversed i.e. the monadic streaming function is the last argument.
--   
--   Equivalent to:
--   
--   <pre>
--   concatForFoldableWith f xs g = Prelude.foldr (f . g) S.nil xs
--   concatForFoldableWith f = flip (S.concatMapFoldableWith f)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed forEachWith to concatForFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatForFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> f a -> (a -> t m b) -> t m b

-- | <tt>concatMapWith mixer generator stream</tt> is a two dimensional
--   looping combinator. The <tt>generator</tt> function is used to
--   generate streams from the elements in the input <tt>stream</tt> and
--   the <tt>mixer</tt> function is used to merge those streams.
--   
--   Note we can merge streams concurrently by using a concurrent merge
--   function.
--   
--   <i>Since: 0.7.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
concatMapWith :: IsStream t => (t m b -> t m b -> t m b) -> (a -> t m b) -> t m a -> t m b
bindWith :: IsStream t => (t m b -> t m b -> t m b) -> t m a -> (a -> t m b) -> t m b

-- | Like <tt>concatMapWith</tt> but carries a state which can be used to
--   share information across multiple steps of concat.
--   
--   <pre>
--   concatSmapMWith combine f initial = concatMapWith combine id . smapM f initial
--   </pre>
--   
--   <i>Pre-release</i>
concatSmapMWith :: (IsStream t, Monad m) => (t m b -> t m b -> t m b) -> (s -> a -> m (s, t m b)) -> m s -> t m a -> t m b

-- | Combine streams in pairs using a binary stream combinator, then
--   combine the resulting streams in pairs recursively until we get to a
--   single combined stream.
--   
--   For example, you can sort a stream using merge sort like this:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.concatPairsWith (Stream.mergeBy compare) Stream.fromPure $ Stream.fromList [5,1,7,9,2]
--   [1,2,5,7,9]
--   </pre>
--   
--   <i>Caution: the stream of streams must be finite</i>
--   
--   <i>Pre-release</i>
concatPairsWith :: IsStream t => (t m b -> t m b -> t m b) -> (a -> t m b) -> t m a -> t m b

-- | Like <tt>iterateM</tt> but iterates after mapping a stream generator
--   on the output.
--   
--   Yield an input element in the output stream, map a stream generator on
--   it and then do the same on the resulting stream. This can be used for
--   a depth first traversal of a tree like structure.
--   
--   Note that <tt>iterateM</tt> is a special case of
--   <a>iterateMapWith</a>:
--   
--   <pre>
--   iterateM f = iterateMapWith serial (fromEffect . f) . fromEffect
--   </pre>
--   
--   It can be used to traverse a tree structure. For example, to list a
--   directory tree:
--   
--   <pre>
--   Stream.iterateMapWith Stream.serial
--       (either Dir.toEither (const nil))
--       (fromPure (Left "tmp"))
--   </pre>
--   
--   <i>Pre-release</i>
iterateMapWith :: IsStream t => (t m a -> t m a -> t m a) -> (a -> t m a) -> t m a -> t m a

-- | Like <tt>iterateMap</tt> but carries a state in the stream generation
--   function. This can be used to traverse graph like structures, we can
--   remember the visited nodes in the state to avoid cycles.
--   
--   Note that a combination of <tt>iterateMap</tt> and <tt>usingState</tt>
--   can also be used to traverse graphs. However, this function provides a
--   more localized state instead of using a global state.
--   
--   See also: <tt>mfix</tt>
--   
--   <i>Pre-release</i>
iterateSmapMWith :: (IsStream t, Monad m) => (t m a -> t m a -> t m a) -> (b -> a -> m (b, t m a)) -> m b -> t m a -> t m a

-- | In an <a>Either</a> stream iterate on <a>Left</a>s. This is a special
--   case of <a>iterateMapWith</a>:
--   
--   <pre>
--   iterateMapLeftsWith combine f = iterateMapWith combine (either f (const nil))
--   </pre>
--   
--   To traverse a directory tree:
--   
--   <pre>
--   iterateMapLeftsWith serial Dir.toEither (fromPure (Left "tmp"))
--   </pre>
--   
--   <i>Pre-release</i>
iterateMapLeftsWith :: IsStream t => (t m (Either a b) -> t m (Either a b) -> t m (Either a b)) -> (a -> t m (Either a b)) -> t m (Either a b) -> t m (Either a b)

-- | <i>Deprecated: Please use unfoldMany instead.</i>
concatUnfold :: (IsStream t, Monad m) => Unfold m a b -> t m a -> t m b

-- | Same as <a>wSerial</a>.

-- | <i>Deprecated: Please use <a>wSerial</a> instead.</i>
(<=>) :: IsStream t => t m a -> t m a -> t m a
infixr 5 <=>

-- | Same as <a>async</a>.

-- | <i>Deprecated: Please use <a>async</a> instead.</i>
(<|) :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a


-- | This module contains functions ending in the shape:
--   
--   <pre>
--   t m a -&gt; m b
--   </pre>
--   
--   We call them stream folding functions, they reduce a stream <tt>t m
--   a</tt> to a monadic value <tt>m b</tt>.
module Streamly.Internal.Data.Stream.IsStream.Eliminate

-- | Fold a stream using the supplied left <a>Fold</a> and reducing the
--   resulting expression strictly at each step. The behavior is similar to
--   <tt>foldl'</tt>. A <a>Fold</a> can terminate early without consuming
--   the full stream. See the documentation of individual <a>Fold</a>s for
--   termination behavior.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.sum (Stream.enumerateFromTo 1 100)
--   5050
--   </pre>
--   
--   Folds never fail, therefore, they produce a default value even when no
--   input is provided. It means we can always fold an empty stream and get
--   a valid result. For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.sum Stream.nil
--   0
--   </pre>
--   
--   However, <tt>foldMany</tt> on an empty stream results in an empty
--   stream. Therefore, <tt>Stream.fold f</tt> is not the same as
--   <tt>Stream.head . Stream.foldMany f</tt>.
--   
--   <pre>
--   fold f = Stream.parse (Parser.fromFold f)
--   </pre>
fold :: Monad m => Fold m a b -> SerialT m a -> m b
fold_ :: Monad m => Fold m a b -> SerialT m a -> m (b, SerialT m a)

-- | We can create higher order folds using <a>foldOn</a>. We can fold a
--   number of streams to a given fold efficiently with full stream fusion.
--   For example, to fold a list of streams on the same sum fold:
--   
--   <pre>
--   &gt;&gt;&gt; concatFold = Prelude.foldl Stream.foldOn Fold.sum
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; fold f = Fold.finish . Stream.foldOn f
--   </pre>
--   
--   <i>Internal</i>
foldOn :: Monad m => Fold m a b -> SerialT m a -> Fold m a b

-- | Parse a stream using the supplied <a>Parser</a>.
--   
--   Unlike folds, parsers may not always result in a valid output, they
--   may result in an error. For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.parse (Parser.takeEQ 1 Fold.drain) Stream.nil
--   *** Exception: ParseError "takeEQ: Expecting exactly 1 elements, input terminated on 0"
--   </pre>
--   
--   Note:
--   
--   <pre>
--   fold f = Stream.parse (Parser.fromFold f)
--   </pre>
--   
--   <tt>parse p</tt> is not the same as <tt>head . parseMany p</tt> on an
--   empty stream.
--   
--   <i>Pre-release</i>
parse :: MonadThrow m => Parser m a b -> SerialT m a -> m b

-- | Parse a stream using the supplied ParserK <a>Parser</a>.
--   
--   <i>Internal</i>
parseK :: MonadThrow m => Parser m a b -> SerialT m a -> m b

-- | Parse a stream using the supplied ParserD <a>Parser</a>.
--   
--   <i>Internal</i>
parseD :: MonadThrow m => Parser m a b -> SerialT m a -> m b

-- | Parse a stream using the supplied <a>Parser</a>.
--   
--   <i>Internal</i>
parse_ :: MonadThrow m => Parser m a b -> SerialT m a -> m (b, SerialT m a)
parseD_ :: MonadThrow m => Parser m a b -> SerialT m a -> m (b, SerialT m a)

-- | Decompose a stream into its head and tail. If the stream is empty,
--   returns <a>Nothing</a>. If the stream is non-empty, returns <tt>Just
--   (a, ma)</tt>, where <tt>a</tt> is the head of the stream and
--   <tt>ma</tt> its tail.
--   
--   This is a brute force primitive. Avoid using it as long as possible,
--   use it when no other combinator can do the job. This can be used to do
--   pretty much anything in an imperative manner, as it just breaks down
--   the stream into individual elements and we can loop over them as we
--   deem fit. For example, this can be used to convert a streamly stream
--   into other stream types.
--   
--   All the folds in this module can be expressed in terms of
--   <a>uncons</a>, however the specific implementations are generally more
--   efficient.
uncons :: (IsStream t, Monad m) => SerialT m a -> m (Maybe (a, t m a))

-- | Right associative/lazy pull fold. <tt>foldrM build final stream</tt>
--   constructs an output structure using the step function <tt>build</tt>.
--   <tt>build</tt> is invoked with the next input element and the
--   remaining (lazy) tail of the output structure. It builds a lazy output
--   expression using the two. When the "tail structure" in the output
--   expression is evaluated it calls <tt>build</tt> again thus lazily
--   consuming the input <tt>stream</tt> until either the output expression
--   built by <tt>build</tt> is free of the "tail" or the input is
--   exhausted in which case <tt>final</tt> is used as the terminating case
--   for the output structure. For more details see the description in the
--   previous section.
--   
--   Example, determine if any element is <a>odd</a> in a stream:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.foldrM (\x xs -&gt; if odd x then return True else xs) (return False) $ Stream.fromList (2:4:5:undefined)
--   True
--   </pre>
--   
--   <i>Since: 0.7.0 (signature changed)</i>
--   
--   <i>Since: 0.2.0 (signature changed)</i>
--   
--   <i>Since: 0.1.0</i>
foldrM :: Monad m => (a -> m b -> m b) -> m b -> SerialT m a -> m b

-- | Right fold, lazy for lazy monads and pure streams, and strict for
--   strict monads.
--   
--   Please avoid using this routine in strict monads like IO unless you
--   need a strict right fold. This is provided only for use in lazy monads
--   (e.g. Identity) or pure streams. Note that with this signature it is
--   not possible to implement a lazy foldr when the monad <tt>m</tt> is
--   strict. In that case it would be strict in its accumulator and
--   therefore would necessarily consume all its input.
foldr :: Monad m => (a -> b -> b) -> b -> SerialT m a -> m b

-- | Lazy left fold to a stream.
foldlS :: IsStream t => (t m b -> a -> t m b) -> t m b -> t m a -> t m b

-- | Lazy left fold to a transformer monad.
--   
--   For example, to reverse a stream:
--   
--   <pre>
--   S.toList $ S.foldlT (flip S.cons) S.nil $ (S.fromList [1..5] :: SerialT IO Int)
--   </pre>
foldlT :: (Monad m, IsStream t, Monad (s m), MonadTrans s) => (s m b -> a -> s m b) -> s m b -> t m a -> s m b

-- | Left associative/strict push fold. <tt>foldl' reduce initial
--   stream</tt> invokes <tt>reduce</tt> with the accumulator and the next
--   input in the input stream, using <tt>initial</tt> as the initial value
--   of the current value of the accumulator. When the input is exhausted
--   the current value of the accumulator is returned. Make sure to use a
--   strict data structure for accumulator to not build unnecessary lazy
--   expressions unless that's what you want. See the previous section for
--   more details.
foldl' :: Monad m => (b -> a -> b) -> b -> SerialT m a -> m b

-- | Strict left fold, for non-empty streams, using first element as the
--   starting value. Returns <a>Nothing</a> if the stream is empty.
foldl1' :: Monad m => (a -> a -> a) -> SerialT m a -> m (Maybe a)

-- | Like <a>foldl'</a> but with a monadic step function.
--   
--   <i>Since: 0.2.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
foldlM' :: Monad m => (b -> a -> m b) -> m b -> SerialT m a -> m b

-- | <pre>
--   mapM_ = Stream.drain . Stream.mapM
--   </pre>
--   
--   Apply a monadic action to each element of the stream and discard the
--   output of the action. This is not really a pure transformation
--   operation but a transformation followed by fold.
mapM_ :: Monad m => (a -> m b) -> SerialT m a -> m ()

-- | <pre>
--   drain = mapM_ (\_ -&gt; return ())
--   drain = Stream.fold Fold.drain
--   </pre>
--   
--   Run a stream, discarding the results. By default it interprets the
--   stream as <a>SerialT</a>, to run other types of streams use the type
--   adapting combinators for example <tt>Stream.drain .
--   <tt>fromAsync</tt></tt>.
drain :: Monad m => SerialT m a -> m ()

-- | Extract the last element of the stream, if any.
--   
--   <pre>
--   last xs = xs !! (Stream.length xs - 1)
--   last = Stream.fold Fold.last
--   </pre>
last :: Monad m => SerialT m a -> m (Maybe a)

-- | Determine the length of the stream.
length :: Monad m => SerialT m a -> m Int

-- | Determine the sum of all elements of a stream of numbers. Returns
--   <tt>0</tt> when the stream is empty. Note that this is not numerically
--   stable for floating point numbers.
--   
--   <pre>
--   sum = Stream.fold Fold.sum
--   </pre>
sum :: (Monad m, Num a) => SerialT m a -> m a

-- | Determine the product of all elements of a stream of numbers. Returns
--   <tt>1</tt> when the stream is empty.
--   
--   <pre>
--   product = Stream.fold Fold.product
--   </pre>
product :: (Monad m, Num a) => SerialT m a -> m a

-- | Fold a stream of monoid elements by appending them.
--   
--   <pre>
--   mconcat = Stream.fold Fold.mconcat
--   </pre>
--   
--   <i>Pre-release</i>
mconcat :: (Monad m, Monoid a) => SerialT m a -> m a

-- | Determine the maximum element in a stream using the supplied
--   comparison function.
--   
--   <pre>
--   maximumBy = Stream.fold Fold.maximumBy
--   </pre>
maximumBy :: Monad m => (a -> a -> Ordering) -> SerialT m a -> m (Maybe a)

-- | <pre>
--   maximum = <a>maximumBy</a> compare
--   maximum = Stream.fold Fold.maximum
--   </pre>
--   
--   Determine the maximum element in a stream.
maximum :: (Monad m, Ord a) => SerialT m a -> m (Maybe a)

-- | Determine the minimum element in a stream using the supplied
--   comparison function.
--   
--   <pre>
--   minimumBy = Stream.fold Fold.minimumBy
--   </pre>
minimumBy :: Monad m => (a -> a -> Ordering) -> SerialT m a -> m (Maybe a)

-- | <pre>
--   minimum = <a>minimumBy</a> compare
--   minimum = Stream.fold Fold.minimum
--   </pre>
--   
--   Determine the minimum element in a stream.
minimum :: (Monad m, Ord a) => SerialT m a -> m (Maybe a)

-- | Ensures that all the elements of the stream are identical and then
--   returns that unique element.
the :: (Eq a, Monad m) => SerialT m a -> m (Maybe a)

-- | <pre>
--   drainN n = Stream.drain . Stream.take n
--   drainN n = Stream.fold (Fold.take n Fold.drain)
--   </pre>
--   
--   Run maximum up to <tt>n</tt> iterations of a stream.
drainN :: Monad m => Int -> SerialT m a -> m ()

-- | <pre>
--   drainWhile p = Stream.drain . Stream.takeWhile p
--   </pre>
--   
--   Run a stream as long as the predicate holds true.
drainWhile :: Monad m => (a -> Bool) -> SerialT m a -> m ()

-- | Lookup the element at the given index.
(!!) :: Monad m => SerialT m a -> Int -> m (Maybe a)

-- | Extract the first element of the stream, if any.
--   
--   <pre>
--   head = (!! 0)
--   head = Stream.fold Fold.head
--   </pre>
head :: Monad m => SerialT m a -> m (Maybe a)

-- | Extract the first element of the stream, if any, otherwise use the
--   supplied default value. It can help avoid one branch in high
--   performance code.
--   
--   <i>Pre-release</i>
headElse :: Monad m => a -> SerialT m a -> m a

-- | <pre>
--   tail = fmap (fmap snd) . Stream.uncons
--   </pre>
--   
--   Extract all but the first element of the stream, if any.
tail :: (IsStream t, Monad m) => SerialT m a -> m (Maybe (t m a))

-- | Extract all but the last element of the stream, if any.
init :: (IsStream t, Monad m) => SerialT m a -> m (Maybe (t m a))

-- | Returns the first element that satisfies the given predicate.
--   
--   <pre>
--   findM = Stream.fold Fold.findM
--   </pre>
findM :: Monad m => (a -> m Bool) -> SerialT m a -> m (Maybe a)

-- | Like <a>findM</a> but with a non-monadic predicate.
--   
--   <pre>
--   find p = findM (return . p)
--   find = Stream.fold Fold.find
--   </pre>
find :: Monad m => (a -> Bool) -> SerialT m a -> m (Maybe a)

-- | Returns the first index that satisfies the given predicate.
--   
--   <pre>
--   findIndex = Stream.fold Fold.findIndex
--   </pre>
findIndex :: Monad m => (a -> Bool) -> SerialT m a -> m (Maybe Int)

-- | Returns the first index where a given value is found in the stream.
--   
--   <pre>
--   elemIndex a = Stream.findIndex (== a)
--   </pre>
elemIndex :: (Monad m, Eq a) => a -> SerialT m a -> m (Maybe Int)

-- | In a stream of (key-value) pairs <tt>(a, b)</tt>, return the value
--   <tt>b</tt> of the first pair where the key equals the given value
--   <tt>a</tt>.
--   
--   <pre>
--   lookup = snd &lt;$&gt; Stream.find ((==) . fst)
--   lookup = Stream.fold Fold.lookup
--   </pre>
lookup :: (Monad m, Eq a) => a -> SerialT m (a, b) -> m (Maybe b)

-- | Determine whether the stream is empty.
--   
--   <pre>
--   null = Stream.fold Fold.null
--   </pre>
null :: Monad m => SerialT m a -> m Bool

-- | Determine whether an element is present in the stream.
--   
--   <pre>
--   elem = Stream.fold Fold.elem
--   </pre>
elem :: (Monad m, Eq a) => a -> SerialT m a -> m Bool

-- | Determine whether an element is not present in the stream.
--   
--   <pre>
--   notElem = Stream.fold Fold.length
--   </pre>
notElem :: (Monad m, Eq a) => a -> SerialT m a -> m Bool

-- | Determine whether all elements of a stream satisfy a predicate.
--   
--   <pre>
--   all = Stream.fold Fold.all
--   </pre>
all :: Monad m => (a -> Bool) -> SerialT m a -> m Bool

-- | Determine whether any of the elements of a stream satisfy a predicate.
--   
--   <pre>
--   any = Stream.fold Fold.any
--   </pre>
any :: Monad m => (a -> Bool) -> SerialT m a -> m Bool

-- | Determines if all elements of a boolean stream are True.
--   
--   <pre>
--   and = Stream.fold Fold.and
--   </pre>
and :: Monad m => SerialT m Bool -> m Bool

-- | Determines whether at least one element of a boolean stream is True.
--   
--   <pre>
--   or = Stream.fold Fold.or
--   </pre>
or :: Monad m => SerialT m Bool -> m Bool

-- | <pre>
--   toList = Stream.foldr (:) []
--   </pre>
--   
--   Convert a stream into a list in the underlying monad. The list can be
--   consumed lazily in a lazy monad (e.g. <tt>Identity</tt>). In a strict
--   monad (e.g. IO) the whole list is generated and buffered before it can
--   be consumed.
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using <a>Streamly.Array</a>
--   instead.
toList :: Monad m => SerialT m a -> m [a]

-- | <pre>
--   toListRev = Stream.foldl' (flip (:)) []
--   </pre>
--   
--   Convert a stream into a list in reverse order in the underlying monad.
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using <a>Streamly.Array</a>
--   instead.
--   
--   <i>Pre-release</i>
toListRev :: Monad m => SerialT m a -> m [a]

-- | Convert a stream to a pure stream.
--   
--   <pre>
--   toStream = Stream.foldr Stream.cons Stream.nil
--   </pre>
--   
--   <i>Pre-release</i>
toStream :: Monad m => SerialT m a -> m (SerialT n a)

-- | Convert a stream to a pure stream in reverse order.
--   
--   <pre>
--   toStreamRev = Stream.foldl' (flip Stream.cons) Stream.nil
--   </pre>
--   
--   <i>Pre-release</i>
toStreamRev :: Monad m => SerialT m a -> m (SerialT n a)

-- | Same as <a>|$.</a>.
--   
--   <i>Internal</i>
foldAsync :: (IsStream t, MonadAsync m) => (t m a -> m b) -> t m a -> m b

-- | Parallel fold application operator; applies a fold function <tt>t m a
--   -&gt; m b</tt> to a stream <tt>t m a</tt> concurrently; The the input
--   stream is evaluated asynchronously in an independent thread yielding
--   elements to a buffer and the folding action runs in another thread
--   consuming the input from the buffer.
--   
--   If you read the signature as <tt>(t m a -&gt; m b) -&gt; (t m a -&gt;
--   m b)</tt> you can look at it as a transformation that converts a fold
--   function to a buffered concurrent fold function.
--   
--   The <tt>.</tt> at the end of the operator is a mnemonic for
--   termination of the stream.
--   
--   In the example below, each stage introduces a delay of 1 sec but
--   output is printed every second because both stages are concurrent.
--   
--   <pre>
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; import Streamly.Prelude ((|$.))
--   
--   &gt;&gt;&gt; :{
--    Stream.foldlM' (\_ a -&gt; threadDelay 1000000 &gt;&gt; print a) (return ())
--        |$. Stream.replicateM 3 (threadDelay 1000000 &gt;&gt; return 1)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|$.) :: (IsStream t, MonadAsync m) => (t m a -> m b) -> t m a -> m b
infixr 0 |$.

-- | Same as <a>|$.</a> but with arguments reversed.
--   
--   <pre>
--   (|&amp;.) = flip (|$.)
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|&.) :: (IsStream t, MonadAsync m) => t m a -> (t m a -> m b) -> m b
infixl 1 |&.

-- | Compare two streams for equality using an equality function.
eqBy :: (IsStream t, Monad m) => (a -> b -> Bool) -> t m a -> t m b -> m Bool

-- | Compare two streams lexicographically using a comparison function.
cmpBy :: (IsStream t, Monad m) => (a -> b -> Ordering) -> t m a -> t m b -> m Ordering

-- | Returns <a>True</a> if the first stream is the same as or a prefix of
--   the second. A stream is a prefix of itself.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.isPrefixOf (Stream.fromList "hello") (Stream.fromList "hello" :: SerialT IO Char)
--   True
--   </pre>
isPrefixOf :: (Eq a, IsStream t, Monad m) => t m a -> t m a -> m Bool

-- | Returns <a>True</a> if the first stream is an infix of the second. A
--   stream is considered an infix of itself.
--   
--   <pre>
--   Stream.isInfixOf (Stream.fromList "hello") (Stream.fromList "hello" :: SerialT IO Char)
--   </pre>
--   
--   True
--   
--   Space: <tt>O(n)</tt> worst case where <tt>n</tt> is the length of the
--   infix.
--   
--   <i>Pre-release</i>
--   
--   <i>Requires <a>Storable</a> constraint</i>
isInfixOf :: (MonadIO m, Eq a, Enum a, Storable a) => SerialT m a -> SerialT m a -> m Bool

-- | Returns <a>True</a> if the first stream is a suffix of the second. A
--   stream is considered a suffix of itself.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.isSuffixOf (Stream.fromList "hello") (Stream.fromList "hello" :: SerialT IO Char)
--   True
--   </pre>
--   
--   Space: <tt>O(n)</tt>, buffers entire input stream and the suffix.
--   
--   <i>Pre-release</i>
--   
--   <i>Suboptimal</i> - Help wanted.
isSuffixOf :: (Monad m, Eq a) => SerialT m a -> SerialT m a -> m Bool

-- | Returns <a>True</a> if all the elements of the first stream occur, in
--   order, in the second stream. The elements do not have to occur
--   consecutively. A stream is a subsequence of itself.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.isSubsequenceOf (Stream.fromList "hlo") (Stream.fromList "hello" :: SerialT IO Char)
--   True
--   </pre>
isSubsequenceOf :: (Eq a, IsStream t, Monad m) => t m a -> t m a -> m Bool

-- | <tt>stripPrefix prefix stream</tt> strips <tt>prefix</tt> from
--   <tt>stream</tt> if it is a prefix of stream. Returns <a>Nothing</a> if
--   the stream does not start with the given prefix, stripped stream
--   otherwise. Returns <tt>Just nil</tt> when the prefix is the same as
--   the stream.
--   
--   See also "Streamly.Internal.Data.Stream.IsStream.Nesting.dropPrefix".
--   
--   Space: <tt>O(1)</tt>
stripPrefix :: (Eq a, IsStream t, Monad m) => t m a -> t m a -> m (Maybe (t m a))

-- | Drops the given suffix from a stream. Returns <a>Nothing</a> if the
--   stream does not end with the given suffix. Returns <tt>Just nil</tt>
--   when the suffix is the same as the stream.
--   
--   It may be more efficient to convert the stream to an Array and use
--   stripSuffix on that especially if the elements have a Storable or Prim
--   instance.
--   
--   See also "Streamly.Internal.Data.Stream.IsStream.Nesting.dropSuffix".
--   
--   Space: <tt>O(n)</tt>, buffers the entire input stream as well as the
--   suffix
--   
--   <i>Pre-release</i>
stripSuffix :: (Monad m, Eq a) => SerialT m a -> SerialT m a -> m (Maybe (SerialT m a))

-- | Strict left fold with an extraction function. Like the standard strict
--   left fold, but applies a user supplied extraction function (the third
--   argument) to the folded value at the end. This is designed to work
--   with the <tt>foldl</tt> library. The suffix <tt>x</tt> is a mnemonic
--   for extraction.

-- | <i>Deprecated: Please use foldl' followed by fmap instead.</i>
foldx :: Monad m => (x -> a -> x) -> x -> (x -> b) -> SerialT m a -> m b

-- | Like <a>foldx</a>, but with a monadic step function.

-- | <i>Deprecated: Please use foldlM' followed by fmap instead.</i>
foldxM :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> SerialT m a -> m b

-- | Lazy right fold for non-empty streams, using first element as the
--   starting value. Returns <a>Nothing</a> if the stream is empty.

-- | <i>Deprecated: Use foldrM instead.</i>
foldr1 :: Monad m => (a -> a -> a) -> SerialT m a -> m (Maybe a)

-- | Run a stream, discarding the results. By default it interprets the
--   stream as <a>SerialT</a>, to run other types of streams use the type
--   adapting combinators for example <tt>runStream .
--   <tt>fromAsync</tt></tt>.

-- | <i>Deprecated: Please use "drain" instead</i>
runStream :: Monad m => SerialT m a -> m ()

-- | <pre>
--   runN n = runStream . take n
--   </pre>
--   
--   Run maximum up to <tt>n</tt> iterations of a stream.

-- | <i>Deprecated: Please use "drainN" instead</i>
runN :: Monad m => Int -> SerialT m a -> m ()

-- | <pre>
--   runWhile p = runStream . takeWhile p
--   </pre>
--   
--   Run a stream as long as the predicate holds true.

-- | <i>Deprecated: Please use "drainWhile" instead</i>
runWhile :: Monad m => (a -> Bool) -> SerialT m a -> m ()

-- | <pre>
--   toHandle h = S.mapM_ $ hPutStrLn h
--   </pre>
--   
--   Write a stream of Strings to an IO Handle.

-- | <i>Deprecated: Please use Streamly.FileSystem.Handle module (see the
--   changelog)</i>
toHandle :: MonadIO m => Handle -> SerialT m String -> m ()


-- | Top level IsStream module that can use all other lower level IsStream
--   modules.
module Streamly.Internal.Data.Stream.IsStream.Top

-- | <tt>sampleFromthen offset stride</tt> samples the element at
--   <tt>offset</tt> index and then every element at strides of
--   <tt>stride</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.sampleFromThen 2 3 $ Stream.enumerateFromTo 0 10
--   [2,5,8]
--   </pre>
--   
--   <i>Pre-release</i>
sampleFromThen :: (IsStream t, Monad m, Functor (t m)) => Int -> Int -> t m a -> t m a

-- | Like <tt>sampleInterval</tt> but samples at the beginning of the time
--   window.
--   
--   <pre>
--   sampleIntervalStart n = Stream.catMaybes . Stream.intervalsOf n Fold.head
--   </pre>
--   
--   <i>Pre-release</i>
sampleIntervalStart :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m a -> t m a

-- | Continuously evaluate the input stream and sample the last event in
--   time window of <tt>n</tt> seconds.
--   
--   This is also known as <tt>throttle</tt> in some libraries.
--   
--   <pre>
--   sampleIntervalEnd n = Stream.catMaybes . Stream.intervalsOf n Fold.last
--   </pre>
--   
--   <i>Pre-release</i>
sampleIntervalEnd :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m a -> t m a

-- | Like <a>sampleBurstEnd</a> but samples the event at the beginning of
--   the burst instead of at the end of it.
--   
--   <i>Pre-release</i>
sampleBurstStart :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m a -> t m a

-- | Sample one event at the end of each burst of events. A burst is a
--   group of events close together in time, it ends when an event is
--   spaced by more than the specified time interval from the previous
--   event.
--   
--   This is known as <tt>debounce</tt> in some libraries.
--   
--   The clock granularity is 10 ms.
--   
--   <i>Pre-release</i>
sampleBurstEnd :: (IsStream t, MonadAsync m, Functor (t m)) => Double -> t m a -> t m a

-- | Sort the input stream using a supplied comparison function.
--   
--   <i>O(n) space</i>
--   
--   Note: this is not the fastest possible implementation as of now.
--   
--   <i>Pre-release</i>
sortBy :: MonadCatch m => (a -> a -> Ordering) -> SerialT m a -> SerialT m a

-- | <a>intersectBy</a> is essentially a filtering operation that retains
--   only those elements in the first stream that are present in the second
--   stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intersectBy (==) (Stream.fromList [1,2,2,4]) (Stream.fromList [2,1,1,3])
--   [1,2,2]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intersectBy (==) (Stream.fromList [2,1,1,3]) (Stream.fromList [1,2,2,4])
--   [2,1,1]
--   </pre>
--   
--   <a>intersectBy</a> is similar to but not the same as <a>innerJoin</a>:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ fmap fst $ Stream.innerJoin (==) (Stream.fromList [1,2,2,4]) (Stream.fromList [2,1,1,3])
--   [1,1,2,2]
--   </pre>
--   
--   Space: O(n) where <tt>n</tt> is the number of elements in the second
--   stream.
--   
--   Time: O(m x n) where <tt>m</tt> is the number of elements in the first
--   stream and <tt>n</tt> is the number of elements in the second stream.
--   
--   <i>Pre-release</i>
intersectBy :: (IsStream t, Monad m) => (a -> a -> Bool) -> t m a -> t m a -> t m a

-- | Like <a>intersectBy</a> but works only on sorted streams.
--   
--   Space: O(1)
--   
--   Time: O(m+n)
--   
--   <i>Unimplemented</i>
mergeIntersectBy :: (a -> a -> Ordering) -> t m a -> t m a -> t m a

-- | Delete first occurrences of those elements from the first stream that
--   are present in the second stream. If an element occurs multiple times
--   in the second stream as many occurrences of it are deleted from the
--   first stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.differenceBy (==) (Stream.fromList [1,2,2]) (Stream.fromList [1,2,3])
--   [2]
--   </pre>
--   
--   The following laws hold:
--   
--   <pre>
--   (s1 <tt>serial</tt> s2) `differenceBy eq` s1 === s2
--   (s1 <tt>wSerial</tt> s2) `differenceBy eq` s1 === s2
--   </pre>
--   
--   Same as the list <a>//</a> operation.
--   
--   Space: O(m) where <tt>m</tt> is the number of elements in the first
--   stream.
--   
--   Time: O(m x n) where <tt>m</tt> is the number of elements in the first
--   stream and <tt>n</tt> is the number of elements in the second stream.
--   
--   <i>Pre-release</i>
differenceBy :: (IsStream t, Monad m) => (a -> a -> Bool) -> t m a -> t m a -> t m a

-- | Like <a>differenceBy</a> but works only on sorted streams.
--   
--   Space: O(1)
--   
--   <i>Unimplemented</i>
mergeDifferenceBy :: (a -> a -> Ordering) -> t m a -> t m a -> t m a

-- | This is essentially an append operation that appends all the extra
--   occurrences of elements from the second stream that are not already
--   present in the first stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.unionBy (==) (Stream.fromList [1,2,2,4]) (Stream.fromList [1,1,2,3])
--   [1,2,2,4,3]
--   </pre>
--   
--   Equivalent to the following except that <tt>s1</tt> is evaluated only
--   once:
--   
--   <pre>
--   unionBy eq s1 s2 = s1 `serial` (s2 `differenceBy eq` s1)
--   </pre>
--   
--   Similar to <a>outerJoin</a> but not the same.
--   
--   Space: O(n)
--   
--   Time: O(m x n)
--   
--   <i>Pre-release</i>
unionBy :: (IsStream t, MonadAsync m, Semigroup (t m a)) => (a -> a -> Bool) -> t m a -> t m a -> t m a

-- | Like <a>unionBy</a> but works only on sorted streams.
--   
--   Space: O(1)
--   
--   <i>Unimplemented</i>
mergeUnionBy :: (a -> a -> Ordering) -> t m a -> t m a -> t m a

-- | This is the same as <a>outerProduct</a> but less efficient.
--   
--   The second stream is evaluated multiple times. If the second stream is
--   consume-once stream then it can be cached in an <a>Array</a> before
--   calling this function. Caching may also improve performance if the
--   stream is expensive to evaluate.
--   
--   Time: O(m x n)
--   
--   <i>Pre-release</i>
crossJoin :: Monad (t m) => t m a -> t m b -> t m (a, b)

-- | For all elements in <tt>t m a</tt>, for all elements in <tt>t m b</tt>
--   if <tt>a</tt> and <tt>b</tt> are equal by the given equality pedicate
--   then return the tuple (a, b).
--   
--   The second stream is evaluated multiple times. If the stream is a
--   consume-once stream then the caller should cache it in an <a>Array</a>
--   before calling this function. Caching may also improve performance if
--   the stream is expensive to evaluate.
--   
--   For space efficiency use the smaller stream as the second stream.
--   
--   Space: O(n) assuming the second stream is cached in memory.
--   
--   Time: O(m x n)
--   
--   <i>Pre-release</i>
innerJoin :: forall (t :: (Type -> Type) -> Type -> Type) m a b. (IsStream t, Monad (t m)) => (a -> b -> Bool) -> t m a -> t m b -> t m (a, b)

-- | Like <a>innerJoin</a> but works only on sorted streams.
--   
--   Space: O(1)
--   
--   Time: O(m + n)
--   
--   <i>Unimplemented</i>
mergeInnerJoin :: (a -> b -> Ordering) -> t m a -> t m b -> t m (a, b)

-- | Like <a>innerJoin</a> but uses a hashmap for efficiency.
--   
--   For space efficiency use the smaller stream as the second stream.
--   
--   Space: O(n)
--   
--   Time: O(m + n)
--   
--   <i>Unimplemented</i>
hashInnerJoin :: (a -> b -> Bool) -> t m a -> t m b -> t m (a, b)

-- | For all elements in <tt>t m a</tt>, for all elements in <tt>t m b</tt>
--   if <tt>a</tt> and <tt>b</tt> are equal then return the tuple <tt>(a,
--   Just b)</tt>. If <tt>a</tt> is not present in <tt>t m b</tt> then
--   return <tt>(a, Nothing)</tt>.
--   
--   The second stream is evaluated multiple times. If the stream is a
--   consume-once stream then the caller should cache it in an <a>Array</a>
--   before calling this function. Caching may also improve performance if
--   the stream is expensive to evaluate.
--   
--   <pre>
--   rightJoin = flip leftJoin
--   </pre>
--   
--   Space: O(n) assuming the second stream is cached in memory.
--   
--   Time: O(m x n)
--   
--   <i>Unimplemented</i>
leftJoin :: Monad m => (a -> b -> Bool) -> SerialT m a -> SerialT m b -> SerialT m (a, Maybe b)

-- | Like <a>leftJoin</a> but works only on sorted streams.
--   
--   Space: O(1)
--   
--   Time: O(m + n)
--   
--   <i>Unimplemented</i>
mergeLeftJoin :: (a -> b -> Ordering) -> t m a -> t m b -> t m (a, Maybe b)

-- | Like <a>outerJoin</a> but uses a hashmap for efficiency.
--   
--   Space: O(n)
--   
--   Time: O(m + n)
--   
--   <i>Unimplemented</i>
hashLeftJoin :: (a -> b -> Bool) -> t m a -> t m b -> t m (a, Maybe b)

-- | For all elements in <tt>t m a</tt>, for all elements in <tt>t m b</tt>
--   if <tt>a</tt> and <tt>b</tt> are equal by the given equality pedicate
--   then return the tuple (Just a, Just b). If <tt>a</tt> is not found in
--   <tt>t m b</tt> then return (a, Nothing), return (Nothing, b) for
--   vice-versa.
--   
--   For space efficiency use the smaller stream as the second stream.
--   
--   Space: O(n)
--   
--   Time: O(m x n)
--   
--   <i>Unimplemented</i>
outerJoin :: MonadIO m => (a -> b -> Bool) -> SerialT m a -> SerialT m b -> SerialT m (Maybe a, Maybe b)

-- | Like <a>outerJoin</a> but works only on sorted streams.
--   
--   Space: O(1)
--   
--   Time: O(m + n)
--   
--   <i>Unimplemented</i>
mergeOuterJoin :: (a -> b -> Ordering) -> t m a -> t m b -> t m (Maybe a, Maybe b)

-- | Like <a>outerJoin</a> but uses a hashmap for efficiency.
--   
--   For space efficiency use the smaller stream as the second stream.
--   
--   Space: O(n)
--   
--   Time: O(m + n)
--   
--   <i>Unimplemented</i>
hashOuterJoin :: (a -> b -> Ordering) -> t m a -> t m b -> t m (Maybe a, Maybe b)


-- | This is an internal module which is a superset of the corresponding
--   released module <a>Streamly.Prelude</a>. It contains some additional
--   unreleased or experimental APIs.
module Streamly.Internal.Data.Stream.IsStream

-- | The type <tt>Stream m a</tt> represents a monadic stream of values of
--   type <tt>a</tt> constructed using actions in monad <tt>m</tt>. It uses
--   stop, singleton and yield continuations equivalent to the following
--   direct style type:
--   
--   <pre>
--   data Stream m a = Stop | Singleton a | Yield a (Stream m a)
--   </pre>
--   
--   To facilitate parallel composition we maintain a local state in an
--   <tt>SVar</tt> that is shared across and is used for synchronization of
--   the streams being composed.
--   
--   The singleton case can be expressed in terms of stop and yield but we
--   have it as a separate case to optimize composition operations for
--   streams with single element. We build singleton streams in the
--   implementation of <a>pure</a> for Applicative and Monad, and in
--   <a>lift</a> for MonadTrans.
newtype Stream m a
MkStream :: (forall r. State Stream m a -> (a -> Stream m a -> m r) -> (a -> m r) -> m r -> m r) -> Stream m a

-- | An interleaving serial IO stream of elements of type <tt>a</tt>. See
--   <a>WSerialT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WSerial = WSerialT IO

-- | For <a>WSerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wSerial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wSerial</a> -- <a>Monad</a>
--   </pre>
--   
--   Note that <a>&lt;&gt;</a> is associative only if we disregard the
--   ordering of elements in the resulting stream.
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like interleaved nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   It is a result of interleaving all the nested iterations corresponding
--   to element <tt>1</tt> in the first stream with all the nested
--   iterations of element <tt>2</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromList [(1,3),(1,4)] `Stream.wSerial` Stream.fromList [(2,3),(2,4)]
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>SerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WSerialT m a

-- | A serial IO stream of elements of type <tt>a</tt>. See <a>SerialT</a>
--   documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Serial = SerialT IO

-- | For <a>SerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>serial</a> -- <a>Monad</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(1,4),(2,3),(2,4)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data SerialT m a

-- | A round robin parallely composing IO stream of elements of type
--   <tt>a</tt>. See <a>WAsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WAsync = WAsyncT IO

-- | For <a>WAsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wAsync</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wAsync</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>wAsync</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>wAsync</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one <a>WAsyncT</a> output stream and all the iterations corresponding
--   to <tt>2</tt> constitute another <a>WAsyncT</a> output stream and
--   these two output streams are merged using <tt>wAsync</tt>.
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>AsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WAsyncT m a

-- | A demand driven left biased parallely composing IO stream of elements
--   of type <tt>a</tt>. See <a>AsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Async = AsyncT IO

-- | For <a>AsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>async</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>async</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>async</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>async</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>async</tt>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
data AsyncT m a

-- | A serial IO stream of elements of type <tt>a</tt> with concurrent
--   lookahead. See <a>AheadT</a> documentation for more details.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
type Ahead = AheadT IO

-- | For <a>AheadT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>ahead</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>ahead</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations executed concurrently, ahead of time, producing side
--   effects of iterations out of order, but results in order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [2,1]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, ahead of time:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,5,4,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>ahead</tt>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
data AheadT m a

-- | A parallely composing IO stream of elements of type <tt>a</tt>. See
--   <a>ParallelT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Parallel = ParallelT IO

-- | For <a>ParallelT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>parallel</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>parallel</a>
--   </pre>
--   
--   See <a>AsyncT</a>, <a>ParallelT</a> is similar except that all
--   iterations are strictly concurrent while in <tt>AsyncT</tt> it depends
--   on the consumer demand and available threads. See <tt>parallel</tt>
--   for more details.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
--   
--   <i>Since: 0.7.0 (maxBuffer applies to ParallelT streams)</i>
data ParallelT m a

-- | An IO stream whose applicative instance zips streams wAsyncly.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipAsync = ZipAsyncM IO

-- | For <a>ZipAsyncM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipAsyncWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped concurrently, the
--   following would take half the time that it would take in serial
--   zipping:
--   
--   <pre>
--   &gt;&gt;&gt; s = Stream.fromFoldableM $ Prelude.map delay [1, 1, 1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipAsync $ (,) &lt;$&gt; s &lt;*&gt; s
--   ...
--   [(1,1),(1,1),(1,1)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipAsyncM m a

-- | An IO stream whose applicative instance zips streams serially.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipSerial = ZipSerialM IO

-- | For <a>ZipSerialM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped serially:
--   
--   <pre>
--   &gt;&gt;&gt; s1 = Stream.fromFoldable [1, 2]
--   
--   &gt;&gt;&gt; s2 = Stream.fromFoldable [3, 4]
--   
--   &gt;&gt;&gt; s3 = Stream.fromFoldable [5, 6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipSerial $ (,,) &lt;$&gt; s1 &lt;*&gt; s2 &lt;*&gt; s3
--   [(1,3,5),(2,4,6)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipSerialM m a

-- | Same as <a>IsStream</a>.

-- | <i>Deprecated: Please use IsStream instead.</i>
type Streaming = IsStream

-- | Class of types that can represent a stream of elements of some type
--   <tt>a</tt> in some monad <tt>m</tt>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
class (forall m a. MonadAsync m => Semigroup (t m a), forall m a. MonadAsync m => Monoid (t m a), forall m. Monad m => Functor (t m), forall m. MonadAsync m => Applicative (t m)) => IsStream t
fromStream :: IsStream t => Stream m a -> t m a

-- | Constructs a stream by adding a monadic action at the head of an
--   existing stream. For example:
--   
--   <pre>
--   &gt; toList $ getLine `consM` getLine `consM` nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
consM :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a

-- | Operator equivalent of <a>consM</a>. We can read it as "<tt>parallel
--   colon</tt>" to remember that <tt>|</tt> comes before <tt>:</tt>.
--   
--   <pre>
--   &gt; toList $ getLine |: getLine |: nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <pre>
--   let delay = threadDelay 1000000 &gt;&gt; print 1
--   drain $ fromSerial  $ delay |: delay |: delay |: nil
--   drain $ fromParallel $ delay |: delay |: delay |: nil
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
(|:) :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a
infixr 5 `consM`
infixr 5 |:
fromStreamS :: (IsStream t, Monad m) => Stream m a -> t m a
toStreamS :: (IsStream t, Monad m) => t m a -> Stream m a
toStreamD :: (IsStream t, Monad m) => t m a -> Stream m a

-- | <pre>
--   fromList = <a>foldr</a> <a>cons</a> <a>nil</a>
--   </pre>
--   
--   Construct a stream from a list of pure values. This is more efficient
--   than <a>fromFoldable</a> for serial streams.
fromList :: (Monad m, IsStream t) => [a] -> t m a
foldrMx :: (IsStream t, Monad m) => (a -> m x -> m x) -> m x -> (m x -> m b) -> t m a -> m b

-- | Like <a>foldlx'</a>, but with a monadic step function.
foldlMx' :: (IsStream t, Monad m) => (x -> a -> m x) -> m x -> (x -> m b) -> t m a -> m b

-- | Strict left fold with an extraction function. Like the standard strict
--   left fold, but applies a user supplied extraction function (the third
--   argument) to the folded value at the end. This is designed to work
--   with the <tt>foldl</tt> library. The suffix <tt>x</tt> is a mnemonic
--   for extraction.
foldlx' :: (IsStream t, Monad m) => (x -> a -> x) -> x -> (x -> b) -> t m a -> m b

-- | Adapt any specific stream type to any other specific stream type.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
adapt :: (IsStream t1, IsStream t2) => t1 m a -> t2 m a
fromStreamD :: (IsStream t, Monad m) => Stream m a -> t m a

-- | Adapt a polymorphic consM operation to a StreamK cons operation
toConsK :: IsStream t => (m a -> t m a -> t m a) -> m a -> Stream m a -> Stream m a

-- | Build a stream from an <tt>SVar</tt>, a stop continuation, a singleton
--   stream continuation and a yield continuation.
mkStream :: IsStream t => (forall r. State Stream m a -> (a -> t m a -> m r) -> (a -> m r) -> m r -> m r) -> t m a

-- | Fold a stream by providing an SVar, a stop continuation, a singleton
--   continuation and a yield continuation. The stream would share the
--   current SVar passed via the State.
foldStreamShared :: IsStream t => State Stream m a -> (a -> t m a -> m r) -> (a -> m r) -> m r -> t m a -> m r

-- | Fold a stream by providing a State, stop continuation, a singleton
--   continuation and a yield continuation. The stream will not use the
--   SVar passed via State.
foldStream :: IsStream t => State Stream m a -> (a -> t m a -> m r) -> (a -> m r) -> m r -> t m a -> m r

-- | Fix the type of a polymorphic stream as <a>SerialT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromSerial :: IsStream t => SerialT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>WSerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromWSerial :: IsStream t => WSerialT m a -> t m a

-- | Same as <a>fromWSerial</a>.

-- | <i>Deprecated: Please use fromWSerial instead.</i>
interleaving :: IsStream t => WSerialT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>AsyncT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromAsync :: IsStream t => AsyncT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>WAsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromWAsync :: IsStream t => WAsyncT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>AheadT</a>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
fromAhead :: IsStream t => AheadT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>ParallelT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromParallel :: IsStream t => ParallelT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>ZipSerialM</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromZipSerial :: IsStream t => ZipSerialM m a -> t m a

-- | Same as <a>fromZipSerial</a>.

-- | <i>Deprecated: Please use fromZipSerial instead.</i>
zipping :: IsStream t => ZipSerialM m a -> t m a

-- | Fix the type of a polymorphic stream as <a>ZipAsyncM</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromZipAsync :: IsStream t => ZipAsyncM m a -> t m a

-- | Same as <a>fromZipAsync</a>.

-- | <i>Deprecated: Please use fromZipAsync instead.</i>
zippingAsync :: IsStream t => ZipAsyncM m a -> t m a

-- | Construct a stream by adding a pure value at the head of an existing
--   stream. For serial streams this is the same as <tt>(return a) `consM`
--   r</tt> but more efficient. For concurrent streams this is not
--   concurrent whereas <a>consM</a> is concurrent. For example:
--   
--   <pre>
--   &gt; toList $ 1 `cons` 2 `cons` 3 `cons` nil
--   [1,2,3]
--   </pre>
cons :: IsStream t => a -> t m a -> t m a
infixr 5 `cons`

-- | Operator equivalent of <a>cons</a>.
--   
--   <pre>
--   &gt; toList $ 1 .: 2 .: 3 .: nil
--   [1,2,3]
--   </pre>
(.:) :: IsStream t => a -> t m a -> t m a
infixr 5 .:
nil :: IsStream t => t m a
nilM :: (IsStream t, Monad m) => m b -> t m a
bindWith :: IsStream t => (t m b -> t m b -> t m b) -> t m a -> (a -> t m b) -> t m b

-- | <tt>concatMapWith mixer generator stream</tt> is a two dimensional
--   looping combinator. The <tt>generator</tt> function is used to
--   generate streams from the elements in the input <tt>stream</tt> and
--   the <tt>mixer</tt> function is used to merge those streams.
--   
--   Note we can merge streams concurrently by using a concurrent merge
--   function.
--   
--   <i>Since: 0.7.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
concatMapWith :: IsStream t => (t m b -> t m b -> t m b) -> (a -> t m b) -> t m a -> t m b

-- | A variant of <a>foldMap</a> that allows you to map a monadic streaming
--   action on a <a>Foldable</a> container and then fold it using the
--   specified stream merge operation.
--   
--   <pre>
--   concatMapFoldableWith <tt>async</tt> return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatMapFoldableWith f g = Prelude.foldr (f . g) S.nil
--   concatMapFoldableWith f g xs = S.concatMapWith f g (S.fromFoldable xs)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldMapWith to concatMapFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatMapFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> (a -> t m b) -> f a -> t m b

-- | Like <a>concatMapFoldableWith</a> but with the last two arguments
--   reversed i.e. the monadic streaming function is the last argument.
--   
--   Equivalent to:
--   
--   <pre>
--   concatForFoldableWith f xs g = Prelude.foldr (f . g) S.nil xs
--   concatForFoldableWith f = flip (S.concatMapFoldableWith f)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed forEachWith to concatForFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatForFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> f a -> (a -> t m b) -> t m b

-- | A variant of <a>fold</a> that allows you to fold a <a>Foldable</a>
--   container of streams using the specified stream sum operation.
--   
--   <pre>
--   concatFoldableWith <tt>async</tt> $ map return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatFoldableWith f = Prelude.foldr f S.nil
--   concatFoldableWith f = S.concatMapFoldableWith f id
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldWith to concatFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatFoldableWith :: (IsStream t, Foldable f) => (t m a -> t m a -> t m a) -> f (t m a) -> t m a


module Streamly.Internal.FileSystem.Dir
read :: MonadIO m => Unfold m String String

-- | Read files only.
--   
--   <i>Internal</i>
readFiles :: MonadIO m => Unfold m String String

-- | Read directories only. Filter out "." and ".." entries.
--   
--   <i>Internal</i>
readDirs :: MonadIO m => Unfold m String String

-- | Read directories as Left and files as Right. Filter out "." and ".."
--   entries.
--   
--   <i>Internal</i>
readEither :: MonadIO m => Unfold m String (Either String String)

-- | Raw read of a directory.
--   
--   <i>Pre-release</i>
toStream :: (IsStream t, MonadIO m) => String -> t m String

-- | Read directories as Left and files as Right. Filter out "." and ".."
--   entries.
--   
--   <i>Pre-release</i>
toEither :: (IsStream t, MonadIO m) => String -> t m (Either String String)

-- | Read files only.
--   
--   <i>Internal</i>
toFiles :: (IsStream t, MonadIO m) => String -> t m String

-- | Read directories only.
--   
--   <i>Internal</i>
toDirs :: (IsStream t, MonadIO m) => String -> t m String


-- | Unboxed pinned mutable array type for <a>Storable</a> types with an
--   option to use foreign (non-GHC) memory allocators. Fulfils the
--   following goals:
--   
--   <ul>
--   <li>Random access (array)</li>
--   <li>Efficient storage (unboxed)</li>
--   <li>Performance (unboxed access)</li>
--   <li>Performance - in-place operations (mutable)</li>
--   <li>Performance - GC (pinned, mutable)</li>
--   <li>interfacing with OS (pinned)</li>
--   <li>Fragmentation control (foreign allocators)</li>
--   </ul>
--   
--   Stream and Fold APIs allow easy, efficient and convenient operations
--   on arrays.
module Streamly.Internal.Data.Array.Foreign.Mut

-- | Split the array into a stream of slices using a predicate. The element
--   matching the predicate is dropped.
--   
--   <i>Pre-release</i>
splitOn :: (MonadIO m, Storable a) => (a -> Bool) -> Array a -> SerialT m (Array a)

-- | Generate a stream of array slice descriptors ((index, len)) of
--   specified length from an array, starting from the supplied array
--   index. The last slice may be shorter than the requested length
--   depending on the array length.
--   
--   <i>Pre-release</i>
genSlicesFromLen :: forall m a. (Monad m, Storable a) => Int -> Int -> Unfold m (Array a) (Int, Int)

-- | Generate a stream of slices of specified length from an array,
--   starting from the supplied array index. The last slice may be shorter
--   than the requested length depending on the array length.
--   
--   <i>Pre-release</i>
getSlicesFromLen :: forall m a. (Monad m, Storable a) => Int -> Int -> Unfold m (Array a) (Array a)


-- | To summarize:
--   
--   <ul>
--   <li>Arrays are finite and fixed in size</li>
--   <li>provide <i>O(1)</i> access to elements</li>
--   <li>store only data and not functions</li>
--   <li>provide efficient IO interfacing</li>
--   </ul>
--   
--   <a>Foldable</a> instance is not provided because the implementation
--   would be much less efficient compared to folding via streams.
--   <a>Semigroup</a> and <a>Monoid</a> instances should be used with care;
--   concatenating arrays using binary operations can be highly
--   inefficient. Instead, use <a>toArray</a> to concatenate N arrays at
--   once.
--   
--   Each array is one pointer visible to the GC. Too many small arrays
--   (e.g. single byte) are only as good as holding those elements in a
--   Haskell list. However, small arrays can be compacted into large ones
--   to reduce the overhead. To hold 32GB memory in 32k sized buffers we
--   need 1 million arrays if we use one array for each chunk. This is
--   still significant to add pressure to GC.
module Streamly.Internal.Data.Array.Foreign
data Array a

-- | Create an <a>Array</a> of the given number of elements of type
--   <tt>a</tt> from a read only pointer <tt>Ptr a</tt>. The pointer is not
--   freed when the array is garbage collected. This API is unsafe for the
--   following reasons:
--   
--   <ol>
--   <li>The pointer must point to static pinned memory or foreign memory
--   that does not require freeing..</li>
--   <li>The pointer must be legally accessible upto the given length.</li>
--   <li>To guarantee that the array is immutable, the contents of the
--   address must be guaranteed to not change.</li>
--   </ol>
--   
--   <i>Unsafe</i>
--   
--   <i>Pre-release</i>
fromPtr :: Int -> Ptr a -> Array a

-- | Create an <tt>Array Word8</tt> of the given length from a static, read
--   only machine address <a>Addr#</a>. See <a>fromPtr</a> for safety
--   caveats.
--   
--   A common use case for this API is to create an array from a static
--   unboxed string literal. GHC string literals are of type <a>Addr#</a>,
--   and must contain characters that can be encoded in a byte i.e.
--   characters or literal bytes in the range from 0-255.
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Word (Word8)
--   
--   &gt;&gt;&gt; Array.fromAddr# 5 "hello world!"# :: Array Word8
--   [104,101,108,108,111]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Array.fromAddr# 3 "\255\NUL\255"# :: Array Word8
--   [255,0,255]
--   </pre>
--   
--   <i>See also: <tt>fromString#</tt></i>
--   
--   <i>Unsafe</i>
--   
--   <i>Time complexity: O(1)</i>
--   
--   <i>Pre-release</i>
fromAddr# :: Int -> Addr# -> Array a

-- | Generate a byte array from an <a>Addr#</a> that contains a sequence of
--   NUL (<tt>0</tt>) terminated bytes. The array would not include the NUL
--   byte. The address must be in static read-only memory and must be
--   legally accessible up to and including the first NUL byte.
--   
--   An unboxed string literal (e.g. <tt>"hello"#</tt>) is a common example
--   of an <a>Addr#</a> in static read only memory. It represents the UTF8
--   encoded sequence of bytes terminated by a NUL byte (a <a>CString</a>)
--   corresponding to the given unicode string.
--   
--   <pre>
--   &gt;&gt;&gt; Array.fromCString# "hello world!"#
--   [104,101,108,108,111,32,119,111,114,108,100,33]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Array.fromCString# "\255\NUL\255"#
--   [255]
--   </pre>
--   
--   <i>See also: <a>fromAddr#</a></i>
--   
--   <i>Unsafe</i>
--   
--   <i>Time complexity: O(n) (computes the length of the string)</i>
--   
--   <i>Pre-release</i>
fromCString# :: Addr# -> Array Word8

-- | Create an <a>Array</a> from the first N elements of a list. The array
--   is allocated to size N, if the list terminates before N elements then
--   the array may hold less than N elements.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromListN :: Storable a => Int -> [a] -> Array a

-- | Create an <a>Array</a> from a list. The list must be of finite size.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromList :: Storable a => [a] -> Array a

-- | Create an <a>Array</a> from the first N elements of a stream. The
--   array is allocated to size N, if the stream terminates before N
--   elements then the array may hold less than N elements.
--   
--   <i>Pre-release</i>
fromStreamN :: (MonadIO m, Storable a) => Int -> SerialT m a -> m (Array a)

-- | Create an <a>Array</a> from a stream. This is useful when we want to
--   create a single array from a stream of unknown size. <tt>writeN</tt>
--   is at least twice as efficient when the size is already known.
--   
--   Note that if the input stream is too large memory allocation for the
--   array may fail. When the stream size is not known, <tt>arraysOf</tt>
--   followed by processing of indvidual arrays in the resulting stream
--   should be preferred.
--   
--   <i>Pre-release</i>
fromStream :: (MonadIO m, Storable a) => SerialT m a -> m (Array a)

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
writeN :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | <tt>writeNAligned alignment n</tt> folds a maximum of <tt>n</tt>
--   elements from the input stream to an <a>Array</a> aligned to the given
--   size.
--   
--   <i>Pre-release</i>
writeNAligned :: forall m a. (MonadIO m, Storable a) => Int -> Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
write :: forall m a. (MonadIO m, Storable a) => Fold m a (Array a)

-- | <tt>writeLastN n</tt> folds a maximum of <tt>n</tt> elements from the
--   end of the input stream to an <a>Array</a>.
writeLastN :: (Storable a, MonadIO m) => Int -> Fold m a (Array a)

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
toList :: Storable a => Array a -> [a]

-- | Convert an <a>Array</a> into a stream.
--   
--   <i>Pre-release</i>
toStream :: (Monad m, Storable a) => Array a -> SerialT m a

-- | Convert an <a>Array</a> into a stream in reverse order.
--   
--   <i>Pre-release</i>
toStreamRev :: (Monad m, Storable a) => Array a -> SerialT m a

-- | Unfold an array into a stream.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
read :: forall m a. (Monad m, Storable a) => Unfold m (Array a) a

-- | Unfold an array into a stream, does not check the end of the array,
--   the user is responsible for terminating the stream within the array
--   bounds. For high performance application where the end condition can
--   be determined by a terminating fold.
--   
--   Written in the hope that it may be faster than "read", however, in the
--   case for which this was written, "read" proves to be faster even
--   though the core generated with unsafeRead looks simpler.
--   
--   <i>Pre-release</i>
unsafeRead :: forall m a. (Monad m, Storable a) => Unfold m (Array a) a

-- | Unfold an array into a stream in reverse order.
readRev :: forall m a. (Monad m, Storable a) => Unfold m (Array a) a
producer :: forall m a. (Monad m, Storable a) => Producer m (Array a) a

-- | <i>O(1)</i> Lookup the element at the given index. Index starts from
--   0.
getIndex :: forall a. Storable a => Array a -> Int -> Maybe a

-- | Return element at the specified index without checking the bounds.
unsafeIndex :: forall a. Storable a => Array a -> Int -> a

-- | Like <a>getIndex</a> but indexes the array in reverse from the end.
--   
--   <i>Pre-release</i>
getIndexRev :: forall a. Storable a => Array a -> Int -> Maybe a

-- | <pre>
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Array.Foreign as Array
--   
--   &gt;&gt;&gt; last arr = Array.getIndexRev arr 0
--   </pre>
--   
--   <i>Pre-release</i>
last :: Storable a => Array a -> Maybe a

-- | Given a stream of array indices, read the elements on those indices
--   from the supplied Array. An exception is thrown if an index is out of
--   bounds.
--   
--   This is the most general operation. We can implement other operations
--   in terms of this:
--   
--   <pre>
--   read =
--        let u = lmap (arr -&gt; (0, length arr - 1)) Unfold.enumerateFromTo
--         in Unfold.lmap f (getIndices arr)
--   
--   readRev =
--        let i = length arr - 1
--         in Unfold.lmap f (getIndicesFromThenTo i (i - 1) 0)
--   </pre>
--   
--   <i>Unimplemented</i>
getIndices :: Unfold m (Array a) Int -> Unfold m (Array a) a

-- | Unfolds <tt>(from, then, to, array)</tt> generating a finite stream
--   whose first element is the array value from the index <tt>from</tt>
--   and the successive elements are from the indices in increments of
--   <tt>then</tt> up to <tt>to</tt>. Index enumeration can occur downwards
--   or upwards depending on whether <tt>then</tt> comes before or after
--   <tt>from</tt>.
--   
--   <pre>
--   getIndicesFromThenTo =
--       let f (from, next, to, arr) =
--               (Stream.enumerateFromThenTo from next to, arr)
--        in Unfold.lmap f getIndices
--   </pre>
--   
--   <i>Unimplemented</i>
getIndicesFromThenTo :: Unfold m (Int, Int, Int, Array a) a

-- | <i>O(1)</i> Get the length of the array i.e. the number of elements in
--   the array.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
length :: forall a. Storable a => Array a -> Int

-- | <pre>
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Array.Foreign.Type as Array
--   
--   &gt;&gt;&gt; null arr = Array.byteLength arr == 0
--   </pre>
--   
--   <i>Pre-release</i>
null :: Array a -> Bool

-- | Given a sorted array, perform a binary search to find the given
--   element. Returns the index of the element if found.
--   
--   <i>Unimplemented</i>
binarySearch :: a -> Array a -> Maybe Int

-- | Perform a linear search to find all the indices where a given element
--   is present in an array.
--   
--   <i>Unimplemented</i>
findIndicesOf :: (a -> Bool) -> Unfold Identity (Array a) Int

-- | Cast an array having elements of type <tt>a</tt> into an array having
--   elements of type <tt>b</tt>. The length of the array should be a
--   multiple of the size of the target element otherwise <a>Nothing</a> is
--   returned.
cast :: forall a b. Storable b => Array a -> Maybe (Array b)

-- | Cast an <tt>Array a</tt> into an <tt>Array Word8</tt>.
asBytes :: Array a -> Array Word8

-- | Cast an array having elements of type <tt>a</tt> into an array having
--   elements of type <tt>b</tt>. The array size must be a multiple of the
--   size of type <tt>b</tt> otherwise accessing the last element of the
--   array may result into a crash or a random value.
--   
--   <i>Pre-release</i>
unsafeCast :: Array a -> Array b

-- | Use an <tt>Array a</tt> as <tt>Ptr b</tt>.
--   
--   <i>Unsafe</i>
--   
--   <i>Pre-release</i>
unsafeAsPtr :: Array a -> (Ptr b -> IO c) -> IO c

-- | Convert an array of any type into a null terminated CString Ptr.
--   
--   <i>Unsafe</i>
--   
--   <i>O(n) Time: (creates a copy of the array)</i>
--   
--   <i>Pre-release</i>
unsafeAsCString :: Array a -> (CString -> IO b) -> IO b

-- | Makes an immutable array using the underlying memory of the mutable
--   array.
--   
--   Please make sure that there are no other references to the mutable
--   array lying around, so that it is never used after freezing it using
--   <i>unsafeFreeze</i>. If the underlying array is mutated, the immutable
--   promise is lost.
--   
--   <i>Pre-release</i>
unsafeFreeze :: Array a -> Array a

-- | Makes a mutable array using the underlying memory of the immutable
--   array.
--   
--   Please make sure that there are no other references to the immutable
--   array lying around, so that it is never used after thawing it using
--   <i>unsafeThaw</i>. If the resulting array is mutated, any references
--   to the older immutable array are mutated as well.
--   
--   <i>Pre-release</i>
unsafeThaw :: Array a -> Array a

-- | <i>O(1)</i> Slice an array in constant time.
--   
--   Caution: The bounds of the slice are not checked.
--   
--   <i>Unsafe</i>
--   
--   <i>Pre-release</i>
getSliceUnsafe :: forall a. Storable a => Int -> Int -> Array a -> Array a
genSlicesFromLen :: forall m a. (Monad m, Storable a) => Int -> Int -> Unfold m (Array a) (Int, Int)

-- | Generate a stream of slices of specified length from an array,
--   starting from the supplied array index. The last slice may be shorter
--   than the requested length.
--   
--   <i>Pre-release</i>/
getSlicesFromLen :: forall m a. (Monad m, Storable a) => Int -> Int -> Unfold m (Array a) (Array a)

-- | Split the array into a stream of slices using a predicate. The element
--   matching the predicate is dropped.
--   
--   <i>Pre-release</i>
splitOn :: (Monad m, Storable a) => (a -> Bool) -> Array a -> SerialT m (Array a)

-- | Transform an array into another array using a stream transformation
--   operation.
--   
--   <i>Pre-release</i>
streamTransform :: forall m a b. (MonadIO m, Storable a, Storable b) => (SerialT m a -> SerialT m b) -> Array a -> m (Array b)

-- | Fold an array using a stream fold operation.
--   
--   <i>Pre-release</i>
streamFold :: (MonadIO m, Storable a) => (SerialT m a -> m b) -> Array a -> m b

-- | Fold an array using a <a>Fold</a>.
--   
--   <i>Pre-release</i>
fold :: forall m a b. (MonadIO m, Storable a) => Fold m a b -> Array a -> m b


-- | Parsers for binary encoded basic Haskell data types.
module Streamly.Internal.Data.Binary.Decode

-- | A value of type <tt>()</tt> is encoded as <tt>0</tt> in binary
--   encoding.
--   
--   <pre>
--   0 ==&gt; ()
--   </pre>
--   
--   <i>Pre-release</i>
unit :: MonadCatch m => Parser m Word8 ()

-- | A value of type <a>Bool</a> is encoded as follows in binary encoding.
--   
--   <pre>
--   0 ==&gt; False
--   1 ==&gt; True
--   </pre>
--   
--   <i>Pre-release</i>
bool :: MonadCatch m => Parser m Word8 Bool

-- | A value of type <a>Ordering</a> is encoded as follows in binary
--   encoding.
--   
--   <pre>
--   0 ==&gt; LT
--   1 ==&gt; EQ
--   2 ==&gt; GT
--   </pre>
--   
--   <i>Pre-release</i>
ordering :: MonadCatch m => Parser m Word8 Ordering

-- | Accept the input byte only if it is equal to the specified value.
--   
--   <i>Pre-release</i>
eqWord8 :: MonadCatch m => Word8 -> Parser m Word8 Word8

-- | Accept any byte.
--   
--   <i>Pre-release</i>
word8 :: MonadCatch m => Parser m Word8 Word8

-- | Parse two bytes as a <a>Word16</a>, the first byte is the MSB of the
--   Word16 and second byte is the LSB (big endian representation).
--   
--   <i>Pre-release</i>
word16be :: MonadCatch m => Parser m Word8 Word16

-- | Parse two bytes as a <a>Word16</a>, the first byte is the LSB of the
--   Word16 and second byte is the MSB (little endian representation).
--   
--   <i>Pre-release</i>
word16le :: MonadCatch m => Parser m Word8 Word16

-- | Parse four bytes as a <a>Word32</a>, the first byte is the MSB of the
--   Word32 and last byte is the LSB (big endian representation).
--   
--   <i>Pre-release</i>
word32be :: MonadCatch m => Parser m Word8 Word32

-- | Parse four bytes as a <a>Word32</a>, the first byte is the MSB of the
--   Word32 and last byte is the LSB (big endian representation).
--   
--   <i>Pre-release</i>
word32le :: MonadCatch m => Parser m Word8 Word32

-- | Parse eight bytes as a <a>Word64</a>, the first byte is the MSB of the
--   Word64 and last byte is the LSB (big endian representation).
--   
--   <i>Pre-release</i>
word64be :: MonadCatch m => Parser m Word8 Word64

-- | Parse eight bytes as a <a>Word64</a>, the first byte is the MSB of the
--   Word64 and last byte is the LSB (big endian representation).
--   
--   <i>Pre-release</i>
word64le :: MonadCatch m => Parser m Word8 Word64

-- | Parse eight bytes as a <a>Word64</a> in the host byte order.
--   
--   <i>Pre-release</i>
word64host :: (MonadIO m, MonadCatch m) => Parser m Word8 Word64


-- | Fold a stream of foreign arrays. <tt>Fold m a b</tt> in this module
--   works on a stream of "Array a" and produces an output of type
--   <tt>b</tt>.
--   
--   Though <tt>Fold m a b</tt> in this module works on a stream of
--   <tt>Array a</tt> it is different from <tt>Data.Fold m (Array a)
--   b</tt>. While the latter works on arrays as a whole treating them as
--   atomic elements, the folds in this module can work on the stream of
--   arrays as if it is an element stream with all the arrays coalesced
--   together. This module allows adapting the element stream folds in
--   Data.Fold to correctly work on an array stream as if it is an element
--   stream. For example:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Data.Fold as Fold
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Array.Stream.Foreign as ArrayStream
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Array.Stream.Fold.Foreign as ArrayFold
--   
--   &gt;&gt;&gt; import qualified Streamly.Internal.Data.Stream.IsStream as Stream (arraysOf)
--   
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; ArrayStream.foldArr (ArrayFold.fromFold (Fold.take 7 Fold.toList)) $ Stream.arraysOf 5 $ Stream.fromList "hello world"
--   "hello w"
--   </pre>
module Streamly.Internal.Data.Array.Stream.Fold.Foreign

-- | Array stream fold.
--   
--   An array stream fold is basically an array stream <a>Parser</a> that
--   does not fail. In case of array stream folds the count in
--   <a>Partial</a>, <a>Continue</a> and <a>Done</a> is a count of elements
--   that includes the leftover element count in the array that is
--   currently being processed by the parser. If none of the elements is
--   consumed by the parser the count is at least the whole array length.
--   If the whole array is consumed by the parser then the count will be 0.
--   
--   <i>Pre-release</i>
newtype Fold m a b
Fold :: Parser m (Array a) b -> Fold m a b

-- | Convert an element <a>Fold</a> into an array stream fold.
--   
--   <i>Pre-release</i>
fromFold :: forall m a b. (MonadIO m, Storable a) => Fold m a b -> Fold m a b

-- | Convert an element <tt>Parser</tt> into an array stream fold. If the
--   parser fails the fold would throw an exception.
--   
--   <i>Pre-release</i>
fromParser :: forall m a b. (MonadIO m, Storable a) => Parser m a b -> Fold m a b

-- | Adapt an array stream fold.
--   
--   <i>Pre-release</i>
fromArrayFold :: forall m a b. MonadIO m => Fold m (Array a) b -> Fold m a b

-- | Map a monadic function on the output of a fold.
--   
--   <i>Pre-release</i>
rmapM :: Monad m => (b -> m c) -> Fold m a b -> Fold m a c

-- | A fold that always yields a pure value without consuming any input.
--   
--   <i>Pre-release</i>
fromPure :: Monad m => b -> Fold m a b

-- | A fold that always yields the result of an effectful action without
--   consuming any input.
--   
--   <i>Pre-release</i>
fromEffect :: Monad m => m b -> Fold m a b

-- | Applies two folds sequentially on the input stream and combines their
--   results using the supplied function.
--   
--   <i>Pre-release</i>
serialWith :: MonadThrow m => (a -> b -> c) -> Fold m x a -> Fold m x b -> Fold m x c

-- | Applies a fold on the input stream, generates the next fold from the
--   output of the previously applied fold and then applies that fold.
--   
--   <i>Pre-release</i>
concatMap :: MonadThrow m => (b -> Fold m a c) -> Fold m a b -> Fold m a c
take :: forall m a b. (Monad m, Storable a) => Int -> Fold m a b -> Fold m a b
instance GHC.Base.Functor m => GHC.Base.Functor (Streamly.Internal.Data.Array.Stream.Fold.Foreign.Fold m a)
instance Control.Monad.Catch.MonadThrow m => GHC.Base.Applicative (Streamly.Internal.Data.Array.Stream.Fold.Foreign.Fold m a)
instance Control.Monad.Catch.MonadThrow m => GHC.Base.Monad (Streamly.Internal.Data.Array.Stream.Fold.Foreign.Fold m a)


-- | Combinators to efficiently manipulate streams of immutable arrays.
module Streamly.Internal.Data.Array.Stream.Foreign

-- | <tt>arraysOf n stream</tt> groups the elements in the input stream
--   into arrays of <tt>n</tt> elements each.
--   
--   <pre>
--   arraysOf n = Stream.chunksOf n (Array.writeN n)
--   </pre>
--   
--   <i>Pre-release</i>
arraysOf :: (IsStream t, MonadIO m, Storable a) => Int -> t m a -> t m (Array a)

-- | Convert a stream of arrays into a stream of their elements.
--   
--   Same as the following but more efficient:
--   
--   <pre>
--   concat = Stream.unfoldMany Array.read
--   </pre>
concat :: (IsStream t, MonadIO m, Storable a) => t m (Array a) -> t m a

-- | Convert a stream of arrays into a stream of their elements reversing
--   the contents of each array before flattening.
--   
--   <pre>
--   concatRev = Stream.unfoldMany Array.readRev
--   </pre>
concatRev :: (IsStream t, MonadIO m, Storable a) => t m (Array a) -> t m a

-- | Flatten a stream of arrays after inserting the given element between
--   arrays.
--   
--   <i>Pre-release</i>
interpose :: (MonadIO m, IsStream t, Storable a) => a -> t m (Array a) -> t m a

-- | Flatten a stream of arrays appending the given element after each
--   array.
interposeSuffix :: (MonadIO m, IsStream t, Storable a) => a -> t m (Array a) -> t m a
intercalateSuffix :: (MonadIO m, IsStream t, Storable a) => Array a -> t m (Array a) -> t m a
unlines :: forall m a. (MonadIO m, Storable a) => a -> Stream m (Array a) -> Stream m a

-- | Fold an array stream using the supplied <a>Fold</a>. Returns the fold
--   result and the unconsumed stream.
--   
--   <i>Internal</i>
fold :: (MonadIO m, Storable a) => Fold m a b -> SerialT m (Array a) -> m (b, SerialT m (Array a))

-- | Parse an array stream using the supplied <tt>Parser</tt>. Returns the
--   parse result and the unconsumed stream. Throws <a>ParseError</a> if
--   the parse fails.
--   
--   <i>Internal</i>
parse :: (MonadIO m, MonadThrow m, Storable a) => Parser m a b -> SerialT m (Array a) -> m (b, SerialT m (Array a))
parseD :: forall m a b. (MonadIO m, MonadThrow m, Storable a) => Parser m a b -> Stream m (Array a) -> m (b, Stream m (Array a))

-- | Fold an array stream using the supplied array stream <a>Fold</a>.
--   
--   <i>Pre-release</i>
foldArr :: (MonadIO m, MonadThrow m, Storable a) => Fold m a b -> SerialT m (Array a) -> m b

-- | Like <a>fold</a> but also returns the remaining stream.
--   
--   <i>Pre-release</i>
foldArr_ :: (MonadIO m, MonadThrow m, Storable a) => Fold m a b -> SerialT m (Array a) -> m (b, SerialT m (Array a))
parseArrD :: forall m a b. (MonadIO m, MonadThrow m, Storable a) => Parser m (Array a) b -> Stream m (Array a) -> m (b, Stream m (Array a))

-- | Apply an array stream <a>Fold</a> repeatedly on an array stream and
--   emit the fold outputs in the output stream.
--   
--   See "Streamly.Prelude.foldMany" for more details.
--   
--   <i>Pre-release</i>
foldArrMany :: (IsStream t, MonadThrow m, Storable a) => Fold m a b -> t m (Array a) -> t m b

-- | Given a stream of arrays, splice them all together to generate a
--   single array. The stream must be <i>finite</i>.
toArray :: (MonadIO m, Storable a) => SerialT m (Array a) -> m (Array a)
lpackArraysChunksOf :: (MonadIO m, Storable a) => Int -> Fold m (Array a) () -> Fold m (Array a) ()

-- | Coalesce adjacent arrays in incoming stream to form bigger arrays of a
--   maximum specified size in bytes.
compact :: (MonadIO m, Storable a) => Int -> SerialT m (Array a) -> SerialT m (Array a)

-- | Split a stream of arrays on a given separator byte, dropping the
--   separator and coalescing all the arrays between two separators into a
--   single array.
splitOn :: (IsStream t, MonadIO m) => Word8 -> t m (Array Word8) -> t m (Array Word8)
splitOnSuffix :: (IsStream t, MonadIO m) => Word8 -> t m (Array Word8) -> t m (Array Word8)


module Streamly.Internal.Network.Socket

-- | Specify the socket protocol details.
data SockSpec
SockSpec :: !Family -> !SocketType -> !ProtocolNumber -> ![(SocketOption, Int)] -> SockSpec
[sockFamily] :: SockSpec -> !Family
[sockType] :: SockSpec -> !SocketType
[sockProto] :: SockSpec -> !ProtocolNumber
[sockOpts] :: SockSpec -> ![(SocketOption, Int)]

-- | <tt><a>forSocketM</a> action socket</tt> runs the monadic computation
--   <tt>action</tt> passing the socket handle to it. The handle will be
--   closed on exit from <a>forSocketM</a>, whether by normal termination
--   or by raising an exception. If closing the handle raises an exception,
--   then this exception will be raised by <a>forSocketM</a> rather than
--   any exception raised by <tt>action</tt>.
forSocketM :: (MonadMask m, MonadIO m) => (Socket -> m ()) -> Socket -> m ()

-- | Like <a>forSocketM</a> but runs a streaming computation instead of a
--   monadic computation.
--   
--   <i>Inhibits stream fusion</i>
--   
--   <i>Internal</i>
withSocket :: (IsStream t, MonadAsync m, MonadCatch m) => Socket -> (Socket -> t m a) -> t m a

-- | Unfold a three tuple <tt>(listenQLen, spec, addr)</tt> into a stream
--   of connected protocol sockets corresponding to incoming connections.
--   <tt>listenQLen</tt> is the maximum number of pending connections in
--   the backlog. <tt>spec</tt> is the socket protocol and options
--   specification and <tt>addr</tt> is the protocol address where the
--   server listens for incoming connections.
accept :: MonadIO m => Unfold m (Int, SockSpec, SockAddr) Socket

-- | Start a TCP stream server that listens for connections on the supplied
--   server address specification (address family, local interface IP
--   address and port). The server generates a stream of connected sockets.
--   The first argument is the maximum number of pending connections in the
--   backlog.
--   
--   <i>Pre-release</i>
connections :: MonadAsync m => Int -> SockSpec -> SockAddr -> SerialT m Socket

-- | Connect to a remote host using the given socket specification and
--   remote address. Returns a connected socket or throws an exception.
--   
--   <i>Pre-release</i>
connect :: SockSpec -> SockAddr -> IO Socket

-- | Connect to a remote host using the given socket specification, a local
--   address to bind to and a remote address to connect to. Returns a
--   connected socket or throws an exception.
--   
--   <i>Pre-release</i>
connectFrom :: SockSpec -> SockAddr -> SockAddr -> IO Socket

-- | Unfolds a <a>Socket</a> into a byte stream. IO requests to the socket
--   are performed in sizes of <a>defaultChunkSize</a>.
read :: MonadIO m => Unfold m Socket Word8

-- | Unfolds the tuple <tt>(bufsize, socket)</tt> into a byte stream, read
--   requests to the socket are performed using buffers of
--   <tt>bufsize</tt>.
readWithBufferOf :: MonadIO m => Unfold m (Int, Socket) Word8

-- | Read a byte array from a file handle up to a maximum of the requested
--   size. If no data is available on the handle it blocks until some data
--   becomes available. If data is available then it immediately returns
--   that data without blocking.
readChunk :: Int -> Socket -> IO (Array Word8)

-- | Unfolds a socket into a stream of <a>Word8</a> arrays. Requests to the
--   socket are performed using a buffer of size <a>defaultChunkSize</a>.
--   The size of arrays in the resulting stream are therefore less than or
--   equal to <a>defaultChunkSize</a>.
readChunks :: MonadIO m => Unfold m Socket (Array Word8)

-- | Unfold the tuple <tt>(bufsize, socket)</tt> into a stream of
--   <a>Word8</a> arrays. Read requests to the socket are performed using a
--   buffer of size <tt>bufsize</tt>. The size of an array in the resulting
--   stream is always less than or equal to <tt>bufsize</tt>.
readChunksWithBufferOf :: MonadIO m => Unfold m (Int, Socket) (Array Word8)

-- | <tt>toChunksWithBufferOf size h</tt> reads a stream of arrays from
--   file handle <tt>h</tt>. The maximum size of a single array is limited
--   to <tt>size</tt>. <tt>fromHandleArraysUpto</tt> ignores the prevailing
--   <tt>TextEncoding</tt> and <tt>NewlineMode</tt> on the <tt>Handle</tt>.
toChunksWithBufferOf :: (IsStream t, MonadIO m) => Int -> Socket -> t m (Array Word8)

-- | <tt>toChunks h</tt> reads a stream of arrays from socket handle
--   <tt>h</tt>. The maximum size of a single array is limited to
--   <tt>defaultChunkSize</tt>.
toChunks :: (IsStream t, MonadIO m) => Socket -> t m (Array Word8)

-- | Generate a stream of elements of the given type from a socket. The
--   stream ends when EOF is encountered.
toBytes :: (IsStream t, MonadIO m) => Socket -> t m Word8

-- | Write a byte stream to a socket. Accumulates the input in chunks of up
--   to <a>defaultChunkSize</a> bytes before writing.
--   
--   <pre>
--   write = <a>writeWithBufferOf</a> <a>defaultChunkSize</a>
--   </pre>
write :: MonadIO m => Socket -> Fold m Word8 ()

-- | Write a byte stream to a socket. Accumulates the input in chunks of
--   specified number of bytes before writing.
writeWithBufferOf :: MonadIO m => Int -> Socket -> Fold m Word8 ()

-- | Write a stream of <a>Maybe</a> values. Keep buffering the <a>Just</a>
--   values in an array. Write the array to the <tt>Handle</tt> as soon as
--   a <a>Nothing</a> is encountered or the buffer size exceeds the
--   specified limit.
--   
--   <i>Pre-release</i>
writeMaybesWithBufferOf :: MonadIO m => Int -> Socket -> Fold m (Maybe Word8) ()

-- | Write a stream of arrays to a handle.
putChunks :: (MonadIO m, Storable a) => Socket -> SerialT m (Array a) -> m ()

-- | Like <a>write</a> but provides control over the write buffer. Output
--   will be written to the IO device as soon as we collect the specified
--   number of input elements.
putBytesWithBufferOf :: MonadIO m => Int -> Socket -> SerialT m Word8 -> m ()

-- | Write a byte stream to a file handle. Combines the bytes in chunks of
--   size up to <a>defaultChunkSize</a> before writing. Note that the write
--   behavior depends on the <tt>IOMode</tt> and the current seek position
--   of the handle.
putBytes :: MonadIO m => Socket -> SerialT m Word8 -> m ()

-- | Write an Array to a file handle.
writeChunk :: Storable a => Socket -> Array a -> IO ()

-- | Write a stream of arrays to a socket. Each array in the stream is
--   written to the socket as a separate IO request.
writeChunks :: (MonadIO m, Storable a) => Socket -> Fold m (Array a) ()

-- | <tt>writeChunksWithBufferOf bufsize socket</tt> writes a stream of
--   arrays to <tt>socket</tt> after coalescing the adjacent arrays in
--   chunks of <tt>bufsize</tt>. Multiple arrays are coalesed as long as
--   the total size remains below the specified size. It never splits an
--   array, if a single array is bigger than the specified size it emitted
--   as it is.
writeChunksWithBufferOf :: (MonadIO m, Storable a) => Int -> Socket -> Fold m (Array a) ()


-- | Combinators to build Inet/TCP clients and servers.
module Streamly.Internal.Network.Inet.TCP

-- | Unfold a tuple <tt>(ipAddr, port)</tt> into a stream of connected TCP
--   sockets. <tt>ipAddr</tt> is the local IP address and <tt>port</tt> is
--   the local port on which connections are accepted.
acceptOnAddr :: MonadIO m => Unfold m ((Word8, Word8, Word8, Word8), PortNumber) Socket
acceptOnAddrWith :: MonadIO m => [(SocketOption, Int)] -> Unfold m ((Word8, Word8, Word8, Word8), PortNumber) Socket

-- | Like <a>acceptOnAddr</a> but binds on the IPv4 address
--   <tt>0.0.0.0</tt> i.e. on all IPv4 addresses/interfaces of the machine
--   and listens for TCP connections on the specified port.
--   
--   <pre>
--   acceptOnPort = UF.supplyFirst acceptOnAddr (0,0,0,0)
--   </pre>
acceptOnPort :: MonadIO m => Unfold m PortNumber Socket
acceptOnPortWith :: MonadIO m => [(SocketOption, Int)] -> Unfold m PortNumber Socket

-- | Like <a>acceptOnAddr</a> but binds on the localhost IPv4 address
--   <tt>127.0.0.1</tt>. The server can only be accessed from the local
--   host, it cannot be accessed from other hosts on the network.
--   
--   <pre>
--   acceptOnPortLocal = UF.supplyFirst acceptOnAddr (127,0,0,1)
--   </pre>
acceptOnPortLocal :: MonadIO m => Unfold m PortNumber Socket

-- | Like <a>connections</a> but binds on the specified IPv4 address of the
--   machine and listens for TCP connections on the specified port.
--   
--   <i>Pre-release</i>
connectionsOnAddr :: MonadAsync m => (Word8, Word8, Word8, Word8) -> PortNumber -> SerialT m Socket
connectionsOnAddrWith :: MonadAsync m => [(SocketOption, Int)] -> (Word8, Word8, Word8, Word8) -> PortNumber -> SerialT m Socket

-- | Like <a>connections</a> but binds on the IPv4 address <tt>0.0.0.0</tt>
--   i.e. on all IPv4 addresses/interfaces of the machine and listens for
--   TCP connections on the specified port.
--   
--   <pre>
--   connectionsOnPort = connectionsOnAddr (0,0,0,0)
--   </pre>
--   
--   <i>Pre-release</i>
connectionsOnPort :: MonadAsync m => PortNumber -> SerialT m Socket

-- | Like <a>connections</a> but binds on the localhost IPv4 address
--   <tt>127.0.0.1</tt>. The server can only be accessed from the local
--   host, it cannot be accessed from other hosts on the network.
--   
--   <pre>
--   connectionsOnLocalHost = connectionsOnAddr (127,0,0,1)
--   </pre>
--   
--   <i>Pre-release</i>
connectionsOnLocalHost :: MonadAsync m => PortNumber -> SerialT m Socket

-- | Connect to the specified IP address and port number. Returns a
--   connected socket or throws an exception.
connect :: (Word8, Word8, Word8, Word8) -> PortNumber -> IO Socket

-- | Connect to a remote host using IP address and port and run the
--   supplied action on the resulting socket. <a>withConnectionM</a> makes
--   sure that the socket is closed on normal termination or in case of an
--   exception. If closing the socket raises an exception, then this
--   exception will be raised by <a>withConnectionM</a>.
--   
--   <i>Pre-release</i>
withConnectionM :: (MonadMask m, MonadIO m) => (Word8, Word8, Word8, Word8) -> PortNumber -> (Socket -> m ()) -> m ()

-- | Transform an <a>Unfold</a> from a <a>Socket</a> to an unfold from a
--   remote IP address and port. The resulting unfold opens a socket, uses
--   it using the supplied unfold and then makes sure that the socket is
--   closed on normal termination or in case of an exception. If closing
--   the socket raises an exception, then this exception will be raised by
--   <a>usingConnection</a>.
--   
--   <i>Pre-release</i>
usingConnection :: (MonadCatch m, MonadAsync m) => Unfold m Socket a -> Unfold m ((Word8, Word8, Word8, Word8), PortNumber) a

-- | Read a stream from the supplied IPv4 host address and port number.
read :: (MonadCatch m, MonadAsync m) => Unfold m ((Word8, Word8, Word8, Word8), PortNumber) Word8

-- | <tt><a>withConnection</a> addr port act</tt> opens a connection to the
--   specified IPv4 host address and port and passes the resulting socket
--   handle to the computation <tt>act</tt>. The handle will be closed on
--   exit from <a>withConnection</a>, whether by normal termination or by
--   raising an exception. If closing the handle raises an exception, then
--   this exception will be raised by <a>withConnection</a> rather than any
--   exception raised by <tt>act</tt>.
--   
--   <i>Pre-release</i>
withConnection :: (IsStream t, MonadCatch m, MonadAsync m) => (Word8, Word8, Word8, Word8) -> PortNumber -> (Socket -> t m a) -> t m a

-- | Read a stream from the supplied IPv4 host address and port number.
toBytes :: (IsStream t, MonadCatch m, MonadAsync m) => (Word8, Word8, Word8, Word8) -> PortNumber -> t m Word8

-- | Write a stream to the supplied IPv4 host address and port number.
write :: (MonadAsync m, MonadCatch m) => (Word8, Word8, Word8, Word8) -> PortNumber -> Fold m Word8 ()

-- | Like <a>write</a> but provides control over the write buffer. Output
--   will be written to the IO device as soon as we collect the specified
--   number of input elements.
writeWithBufferOf :: (MonadAsync m, MonadCatch m) => Int -> (Word8, Word8, Word8, Word8) -> PortNumber -> Fold m Word8 ()

-- | Write a stream to the supplied IPv4 host address and port number.
putBytes :: (MonadCatch m, MonadAsync m) => (Word8, Word8, Word8, Word8) -> PortNumber -> SerialT m Word8 -> m ()

-- | Like <a>write</a> but provides control over the write buffer. Output
--   will be written to the IO device as soon as we collect the specified
--   number of input elements.
putBytesWithBufferOf :: (MonadCatch m, MonadAsync m) => Int -> (Word8, Word8, Word8, Word8) -> PortNumber -> SerialT m Word8 -> m ()

-- | Write a stream of arrays to the supplied IPv4 host address and port
--   number.
writeChunks :: (MonadAsync m, MonadCatch m) => (Word8, Word8, Word8, Word8) -> PortNumber -> Fold m (Array Word8) ()

-- | Write a stream of arrays to the supplied IPv4 host address and port
--   number.
putChunks :: (MonadCatch m, MonadAsync m) => (Word8, Word8, Word8, Word8) -> PortNumber -> SerialT m (Array Word8) -> m ()

-- | Send an input stream to a remote host and produce the output stream
--   from the host. The server host just acts as a transformation function
--   on the input stream. Both sending and receiving happen asynchronously.
--   
--   <i>Pre-release</i>
processBytes :: (IsStream t, MonadAsync m, MonadCatch m) => (Word8, Word8, Word8, Word8) -> PortNumber -> SerialT m Word8 -> t m Word8


-- | The fundamental singleton IO APIs are <a>getChunk</a> and
--   <a>putChunk</a> and the fundamental stream IO APIs built on top of
--   those are <a>readChunksWithBufferOf</a> and <a>writeChunks</a>. Rest
--   of this module is just combinatorial programming using these.
--   
--   We can achieve line buffering by folding lines in the input stream
--   into a stream of arrays using Stream.splitOn or Fold.takeEndBy_ and
--   similar operations. One can wrap the input stream in <a>Maybe</a> type
--   and then use <a>writeMaybesWithBufferOf</a> to achieve user controlled
--   buffering.
module Streamly.Internal.FileSystem.Handle

-- | Read a <tt>ByteArray</tt> consisting of one or more bytes from a file
--   handle. If no data is available on the handle it blocks until at least
--   one byte becomes available. If any data is available then it
--   immediately returns that data without blocking. As a result of this
--   behavior, it may read less than or equal to the size requested.
getChunk :: MonadIO m => Int -> Handle -> m (Array Word8)

-- | Read a <tt>ByteArray</tt> consisting of exactly the specified number
--   of bytes from a file handle.
--   
--   <i>Unimplemented</i>
getChunkOf :: Int -> Handle -> IO (Array Word8)

-- | Write an <a>Array</a> to a file handle.
putChunk :: (MonadIO m, Storable a) => Handle -> Array a -> m ()

-- | Unfolds a file handle into a byte stream. IO requests to the device
--   are performed in sizes of <a>defaultChunkSize</a>.
--   
--   <pre>
--   &gt;&gt;&gt; read = Unfold.many Handle.readChunks Array.read
--   </pre>
read :: MonadIO m => Unfold m Handle Word8

-- | Unfolds the tuple <tt>(bufsize, handle)</tt> into a byte stream, read
--   requests to the IO device are performed using buffers of
--   <tt>bufsize</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; readWithBufferOf = Unfold.many Handle.readChunksWithBufferOf Array.read
--   </pre>
readWithBufferOf :: MonadIO m => Unfold m (Int, Handle) Word8

-- | Generate a byte stream from a file <a>Handle</a>.
--   
--   <pre>
--   &gt;&gt;&gt; toBytes h = Stream.unfoldMany Array.read $ Handle.toChunks h
--   </pre>
--   
--   <i>Pre-release</i>
toBytes :: (IsStream t, MonadIO m) => Handle -> t m Word8

-- | <tt>toBytesWithBufferOf bufsize handle</tt> reads a byte stream from a
--   file handle, reads are performed in chunks of up to <tt>bufsize</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; toBytesWithBufferOf size h = Stream.unfoldMany Array.read $ Handle.toChunksWithBufferOf size h
--   </pre>
--   
--   <i>Pre-release</i>
toBytesWithBufferOf :: (IsStream t, MonadIO m) => Int -> Handle -> t m Word8

-- | Unfolds a handle into a stream of <a>Word8</a> arrays. Requests to the
--   IO device are performed using a buffer of size
--   <a>defaultChunkSize</a>. The size of arrays in the resulting stream
--   are therefore less than or equal to <a>defaultChunkSize</a>.
--   
--   <pre>
--   &gt;&gt;&gt; readChunks = Unfold.supplyFirst IO.defaultChunkSize Handle.readChunksWithBufferOf
--   </pre>
readChunks :: MonadIO m => Unfold m Handle (Array Word8)

-- | Unfold the tuple <tt>(bufsize, handle)</tt> into a stream of
--   <a>Word8</a> arrays. Read requests to the IO device are performed
--   using a buffer of size <tt>bufsize</tt>. The size of an array in the
--   resulting stream is always less than or equal to <tt>bufsize</tt>.
readChunksWithBufferOf :: MonadIO m => Unfold m (Int, Handle) (Array Word8)

-- | <tt>toChunksWithBufferOf size handle</tt> reads a stream of arrays
--   from the file handle <tt>handle</tt>. The maximum size of a single
--   array is limited to <tt>size</tt>. The actual size read may be less
--   than or equal to <tt>size</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; toChunksWithBufferOf size h = Stream.unfold Handle.readChunksWithBufferOf (size, h)
--   </pre>
toChunksWithBufferOf :: (IsStream t, MonadIO m) => Int -> Handle -> t m (Array Word8)

-- | <tt>toChunks handle</tt> reads a stream of arrays from the specified
--   file handle. The maximum size of a single array is limited to
--   <tt>defaultChunkSize</tt>. The actual size read may be less than or
--   equal to <tt>defaultChunkSize</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; toChunks = Handle.toChunksWithBufferOf IO.defaultChunkSize
--   </pre>
toChunks :: (IsStream t, MonadIO m) => Handle -> t m (Array Word8)

-- | Write a byte stream to a file handle. Accumulates the input in chunks
--   of up to <a>defaultChunkSize</a> before writing to the IO device.
--   
--   <pre>
--   &gt;&gt;&gt; write = Handle.writeWithBufferOf IO.defaultChunkSize
--   </pre>
write :: MonadIO m => Handle -> Fold m Word8 ()

-- | Like <a>write</a> but uses the experimental <a>Refold</a> API.
--   
--   <i>Internal</i>
consumer :: MonadIO m => Refold m Handle Word8 ()

-- | <tt>writeWithBufferOf reqSize handle</tt> writes the input stream to
--   <tt>handle</tt>. Bytes in the input stream are collected into a buffer
--   until we have a chunk of <tt>reqSize</tt> and then written to the IO
--   device.
--   
--   <pre>
--   &gt;&gt;&gt; writeWithBufferOf n h = Fold.chunksOf n (Array.writeNUnsafe n) (Handle.writeChunks h)
--   </pre>
writeWithBufferOf :: MonadIO m => Int -> Handle -> Fold m Word8 ()

-- | Write a stream of <a>Maybe</a> values. Keep buffering the just values
--   in an array until a <a>Nothing</a> is encountered or the buffer size
--   exceeds the specified limit, at that point flush the buffer to the
--   handle.
--   
--   <i>Pre-release</i>
writeMaybesWithBufferOf :: MonadIO m => Int -> Handle -> Fold m (Maybe Word8) ()

-- | Write a byte stream to a file handle. Accumulates the input in chunks
--   of up to <a>defaultChunkSize</a> before writing.
--   
--   NOTE: This may perform better than the <a>write</a> fold, you can try
--   this if you need some extra perf boost.
--   
--   <pre>
--   &gt;&gt;&gt; putBytes = Handle.putBytesWithBufferOf IO.defaultChunkSize
--   </pre>
putBytes :: MonadIO m => Handle -> SerialT m Word8 -> m ()

-- | <tt>putBytesWithBufferOf bufsize handle stream</tt> writes
--   <tt>stream</tt> to <tt>handle</tt> in chunks of <tt>bufsize</tt>. A
--   write is performed to the IO device as soon as we collect the required
--   input size.
--   
--   <pre>
--   &gt;&gt;&gt; putBytesWithBufferOf n h m = Handle.putChunks h $ Stream.arraysOf n m
--   </pre>
putBytesWithBufferOf :: MonadIO m => Int -> Handle -> SerialT m Word8 -> m ()

-- | Write a stream of arrays to a handle. Each array in the stream is
--   written to the device as a separate IO request.
--   
--   writeChunks h = Fold.drainBy (Handle.putChunk h)
writeChunks :: (MonadIO m, Storable a) => Handle -> Fold m (Array a) ()

-- | <tt>writeChunksWithBufferOf bufsize handle</tt> writes a stream of
--   arrays to <tt>handle</tt> after coalescing the adjacent arrays in
--   chunks of <tt>bufsize</tt>. We never split an array, if a single array
--   is bigger than the specified size it emitted as it is. Multiple arrays
--   are coalesed as long as the total size remains below the specified
--   size.
writeChunksWithBufferOf :: (MonadIO m, Storable a) => Int -> Handle -> Fold m (Array a) ()

-- | <tt>putChunksWithBufferOf bufsize handle stream</tt> writes a stream
--   of arrays to <tt>handle</tt> after coalescing the adjacent arrays in
--   chunks of <tt>bufsize</tt>. The chunk size is only a maximum and the
--   actual writes could be smaller as we do not split the arrays to fit
--   exactly to the specified size.
putChunksWithBufferOf :: (MonadIO m, Storable a) => Int -> Handle -> SerialT m (Array a) -> m ()

-- | Write a stream of arrays to a handle.
--   
--   <pre>
--   &gt;&gt;&gt; putChunks h = Stream.mapM_ (Handle.putChunk h)
--   </pre>
putChunks :: (MonadIO m, Storable a) => Handle -> SerialT m (Array a) -> m ()

-- | The input to the unfold is <tt>(from, to, bufferSize, handle)</tt>. It
--   starts reading from the offset <tt>from</tt> in the file and reads up
--   to the offset <tt>to</tt>.
readChunksFromToWith :: MonadIO m => Unfold m (Int, Int, Int, Handle) (Array Word8)


-- | <pre>
--   &gt;&gt;&gt; import qualified Streamly.FileSystem.Handle as Handle
--   </pre>
--   
--   Read and write byte streams and array streams to and from file handles
--   (<tt>Handle</tt>).
--   
--   The <tt>TextEncoding</tt>, <tt>NewLineMode</tt>, and
--   <tt>Buffering</tt> options of the underlying GHC <tt>Handle</tt> are
--   ignored by these APIs. Please use <tt>Streamly.Unicode.*</tt> modules
--   for encoding and decoding a byte stream, use stream splitting
--   operations in <a>Streamly.Prelude</a> to create a stream of lines or
--   to split the input stream on any other type of boundaries.
--   
--   To set the read or write start position use <tt>hSeek</tt> on the
--   <tt>Handle</tt>, the <a>before</a> combinator may be used to do that
--   on a streaming combinator. To restrict the length of read or write use
--   the stream trimming operations like <a>take</a>.
--   
--   Note that a <tt>Handle</tt> is inherently stateful, therefore, we
--   cannot use these APIs from multiple threads without serialization;
--   reading or writing in one thread would affect the file position for
--   other threads.
--   
--   For additional, experimental APIs take a look at
--   <a>Streamly.Internal.FileSystem.Handle</a> module.
module Streamly.FileSystem.Handle

-- | Read a <tt>ByteArray</tt> consisting of one or more bytes from a file
--   handle. If no data is available on the handle it blocks until at least
--   one byte becomes available. If any data is available then it
--   immediately returns that data without blocking. As a result of this
--   behavior, it may read less than or equal to the size requested.
getChunk :: MonadIO m => Int -> Handle -> m (Array Word8)

-- | Write an <a>Array</a> to a file handle.
putChunk :: (MonadIO m, Storable a) => Handle -> Array a -> m ()

-- | Unfolds a file handle into a byte stream. IO requests to the device
--   are performed in sizes of <a>defaultChunkSize</a>.
--   
--   <pre>
--   &gt;&gt;&gt; read = Unfold.many Handle.readChunks Array.read
--   </pre>
read :: MonadIO m => Unfold m Handle Word8

-- | Unfolds the tuple <tt>(bufsize, handle)</tt> into a byte stream, read
--   requests to the IO device are performed using buffers of
--   <tt>bufsize</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; readWithBufferOf = Unfold.many Handle.readChunksWithBufferOf Array.read
--   </pre>
readWithBufferOf :: MonadIO m => Unfold m (Int, Handle) Word8

-- | Unfolds a handle into a stream of <a>Word8</a> arrays. Requests to the
--   IO device are performed using a buffer of size
--   <a>defaultChunkSize</a>. The size of arrays in the resulting stream
--   are therefore less than or equal to <a>defaultChunkSize</a>.
--   
--   <pre>
--   &gt;&gt;&gt; readChunks = Unfold.supplyFirst IO.defaultChunkSize Handle.readChunksWithBufferOf
--   </pre>
readChunks :: MonadIO m => Unfold m Handle (Array Word8)

-- | Unfold the tuple <tt>(bufsize, handle)</tt> into a stream of
--   <a>Word8</a> arrays. Read requests to the IO device are performed
--   using a buffer of size <tt>bufsize</tt>. The size of an array in the
--   resulting stream is always less than or equal to <tt>bufsize</tt>.
readChunksWithBufferOf :: MonadIO m => Unfold m (Int, Handle) (Array Word8)

-- | Write a byte stream to a file handle. Accumulates the input in chunks
--   of up to <a>defaultChunkSize</a> before writing to the IO device.
--   
--   <pre>
--   &gt;&gt;&gt; write = Handle.writeWithBufferOf IO.defaultChunkSize
--   </pre>
write :: MonadIO m => Handle -> Fold m Word8 ()

-- | <tt>writeWithBufferOf reqSize handle</tt> writes the input stream to
--   <tt>handle</tt>. Bytes in the input stream are collected into a buffer
--   until we have a chunk of <tt>reqSize</tt> and then written to the IO
--   device.
--   
--   <pre>
--   &gt;&gt;&gt; writeWithBufferOf n h = Fold.chunksOf n (Array.writeNUnsafe n) (Handle.writeChunks h)
--   </pre>
writeWithBufferOf :: MonadIO m => Int -> Handle -> Fold m Word8 ()

-- | Write a stream of arrays to a handle. Each array in the stream is
--   written to the device as a separate IO request.
--   
--   writeChunks h = Fold.drainBy (Handle.putChunk h)
writeChunks :: (MonadIO m, Storable a) => Handle -> Fold m (Array a) ()


-- | Read and write streams and arrays to and from files specified by their
--   paths in the file system. Unlike the handle based APIs which can have
--   a read/write session consisting of multiple reads and writes to the
--   handle, these APIs are one shot read or write APIs. These APIs open
--   the file handle, perform the requested operation and close the handle.
--   Thease are safer compared to the handle based APIs as there is no
--   possibility of a file descriptor leakage.
--   
--   <pre>
--   import qualified Streamly.Internal.FileSystem.File as File
--   </pre>
module Streamly.Internal.FileSystem.File

-- | <tt><a>withFile</a> name mode act</tt> opens a file using
--   <a>openFile</a> and passes the resulting handle to the computation
--   <tt>act</tt>. The handle will be closed on exit from <a>withFile</a>,
--   whether by normal termination or by raising an exception. If closing
--   the handle raises an exception, then this exception will be raised by
--   <a>withFile</a> rather than any exception raised by <tt>act</tt>.
--   
--   <i>Pre-release</i>
withFile :: (IsStream t, MonadCatch m, MonadAsync m) => FilePath -> IOMode -> (Handle -> t m a) -> t m a

-- | Unfolds the tuple <tt>(bufsize, filepath)</tt> into a byte stream,
--   read requests to the IO device are performed using buffers of
--   <tt>bufsize</tt>.
--   
--   <i>Pre-release</i>
readWithBufferOf :: (MonadCatch m, MonadAsync m) => Unfold m (Int, FilePath) Word8

-- | Unfolds a file path into a byte stream. IO requests to the device are
--   performed in sizes of <a>defaultChunkSize</a>.
read :: (MonadCatch m, MonadAsync m) => Unfold m FilePath Word8

-- | Generate a stream of bytes from a file specified by path. The stream
--   ends when EOF is encountered. File is locked using multiple reader and
--   single writer locking mode.
--   
--   <i>Pre-release</i>
toBytes :: (IsStream t, MonadCatch m, MonadAsync m) => FilePath -> t m Word8

-- | Unfold the tuple <tt>(bufsize, filepath)</tt> into a stream of
--   <a>Word8</a> arrays. Read requests to the IO device are performed
--   using a buffer of size <tt>bufsize</tt>. The size of an array in the
--   resulting stream is always less than or equal to <tt>bufsize</tt>.
--   
--   <i>Pre-release</i>
readChunksWithBufferOf :: (MonadCatch m, MonadAsync m) => Unfold m (Int, FilePath) (Array Word8)

-- | Unfold the tuple <tt>(from, to, bufsize, filepath)</tt> into a stream
--   of <a>Word8</a> arrays. Read requests to the IO device are performed
--   using a buffer of size <tt>bufsize</tt> starting from absolute offset
--   of <tt>from</tt> till the absolute position of <tt>to</tt>. The size
--   of an array in the resulting stream is always less than or equal to
--   <tt>bufsize</tt>.
--   
--   <i>Pre-release</i>
readChunksFromToWith :: (MonadCatch m, MonadAsync m) => Unfold m (Int, Int, Int, FilePath) (Array Word8)

-- | Unfolds a <a>FilePath</a> into a stream of <a>Word8</a> arrays.
--   Requests to the IO device are performed using a buffer of size
--   <a>defaultChunkSize</a>. The size of arrays in the resulting stream
--   are therefore less than or equal to <a>defaultChunkSize</a>.
--   
--   <i>Pre-release</i>
readChunks :: (MonadCatch m, MonadAsync m) => Unfold m FilePath (Array Word8)

-- | <tt>toChunksWithBufferOf size file</tt> reads a stream of arrays from
--   file <tt>file</tt>. The maximum size of a single array is specified by
--   <tt>size</tt>. The actual size read may be less than or equal to
--   <tt>size</tt>.
toChunksWithBufferOf :: (IsStream t, MonadCatch m, MonadAsync m) => Int -> FilePath -> t m (Array Word8)

-- | <tt>toChunks file</tt> reads a stream of arrays from file
--   <tt>file</tt>. The maximum size of a single array is limited to
--   <tt>defaultChunkSize</tt>. The actual size read may be less than
--   <tt>defaultChunkSize</tt>.
--   
--   <pre>
--   toChunks = toChunksWithBufferOf defaultChunkSize
--   </pre>
toChunks :: (IsStream t, MonadCatch m, MonadAsync m) => FilePath -> t m (Array Word8)

-- | Write a byte stream to a file. Accumulates the input in chunks of up
--   to <a>defaultChunkSize</a> before writing to the IO device.
--   
--   <i>Pre-release</i>
write :: (MonadIO m, MonadCatch m) => FilePath -> Fold m Word8 ()

-- | <tt>writeWithBufferOf chunkSize handle</tt> writes the input stream to
--   <tt>handle</tt>. Bytes in the input stream are collected into a buffer
--   until we have a chunk of size <tt>chunkSize</tt> and then written to
--   the IO device.
--   
--   <i>Pre-release</i>
writeWithBufferOf :: (MonadIO m, MonadCatch m) => Int -> FilePath -> Fold m Word8 ()

-- | Write a byte stream to a file. Combines the bytes in chunks of size up
--   to <a>defaultChunkSize</a> before writing. If the file exists it is
--   truncated to zero size before writing. If the file does not exist it
--   is created. File is locked using single writer locking mode.
--   
--   <i>Pre-release</i>
fromBytes :: (MonadAsync m, MonadCatch m) => FilePath -> SerialT m Word8 -> m ()

-- | Like <a>write</a> but provides control over the write buffer. Output
--   will be written to the IO device as soon as we collect the specified
--   number of input elements.
fromBytesWithBufferOf :: (MonadAsync m, MonadCatch m) => Int -> FilePath -> SerialT m Word8 -> m ()

-- | Write an array to a file. Overwrites the file if it exists.
putChunk :: Storable a => FilePath -> Array a -> IO ()

-- | Write a stream of chunks to a handle. Each chunk in the stream is
--   written to the device as a separate IO request.
--   
--   <i>Pre-release</i>
writeChunks :: (MonadIO m, MonadCatch m, Storable a) => FilePath -> Fold m (Array a) ()

-- | Write a stream of arrays to a file. Overwrites the file if it exists.
fromChunks :: (MonadAsync m, MonadCatch m, Storable a) => FilePath -> SerialT m (Array a) -> m ()

-- | Append a byte stream to a file. Combines the bytes in chunks of size
--   up to <a>defaultChunkSize</a> before writing. If the file exists then
--   the new data is appended to the file. If the file does not exist it is
--   created. File is locked using single writer locking mode.
append :: (MonadAsync m, MonadCatch m) => FilePath -> SerialT m Word8 -> m ()

-- | Like <a>append</a> but provides control over the write buffer. Output
--   will be written to the IO device as soon as we collect the specified
--   number of input elements.
appendWithBufferOf :: (MonadAsync m, MonadCatch m) => Int -> FilePath -> SerialT m Word8 -> m ()

-- | append an array to a file.
appendArray :: Storable a => FilePath -> Array a -> IO ()

-- | Append a stream of arrays to a file.
appendChunks :: (MonadAsync m, MonadCatch m, Storable a) => FilePath -> SerialT m (Array a) -> m ()


-- | This module provides immutable arrays in pinned memory (non GC memory)
--   suitable for long lived data storage, random access and for
--   interfacing with the operating system.
--   
--   Arrays in this module are chunks of pinned memory that hold a sequence
--   of <tt>Storable</tt> values of a given type, they cannot store
--   non-serializable data like functions. Once created an array cannot be
--   modified. Pinned memory allows efficient buffering of long lived data
--   without adding any impact to GC. One array is just one pointer visible
--   to GC and it does not have to be copied across generations. Moreover,
--   pinned memory allows communication with foreign consumers and
--   producers (e.g. file or network IO) without copying the data.
--   
--   <h1>Programmer Notes</h1>
--   
--   To apply a transformation to an array use <a>read</a> to unfold the
--   array into a stream, apply a transformation on the stream and then use
--   <a>write</a> to fold it back to an array.
--   
--   This module is designed to be imported qualified:
--   
--   <pre>
--   import qualified Streamly.Data.Array.Foreign as Array
--   </pre>
--   
--   For experimental APIs see <a>Streamly.Internal.Data.Array.Foreign</a>.
module Streamly.Data.Array.Foreign
data Array a

-- | Create an <a>Array</a> from the first N elements of a list. The array
--   is allocated to size N, if the list terminates before N elements then
--   the array may hold less than N elements.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromListN :: Storable a => Int -> [a] -> Array a

-- | Create an <a>Array</a> from a list. The list must be of finite size.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromList :: Storable a => [a] -> Array a

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
writeN :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
write :: forall m a. (MonadIO m, Storable a) => Fold m a (Array a)

-- | <tt>writeLastN n</tt> folds a maximum of <tt>n</tt> elements from the
--   end of the input stream to an <a>Array</a>.
writeLastN :: (Storable a, MonadIO m) => Int -> Fold m a (Array a)

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
toList :: Storable a => Array a -> [a]

-- | Unfold an array into a stream.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
read :: forall m a. (Monad m, Storable a) => Unfold m (Array a) a

-- | Unfold an array into a stream in reverse order.
readRev :: forall m a. (Monad m, Storable a) => Unfold m (Array a) a

-- | Cast an array having elements of type <tt>a</tt> into an array having
--   elements of type <tt>b</tt>. The length of the array should be a
--   multiple of the size of the target element otherwise <a>Nothing</a> is
--   returned.
cast :: forall a b. Storable b => Array a -> Maybe (Array b)

-- | Cast an <tt>Array a</tt> into an <tt>Array Word8</tt>.
asBytes :: Array a -> Array Word8

-- | <i>O(1)</i> Get the length of the array i.e. the number of elements in
--   the array.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
length :: forall a. Storable a => Array a -> Int

-- | <i>O(1)</i> Lookup the element at the given index. Index starts from
--   0.
getIndex :: forall a. Storable a => Array a -> Int -> Maybe a


-- | Low level IO routines interfacing the operating system.
module Streamly.Internal.System.IOVec.Type
data IOVec
IOVec :: {-# UNPACK #-} !Ptr Word8 -> {-# UNPACK #-} !Word64 -> IOVec
[iovBase] :: IOVec -> {-# UNPACK #-} !Ptr Word8
[iovLen] :: IOVec -> {-# UNPACK #-} !Word64
c_writev :: CInt -> Ptr IOVec -> CInt -> IO CSsize
c_safe_writev :: CInt -> Ptr IOVec -> CInt -> IO CSsize
instance GHC.Show.Show Streamly.Internal.System.IOVec.Type.IOVec
instance GHC.Classes.Eq Streamly.Internal.System.IOVec.Type.IOVec
instance Foreign.Storable.Storable Streamly.Internal.System.IOVec.Type.IOVec


-- | Low level IO routines interfacing the operating system.
module Streamly.Internal.System.IOVec
data IOVec
IOVec :: {-# UNPACK #-} !Ptr Word8 -> {-# UNPACK #-} !Word64 -> IOVec
[iovBase] :: IOVec -> {-# UNPACK #-} !Ptr Word8
[iovLen] :: IOVec -> {-# UNPACK #-} !Word64
c_writev :: CInt -> Ptr IOVec -> CInt -> IO CSsize
c_safe_writev :: CInt -> Ptr IOVec -> CInt -> IO CSsize

-- | <tt>groupIOVecsOf maxBytes maxEntries</tt> groups arrays in the
--   incoming stream to create a stream of <a>IOVec</a> arrays with a
--   maximum of <tt>maxBytes</tt> bytes in each array and a maximum of
--   <tt>maxEntries</tt> entries in each array.
groupIOVecsOf :: MonadIO m => Int -> Int -> Stream m (Array a) -> Stream m (Array IOVec)

-- | <tt>groupIOVecsOf maxBytes maxEntries</tt> groups arrays in the
--   incoming stream to create a stream of <a>IOVec</a> arrays with a
--   maximum of <tt>maxBytes</tt> bytes in each array and a maximum of
--   <tt>maxEntries</tt> entries in each array.
groupIOVecsOfMut :: MonadIO m => Int -> Int -> Stream m (Array a) -> Stream m (Array IOVec)


-- | Low level IO routines interfacing the operating system.
module Streamly.Internal.FileSystem.FDIO

-- | <tt>write FD buffer offset length</tt> tries to write data on the
--   given filesystem fd (cannot be a socket) up to sepcified length
--   starting from the given offset in the buffer. The write will not block
--   the OS thread, it may suspend the Haskell thread until write can
--   proceed. Returns the actual amount of data written.
write :: FD -> Ptr Word8 -> Int -> CSize -> IO CInt

-- | Keep writing in a loop until all data in the buffer has been written.
writeAll :: FD -> Ptr Word8 -> Int -> IO ()

-- | <tt>write FD iovec count</tt> tries to write data on the given
--   filesystem fd (cannot be a socket) from an iovec with specified number
--   of entries. The write will not block the OS thread, it may suspend the
--   Haskell thread until write can proceed. Returns the actual amount of
--   data written.
writev :: FD -> Ptr IOVec -> Int -> IO CInt

-- | Keep writing an iovec in a loop until all the iovec entries are
--   written.
writevAll :: FD -> Ptr IOVec -> Int -> IO ()


module Streamly.Internal.Unicode.Char

-- | Select alphabetic characters in the ascii character set.
--   
--   <i>Pre-release</i>
isAsciiAlpha :: Char -> Bool
data NormalizationMode

-- | Canonical decomposition.
NFD :: NormalizationMode

-- | Compatibility decomposition.
NFKD :: NormalizationMode

-- | Canonical decomposition followed by canonical composition.
NFC :: NormalizationMode

-- | Compatibility decomposition followed by canonical composition.
NFKC :: NormalizationMode
normalize :: (IsStream t, Monad m) => NormalizationMode -> t m Char -> t m Char
instance GHC.Enum.Enum Streamly.Internal.Unicode.Char.NormalizationMode
instance GHC.Show.Show Streamly.Internal.Unicode.Char.NormalizationMode
instance GHC.Classes.Eq Streamly.Internal.Unicode.Char.NormalizationMode


-- | To parse a text input, use the decode routines from
--   <a>Streamly.Unicode.Stream</a> module to convert an input byte stream
--   to a Unicode Char stream and then use these parsers on the Char
--   stream.
module Streamly.Internal.Unicode.Char.Parser
space :: MonadCatch m => Parser m Char Char
lower :: MonadCatch m => Parser m Char Char
upper :: MonadCatch m => Parser m Char Char
alpha :: MonadCatch m => Parser m Char Char
alphaNum :: MonadCatch m => Parser m Char Char
print :: MonadCatch m => Parser m Char Char
digit :: MonadCatch m => Parser m Char Char
octDigit :: MonadCatch m => Parser m Char Char
hexDigit :: MonadCatch m => Parser m Char Char
letter :: MonadCatch m => Parser m Char Char
mark :: MonadCatch m => Parser m Char Char
number :: MonadCatch m => Parser m Char Char
punctuation :: MonadCatch m => Parser m Char Char
symbol :: MonadCatch m => Parser m Char Char
separator :: MonadCatch m => Parser m Char Char
ascii :: MonadCatch m => Parser m Char Char
latin1 :: MonadCatch m => Parser m Char Char
asciiUpper :: MonadCatch m => Parser m Char Char
asciiLower :: MonadCatch m => Parser m Char Char

-- | Match a specific character.
char :: MonadCatch m => Char -> Parser m Char Char

-- | Parse and decode an unsigned integral decimal number.
decimal :: (MonadCatch m, Integral a) => Parser m Char a

-- | Parse and decode an unsigned integral hexadecimal number. The hex
--   digits <tt>'a'</tt> through <tt>'f'</tt> may be upper or lower case.
--   
--   Note: This parser does not accept a leading <tt>"0x"</tt> string.
hexadecimal :: (MonadCatch m, Integral a, Bits a) => Parser m Char a

-- | Allow an optional leading <tt>'+'</tt> or <tt>'-'</tt> sign character
--   before any parser.
signed :: (Num a, MonadCatch m) => Parser m Char a -> Parser m Char a

-- | Parse a <a>Double</a>.
--   
--   This parser accepts an optional leading sign character, followed by at
--   most one decimal digit. The syntax is similar to that accepted by the
--   <a>read</a> function, with the exception that a trailing <tt>'.'</tt>
--   is consumed.
--   
--   <h3>Examples</h3>
--   
--   Examples with behaviour identical to <a>read</a>, if you feed an empty
--   continuation to the first result:
--   
--   <pre>
--   IS.parse double (IS.fromList "3")     == 3.0
--   IS.parse double (IS.fromList "3.1")   == 3.1
--   IS.parse double (IS.fromList "3e4")   == 30000.0
--   IS.parse double (IS.fromList "3.1e4") == 31000.0
--   IS.parse double (IS.fromList "3e")    == 30
--   </pre>
--   
--   Examples with behaviour identical to <a>read</a>:
--   
--   <pre>
--   IS.parse (IS.fromList ".3")    == error "Parse failed"
--   IS.parse (IS.fromList "e3")    == error "Parse failed"
--   </pre>
--   
--   Example of difference from <a>read</a>:
--   
--   <pre>
--   IS.parse double (IS.fromList "3.foo") == 3.0
--   </pre>
--   
--   This function does not accept string representations of "NaN" or
--   "Infinity".
--   
--   <i>Unimplemented</i>
double :: Parser m Char Double


module Streamly.Internal.Unicode.Stream

-- | Decode a stream of bytes to Unicode characters by mapping each byte to
--   a corresponding Unicode <a>Char</a> in 0-255 range.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
decodeLatin1 :: (IsStream t, Monad m) => t m Word8 -> t m Char

-- | Decode a UTF-8 encoded bytestream to a stream of Unicode characters.
--   Any invalid codepoint encountered is replaced with the unicode
--   replacement character.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
decodeUtf8 :: (Monad m, IsStream t) => t m Word8 -> t m Char

-- | Decode a UTF-8 encoded bytestream to a stream of Unicode characters.
--   The function throws an error if an invalid codepoint is encountered.
decodeUtf8' :: (Monad m, IsStream t) => t m Word8 -> t m Char

-- | Decode a UTF-8 encoded bytestream to a stream of Unicode characters.
--   Any invalid codepoint encountered is dropped.
decodeUtf8_ :: (Monad m, IsStream t) => t m Word8 -> t m Char
data DecodeError
DecodeError :: !DecodeState -> !CodePoint -> DecodeError
type DecodeState = Word8
type CodePoint = Int

-- | <i>Pre-release</i>
decodeUtf8Either :: (Monad m, IsStream t) => t m Word8 -> t m (Either DecodeError Char)

-- | <i>Pre-release</i>
resumeDecodeUtf8Either :: (Monad m, IsStream t) => DecodeState -> CodePoint -> t m Word8 -> t m (Either DecodeError Char)

-- | <i>Pre-release</i>
decodeUtf8Arrays :: (MonadIO m, IsStream t) => t m (Array Word8) -> t m Char

-- | <i>Pre-release</i>
decodeUtf8Arrays' :: (MonadIO m, IsStream t) => t m (Array Word8) -> t m Char

-- | <i>Pre-release</i>
decodeUtf8Arrays_ :: (MonadIO m, IsStream t) => t m (Array Word8) -> t m Char

-- | Like <a>encodeLatin1'</a> but silently maps input codepoints beyond
--   255 to arbitrary Latin1 chars in 0-255 range. No error or exception is
--   thrown when such mapping occurs.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
encodeLatin1 :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to bytes by mapping each
--   character to a byte in 0-255 range. Throws an error if the input
--   stream contains characters beyond 255.
encodeLatin1' :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Like <a>encodeLatin1</a> but drops the input characters beyond 255.
encodeLatin1_ :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to a UTF-8 encoded bytestream.
--   Any Invalid characters (U+D800-U+D8FF) in the input stream are
--   replaced by the Unicode replacement character U+FFFD.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
encodeUtf8 :: (Monad m, IsStream t) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to a UTF-8 encoded bytestream.
--   When any invalid character (U+D800-U+D8FF) is encountered in the input
--   stream the function errors out.
encodeUtf8' :: (Monad m, IsStream t) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to a UTF-8 encoded bytestream.
--   Any Invalid characters (U+D800-U+D8FF) in the input stream are
--   dropped.
encodeUtf8_ :: (Monad m, IsStream t) => t m Char -> t m Word8

-- | Encode a stream of <a>String</a> using the supplied encoding scheme.
--   Each string is encoded as an <tt>Array Word8</tt>.
encodeStrings :: (MonadIO m, IsStream t) => (SerialT m Char -> SerialT m Word8) -> t m String -> t m (Array Word8)

-- | Remove leading whitespace from a string.
--   
--   <pre>
--   stripHead = S.dropWhile isSpace
--   </pre>
--   
--   <i>Pre-release</i>
stripHead :: (Monad m, IsStream t) => t m Char -> t m Char

-- | Fold each line of the stream using the supplied <a>Fold</a> and stream
--   the result.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ lines Fold.toList (Stream.fromList "lines\nthis\nstring\n\n\n")
--   ["lines","this","string","",""]
--   </pre>
--   
--   <pre>
--   lines = S.splitOnSuffix (== '\n')
--   </pre>
--   
--   <i>Pre-release</i>
lines :: (Monad m, IsStream t) => Fold m Char b -> t m Char -> t m b

-- | Fold each word of the stream using the supplied <a>Fold</a> and stream
--   the result.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ words Fold.toList (Stream.fromList "fold these     words")
--   ["fold","these","words"]
--   </pre>
--   
--   <pre>
--   words = S.wordsBy isSpace
--   </pre>
--   
--   <i>Pre-release</i>
words :: (Monad m, IsStream t) => Fold m Char b -> t m Char -> t m b

-- | Unfold a stream to character streams using the supplied <a>Unfold</a>
--   and concat the results suffixing a newline character <tt>\n</tt> to
--   each stream.
--   
--   <pre>
--   unlines = Stream.interposeSuffix 'n'
--   unlines = Stream.intercalateSuffix Unfold.fromList "n"
--   </pre>
--   
--   <i>Pre-release</i>
unlines :: (MonadIO m, IsStream t) => Unfold m a Char -> t m a -> t m Char

-- | Unfold the elements of a stream to character streams using the
--   supplied <a>Unfold</a> and concat the results with a whitespace
--   character infixed between the streams.
--   
--   <pre>
--   unwords = Stream.interpose ' '
--   unwords = Stream.intercalate Unfold.fromList " "
--   </pre>
--   
--   <i>Pre-release</i>
unwords :: (MonadIO m, IsStream t) => Unfold m a Char -> t m a -> t m Char
decodeUtf8D :: Monad m => Stream m Word8 -> Stream m Char
decodeUtf8D' :: Monad m => Stream m Word8 -> Stream m Char
decodeUtf8D_ :: Monad m => Stream m Word8 -> Stream m Char

-- | See section "3.9 Unicode Encoding Forms" in
--   <a>https://www.unicode.org/versions/Unicode13.0.0/UnicodeStandard-13.0.pdf</a>
encodeUtf8D :: Monad m => Stream m Char -> Stream m Word8
encodeUtf8D' :: Monad m => Stream m Char -> Stream m Word8
encodeUtf8D_ :: Monad m => Stream m Char -> Stream m Word8
decodeUtf8EitherD :: Monad m => Stream m Word8 -> Stream m (Either DecodeError Char)
resumeDecodeUtf8EitherD :: Monad m => DecodeState -> CodePoint -> Stream m Word8 -> Stream m (Either DecodeError Char)
decodeUtf8ArraysD :: MonadIO m => Stream m (Array Word8) -> Stream m Char
decodeUtf8ArraysD' :: MonadIO m => Stream m (Array Word8) -> Stream m Char
decodeUtf8ArraysD_ :: MonadIO m => Stream m (Array Word8) -> Stream m Char

-- | Same as <a>decodeUtf8</a>

-- | <i>Deprecated: Please use <a>decodeUtf8</a> instead</i>
decodeUtf8Lax :: (IsStream t, Monad m) => t m Word8 -> t m Char

-- | Same as <a>encodeLatin1</a>

-- | <i>Deprecated: Please use <a>encodeLatin1</a> instead</i>
encodeLatin1Lax :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Same as <a>encodeUtf8</a>

-- | <i>Deprecated: Please use <a>encodeUtf8</a> instead</i>
encodeUtf8Lax :: (IsStream t, Monad m) => t m Char -> t m Word8
instance GHC.Show.Show Streamly.Internal.Unicode.Stream.DecodeError
instance GHC.Show.Show Streamly.Internal.Unicode.Stream.CodingFailureMode


module Streamly.Internal.Console.Stdio

-- | Unfold standard input into a stream of <a>Word8</a>.
read :: MonadIO m => Unfold m () Word8

-- | Read a byte stream from standard input.
--   
--   <pre>
--   getBytes = Handle.toBytes stdin
--   getBytes = Stream.unfold Stdio.read ()
--   </pre>
--   
--   <i>Pre-release</i>
getBytes :: MonadIO m => SerialT m Word8

-- | Read a character stream from Utf8 encoded standard input.
--   
--   <pre>
--   getChars = Unicode.decodeUtf8 Stdio.getBytes
--   </pre>
--   
--   <i>Pre-release</i>
getChars :: MonadIO m => SerialT m Char

-- | Unfolds standard input into a stream of <a>Word8</a> arrays.
readChunks :: MonadIO m => Unfold m () (Array Word8)

-- | Read a stream of chunks from standard input. The maximum size of a
--   single chunk is limited to <tt>defaultChunkSize</tt>. The actual size
--   read may be less than <tt>defaultChunkSize</tt>.
--   
--   <pre>
--   getChunks = Handle.toChunks stdin
--   getChunks = Stream.unfold Stdio.readChunks ()
--   </pre>
--   
--   <i>Pre-release</i>
getChunks :: MonadIO m => SerialT m (Array Word8)

-- | Fold a stream of <a>Word8</a> to standard output.
write :: MonadIO m => Fold m Word8 ()

-- | Fold a stream of <a>Word8</a> to standard error.
writeErr :: MonadIO m => Fold m Word8 ()

-- | Write a stream of bytes to standard output.
--   
--   <pre>
--   putBytes = Handle.putBytes stdout
--   putBytes = Stream.fold Stdio.write
--   </pre>
--   
--   <i>Pre-release</i>
putBytes :: MonadIO m => SerialT m Word8 -> m ()

-- | Encode a character stream to Utf8 and write it to standard output.
--   
--   <pre>
--   putChars = Stdio.putBytes . Unicode.encodeUtf8
--   </pre>
--   
--   <i>Pre-release</i>
putChars :: MonadIO m => SerialT m Char -> m ()

-- | Fold a stream of <tt>Array Word8</tt> to standard output.
writeChunks :: MonadIO m => Fold m (Array Word8) ()

-- | Fold a stream of <tt>Array Word8</tt> to standard error.
writeErrChunks :: MonadIO m => Fold m (Array Word8) ()

-- | Write a stream of chunks to standard output.
--   
--   <pre>
--   putChunks = Handle.putChunks stdout
--   putChunks = Stream.fold Stdio.writeChunks
--   </pre>
--   
--   <i>Pre-release</i>
putChunks :: MonadIO m => SerialT m (Array Word8) -> m ()

-- | Write a stream of strings to standard output using the supplied
--   encoding. Output is flushed to the device for each string.
--   
--   <i>Pre-release</i>
putStringsWith :: MonadIO m => (SerialT m Char -> SerialT m Word8) -> SerialT m String -> m ()

-- | Write a stream of strings to standard output using UTF8 encoding.
--   Output is flushed to the device for each string.
--   
--   <i>Pre-release</i>
putStrings :: MonadIO m => SerialT m String -> m ()

-- | Like <a>putStrings</a> but adds a newline at the end of each string.
--   
--   XXX This is not portable, on Windows we need to use "rn" instead.
--   
--   <i>Pre-release</i>
putStringsLn :: MonadIO m => SerialT m String -> m ()


-- | Combinators to work with standard input, output and error streams.
--   
--   See also: <a>Streamly.Internal.Console.Stdio</a>
module Streamly.Console.Stdio

-- | Unfold standard input into a stream of <a>Word8</a>.
read :: MonadIO m => Unfold m () Word8

-- | Unfolds standard input into a stream of <a>Word8</a> arrays.
readChunks :: MonadIO m => Unfold m () (Array Word8)

-- | Fold a stream of <a>Word8</a> to standard output.
write :: MonadIO m => Fold m Word8 ()

-- | Fold a stream of <tt>Array Word8</tt> to standard output.
writeChunks :: MonadIO m => Fold m (Array Word8) ()

-- | Fold a stream of <a>Word8</a> to standard error.
writeErr :: MonadIO m => Fold m Word8 ()

-- | Fold a stream of <tt>Array Word8</tt> to standard error.
writeErrChunks :: MonadIO m => Fold m (Array Word8) ()


-- | <h1>Processing Unicode Strings</h1>
--   
--   A <a>Char</a> stream is the canonical representation to process
--   Unicode strings. It can be processed efficiently using regular stream
--   processing operations. A byte stream of Unicode text read from an IO
--   device or from an <a>Array</a> in memory can be decoded into a
--   <a>Char</a> stream using the decoding routines in this module. A
--   <a>String</a> (<tt>[Char]</tt>) can be converted into a <a>Char</a>
--   stream using <a>fromList</a>. An <tt>Array Char</tt> can be
--   <a>unfold</a>ed into a stream using the array <a>read</a> unfold.
--   
--   <h1>Storing Unicode Strings</h1>
--   
--   A stream of <a>Char</a> can be encoded into a byte stream using the
--   encoding routines in this module and then written to IO devices or to
--   arrays in memory.
--   
--   If you have to store a <a>Char</a> stream in memory you can convert it
--   into a <a>String</a> using <a>toList</a> or using the <a>toList</a>
--   fold. The <a>String</a> type can be more efficient than pinned arrays
--   for short and short lived strings.
--   
--   For longer or long lived streams you can <a>fold</a> the <a>Char</a>
--   stream as <tt>Array Char</tt> using the array <a>write</a> fold. The
--   <tt>Array</tt> type provides a more compact representation and pinned
--   memory reducing GC overhead. If space efficiency is a concern you can
--   use <a>encodeUtf8'</a> on the <a>Char</a> stream before writing it to
--   an <tt>Array</tt> providing an even more compact representation.
--   
--   <h1>String Literals</h1>
--   
--   <tt>SerialT Identity Char</tt> and <tt>Array Char</tt> are instances
--   of <tt>IsString</tt> and <tt>IsList</tt>, therefore,
--   <tt>OverloadedStrings</tt> and <tt>OverloadedLists</tt> extensions can
--   be used for convenience when specifying unicode strings literals using
--   these types.
--   
--   <h1>Pitfalls</h1>
--   
--   <ul>
--   <li>Case conversion: Some unicode characters translate to more than
--   one code point on case conversion. The <tt>toUpper</tt> and
--   <tt>toLower</tt> functions in <tt>base</tt> package do not handle such
--   characters. Therefore, operations like <tt>map toUpper</tt> on a
--   character stream or character array may not always perform correct
--   conversion.</li>
--   <li>String comparison: In some cases, visually identical strings may
--   have different unicode representations, therefore, a character stream
--   or character array cannot be directly compared. A normalized
--   comparison may be needed to check string equivalence correctly.</li>
--   </ul>
--   
--   <h1>Experimental APIs</h1>
--   
--   Some experimental APIs to conveniently process text using the
--   <tt>Array Char</tt> represenation directly can be found in
--   <a>Streamly.Internal.Memory.Unicode.Array</a>.

-- | <i>Deprecated: Use <a>Streamly.Unicode.Stream</a> instead</i>
module Streamly.Data.Unicode.Stream

-- | Decode a stream of bytes to Unicode characters by mapping each byte to
--   a corresponding Unicode <a>Char</a> in 0-255 range.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
decodeLatin1 :: (IsStream t, Monad m) => t m Word8 -> t m Char

-- | Decode a UTF-8 encoded bytestream to a stream of Unicode characters.
--   Any invalid codepoint encountered is replaced with the unicode
--   replacement character.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
decodeUtf8 :: (Monad m, IsStream t) => t m Word8 -> t m Char

-- | Like <a>encodeLatin1'</a> but silently maps input codepoints beyond
--   255 to arbitrary Latin1 chars in 0-255 range. No error or exception is
--   thrown when such mapping occurs.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
encodeLatin1 :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to a UTF-8 encoded bytestream.
--   Any Invalid characters (U+D800-U+D8FF) in the input stream are
--   replaced by the Unicode replacement character U+FFFD.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
encodeUtf8 :: (Monad m, IsStream t) => t m Char -> t m Word8

-- | Same as <a>decodeUtf8</a>

-- | <i>Deprecated: Please use <a>decodeUtf8</a> instead</i>
decodeUtf8Lax :: (IsStream t, Monad m) => t m Word8 -> t m Char

-- | Same as <a>encodeLatin1</a>

-- | <i>Deprecated: Please use <a>encodeLatin1</a> instead</i>
encodeLatin1Lax :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Same as <a>encodeUtf8</a>

-- | <i>Deprecated: Please use <a>encodeUtf8</a> instead</i>
encodeUtf8Lax :: (IsStream t, Monad m) => t m Char -> t m Word8


module Streamly.Internal.Unicode.Utf8

-- | A space efficient, packed, unboxed Unicode container.
data Utf8
pack :: String -> Utf8
unpack :: Utf8 -> String
toArray :: Utf8 -> Array Word8
instance Control.DeepSeq.NFData Streamly.Internal.Unicode.Utf8.Utf8


-- | This module provides immutable arrays in pinned memory (non GC memory)
--   suitable for long lived data storage, random access and for
--   interfacing with the operating system.
--   
--   Arrays in this module are chunks of pinned memory that hold a sequence
--   of <tt>Storable</tt> values of a given type, they cannot store
--   non-serializable data like functions. Once created an array cannot be
--   modified. Pinned memory allows efficient buffering of long lived data
--   without adding any impact to GC. One array is just one pointer visible
--   to GC and it does not have to be copied across generations. Moreover,
--   pinned memory allows communication with foreign consumers and
--   producers (e.g. file or network IO) without copying the data.
--   
--   <h1>Programmer Notes</h1>
--   
--   To apply a transformation to an array use <a>read</a> to unfold the
--   array into a stream, apply a transformation on the stream and then use
--   <a>write</a> to fold it back to an array.
--   
--   This module is designed to be imported qualified:
--   
--   <pre>
--   import qualified Streamly.Array as A
--   </pre>
--   
--   For experimental APIs see <a>Streamly.Internal.Data.Array.Foreign</a>.

-- | <i>Deprecated: Use Streamly.Data.Array.Foreign instead</i>
module Streamly.Memory.Array
data Array a

-- | Create an <a>Array</a> from the first N elements of a list. The array
--   is allocated to size N, if the list terminates before N elements then
--   the array may hold less than N elements.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromListN :: Storable a => Int -> [a] -> Array a

-- | Create an <a>Array</a> from a list. The list must be of finite size.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
fromList :: Storable a => [a] -> Array a

-- | <tt>writeN n</tt> folds a maximum of <tt>n</tt> elements from the
--   input stream to an <a>Array</a>.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
writeN :: forall m a. (MonadIO m, Storable a) => Int -> Fold m a (Array a)

-- | Fold the whole input to a single array.
--   
--   <i>Caution! Do not use this on infinite streams.</i>
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
write :: forall m a. (MonadIO m, Storable a) => Fold m a (Array a)

-- | Convert an <a>Array</a> into a list.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
toList :: Storable a => Array a -> [a]

-- | Unfold an array into a stream.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
read :: forall m a. (Monad m, Storable a) => Unfold m (Array a) a

-- | <i>O(1)</i> Get the length of the array i.e. the number of elements in
--   the array.
--   
--   <i>Since 0.7.0 (Streamly.Memory.Array)</i>
length :: forall a. Storable a => Array a -> Int


-- | Combinators to build Inet/TCP clients and servers.
--   
--   <pre>
--   import qualified Streamly.Network.Inet.TCP as TCP
--   </pre>
module Streamly.Network.Inet.TCP

-- | Unfold a tuple <tt>(ipAddr, port)</tt> into a stream of connected TCP
--   sockets. <tt>ipAddr</tt> is the local IP address and <tt>port</tt> is
--   the local port on which connections are accepted.
acceptOnAddr :: MonadIO m => Unfold m ((Word8, Word8, Word8, Word8), PortNumber) Socket

-- | Like <a>acceptOnAddr</a> but binds on the IPv4 address
--   <tt>0.0.0.0</tt> i.e. on all IPv4 addresses/interfaces of the machine
--   and listens for TCP connections on the specified port.
--   
--   <pre>
--   acceptOnPort = UF.supplyFirst acceptOnAddr (0,0,0,0)
--   </pre>
acceptOnPort :: MonadIO m => Unfold m PortNumber Socket

-- | Like <a>acceptOnAddr</a> but binds on the localhost IPv4 address
--   <tt>127.0.0.1</tt>. The server can only be accessed from the local
--   host, it cannot be accessed from other hosts on the network.
--   
--   <pre>
--   acceptOnPortLocal = UF.supplyFirst acceptOnAddr (127,0,0,1)
--   </pre>
acceptOnPortLocal :: MonadIO m => Unfold m PortNumber Socket

-- | Connect to the specified IP address and port number. Returns a
--   connected socket or throws an exception.
connect :: (Word8, Word8, Word8, Word8) -> PortNumber -> IO Socket


-- | This module provides Array and stream based socket operations to
--   connect to remote hosts, to receive connections from remote hosts, and
--   to read and write streams and arrays of bytes to and from network
--   sockets.
--   
--   For basic socket types and operations please consult the
--   <tt>Network.Socket</tt> module of the <a>network</a> package.
--   
--   <h1>Examples</h1>
--   
--   To write a server, use the <a>accept</a> unfold to start listening for
--   connections from clients. <a>accept</a> supplies a stream of connected
--   sockets. We can map an effectful action on this socket stream to
--   handle the connections. The action would typically use socket reading
--   and writing operations to communicate with the remote host. We can
--   read/write a stream of bytes or a stream of chunks of bytes
--   (<tt>Array</tt>).
--   
--   Following is a short example of a concurrent echo server. Please note
--   that this example can be written even more succinctly by using higher
--   level operations from <a>Streamly.Network.Inet.TCP</a> module.
--   
--   <pre>
--   {-# LANGUAGE FlexibleContexts #-}
--   
--   import Data.Function ((&amp;))
--   import Network.Socket
--   import Streamly.Network.Socket (SockSpec(..))
--   
--   import qualified Streamly.Prelude as Stream
--   import qualified Streamly.Network.Socket as Socket
--   
--   main = do
--       let spec = SockSpec
--                  { sockFamily = AF_INET
--                  , sockType   = Stream
--                  , sockProto  = defaultProtocol
--                  , sockOpts   = []
--                  }
--           addr = SockAddrInet 8090 (tupleToHostAddress (0,0,0,0))
--        in server spec addr
--   
--       where
--   
--       server spec addr =
--             Stream.unfold Socket.accept (maxListenQueue, spec, addr) -- ParallelT IO Socket
--           &amp; Stream.mapM (Socket.forSocketM echo)                     -- ParallelT IO ()
--           &amp; Stream.fromParallel                                      -- SerialT IO ()
--           &amp; Stream.drain                                             -- IO ()
--   
--       echo sk =
--             Stream.unfold Socket.readChunks sk  -- SerialT IO (Array Word8)
--           &amp; Stream.fold (Socket.writeChunks sk) -- IO ()
--   </pre>
--   
--   <h1>Programmer Notes</h1>
--   
--   Read IO requests to connected stream sockets are performed in chunks
--   of <a>defaultChunkSize</a>. Unless specified otherwise in the API,
--   writes are collected into chunks of <a>defaultChunkSize</a> before
--   they are written to the socket. APIs are provided to control the
--   chunking behavior.
--   
--   <pre>
--   import qualified Streamly.Network.Socket as Socket
--   </pre>
--   
--   <h1>See Also</h1>
--   
--   <ul>
--   <li><a>Streamly.Internal.Network.Socket</a></li>
--   <li><a>network</a></li>
--   </ul>
module Streamly.Network.Socket

-- | Specify the socket protocol details.
data SockSpec
SockSpec :: !Family -> !SocketType -> !ProtocolNumber -> ![(SocketOption, Int)] -> SockSpec
[sockFamily] :: SockSpec -> !Family
[sockType] :: SockSpec -> !SocketType
[sockProto] :: SockSpec -> !ProtocolNumber
[sockOpts] :: SockSpec -> ![(SocketOption, Int)]

-- | Unfold a three tuple <tt>(listenQLen, spec, addr)</tt> into a stream
--   of connected protocol sockets corresponding to incoming connections.
--   <tt>listenQLen</tt> is the maximum number of pending connections in
--   the backlog. <tt>spec</tt> is the socket protocol and options
--   specification and <tt>addr</tt> is the protocol address where the
--   server listens for incoming connections.
accept :: MonadIO m => Unfold m (Int, SockSpec, SockAddr) Socket

-- | Unfolds a <a>Socket</a> into a byte stream. IO requests to the socket
--   are performed in sizes of <a>defaultChunkSize</a>.
read :: MonadIO m => Unfold m Socket Word8

-- | Unfolds the tuple <tt>(bufsize, socket)</tt> into a byte stream, read
--   requests to the socket are performed using buffers of
--   <tt>bufsize</tt>.
readWithBufferOf :: MonadIO m => Unfold m (Int, Socket) Word8

-- | Unfolds a socket into a stream of <a>Word8</a> arrays. Requests to the
--   socket are performed using a buffer of size <a>defaultChunkSize</a>.
--   The size of arrays in the resulting stream are therefore less than or
--   equal to <a>defaultChunkSize</a>.
readChunks :: MonadIO m => Unfold m Socket (Array Word8)

-- | Unfold the tuple <tt>(bufsize, socket)</tt> into a stream of
--   <a>Word8</a> arrays. Read requests to the socket are performed using a
--   buffer of size <tt>bufsize</tt>. The size of an array in the resulting
--   stream is always less than or equal to <tt>bufsize</tt>.
readChunksWithBufferOf :: MonadIO m => Unfold m (Int, Socket) (Array Word8)

-- | Read a byte array from a file handle up to a maximum of the requested
--   size. If no data is available on the handle it blocks until some data
--   becomes available. If data is available then it immediately returns
--   that data without blocking.
readChunk :: Int -> Socket -> IO (Array Word8)

-- | Write a byte stream to a socket. Accumulates the input in chunks of up
--   to <a>defaultChunkSize</a> bytes before writing.
--   
--   <pre>
--   write = <a>writeWithBufferOf</a> <a>defaultChunkSize</a>
--   </pre>
write :: MonadIO m => Socket -> Fold m Word8 ()

-- | Write a byte stream to a socket. Accumulates the input in chunks of
--   specified number of bytes before writing.
writeWithBufferOf :: MonadIO m => Int -> Socket -> Fold m Word8 ()

-- | Write a stream of arrays to a socket. Each array in the stream is
--   written to the socket as a separate IO request.
writeChunks :: (MonadIO m, Storable a) => Socket -> Fold m (Array a) ()

-- | <tt>writeChunksWithBufferOf bufsize socket</tt> writes a stream of
--   arrays to <tt>socket</tt> after coalescing the adjacent arrays in
--   chunks of <tt>bufsize</tt>. Multiple arrays are coalesed as long as
--   the total size remains below the specified size. It never splits an
--   array, if a single array is bigger than the specified size it emitted
--   as it is.
writeChunksWithBufferOf :: (MonadIO m, Storable a) => Int -> Socket -> Fold m (Array a) ()

-- | Write an Array to a file handle.
writeChunk :: Storable a => Socket -> Array a -> IO ()

-- | <tt><a>forSocketM</a> action socket</tt> runs the monadic computation
--   <tt>action</tt> passing the socket handle to it. The handle will be
--   closed on exit from <a>forSocketM</a>, whether by normal termination
--   or by raising an exception. If closing the handle raises an exception,
--   then this exception will be raised by <a>forSocketM</a> rather than
--   any exception raised by <tt>action</tt>.
forSocketM :: (MonadMask m, MonadIO m) => (Socket -> m ()) -> Socket -> m ()


-- | To run examples in this module:
--   
--   <pre>
--   &gt;&gt;&gt; import qualified Streamly.Data.Fold as Fold
--   
--   &gt;&gt;&gt; import qualified Streamly.Prelude as Stream
--   </pre>
--   
--   We will add some more imports in the examples as needed.
--   
--   For effectful streams we will use the following IO action that blocks
--   for <tt>n</tt> seconds:
--   
--   <pre>
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; :{
--    delay n = do
--        threadDelay (n * 1000000)   -- sleep for n seconds
--        putStrLn (show n ++ " sec") -- print "n sec"
--        return n                    -- IO Int
--   :}
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; delay 1
--   1 sec
--   1
--   </pre>
--   
--   <h1>Overview</h1>
--   
--   Streamly is a framework for modular data flow based programming and
--   declarative concurrency. Powerful stream fusion framework in streamly
--   allows high performance combinatorial programming even when using byte
--   level streams. Streamly API is similar to Haskell lists.
--   
--   The basic stream type is <a>SerialT</a>. The type <tt>SerialT IO
--   a</tt> is an effectful equivalent of a list <tt>[a]</tt> using the IO
--   monad. Streams can be constructed like lists, except that they use
--   <a>nil</a> instead of '[]' and <a>cons</a> instead of <tt>:</tt>.
--   
--   <a>cons</a> constructs a pure stream which is more or less the same as
--   a list:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (SerialT, cons, consM, nil)
--   
--   &gt;&gt;&gt; stream = 1 `cons` 2 `cons` nil :: SerialT IO Int
--   
--   &gt;&gt;&gt; Stream.toList stream -- IO [Int]
--   [1,2]
--   </pre>
--   
--   <a>consM</a> constructs a stream from effectful actions:
--   
--   <pre>
--   &gt;&gt;&gt; stream = delay 1 `consM` delay 2 `consM` nil
--   
--   &gt;&gt;&gt; Stream.toList stream
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   <h2>Console Echo Program</h2>
--   
--   In the following example, <a>repeatM</a> generates an infinite stream
--   of <a>String</a> by repeatedly performing the <a>getLine</a> IO
--   action. <a>mapM</a> then applies <a>putStrLn</a> on each element in
--   the stream converting it to stream of <tt>()</tt>. Finally,
--   <a>drain</a> folds the stream to IO discarding the () values, thus
--   producing only effects.
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Function ((&amp;))
--   </pre>
--   
--   <pre>
--   &gt; :{
--    Stream.repeatM getLine      -- SerialT IO String
--        &amp; Stream.mapM putStrLn  -- SerialT IO ()
--        &amp; Stream.drain          -- IO ()
--   :}
--   </pre>
--   
--   This is a console echo program. It is an example of a declarative loop
--   written using streaming combinators. Compare it with an imperative
--   <tt>while</tt> loop.
--   
--   Hopefully, this gives you an idea how we can program declaratively by
--   representing loops using streams. In this module, you can find all
--   <a>Data.List</a> like functions and many more powerful combinators to
--   perform common programming tasks. Also see
--   <a>Streamly.Internal.Data.Stream.IsStream</a> module for many more
--   <tt>Pre-release</tt> combinators. See the
--   <a>https://github.com/composewell/streamly-examples</a> repository for
--   many more real world examples of stream programming.
--   
--   <h2>Polymorphic Combinators</h2>
--   
--   Streamly has several stream types, <a>SerialT</a> is one type of
--   stream with serial execution of actions, <a>AsyncT</a> is another with
--   concurrent execution. The combinators in this module are polymorphic
--   in stream type. For example,
--   
--   <pre>
--   repeatM :: (IsStream t, MonadAsync m) =&gt; m a -&gt; t m a
--   </pre>
--   
--   <tt>t</tt> is the stream type, <tt>m</tt> is the underlying
--   <a>Monad</a> of the stream (e.g. IO) and <tt>a</tt> is the type of
--   elements in the stream (e.g. Int).
--   
--   Stream elimination combinators accept a <a>SerialT</a> type instead of
--   a polymorphic type to force a concrete monomorphic type by default,
--   reducing type errors. That's why in the console echo example above the
--   stream type is <a>SerialT</a>.
--   
--   <pre>
--   drain :: Monad m =&gt; SerialT m a -&gt; m ()
--   </pre>
--   
--   We can force a certain stream type in polymorphic code by using
--   "Stream Type Adaptors". For example, to force <a>AsyncT</a>:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromAsync $ Stream.replicateM 10 $ delay 1
--   ...
--   </pre>
--   
--   <h2>Combining two streams</h2>
--   
--   Two streams can be combined to form a single stream in various
--   interesting ways. <a>serial</a> (append), <a>wSerial</a> (interleave),
--   <a>ahead</a> (concurrent, ordered append), <a>async</a> (lazy
--   concurrent, unordered append) , <a>wAsync</a> (lazy concurrent,
--   unordered interleave), <a>parallel</a> (strict concurrent merge),
--   <a>zipWith</a>, <a>zipAsyncWith</a> (concurrent zip), <a>mergeBy</a>,
--   <a>mergeAsyncBy</a> (concurrent merge) are some ways of combining two
--   streams.
--   
--   For example, the <a>parallel</a> combinator schedules both the streams
--   concurrently.
--   
--   <pre>
--   &gt;&gt;&gt; stream1 = Stream.fromListM [delay 3, delay 4]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromListM [delay 1, delay 2]
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `parallel` stream2
--   ...
--   </pre>
--   
--   We can chain the operations to combine more than two streams:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromListM [delay 1, delay 2]
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `parallel` stream2 `parallel` stream3
--   ...
--   </pre>
--   
--   Concurrent generation (<a>consM</a>) and concurrent merging of streams
--   is the fundamental basis of all concurrency in streamly.
--   
--   <h2>Combining many streams</h2>
--   
--   The <a>concatMapWith</a> combinator can be used to generalize the two
--   stream combining combinators to <tt>n</tt> streams. For example, we
--   can use <tt>concatMapWith parallel</tt> to read concurrently from all
--   incoming network connections and combine the input streams into a
--   single output stream:
--   
--   <pre>
--   import qualified Streamly.Network.Inet.TCP as TCP
--   import qualified Streamly.Network.Socket as Socket
--   
--   Stream.unfold TCP.acceptOnPort 8090
--    &amp; Stream.concatMapWith Stream.parallel (Stream.unfold Socket.read)
--   </pre>
--   
--   See the <tt>streamly-examples</tt> repository for a full working
--   example.
--   
--   <h2>Concurrent Nested Loops</h2>
--   
--   The Monad instance of <a>SerialT</a> is an example of nested looping.
--   It is in fact a list transformer. Different stream types provide
--   different variants of nested looping. For example, the <a>Monad</a>
--   instance of <a>ParallelT</a> uses <tt>concatMapWith parallel</tt> as
--   its bind operation. Therefore, each iteration of the loop for
--   <a>ParallelT</a> stream can run concurrently. See the documentation
--   for individual stream types for the specific execution behavior of the
--   stream as well as the behavior of <a>Semigroup</a> and <a>Monad</a>
--   instances.
--   
--   <h2>Stream Types</h2>
--   
--   Streamly has several stream types. These types differ in three
--   fundamental operations, <a>consM</a> (<a>IsStream</a> instance),
--   <a>&lt;&gt;</a> (<a>Semigroup</a> instance) and <a>&gt;&gt;=</a>
--   (<a>Monad</a> instance). Below we will see how <a>consM</a> behaves
--   for <a>SerialT</a>, <a>AsyncT</a> and <a>AheadT</a> stream types.
--   
--   <a>SerialT</a> executes actions serially, so the total delay in the
--   following example is <tt>2 + 1 = 3</tt> seconds:
--   
--   <pre>
--   &gt;&gt;&gt; stream = delay 2 `consM` delay 1 `consM` nil
--   
--   &gt;&gt;&gt; Stream.toList stream -- IO [Int]
--   2 sec
--   1 sec
--   [2,1]
--   </pre>
--   
--   <a>AsyncT</a> executes the actions concurrently, so the total delay is
--   <tt>max 2 1 = 2</tt> seconds:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAsync stream -- IO [Int]
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   <a>AsyncT</a> produces the results in the order in which execution
--   finishes. Notice the order of elements in the list above, it is not
--   the same as the order of actions in the stream.
--   
--   <a>AheadT</a> is similar to <a>AsyncT</a> but the order of results is
--   the same as the order of actions, even though they execute
--   concurrently:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAhead stream -- IO [Int]
--   1 sec
--   2 sec
--   [2,1]
--   </pre>
--   
--   <h2>Semigroup Instance</h2>
--   
--   Earlier we distinguished stream types based on the execution behavior
--   of actions within a stream. Stream types are also distinguished based
--   on how actions from different streams are scheduled for execution when
--   two streams are combined together.
--   
--   For example, both <a>SerialT</a> and <a>WSerialT</a> execute actions
--   within the stream serially, however, they differ in how actions from
--   individual streams are executed when two streams are combined with
--   <a>&lt;&gt;</a> (the <a>Semigroup</a> instance).
--   
--   For <a>SerialT</a>, <a>&lt;&gt;</a> has an appending behavior i.e. it
--   executes the actions from the second stream after executing actions
--   from the first stream:
--   
--   <pre>
--   &gt;&gt;&gt; stream1 = Stream.fromListM [delay 1, delay 2]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromListM [delay 3, delay 4]
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 &lt;&gt; stream2
--   1 sec
--   2 sec
--   3 sec
--   4 sec
--   [1,2,3,4]
--   </pre>
--   
--   For <a>WSerialT</a>, <a>&lt;&gt;</a> has an interleaving behavior i.e.
--   it executes one action from the first stream and then one action from
--   the second stream and so on:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWSerial $ stream1 &lt;&gt; stream2
--   1 sec
--   3 sec
--   2 sec
--   4 sec
--   [1,3,2,4]
--   </pre>
--   
--   The <a>&lt;&gt;</a> operation of <a>SerialT</a> and <a>WSerialT</a> is
--   the same as <a>serial</a> and <a>wSerial</a> respectively. The
--   <a>serial</a> combinator combines two streams of any type in the same
--   way as a serial stream combines.
--   
--   <h2>Concurrent Combinators</h2>
--   
--   Like <a>consM</a>, there are several other stream generation
--   operations whose execution behavior depends on the stream type, they
--   all follow behavior similar to <a>consM</a>.
--   
--   By default, folds like <a>drain</a> force the stream type to be
--   <a>SerialT</a>, so <a>replicateM</a> in the following code runs
--   serially, and takes 10 seconds:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.replicateM 10 $ delay 1
--   ...
--   </pre>
--   
--   We can use the <a>fromAsync</a> combinator to force the argument
--   stream to be of <a>AsyncT</a> type, <a>replicateM</a> in the following
--   example executes the replicated actions concurrently, thus taking only
--   1 second:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromAsync $ Stream.replicateM 10 $ delay 1
--   ...
--   </pre>
--   
--   We can use <a>mapM</a> to map an action concurrently:
--   
--   <pre>
--   &gt;&gt;&gt; f x = delay 1 &gt;&gt; return (x + 1)
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAhead $ Stream.mapM f $ Stream.fromList [1..3]
--   ...
--   [2,3,4]
--   </pre>
--   
--   <a>fromAhead</a> forces mapM to happen in <a>AheadT</a> style, thus
--   all three actions take only one second even though each individual
--   action blocks for a second.
--   
--   See the documentation of individual combinators to check if it is
--   concurrent or not. The concurrent combinators necessarily have a
--   <tt>MonadAsync m</tt> constraint. However, a <tt>MonadAsync m</tt>
--   constraint does not necessarily mean that the combinator is
--   concurrent.
--   
--   <h2>Automatic Concurrency Control</h2>
--   
--   <a>SerialT</a> (and <a>WSerialT</a>) runs all tasks serially whereas
--   <a>ParallelT</a> runs all tasks concurrently i.e. one thread per task.
--   The stream types <a>AsyncT</a>, <a>WAsyncT</a>, and <a>AheadT</a>
--   provide demand driven concurrency. It means that based on the rate at
--   which the consumer is consuming the stream, it maintains the optimal
--   number of threads to increase or decrease parallelism.
--   
--   However, the programmer can control the maximum number of threads
--   using <a>maxThreads</a>. It provides an upper bound on the concurrent
--   IO requests or CPU cores that can be used. <a>maxBuffer</a> limits the
--   number of evaluated stream elements that we can buffer. See the
--   "Concurrency Control" section for details.
--   
--   <h2>Caveats</h2>
--   
--   When we use combinators like <a>fromAsync</a> on a piece of code, all
--   combinators inside the argument of fromAsync become concurrent which
--   is often counter productive. Therefore, we recommend that in a
--   pipeline, you identify the combinators that you really want to be
--   concurrent and add a <a>fromSerial</a> after those combinators so that
--   the code following the combinator remains serial:
--   
--   <pre>
--   Stream.fromAsync $ ... concurrent combinator here ... $ Stream.fromSerial $ ...
--   </pre>
--   
--   <h2>Conventions</h2>
--   
--   Functions with the suffix <tt>M</tt> are general functions that work
--   on monadic arguments. The corresponding functions without the suffix
--   <tt>M</tt> work on pure arguments and can in general be derived from
--   their monadic versions but are provided for convenience and for
--   consistency with other pure APIs in the <tt>base</tt> package.
--   
--   In many cases, short definitions of the combinators are provided in
--   the documentation for illustration. The actual implementation may
--   differ for performance reasons.
module Streamly.Prelude
nil :: IsStream t => t m a

-- | Construct a stream by adding a pure value at the head of an existing
--   stream. For serial streams this is the same as <tt>(return a) `consM`
--   r</tt> but more efficient. For concurrent streams this is not
--   concurrent whereas <a>consM</a> is concurrent. For example:
--   
--   <pre>
--   &gt; toList $ 1 `cons` 2 `cons` 3 `cons` nil
--   [1,2,3]
--   </pre>
cons :: IsStream t => a -> t m a -> t m a
infixr 5 `cons`

-- | Operator equivalent of <a>cons</a>.
--   
--   <pre>
--   &gt; toList $ 1 .: 2 .: 3 .: nil
--   [1,2,3]
--   </pre>
(.:) :: IsStream t => a -> t m a -> t m a
infixr 5 .:

-- | Constructs a stream by adding a monadic action at the head of an
--   existing stream. For example:
--   
--   <pre>
--   &gt; toList $ getLine `consM` getLine `consM` nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
consM :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a
infixr 5 `consM`

-- | Operator equivalent of <a>consM</a>. We can read it as "<tt>parallel
--   colon</tt>" to remember that <tt>|</tt> comes before <tt>:</tt>.
--   
--   <pre>
--   &gt; toList $ getLine |: getLine |: nil
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   <pre>
--   let delay = threadDelay 1000000 &gt;&gt; print 1
--   drain $ fromSerial  $ delay |: delay |: delay |: nil
--   drain $ fromParallel $ delay |: delay |: delay |: nil
--   </pre>
--   
--   <i>Concurrent (do not use <a>fromParallel</a> to construct infinite
--   streams)</i>
(|:) :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a
infixr 5 |:

-- | Convert an <a>Unfold</a> into a stream by supplying it an input seed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.unfold (Unfold.replicateM 3) (putStrLn "hello")
--   hello
--   hello
--   hello
--   </pre>
--   
--   <i>Since: 0.7.0</i>
unfold :: (IsStream t, Monad m) => Unfold m a b -> a -> t m b

-- | <pre>
--   &gt;&gt;&gt; :{
--   unfoldr step s =
--       case step s of
--           Nothing -&gt; Stream.nil
--           Just (a, b) -&gt; a `Stream.cons` unfoldr step b
--   :}
--   </pre>
--   
--   Build a stream by unfolding a <i>pure</i> step function <tt>step</tt>
--   starting from a seed <tt>s</tt>. The step function returns the next
--   element in the stream and the next seed value. When it is done it
--   returns <a>Nothing</a> and the stream ends. For example,
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   let f b =
--           if b &gt; 2
--           then Nothing
--           else Just (b, b + 1)
--   in Stream.toList $ Stream.unfoldr f 0
--   :}
--   [0,1,2]
--   </pre>
unfoldr :: (Monad m, IsStream t) => (b -> Maybe (a, b)) -> b -> t m a

-- | Build a stream by unfolding a <i>monadic</i> step function starting
--   from a seed. The step function returns the next element in the stream
--   and the next seed value. When it is done it returns <a>Nothing</a> and
--   the stream ends. For example,
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   let f b =
--           if b &gt; 2
--           then return Nothing
--           else return (Just (b, b + 1))
--   in Stream.toList $ Stream.unfoldrM f 0
--   :}
--   [0,1,2]
--   </pre>
--   
--   When run concurrently, the next unfold step can run concurrently with
--   the processing of the output of the previous step. Note that more than
--   one step cannot run concurrently as the next step depends on the
--   output of the previous step.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   let f b =
--           if b &gt; 2
--           then return Nothing
--           else threadDelay 1000000 &gt;&gt; return (Just (b, b + 1))
--   in Stream.toList $ Stream.delay 1 $ Stream.fromAsync $ Stream.unfoldrM f 0
--   :}
--   [0,1,2]
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.1.0</i>
unfoldrM :: forall t m b a. (IsStream t, MonadAsync m) => (b -> m (Maybe (a, b))) -> b -> t m a

-- | <pre>
--   fromPure a = a `cons` nil
--   </pre>
--   
--   Create a singleton stream from a pure value.
--   
--   The following holds in monadic streams, but not in Zip streams:
--   
--   <pre>
--   fromPure = pure
--   fromPure = fromEffect . pure
--   </pre>
--   
--   In Zip applicative streams <a>fromPure</a> is not the same as
--   <a>pure</a> because in that case <a>pure</a> is equivalent to
--   <a>repeat</a> instead. <a>fromPure</a> and <a>pure</a> are equally
--   efficient, in other cases <a>fromPure</a> may be slightly more
--   efficient than the other equivalent definitions.
--   
--   <i>Since: 0.8.0 (Renamed yield to fromPure)</i>
fromPure :: IsStream t => a -> t m a

-- | <pre>
--   fromEffect m = m `consM` nil
--   </pre>
--   
--   Create a singleton stream from a monadic action.
--   
--   <pre>
--   &gt; Stream.toList $ Stream.fromEffect getLine
--   hello
--   ["hello"]
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed yieldM to fromEffect)</i>
fromEffect :: (Monad m, IsStream t) => m a -> t m a

-- | Generate an infinite stream by repeating a pure value.
repeat :: (IsStream t, Monad m) => a -> t m a

-- | <pre>
--   &gt;&gt;&gt; repeatM = fix . consM
--   
--   &gt;&gt;&gt; repeatM = cycle1 . fromEffect
--   </pre>
--   
--   Generate a stream by repeatedly executing a monadic action forever.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   repeatAsync =
--          Stream.repeatM (threadDelay 1000000 &gt;&gt; print 1)
--        &amp; Stream.take 10
--        &amp; Stream.fromAsync
--        &amp; Stream.drain
--   :}
--   </pre>
--   
--   <i>Concurrent, infinite (do not use with <tt>fromParallel</tt>)</i>
repeatM :: (IsStream t, MonadAsync m) => m a -> t m a

-- | <pre>
--   &gt;&gt;&gt; replicate n = Stream.take n . Stream.repeat
--   </pre>
--   
--   Generate a stream of length <tt>n</tt> by repeating a value <tt>n</tt>
--   times.
replicate :: (IsStream t, Monad m) => Int -> a -> t m a

-- | <pre>
--   &gt;&gt;&gt; replicateM n = Stream.take n . Stream.repeatM
--   </pre>
--   
--   Generate a stream by performing a monadic action <tt>n</tt> times.
--   Same as:
--   
--   <pre>
--   &gt;&gt;&gt; pr n = threadDelay 1000000 &gt;&gt; print n
--   </pre>
--   
--   This runs serially and takes 3 seconds:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromSerial $ Stream.replicateM 3 $ pr 1
--   1
--   1
--   1
--   </pre>
--   
--   This runs concurrently and takes just 1 second:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromAsync  $ Stream.replicateM 3 $ pr 1
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
replicateM :: forall t m a. (IsStream t, MonadAsync m) => Int -> m a -> t m a

-- | Types that can be enumerated as a stream. The operations in this type
--   class are equivalent to those in the <a>Enum</a> type class, except
--   that these generate a stream instead of a list. Use the functions in
--   <a>Streamly.Internal.Data.Stream.Enumeration</a> module to define new
--   instances.
class Enum a => Enumerable a

-- | <tt>enumerateFrom from</tt> generates a stream starting with the
--   element <tt>from</tt>, enumerating up to <a>maxBound</a> when the type
--   is <a>Bounded</a> or generating an infinite stream when the type is
--   not <a>Bounded</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFrom (0 :: Int)
--   [0,1,2,3]
--   </pre>
--   
--   For <a>Fractional</a> types, enumeration is numerically stable.
--   However, no overflow or underflow checks are performed.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFrom 1.1
--   [1.1,2.1,3.1,4.1]
--   </pre>
enumerateFrom :: (Enumerable a, IsStream t, Monad m) => a -> t m a

-- | Generate a finite stream starting with the element <tt>from</tt>,
--   enumerating the type up to the value <tt>to</tt>. If <tt>to</tt> is
--   smaller than <tt>from</tt> then an empty stream is returned.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 0 4
--   [0,1,2,3,4]
--   </pre>
--   
--   For <a>Fractional</a> types, the last element is equal to the
--   specified <tt>to</tt> value after rounding to the nearest integral
--   value.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 1.1 4
--   [1.1,2.1,3.1,4.1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromTo 1.1 4.6
--   [1.1,2.1,3.1,4.1,5.1]
--   </pre>
enumerateFromTo :: (Enumerable a, IsStream t, Monad m) => a -> a -> t m a

-- | <tt>enumerateFromThen from then</tt> generates a stream whose first
--   element is <tt>from</tt>, the second element is <tt>then</tt> and the
--   successive elements are in increments of <tt>then - from</tt>.
--   Enumeration can occur downwards or upwards depending on whether
--   <tt>then</tt> comes before or after <tt>from</tt>. For <a>Bounded</a>
--   types the stream ends when <a>maxBound</a> is reached, for unbounded
--   types it keeps enumerating infinitely.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThen 0 2
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.take 4 $ Stream.enumerateFromThen 0 (-2)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThen :: (Enumerable a, IsStream t, Monad m) => a -> a -> t m a

-- | <tt>enumerateFromThenTo from then to</tt> generates a finite stream
--   whose first element is <tt>from</tt>, the second element is
--   <tt>then</tt> and the successive elements are in increments of
--   <tt>then - from</tt> up to <tt>to</tt>. Enumeration can occur
--   downwards or upwards depending on whether <tt>then</tt> comes before
--   or after <tt>from</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenTo 0 2 6
--   [0,2,4,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.enumerateFromThenTo 0 (-2) (-6)
--   [0,-2,-4,-6]
--   </pre>
enumerateFromThenTo :: (Enumerable a, IsStream t, Monad m) => a -> a -> a -> t m a

-- | <pre>
--   enumerate = enumerateFrom minBound
--   </pre>
--   
--   Enumerate a <a>Bounded</a> type from its <a>minBound</a> to
--   <a>maxBound</a>
enumerate :: (IsStream t, Monad m, Bounded a, Enumerable a) => t m a

-- | <pre>
--   enumerateTo = enumerateFromTo minBound
--   </pre>
--   
--   Enumerate a <a>Bounded</a> type from its <a>minBound</a> to specified
--   value.
enumerateTo :: (IsStream t, Monad m, Bounded a, Enumerable a) => a -> t m a

-- | <pre>
--   &gt;&gt;&gt; iterate f x = x `Stream.cons` iterate f x
--   </pre>
--   
--   Generate an infinite stream with <tt>x</tt> as the first element and
--   each successive element derived by applying the function <tt>f</tt> on
--   the previous element.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 5 $ Stream.iterate (+1) 1
--   [1,2,3,4,5]
--   </pre>
iterate :: (IsStream t, Monad m) => (a -> a) -> a -> t m a

-- | <pre>
--   &gt;&gt;&gt; iterateM f m = m &gt;&gt;= \a -&gt; return a `Stream.consM` iterateM f (f a)
--   </pre>
--   
--   Generate an infinite stream with the first element generated by the
--   action <tt>m</tt> and each successive element derived by applying the
--   monadic function <tt>f</tt> on the previous element.
--   
--   <pre>
--   &gt;&gt;&gt; pr n = threadDelay 1000000 &gt;&gt; print n
--   
--   &gt;&gt;&gt; :{
--   Stream.iterateM (\x -&gt; pr x &gt;&gt; return (x + 1)) (return 0)
--       &amp; Stream.take 3
--       &amp; Stream.fromSerial
--       &amp; Stream.toList
--   :}
--   0
--   1
--   [0,1,2]
--   </pre>
--   
--   When run concurrently, the next iteration can run concurrently with
--   the processing of the previous iteration. Note that more than one
--   iteration cannot run concurrently as the next iteration depends on the
--   output of the previous iteration.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.iterateM (\x -&gt; pr x &gt;&gt; return (x + 1)) (return 0)
--       &amp; Stream.delay 1
--       &amp; Stream.take 3
--       &amp; Stream.fromAsync
--       &amp; Stream.toList
--   :}
--   0
--   1
--   ...
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.1.2</i>
--   
--   <i>Since: 0.7.0 (signature change)</i>
iterateM :: forall t m a. (IsStream t, MonadAsync m) => (a -> m a) -> m a -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromIndices f = fmap f $ Stream.enumerateFrom 0
--   
--   &gt;&gt;&gt; fromIndices f = let g i = f i `Stream.cons` g (i + 1) in g 0
--   </pre>
--   
--   Generate an infinite stream, whose values are the output of a function
--   <tt>f</tt> applied on the corresponding index. Index starts at 0.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 5 $ Stream.fromIndices id
--   [0,1,2,3,4]
--   </pre>
fromIndices :: (IsStream t, Monad m) => (Int -> a) -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromIndicesM f = Stream.mapM f $ Stream.enumerateFrom 0
--   
--   &gt;&gt;&gt; fromIndicesM f = let g i = f i `Stream.consM` g (i + 1) in g 0
--   </pre>
--   
--   Generate an infinite stream, whose values are the output of a monadic
--   function <tt>f</tt> applied on the corresponding index. Index starts
--   at 0.
--   
--   <i>Concurrent</i>
fromIndicesM :: forall t m a. (IsStream t, MonadAsync m) => (Int -> m a) -> t m a

-- | <pre>
--   fromList = <a>foldr</a> <a>cons</a> <a>nil</a>
--   </pre>
--   
--   Construct a stream from a list of pure values. This is more efficient
--   than <a>fromFoldable</a> for serial streams.
fromList :: (Monad m, IsStream t) => [a] -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromListM = Stream.fromFoldableM
--   
--   &gt;&gt;&gt; fromListM = Stream.sequence . Stream.fromList
--   
--   &gt;&gt;&gt; fromListM = Stream.mapM id . Stream.fromList
--   
--   &gt;&gt;&gt; fromListM = Prelude.foldr Stream.consM Stream.nil
--   </pre>
--   
--   Construct a stream from a list of monadic actions. This is more
--   efficient than <a>fromFoldableM</a> for serial streams.
fromListM :: (MonadAsync m, IsStream t) => [m a] -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromFoldable = Prelude.foldr Stream.cons Stream.nil
--   </pre>
--   
--   Construct a stream from a <a>Foldable</a> containing pure values:
fromFoldable :: (IsStream t, Foldable f) => f a -> t m a

-- | <pre>
--   &gt;&gt;&gt; fromFoldableM = Prelude.foldr Stream.consM Stream.nil
--   </pre>
--   
--   Construct a stream from a <a>Foldable</a> containing monadic actions.
--   
--   <pre>
--   &gt;&gt;&gt; pr n = threadDelay 1000000 &gt;&gt; print n
--   
--   &gt;&gt;&gt; Stream.drain $ Stream.fromSerial $ Stream.fromFoldableM $ map pr [1,2,3]
--   1
--   2
--   3
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.fromAsync $ Stream.fromFoldableM $ map pr [1,2,3]
--   ...
--   ...
--   ...
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   containers)</i>
fromFoldableM :: (IsStream t, MonadAsync m, Foldable f) => f (m a) -> t m a

-- | Fold a stream using the supplied left <a>Fold</a> and reducing the
--   resulting expression strictly at each step. The behavior is similar to
--   <tt>foldl'</tt>. A <a>Fold</a> can terminate early without consuming
--   the full stream. See the documentation of individual <a>Fold</a>s for
--   termination behavior.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.sum (Stream.enumerateFromTo 1 100)
--   5050
--   </pre>
--   
--   Folds never fail, therefore, they produce a default value even when no
--   input is provided. It means we can always fold an empty stream and get
--   a valid result. For example:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.fold Fold.sum Stream.nil
--   0
--   </pre>
--   
--   However, <tt>foldMany</tt> on an empty stream results in an empty
--   stream. Therefore, <tt>Stream.fold f</tt> is not the same as
--   <tt>Stream.head . Stream.foldMany f</tt>.
--   
--   <pre>
--   fold f = Stream.parse (Parser.fromFold f)
--   </pre>
fold :: Monad m => Fold m a b -> SerialT m a -> m b

-- | Decompose a stream into its head and tail. If the stream is empty,
--   returns <a>Nothing</a>. If the stream is non-empty, returns <tt>Just
--   (a, ma)</tt>, where <tt>a</tt> is the head of the stream and
--   <tt>ma</tt> its tail.
--   
--   This is a brute force primitive. Avoid using it as long as possible,
--   use it when no other combinator can do the job. This can be used to do
--   pretty much anything in an imperative manner, as it just breaks down
--   the stream into individual elements and we can loop over them as we
--   deem fit. For example, this can be used to convert a streamly stream
--   into other stream types.
--   
--   All the folds in this module can be expressed in terms of
--   <a>uncons</a>, however the specific implementations are generally more
--   efficient.
uncons :: (IsStream t, Monad m) => SerialT m a -> m (Maybe (a, t m a))

-- | <pre>
--   tail = fmap (fmap snd) . Stream.uncons
--   </pre>
--   
--   Extract all but the first element of the stream, if any.
tail :: (IsStream t, Monad m) => SerialT m a -> m (Maybe (t m a))

-- | Extract all but the last element of the stream, if any.
init :: (IsStream t, Monad m) => SerialT m a -> m (Maybe (t m a))

-- | Right associative/lazy pull fold. <tt>foldrM build final stream</tt>
--   constructs an output structure using the step function <tt>build</tt>.
--   <tt>build</tt> is invoked with the next input element and the
--   remaining (lazy) tail of the output structure. It builds a lazy output
--   expression using the two. When the "tail structure" in the output
--   expression is evaluated it calls <tt>build</tt> again thus lazily
--   consuming the input <tt>stream</tt> until either the output expression
--   built by <tt>build</tt> is free of the "tail" or the input is
--   exhausted in which case <tt>final</tt> is used as the terminating case
--   for the output structure. For more details see the description in the
--   previous section.
--   
--   Example, determine if any element is <a>odd</a> in a stream:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.foldrM (\x xs -&gt; if odd x then return True else xs) (return False) $ Stream.fromList (2:4:5:undefined)
--   True
--   </pre>
--   
--   <i>Since: 0.7.0 (signature changed)</i>
--   
--   <i>Since: 0.2.0 (signature changed)</i>
--   
--   <i>Since: 0.1.0</i>
foldrM :: Monad m => (a -> m b -> m b) -> m b -> SerialT m a -> m b

-- | Right fold, lazy for lazy monads and pure streams, and strict for
--   strict monads.
--   
--   Please avoid using this routine in strict monads like IO unless you
--   need a strict right fold. This is provided only for use in lazy monads
--   (e.g. Identity) or pure streams. Note that with this signature it is
--   not possible to implement a lazy foldr when the monad <tt>m</tt> is
--   strict. In that case it would be strict in its accumulator and
--   therefore would necessarily consume all its input.
foldr :: Monad m => (a -> b -> b) -> b -> SerialT m a -> m b

-- | Left associative/strict push fold. <tt>foldl' reduce initial
--   stream</tt> invokes <tt>reduce</tt> with the accumulator and the next
--   input in the input stream, using <tt>initial</tt> as the initial value
--   of the current value of the accumulator. When the input is exhausted
--   the current value of the accumulator is returned. Make sure to use a
--   strict data structure for accumulator to not build unnecessary lazy
--   expressions unless that's what you want. See the previous section for
--   more details.
foldl' :: Monad m => (b -> a -> b) -> b -> SerialT m a -> m b

-- | Strict left fold, for non-empty streams, using first element as the
--   starting value. Returns <a>Nothing</a> if the stream is empty.
foldl1' :: Monad m => (a -> a -> a) -> SerialT m a -> m (Maybe a)

-- | Like <a>foldl'</a> but with a monadic step function.
--   
--   <i>Since: 0.2.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
foldlM' :: Monad m => (b -> a -> m b) -> m b -> SerialT m a -> m b

-- | <pre>
--   drain = mapM_ (\_ -&gt; return ())
--   drain = Stream.fold Fold.drain
--   </pre>
--   
--   Run a stream, discarding the results. By default it interprets the
--   stream as <a>SerialT</a>, to run other types of streams use the type
--   adapting combinators for example <tt>Stream.drain .
--   <tt>fromAsync</tt></tt>.
drain :: Monad m => SerialT m a -> m ()

-- | Extract the last element of the stream, if any.
--   
--   <pre>
--   last xs = xs !! (Stream.length xs - 1)
--   last = Stream.fold Fold.last
--   </pre>
last :: Monad m => SerialT m a -> m (Maybe a)

-- | Determine the length of the stream.
length :: Monad m => SerialT m a -> m Int

-- | Determine the sum of all elements of a stream of numbers. Returns
--   <tt>0</tt> when the stream is empty. Note that this is not numerically
--   stable for floating point numbers.
--   
--   <pre>
--   sum = Stream.fold Fold.sum
--   </pre>
sum :: (Monad m, Num a) => SerialT m a -> m a

-- | Determine the product of all elements of a stream of numbers. Returns
--   <tt>1</tt> when the stream is empty.
--   
--   <pre>
--   product = Stream.fold Fold.product
--   </pre>
product :: (Monad m, Num a) => SerialT m a -> m a

-- | Determine the maximum element in a stream using the supplied
--   comparison function.
--   
--   <pre>
--   maximumBy = Stream.fold Fold.maximumBy
--   </pre>
maximumBy :: Monad m => (a -> a -> Ordering) -> SerialT m a -> m (Maybe a)

-- | <pre>
--   maximum = <a>maximumBy</a> compare
--   maximum = Stream.fold Fold.maximum
--   </pre>
--   
--   Determine the maximum element in a stream.
maximum :: (Monad m, Ord a) => SerialT m a -> m (Maybe a)

-- | Determine the minimum element in a stream using the supplied
--   comparison function.
--   
--   <pre>
--   minimumBy = Stream.fold Fold.minimumBy
--   </pre>
minimumBy :: Monad m => (a -> a -> Ordering) -> SerialT m a -> m (Maybe a)

-- | <pre>
--   minimum = <a>minimumBy</a> compare
--   minimum = Stream.fold Fold.minimum
--   </pre>
--   
--   Determine the minimum element in a stream.
minimum :: (Monad m, Ord a) => SerialT m a -> m (Maybe a)

-- | Ensures that all the elements of the stream are identical and then
--   returns that unique element.
the :: (Eq a, Monad m) => SerialT m a -> m (Maybe a)

-- | <pre>
--   drainN n = Stream.drain . Stream.take n
--   drainN n = Stream.fold (Fold.take n Fold.drain)
--   </pre>
--   
--   Run maximum up to <tt>n</tt> iterations of a stream.
drainN :: Monad m => Int -> SerialT m a -> m ()

-- | <pre>
--   drainWhile p = Stream.drain . Stream.takeWhile p
--   </pre>
--   
--   Run a stream as long as the predicate holds true.
drainWhile :: Monad m => (a -> Bool) -> SerialT m a -> m ()

-- | Lookup the element at the given index.
(!!) :: Monad m => SerialT m a -> Int -> m (Maybe a)

-- | Extract the first element of the stream, if any.
--   
--   <pre>
--   head = (!! 0)
--   head = Stream.fold Fold.head
--   </pre>
head :: Monad m => SerialT m a -> m (Maybe a)

-- | Returns the first element that satisfies the given predicate.
--   
--   <pre>
--   findM = Stream.fold Fold.findM
--   </pre>
findM :: Monad m => (a -> m Bool) -> SerialT m a -> m (Maybe a)

-- | Like <a>findM</a> but with a non-monadic predicate.
--   
--   <pre>
--   find p = findM (return . p)
--   find = Stream.fold Fold.find
--   </pre>
find :: Monad m => (a -> Bool) -> SerialT m a -> m (Maybe a)

-- | In a stream of (key-value) pairs <tt>(a, b)</tt>, return the value
--   <tt>b</tt> of the first pair where the key equals the given value
--   <tt>a</tt>.
--   
--   <pre>
--   lookup = snd &lt;$&gt; Stream.find ((==) . fst)
--   lookup = Stream.fold Fold.lookup
--   </pre>
lookup :: (Monad m, Eq a) => a -> SerialT m (a, b) -> m (Maybe b)

-- | Returns the first index that satisfies the given predicate.
--   
--   <pre>
--   findIndex = Stream.fold Fold.findIndex
--   </pre>
findIndex :: Monad m => (a -> Bool) -> SerialT m a -> m (Maybe Int)

-- | Returns the first index where a given value is found in the stream.
--   
--   <pre>
--   elemIndex a = Stream.findIndex (== a)
--   </pre>
elemIndex :: (Monad m, Eq a) => a -> SerialT m a -> m (Maybe Int)

-- | Determine whether the stream is empty.
--   
--   <pre>
--   null = Stream.fold Fold.null
--   </pre>
null :: Monad m => SerialT m a -> m Bool

-- | Determine whether an element is present in the stream.
--   
--   <pre>
--   elem = Stream.fold Fold.elem
--   </pre>
elem :: (Monad m, Eq a) => a -> SerialT m a -> m Bool

-- | Determine whether an element is not present in the stream.
--   
--   <pre>
--   notElem = Stream.fold Fold.length
--   </pre>
notElem :: (Monad m, Eq a) => a -> SerialT m a -> m Bool

-- | Determine whether all elements of a stream satisfy a predicate.
--   
--   <pre>
--   all = Stream.fold Fold.all
--   </pre>
all :: Monad m => (a -> Bool) -> SerialT m a -> m Bool

-- | Determine whether any of the elements of a stream satisfy a predicate.
--   
--   <pre>
--   any = Stream.fold Fold.any
--   </pre>
any :: Monad m => (a -> Bool) -> SerialT m a -> m Bool

-- | Determines if all elements of a boolean stream are True.
--   
--   <pre>
--   and = Stream.fold Fold.and
--   </pre>
and :: Monad m => SerialT m Bool -> m Bool

-- | Determines whether at least one element of a boolean stream is True.
--   
--   <pre>
--   or = Stream.fold Fold.or
--   </pre>
or :: Monad m => SerialT m Bool -> m Bool

-- | <pre>
--   toList = Stream.foldr (:) []
--   </pre>
--   
--   Convert a stream into a list in the underlying monad. The list can be
--   consumed lazily in a lazy monad (e.g. <tt>Identity</tt>). In a strict
--   monad (e.g. IO) the whole list is generated and buffered before it can
--   be consumed.
--   
--   <i>Warning!</i> working on large lists accumulated as buffers in
--   memory could be very inefficient, consider using <a>Streamly.Array</a>
--   instead.
toList :: Monad m => SerialT m a -> m [a]

-- | Parallel fold application operator; applies a fold function <tt>t m a
--   -&gt; m b</tt> to a stream <tt>t m a</tt> concurrently; The the input
--   stream is evaluated asynchronously in an independent thread yielding
--   elements to a buffer and the folding action runs in another thread
--   consuming the input from the buffer.
--   
--   If you read the signature as <tt>(t m a -&gt; m b) -&gt; (t m a -&gt;
--   m b)</tt> you can look at it as a transformation that converts a fold
--   function to a buffered concurrent fold function.
--   
--   The <tt>.</tt> at the end of the operator is a mnemonic for
--   termination of the stream.
--   
--   In the example below, each stage introduces a delay of 1 sec but
--   output is printed every second because both stages are concurrent.
--   
--   <pre>
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; import Streamly.Prelude ((|$.))
--   
--   &gt;&gt;&gt; :{
--    Stream.foldlM' (\_ a -&gt; threadDelay 1000000 &gt;&gt; print a) (return ())
--        |$. Stream.replicateM 3 (threadDelay 1000000 &gt;&gt; return 1)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|$.) :: (IsStream t, MonadAsync m) => (t m a -> m b) -> t m a -> m b
infixr 0 |$.

-- | Same as <a>|$.</a> but with arguments reversed.
--   
--   <pre>
--   (|&amp;.) = flip (|$.)
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|&.) :: (IsStream t, MonadAsync m) => t m a -> (t m a -> m b) -> m b
infixl 1 |&.

-- | Compare two streams for equality using an equality function.
eqBy :: (IsStream t, Monad m) => (a -> b -> Bool) -> t m a -> t m b -> m Bool

-- | Compare two streams lexicographically using a comparison function.
cmpBy :: (IsStream t, Monad m) => (a -> b -> Ordering) -> t m a -> t m b -> m Ordering

-- | Returns <a>True</a> if the first stream is the same as or a prefix of
--   the second. A stream is a prefix of itself.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.isPrefixOf (Stream.fromList "hello") (Stream.fromList "hello" :: SerialT IO Char)
--   True
--   </pre>
isPrefixOf :: (Eq a, IsStream t, Monad m) => t m a -> t m a -> m Bool

-- | Returns <a>True</a> if all the elements of the first stream occur, in
--   order, in the second stream. The elements do not have to occur
--   consecutively. A stream is a subsequence of itself.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.isSubsequenceOf (Stream.fromList "hlo") (Stream.fromList "hello" :: SerialT IO Char)
--   True
--   </pre>
isSubsequenceOf :: (Eq a, IsStream t, Monad m) => t m a -> t m a -> m Bool

-- | <tt>stripPrefix prefix stream</tt> strips <tt>prefix</tt> from
--   <tt>stream</tt> if it is a prefix of stream. Returns <a>Nothing</a> if
--   the stream does not start with the given prefix, stripped stream
--   otherwise. Returns <tt>Just nil</tt> when the prefix is the same as
--   the stream.
--   
--   See also "Streamly.Internal.Data.Stream.IsStream.Nesting.dropPrefix".
--   
--   Space: <tt>O(1)</tt>
stripPrefix :: (Eq a, IsStream t, Monad m) => t m a -> t m a -> m (Maybe (t m a))

-- | <pre>
--   map = fmap
--   </pre>
--   
--   Same as <a>fmap</a>.
--   
--   <pre>
--   &gt; S.toList $ S.map (+1) $ S.fromList [1,2,3]
--   [2,3,4]
--   </pre>
map :: (IsStream t, Monad m) => (a -> b) -> t m a -> t m b

-- | <pre>
--   sequence = mapM id
--   </pre>
--   
--   Replace the elements of a stream of monadic actions with the outputs
--   of those actions.
--   
--   <pre>
--   &gt;&gt;&gt; drain $ Stream.sequence $ Stream.fromList [putStr "a", putStr "b", putStrLn "c"]
--   abc
--   
--   &gt;&gt;&gt; :{
--   drain $ Stream.replicateM 3 (return $ threadDelay 1000000 &gt;&gt; print 1)
--    &amp; (fromSerial . Stream.sequence)
--   :}
--   1
--   1
--   1
--   
--   &gt;&gt;&gt; :{
--   drain $ Stream.replicateM 3 (return $ threadDelay 1000000 &gt;&gt; print 1)
--    &amp; (fromAsync . Stream.sequence)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   streams)</i>
sequence :: (IsStream t, MonadAsync m) => t m (m a) -> t m a

-- | <pre>
--   mapM f = sequence . map f
--   </pre>
--   
--   Apply a monadic function to each element of the stream and replace it
--   with the output of the resulting action.
--   
--   <pre>
--   &gt;&gt;&gt; drain $ Stream.mapM putStr $ Stream.fromList ["a", "b", "c"]
--   abc
--   
--   &gt;&gt;&gt; :{
--      drain $ Stream.replicateM 10 (return 1)
--        &amp; (fromSerial . Stream.mapM (x -&gt; threadDelay 1000000 &gt;&gt; print x))
--   :}
--   1
--   ...
--   1
--   
--   &gt; drain $ Stream.replicateM 10 (return 1)
--    &amp; (fromAsync . Stream.mapM (x -&gt; threadDelay 1000000 &gt;&gt; print x))
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   streams)</i>
mapM :: forall t m a b. (IsStream t, MonadAsync m) => (a -> m b) -> t m a -> t m b

-- | <pre>
--   mapM_ = Stream.drain . Stream.mapM
--   </pre>
--   
--   Apply a monadic action to each element of the stream and discard the
--   output of the action. This is not really a pure transformation
--   operation but a transformation followed by fold.
mapM_ :: Monad m => (a -> m b) -> SerialT m a -> m ()

-- | Apply a monadic function to each element flowing through the stream
--   and discard the results.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.trace print (Stream.enumerateFromTo 1 2)
--   1
--   2
--   </pre>
--   
--   Compare with <a>tap</a>.
trace :: (IsStream t, MonadAsync m) => (a -> m b) -> t m a -> t m a

-- | Tap the data flowing through a stream into a <a>Fold</a>. For example,
--   you may add a tap to log the contents flowing through the stream. The
--   fold is used only for effects, its result is discarded.
--   
--   <pre>
--                     Fold m a b
--                         |
--   -----stream m a ---------------stream m a-----
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.drain $ Stream.tap (Fold.drainBy print) (Stream.enumerateFromTo 1 2)
--   1
--   2
--   </pre>
--   
--   Compare with <a>trace</a>.
tap :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m a

-- | Introduce a delay of specified seconds before consuming an element of
--   the stream except the first one.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.mapM_ print $ Stream.timestamped $ Stream.delay 1 $ Stream.enumerateFromTo 1 3
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),1)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),2)
--   (AbsTime (TimeSpec {sec = ..., nsec = ...}),3)
--   </pre>
delay :: (IsStream t, MonadIO m) => Double -> t m a -> t m a

-- | Strict left scan. Like <a>map</a>, <a>scanl'</a> too is a one to one
--   transformation, however it adds an extra element.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.scanl' (+) 0 $ fromList [1,2,3,4]
--   [0,1,3,6,10]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.scanl' (flip (:)) [] $ Stream.fromList [1,2,3,4]
--   [[],[1],[2,1],[3,2,1],[4,3,2,1]]
--   </pre>
--   
--   The output of <a>scanl'</a> is the initial value of the accumulator
--   followed by all the intermediate steps and the final result of
--   <tt>foldl'</tt>.
--   
--   By streaming the accumulated state after each fold step, we can share
--   the state across multiple stages of stream composition. Each stage can
--   modify or extend the state, do some processing with it and emit it for
--   the next stage, thus modularizing the stream processing. This can be
--   useful in stateful or event-driven programming.
--   
--   Consider the following monolithic example, computing the sum and the
--   product of the elements in a stream in one go using a <tt>foldl'</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.foldl' ((s, p) x -&gt; (s + x, p * x)) (0,1) $ Stream.fromList <a>1,2,3,4</a>
--   </pre>
--   
--   Using <tt>scanl'</tt> we can make it modular by computing the sum in
--   the first stage and passing it down to the next stage for computing
--   the product:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--     Stream.foldl' ((_, p) (s, x) -&gt; (s, p * x)) (0,1)
--     $ Stream.scanl' ((s, _) x -&gt; (s + x, x)) (0,1)
--     $ Stream.fromList [1,2,3,4]
--   :}
--   (10,24)
--   </pre>
--   
--   IMPORTANT: <a>scanl'</a> evaluates the accumulator to WHNF. To avoid
--   building lazy expressions inside the accumulator, it is recommended
--   that a strict data structure is used for accumulator.
--   
--   <pre>
--   &gt;&gt;&gt; scanl' f z xs = scanlM' (\a b -&gt; return (f a b)) (return z) xs
--   
--   &gt;&gt;&gt; scanl' f z xs = z `Stream.cons` postscanl' f z xs
--   </pre>
--   
--   See also: <tt>usingStateT</tt>
scanl' :: (IsStream t, Monad m) => (b -> a -> b) -> b -> t m a -> t m b

-- | Like <a>scanl'</a> but with a monadic step function and a monadic
--   seed.
--   
--   <i>Since: 0.4.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
scanlM' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> t m a -> t m b

-- | Like <a>scanl'</a> but does not stream the initial value of the
--   accumulator.
--   
--   <pre>
--   &gt;&gt;&gt; postscanl' f z = postscanlM' (\a b -&gt; return (f a b)) (return z)
--   
--   &gt;&gt;&gt; postscanl' f z xs = Stream.drop 1 $ Stream.scanl' f z xs
--   </pre>
postscanl' :: (IsStream t, Monad m) => (b -> a -> b) -> b -> t m a -> t m b

-- | Like <tt>postscanl'</tt> but with a monadic step function and a
--   monadic seed.
--   
--   <pre>
--   &gt;&gt;&gt; postscanlM' f z xs = Stream.drop 1 $ Stream.scanlM' f z xs
--   </pre>
--   
--   <i>Since: 0.7.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
postscanlM' :: (IsStream t, Monad m) => (b -> a -> m b) -> m b -> t m a -> t m b

-- | Like <a>scanl'</a> but for a non-empty stream. The first element of
--   the stream is used as the initial value of the accumulator. Does
--   nothing if the stream is empty.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.scanl1' (+) $ fromList [1,2,3,4]
--   [1,3,6,10]
--   </pre>
scanl1' :: (IsStream t, Monad m) => (a -> a -> a) -> t m a -> t m a

-- | Like <a>scanl1'</a> but with a monadic step function.
scanl1M' :: (IsStream t, Monad m) => (a -> a -> m a) -> t m a -> t m a

-- | Scan a stream using the given monadic fold.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.takeWhile (&lt; 10) $ Stream.scan Fold.sum (Stream.fromList [1..10])
--   [0,1,3,6]
--   </pre>
scan :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m b

-- | Postscan a stream using the given monadic fold.
--   
--   The following example extracts the input stream up to a point where
--   the running average of elements is no more than 10:
--   
--   <pre>
--   &gt;&gt;&gt; import Data.Maybe (fromJust)
--   
--   &gt;&gt;&gt; let avg = Fold.teeWith (/) Fold.sum (fmap fromIntegral Fold.length)
--   
--   &gt;&gt;&gt; :{
--    Stream.toList
--     $ Stream.map (fromJust . fst)
--     $ Stream.takeWhile (\(_,x) -&gt; x &lt;= 10)
--     $ Stream.postscan (Fold.tee Fold.last avg) (Stream.enumerateFromTo 1.0 100.0)
--   :}
--   [1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0]
--   </pre>
postscan :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m b

-- | Deletes the first occurrence of the element in the stream that
--   satisfies the given equality predicate.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.deleteBy (==) 3 $ Stream.fromList [1,3,3,5]
--   [1,3,5]
--   </pre>
deleteBy :: (IsStream t, Monad m) => (a -> a -> Bool) -> a -> t m a -> t m a

-- | Include only those elements that pass a predicate.
filter :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m a

-- | Same as <a>filter</a> but with a monadic predicate.
filterM :: (IsStream t, Monad m) => (a -> m Bool) -> t m a -> t m a

-- | Drop repeated elements that are adjacent to each other.
uniq :: (Eq a, IsStream t, Monad m) => t m a -> t m a

-- | Take first <tt>n</tt> elements from the stream and discard the rest.
take :: (IsStream t, Monad m) => Int -> t m a -> t m a

-- | End the stream as soon as the predicate fails on an element.
takeWhile :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m a

-- | Same as <a>takeWhile</a> but with a monadic predicate.
takeWhileM :: (IsStream t, Monad m) => (a -> m Bool) -> t m a -> t m a

-- | Discard first <tt>n</tt> elements from the stream and take the rest.
drop :: (IsStream t, Monad m) => Int -> t m a -> t m a

-- | Drop elements in the stream as long as the predicate succeeds and then
--   take the rest of the stream.
dropWhile :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m a

-- | Same as <a>dropWhile</a> but with a monadic predicate.
dropWhileM :: (IsStream t, Monad m) => (a -> m Bool) -> t m a -> t m a

-- | <tt>insertBy cmp elem stream</tt> inserts <tt>elem</tt> before the
--   first element in <tt>stream</tt> that is less than <tt>elem</tt> when
--   compared using <tt>cmp</tt>.
--   
--   <pre>
--   insertBy cmp x = <tt>mergeBy</tt> cmp (<tt>fromPure</tt> x)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.insertBy compare 2 $ Stream.fromList [1,3,5]
--   [1,2,3,5]
--   </pre>
insertBy :: (IsStream t, Monad m) => (a -> a -> Ordering) -> a -> t m a -> t m a

-- | Insert an effect and its output before consuming an element of a
--   stream except the first one.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.trace putChar $ Stream.intersperseM (putChar '.' &gt;&gt; return ',') $ Stream.fromList "hello"
--   h.,e.,l.,l.,o"h,e,l,l,o"
--   </pre>
intersperseM :: (IsStream t, MonadAsync m) => m a -> t m a -> t m a

-- | Insert a pure value between successive elements of a stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intersperse ',' $ Stream.fromList "hello"
--   "h,e,l,l,o"
--   </pre>
intersperse :: (IsStream t, MonadAsync m) => a -> t m a -> t m a

-- | Returns the elements of the stream in reverse order. The stream must
--   be finite. Note that this necessarily buffers the entire stream in
--   memory.
--   
--   <pre>
--   &gt;&gt;&gt; reverse = Stream.foldlT (flip Stream.cons) Stream.nil
--   </pre>
--   
--   <i>Since 0.7.0 (Monad m constraint)</i>
--   
--   <i>Since: 0.1.1</i>
reverse :: (IsStream t, Monad m) => t m a -> t m a

-- | <pre>
--   indexed = Stream.postscanl' (\(i, _) x -&gt; (i + 1, x)) (-1,undefined)
--   indexed = Stream.zipWith (,) (Stream.enumerateFrom 0)
--   </pre>
--   
--   Pair each element in a stream with its index, starting from index 0.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.indexed $ Stream.fromList "hello"
--   [(0,'h'),(1,'e'),(2,'l'),(3,'l'),(4,'o')]
--   </pre>
indexed :: (IsStream t, Monad m) => t m a -> t m (Int, a)

-- | <pre>
--   indexedR n = Stream.postscanl' (\(i, _) x -&gt; (i - 1, x)) (n + 1,undefined)
--   indexedR n = Stream.zipWith (,) (Stream.enumerateFromThen n (n - 1))
--   </pre>
--   
--   Pair each element in a stream with its index, starting from the given
--   index <tt>n</tt> and counting down.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.indexedR 10 $ Stream.fromList "hello"
--   [(10,'h'),(9,'e'),(8,'l'),(7,'l'),(6,'o')]
--   </pre>
indexedR :: (IsStream t, Monad m) => Int -> t m a -> t m (Int, a)

-- | Find all the indices where the element in the stream satisfies the
--   given predicate.
--   
--   <pre>
--   findIndices = fold Fold.findIndices
--   </pre>
findIndices :: (IsStream t, Monad m) => (a -> Bool) -> t m a -> t m Int

-- | Find all the indices where the value of the element in the stream is
--   equal to the given value.
--   
--   <pre>
--   elemIndices a = findIndices (== a)
--   </pre>
elemIndices :: (IsStream t, Eq a, Monad m) => a -> t m a -> t m Int

-- | Map a <a>Maybe</a> returning function to a stream, filter out the
--   <a>Nothing</a> elements, and return a stream of values extracted from
--   <a>Just</a>.
--   
--   Equivalent to:
--   
--   <pre>
--   mapMaybe f = Stream.map <a>fromJust</a> . Stream.filter <a>isJust</a> . Stream.map f
--   </pre>
mapMaybe :: (IsStream t, Monad m) => (a -> Maybe b) -> t m a -> t m b

-- | Like <a>mapMaybe</a> but maps a monadic function.
--   
--   Equivalent to:
--   
--   <pre>
--   mapMaybeM f = Stream.map <a>fromJust</a> . Stream.filter <a>isJust</a> . Stream.mapM f
--   </pre>
--   
--   <i>Concurrent (do not use with <tt>fromParallel</tt> on infinite
--   streams)</i>
mapMaybeM :: (IsStream t, MonadAsync m, Functor (t m)) => (a -> m (Maybe b)) -> t m a -> t m b

-- | Parallel transform application operator; applies a stream
--   transformation function <tt>t m a -&gt; t m b</tt> to a stream <tt>t m
--   a</tt> concurrently; the input stream is evaluated asynchronously in
--   an independent thread yielding elements to a buffer and the
--   transformation function runs in another thread consuming the input
--   from the buffer. <a>|$</a> is just like regular function application
--   operator <a>$</a> except that it is concurrent.
--   
--   If you read the signature as <tt>(t m a -&gt; t m b) -&gt; (t m a
--   -&gt; t m b)</tt> you can look at it as a transformation that converts
--   a transform function to a buffered concurrent transform function.
--   
--   The following code prints a value every second even though each stage
--   adds a 1 second delay.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.drain $
--      Stream.mapM (\x -&gt; threadDelay 1000000 &gt;&gt; print x)
--        |$ Stream.replicateM 3 (threadDelay 1000000 &gt;&gt; return 1)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|$) :: (IsStream t, MonadAsync m) => (t m a -> t m b) -> t m a -> t m b
infixr 0 |$

-- | Same as <a>|$</a> but with arguments reversed.
--   
--   (|&amp;) = flip (|$)
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|&) :: (IsStream t, MonadAsync m) => t m a -> (t m a -> t m b) -> t m b
infixl 1 |&

-- | Make the stream producer and consumer run concurrently by introducing
--   a buffer between them. The producer thread evaluates the input stream
--   until the buffer fills, it terminates if the buffer is full and a
--   worker thread is kicked off again to evaluate the remaining stream
--   when there is space in the buffer. The consumer consumes the stream
--   lazily from the buffer.
--   
--   <i>Since: 0.2.0 (Streamly)</i>
mkAsync :: (IsStream t, MonadAsync m) => t m a -> t m a

-- | Specify the maximum number of threads that can be spawned concurrently
--   for any concurrent combinator in a stream. A value of 0 resets the
--   thread limit to default, a negative value means there is no limit. The
--   default value is 1500. <a>maxThreads</a> does not affect
--   <tt>ParallelT</tt> streams as they can use unbounded number of
--   threads.
--   
--   When the actions in a stream are IO bound, having blocking IO calls,
--   this option can be used to control the maximum number of in-flight IO
--   requests. When the actions are CPU bound this option can be used to
--   control the amount of CPU used by the stream.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxThreads :: IsStream t => Int -> t m a -> t m a

-- | Specify the maximum size of the buffer for storing the results from
--   concurrent computations. If the buffer becomes full we stop spawning
--   more concurrent tasks until there is space in the buffer. A value of 0
--   resets the buffer size to default, a negative value means there is no
--   limit. The default value is 1500.
--   
--   CAUTION! using an unbounded <a>maxBuffer</a> value (i.e. a negative
--   value) coupled with an unbounded <a>maxThreads</a> value is a recipe
--   for disaster in presence of infinite streams, or very large streams.
--   Especially, it must not be used when <a>pure</a> is used in
--   <tt>ZipAsyncM</tt> streams as <a>pure</a> in applicative zip streams
--   generates an infinite stream causing unbounded concurrent generation
--   with no limit on the buffer or threads.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxBuffer :: IsStream t => Int -> t m a -> t m a

-- | Specifies the stream yield rate in yields per second (<tt>Hertz</tt>).
--   We keep accumulating yield credits at <a>rateGoal</a>. At any point of
--   time we allow only as many yields as we have accumulated as per
--   <a>rateGoal</a> since the start of time. If the consumer or the
--   producer is slower or faster, the actual rate may fall behind or
--   exceed <a>rateGoal</a>. We try to recover the gap between the two by
--   increasing or decreasing the pull rate from the producer. However, if
--   the gap becomes more than <a>rateBuffer</a> we try to recover only as
--   much as <a>rateBuffer</a>.
--   
--   <a>rateLow</a> puts a bound on how low the instantaneous rate can go
--   when recovering the rate gap. In other words, it determines the
--   maximum yield latency. Similarly, <a>rateHigh</a> puts a bound on how
--   high the instantaneous rate can go when recovering the rate gap. In
--   other words, it determines the minimum yield latency. We reduce the
--   latency by increasing concurrency, therefore we can say that it puts
--   an upper bound on concurrency.
--   
--   If the <a>rateGoal</a> is 0 or negative the stream never yields a
--   value. If the <a>rateBuffer</a> is 0 or negative we do not attempt to
--   recover.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
data Rate
Rate :: Double -> Double -> Double -> Int -> Rate

-- | The lower rate limit
[rateLow] :: Rate -> Double

-- | The target rate we want to achieve
[rateGoal] :: Rate -> Double

-- | The upper rate limit
[rateHigh] :: Rate -> Double

-- | Maximum slack from the goal
[rateBuffer] :: Rate -> Int

-- | Specify the pull rate of a stream. A <a>Nothing</a> value resets the
--   rate to default which is unlimited. When the rate is specified,
--   concurrent production may be ramped up or down automatically to
--   achieve the specified yield rate. The specific behavior for different
--   styles of <a>Rate</a> specifications is documented under <a>Rate</a>.
--   The effective maximum production rate achieved by a stream is governed
--   by:
--   
--   <ul>
--   <li>The <a>maxThreads</a> limit</li>
--   <li>The <a>maxBuffer</a> limit</li>
--   <li>The maximum rate that the stream producer can achieve</li>
--   <li>The maximum rate that the stream consumer can achieve</li>
--   </ul>
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
rate :: IsStream t => Maybe Rate -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r (2*r) maxBound)</tt>
--   
--   Specifies the average production rate of a stream in number of yields
--   per second (i.e. <tt>Hertz</tt>). Concurrent production is ramped up
--   or down automatically to achieve the specified average yield rate. The
--   rate can go down to half of the specified rate on the lower side and
--   double of the specified rate on the higher side.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
avgRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r (2*r) maxBound)</tt>
--   
--   Specifies the minimum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go below the
--   specified rate, even though it may possibly go above it at times, the
--   upper limit is double of the specified rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
minRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r r maxBound)</tt>
--   
--   Specifies the maximum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go above the
--   specified rate, even though it may possibly go below it at times, the
--   lower limit is half of the specified rate. This can be useful in
--   applications where certain resource usage must not be allowed to go
--   beyond certain limits.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
maxRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r r 0)</tt>
--   
--   Specifies a constant yield rate. If for some reason the actual rate
--   goes above or below the specified rate we do not try to recover it by
--   increasing or decreasing the rate in future. This can be useful in
--   applications like graphics frame refresh where we need to maintain a
--   constant refresh rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
constRate :: IsStream t => Double -> t m a -> t m a

-- | Appends two streams sequentially, yielding all elements from the first
--   stream, and then all elements from the second stream.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (serial)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [3,4]
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `serial` stream2
--   [1,2,3,4]
--   </pre>
--   
--   This operation can be used to fold an infinite lazy container of
--   streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
serial :: IsStream t => t m a -> t m a -> t m a
infixr 6 `serial`

-- | Interleaves two streams, yielding one element from each stream
--   alternately. When one stream stops the rest of the other stream is
--   used in the output stream.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [3,4]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWSerial $ stream1 `wSerial` stream2
--   [1,3,2,4]
--   </pre>
--   
--   Note, for singleton streams <a>wSerial</a> and <a>serial</a> are
--   identical.
--   
--   Note that this operation cannot be used to fold a container of
--   infinite streams but it can be used for very large streams as the
--   state that it needs to maintain is proportional to the logarithm of
--   the number of streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
wSerial :: IsStream t => t m a -> t m a -> t m a
infixr 6 `wSerial`

-- | Appends two streams, both the streams may be evaluated concurrently
--   but the outputs are used in the same order as the corresponding
--   actions in the original streams, side effects will happen in the order
--   in which the streams are evaluated:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (ahead, SerialT)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromEffect (delay 4) :: SerialT IO Int
--   
--   &gt;&gt;&gt; stream2 = Stream.fromEffect (delay 2) :: SerialT IO Int
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `ahead` stream2 :: IO [Int]
--   2 sec
--   4 sec
--   [4,2]
--   </pre>
--   
--   Multiple streams can be combined. With enough threads, all of them can
--   be scheduled simultaneously:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `ahead` stream2 `ahead` stream3
--   1 sec
--   2 sec
--   4 sec
--   [4,2,1]
--   </pre>
--   
--   With 2 threads, only two can be scheduled at a time, when one of those
--   finishes, the third one gets scheduled:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 2 $ stream1 `ahead` stream2 `ahead` stream3
--   2 sec
--   1 sec
--   4 sec
--   [4,2,1]
--   </pre>
--   
--   Only streams are scheduled for ahead evaluation, how actions within a
--   stream are evaluated depends on the stream type. If it is a concurrent
--   stream they will be evaluated concurrently. It may not make much sense
--   combining serial streams using <a>ahead</a>.
--   
--   <a>ahead</a> can be safely used to fold an infinite lazy container of
--   streams.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
ahead :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `ahead`

-- | Merges two streams, both the streams may be evaluated concurrently,
--   outputs from both are used as they arrive:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (async)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromEffect (delay 4)
--   
--   &gt;&gt;&gt; stream2 = Stream.fromEffect (delay 2)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2
--   2 sec
--   4 sec
--   [2,4]
--   </pre>
--   
--   Multiple streams can be combined. With enough threads, all of them can
--   be scheduled simultaneously:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2 `async` stream3
--   ...
--   [1,2,4]
--   </pre>
--   
--   With 2 threads, only two can be scheduled at a time, when one of those
--   finishes, the third one gets scheduled:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3
--   ...
--   [2,1,4]
--   </pre>
--   
--   With a single thread, it becomes serial:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 1 $ stream1 `async` stream2 `async` stream3
--   ...
--   [4,2,1]
--   </pre>
--   
--   Only streams are scheduled for async evaluation, how actions within a
--   stream are evaluated depends on the stream type. If it is a concurrent
--   stream they will be evaluated concurrently.
--   
--   In the following example, both the streams are scheduled for
--   concurrent evaluation but each individual stream is evaluated
--   serially:
--   
--   <pre>
--   &gt;&gt;&gt; stream1 = Stream.fromListM $ Prelude.map delay [3,3] -- SerialT IO Int
--   
--   &gt;&gt;&gt; stream2 = Stream.fromListM $ Prelude.map delay [1,1] -- SerialT IO Int
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2 -- IO [Int]
--   ...
--   [1,1,3,3]
--   </pre>
--   
--   If total threads are 2, the third stream is scheduled only after one
--   of the first two has finished:
--   
--   <pre>
--   stream3 = Stream.fromListM $ Prelude.map delay [2,2] -- SerialT IO Int
--   Stream.toList $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3 -- IO [Int]
--   </pre>
--   
--   ... [1,1,3,2,3,2]
--   
--   Thus <a>async</a> goes deep in first few streams rather than going
--   wide in all streams. It prefers to evaluate the leftmost streams as
--   much as possible. Because of this behavior, <a>async</a> can be safely
--   used to fold an infinite lazy container of streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
async :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `async`

-- | For singleton streams, <a>wAsync</a> is the same as <a>async</a>. See
--   <a>async</a> for singleton stream behavior. For multi-element streams,
--   while <a>async</a> is left biased i.e. it tries to evaluate the left
--   side stream as much as possible, <a>wAsync</a> tries to schedule them
--   both fairly. In other words, <a>async</a> goes deep while
--   <a>wAsync</a> goes wide. However, outputs are always used as they
--   arrive.
--   
--   With a single thread, <a>async</a> starts behaving like <a>serial</a>
--   while <a>wAsync</a> starts behaving like <a>wSerial</a>.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (async, wAsync)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2,3]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [4,5,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAsync $ Stream.maxThreads 1 $ stream1 `async` stream2
--   [1,2,3,4,5,6]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWAsync $ Stream.maxThreads 1 $ stream1 `wAsync` stream2
--   [1,4,2,5,3,6]
--   </pre>
--   
--   With two threads available, and combining three streams:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromList [7,8,9]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAsync $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3
--   [1,2,3,4,5,6,7,8,9]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWAsync $ Stream.maxThreads 2 $ stream1 `wAsync` stream2 `wAsync` stream3
--   [1,4,2,7,5,3,8,6,9]
--   </pre>
--   
--   This operation cannot be used to fold an infinite lazy container of
--   streams, because it schedules all the streams in a round robin manner.
--   
--   Note that <tt>WSerialT</tt> and single threaded <tt>WAsyncT</tt> both
--   interleave streams but the exact scheduling is slightly different in
--   both cases.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
wAsync :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `wAsync`

-- | Like <a>async</a> except that the execution is much more strict. There
--   is no limit on the number of threads. While <a>async</a> may not
--   schedule a stream if there is no demand from the consumer,
--   <a>parallel</a> always evaluates both the streams immediately. The
--   only limit that applies to <a>parallel</a> is <a>maxBuffer</a>.
--   Evaluation may block if the output buffer becomes full.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (parallel)
--   
--   &gt;&gt;&gt; stream = Stream.fromEffect (delay 2) `parallel` Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList stream -- IO [Int]
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   <a>parallel</a> guarantees that all the streams are scheduled for
--   execution immediately, therefore, we could use things like starting
--   timers inside the streams and relying on the fact that all timers were
--   started at the same time.
--   
--   Unlike <a>async</a> this operation cannot be used to fold an infinite
--   lazy container of streams, because it schedules all the streams
--   strictly concurrently.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
parallel :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `parallel`

-- | Merge two streams using a comparison function. The head elements of
--   both the streams are compared and the smaller of the two elements is
--   emitted, if both elements are equal then the element from the first
--   stream is used first.
--   
--   If the streams are sorted in ascending order, the resulting stream
--   would also remain sorted in ascending order.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.mergeBy compare (Stream.fromList [1,3,5]) (Stream.fromList [2,4,6,8])
--   [1,2,3,4,5,6,8]
--   </pre>
--   
--   See also: <a>mergeByMFused</a>
mergeBy :: (IsStream t, Monad m) => (a -> a -> Ordering) -> t m a -> t m a -> t m a

-- | Like <a>mergeBy</a> but with a monadic comparison function.
--   
--   Merge two streams randomly:
--   
--   <pre>
--   &gt; randomly _ _ = randomIO &gt;&gt;= x -&gt; return $ if x then LT else GT
--   &gt; Stream.toList $ Stream.mergeByM randomly (Stream.fromList [1,1,1,1]) (Stream.fromList [2,2,2,2])
--   [2,1,2,2,2,1,1,1]
--   </pre>
--   
--   Merge two streams in a proportion of 2:1:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   do
--    let proportionately m n = do
--         ref &lt;- newIORef $ cycle $ Prelude.concat [Prelude.replicate m LT, Prelude.replicate n GT]
--         return $ _ _ -&gt; do
--            r &lt;- readIORef ref
--            writeIORef ref $ Prelude.tail r
--            return $ Prelude.head r
--    f &lt;- proportionately 2 1
--    xs &lt;- Stream.toList $ Stream.mergeByM f (Stream.fromList [1,1,1,1,1,1]) (Stream.fromList [2,2,2])
--    print xs
--   :}
--   [1,1,2,1,1,2,1,1,2]
--   </pre>
--   
--   See also: <a>mergeByMFused</a>
mergeByM :: (IsStream t, Monad m) => (a -> a -> m Ordering) -> t m a -> t m a -> t m a

-- | Like <a>mergeBy</a> but merges concurrently (i.e. both the elements
--   being merged are generated concurrently).
mergeAsyncBy :: (IsStream t, MonadAsync m) => (a -> a -> Ordering) -> t m a -> t m a -> t m a

-- | Like <a>mergeByM</a> but merges concurrently (i.e. both the elements
--   being merged are generated concurrently).
mergeAsyncByM :: (IsStream t, MonadAsync m) => (a -> a -> m Ordering) -> t m a -> t m a -> t m a

-- | Stream <tt>a</tt> is evaluated first, followed by stream <tt>b</tt>,
--   the resulting elements <tt>a</tt> and <tt>b</tt> are then zipped using
--   the supplied zip function and the result <tt>c</tt> is yielded to the
--   consumer.
--   
--   If stream <tt>a</tt> or stream <tt>b</tt> ends, the zipped stream
--   ends. If stream <tt>b</tt> ends first, the element <tt>a</tt> from
--   previous evaluation of stream <tt>a</tt> is discarded.
--   
--   <pre>
--   &gt; S.toList $ S.zipWith (+) (S.fromList [1,2,3]) (S.fromList [4,5,6])
--   [5,7,9]
--   </pre>
zipWith :: (IsStream t, Monad m) => (a -> b -> c) -> t m a -> t m b -> t m c

-- | Like <a>zipWith</a> but using a monadic zipping function.
zipWithM :: (IsStream t, Monad m) => (a -> b -> m c) -> t m a -> t m b -> t m c

-- | Like <a>zipWith</a> but zips concurrently i.e. both the streams being
--   zipped are evaluated concurrently using the <tt>ParallelT</tt>
--   concurrent evaluation style. The maximum number of elements of each
--   stream evaluated in advance can be controlled by <tt>maxBuffer</tt>.
--   
--   The stream ends if stream <tt>a</tt> or stream <tt>b</tt> ends.
--   However, if stream <tt>b</tt> ends while we are still evaluating
--   stream <tt>a</tt> and waiting for a result then stream will not end
--   until after the evaluation of stream <tt>a</tt> finishes. This
--   behavior can potentially be changed in future to end the stream
--   immediately as soon as any of the stream end is detected.
zipAsyncWith :: (IsStream t, MonadAsync m) => (a -> b -> c) -> t m a -> t m b -> t m c

-- | Like <a>zipAsyncWith</a> but with a monadic zipping function.
zipAsyncWithM :: (IsStream t, MonadAsync m) => (a -> b -> m c) -> t m a -> t m b -> t m c

-- | Like <a>concatMap</a> but uses an <a>Unfold</a> for stream generation.
--   Unlike <a>concatMap</a> this can fuse the <a>Unfold</a> code with the
--   inner loop and therefore provide many times better performance.
unfoldMany :: (IsStream t, Monad m) => Unfold m a b -> t m a -> t m b

-- | <tt>intersperse</tt> followed by unfold and concat.
--   
--   <pre>
--   intercalate unf a str = unfoldMany unf $ intersperse a str
--   intersperse = intercalate (Unfold.function id)
--   unwords = intercalate Unfold.fromList " "
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intercalate Unfold.fromList " " $ Stream.fromList ["abc", "def", "ghi"]
--   "abc def ghi"
--   </pre>
intercalate :: (IsStream t, Monad m) => Unfold m b c -> b -> t m b -> t m c

-- | <tt>intersperseSuffix</tt> followed by unfold and concat.
--   
--   <pre>
--   intercalateSuffix unf a str = unfoldMany unf $ intersperseSuffix a str
--   intersperseSuffix = intercalateSuffix (Unfold.function id)
--   unlines = intercalateSuffix Unfold.fromList "\n"
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.intercalateSuffix Unfold.fromList "\n" $ Stream.fromList ["abc", "def", "ghi"]
--   "abc\ndef\nghi\n"
--   </pre>
intercalateSuffix :: (IsStream t, Monad m) => Unfold m b c -> b -> t m b -> t m c

-- | <tt>concatMapWith mixer generator stream</tt> is a two dimensional
--   looping combinator. The <tt>generator</tt> function is used to
--   generate streams from the elements in the input <tt>stream</tt> and
--   the <tt>mixer</tt> function is used to merge those streams.
--   
--   Note we can merge streams concurrently by using a concurrent merge
--   function.
--   
--   <i>Since: 0.7.0</i>
--   
--   <i>Since: 0.8.0 (signature change)</i>
concatMapWith :: IsStream t => (t m b -> t m b -> t m b) -> (a -> t m b) -> t m a -> t m b

-- | Map a stream producing function on each element of the stream and then
--   flatten the results into a single stream.
--   
--   <pre>
--   &gt;&gt;&gt; concatMap f = Stream.concatMapM (return . f)
--   
--   &gt;&gt;&gt; concatMap f = Stream.concatMapWith Stream.serial f
--   
--   &gt;&gt;&gt; concatMap f = Stream.concat . Stream.map f
--   
--   &gt;&gt;&gt; concatMap f = Stream.unfoldMany (Unfold.lmap f Unfold.fromStream)
--   </pre>
concatMap :: (IsStream t, Monad m) => (a -> t m b) -> t m a -> t m b

-- | Map a stream producing monadic function on each element of the stream
--   and then flatten the results into a single stream. Since the stream
--   generation function is monadic, unlike <a>concatMap</a>, it can
--   produce an effect at the beginning of each iteration of the inner
--   loop.
concatMapM :: (IsStream t, Monad m) => (a -> m (t m b)) -> t m a -> t m b

-- | A variant of <a>fold</a> that allows you to fold a <a>Foldable</a>
--   container of streams using the specified stream sum operation.
--   
--   <pre>
--   concatFoldableWith <tt>async</tt> $ map return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatFoldableWith f = Prelude.foldr f S.nil
--   concatFoldableWith f = S.concatMapFoldableWith f id
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldWith to concatFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatFoldableWith :: (IsStream t, Foldable f) => (t m a -> t m a -> t m a) -> f (t m a) -> t m a

-- | A variant of <a>foldMap</a> that allows you to map a monadic streaming
--   action on a <a>Foldable</a> container and then fold it using the
--   specified stream merge operation.
--   
--   <pre>
--   concatMapFoldableWith <tt>async</tt> return [1..3]
--   </pre>
--   
--   Equivalent to:
--   
--   <pre>
--   concatMapFoldableWith f g = Prelude.foldr (f . g) S.nil
--   concatMapFoldableWith f g xs = S.concatMapWith f g (S.fromFoldable xs)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed foldMapWith to concatMapFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatMapFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> (a -> t m b) -> f a -> t m b

-- | Like <a>concatMapFoldableWith</a> but with the last two arguments
--   reversed i.e. the monadic streaming function is the last argument.
--   
--   Equivalent to:
--   
--   <pre>
--   concatForFoldableWith f xs g = Prelude.foldr (f . g) S.nil xs
--   concatForFoldableWith f = flip (S.concatMapFoldableWith f)
--   </pre>
--   
--   <i>Since: 0.8.0 (Renamed forEachWith to concatForFoldableWith)</i>
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
concatForFoldableWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> f a -> (a -> t m b) -> t m b

-- | Apply a <a>Fold</a> repeatedly on a stream and emit the fold outputs
--   in the output stream.
--   
--   To sum every two contiguous elements in a stream:
--   
--   <pre>
--   &gt;&gt;&gt; f = Fold.take 2 Fold.sum
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany f $ Stream.fromList [1..10]
--   [3,7,11,15,19]
--   </pre>
--   
--   On an empty stream the output is empty:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.foldMany f $ Stream.fromList []
--   []
--   </pre>
--   
--   Note <tt>Stream.foldMany (Fold.take 0)</tt> would result in an
--   infinite loop in a non-empty stream.
foldMany :: (IsStream t, Monad m) => Fold m a b -> t m a -> t m b

-- | Group the input stream into groups of <tt>n</tt> elements each and
--   then fold each group using the provided fold function.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.chunksOf 2 Fold.sum (Stream.enumerateFromTo 1 10)
--   [3,7,11,15,19]
--   </pre>
--   
--   This can be considered as an n-fold version of <a>take</a> where we
--   apply <a>take</a> repeatedly on the leftover stream until the stream
--   exhausts.
--   
--   <pre>
--   chunksOf n f = foldMany (FL.take n f)
--   </pre>
chunksOf :: (IsStream t, Monad m) => Int -> Fold m a b -> t m a -> t m b

-- | Group the input stream into windows of <tt>n</tt> second each and then
--   fold each group using the provided fold function.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.take 5 $ Stream.intervalsOf 1 Fold.sum $ Stream.constRate 2 $ Stream.enumerateFrom 1
--   [...,...,...,...,...]
--   </pre>
intervalsOf :: (IsStream t, MonadAsync m) => Double -> Fold m a b -> t m a -> t m b

-- | Split on an infixed separator element, dropping the separator. The
--   supplied <a>Fold</a> is applied on the split segments. Splits the
--   stream on separator elements determined by the supplied predicate,
--   separator is considered as infixed between two segments:
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' p xs = Stream.toList $ Stream.splitOn p Fold.toList (Stream.fromList xs)
--   
--   &gt;&gt;&gt; splitOn' (== '.') "a.b"
--   ["a","b"]
--   </pre>
--   
--   An empty stream is folded to the default value of the fold:
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') ""
--   [""]
--   </pre>
--   
--   If one or both sides of the separator are missing then the empty
--   segment on that side is folded to the default output of the fold:
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') "."
--   ["",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') ".a"
--   ["","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') "a."
--   ["a",""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOn' (== '.') "a..b"
--   ["a","","b"]
--   </pre>
--   
--   splitOn is an inverse of intercalating single element:
--   
--   <pre>
--   Stream.intercalate (Stream.fromPure '.') Unfold.fromList . Stream.splitOn (== '.') Fold.toList === id
--   </pre>
--   
--   Assuming the input stream does not contain the separator:
--   
--   <pre>
--   Stream.splitOn (== '.') Fold.toList . Stream.intercalate (Stream.fromPure '.') Unfold.fromList === id
--   </pre>
splitOn :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Split on a suffixed separator element, dropping the separator. The
--   supplied <a>Fold</a> is applied on the split segments.
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' p xs = Stream.toList $ Stream.splitOnSuffix p Fold.toList (Stream.fromList xs)
--   
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a.b."
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a."
--   ["a"]
--   </pre>
--   
--   An empty stream results in an empty output stream:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') ""
--   []
--   </pre>
--   
--   An empty segment consisting of only a suffix is folded to the default
--   output of the fold:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "."
--   [""]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a..b.."
--   ["a","","b",""]
--   </pre>
--   
--   A suffix is optional at the end of the stream:
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a"
--   ["a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') ".a"
--   ["","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitOnSuffix' (== '.') "a.b"
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   lines = splitOnSuffix (== '\n')
--   </pre>
--   
--   <a>splitOnSuffix</a> is an inverse of <tt>intercalateSuffix</tt> with
--   a single element:
--   
--   <pre>
--   Stream.intercalateSuffix (Stream.fromPure '.') Unfold.fromList . Stream.splitOnSuffix (== '.') Fold.toList === id
--   </pre>
--   
--   Assuming the input stream does not contain the separator:
--   
--   <pre>
--   Stream.splitOnSuffix (== '.') Fold.toList . Stream.intercalateSuffix (Stream.fromPure '.') Unfold.fromList === id
--   </pre>
splitOnSuffix :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Like <a>splitOnSuffix</a> but keeps the suffix attached to the
--   resulting splits.
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' p xs = Stream.toList $ splitWithSuffix p Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') ""
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "."
--   ["."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a"
--   ["a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') ".a"
--   [".","a"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a."
--   ["a."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a.b"
--   ["a.","b"]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a.b."
--   ["a.","b."]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; splitWithSuffix' (== '.') "a..b.."
--   ["a.",".","b.","."]
--   </pre>
splitWithSuffix :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Like <a>splitOn</a> after stripping leading, trailing, and repeated
--   separators. Therefore, <tt>".a..b."</tt> with <a>.</a> as the
--   separator would be parsed as <tt>["a","b"]</tt>. In other words, its
--   like parsing words from whitespace separated text.
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' p xs = Stream.toList $ Stream.wordsBy p Fold.toList (Stream.fromList xs)
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' (== ',') ""
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' (== ',') ","
--   []
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; wordsBy' (== ',') ",a,,b,"
--   ["a","b"]
--   </pre>
--   
--   <pre>
--   words = wordsBy isSpace
--   </pre>
wordsBy :: (IsStream t, Monad m) => (a -> Bool) -> Fold m a b -> t m a -> t m b

-- | <pre>
--   groups = groupsBy (==)
--   groups = groupsByRolling (==)
--   </pre>
--   
--   Groups contiguous spans of equal elements together in individual
--   groups.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.groups Fold.toList $ Stream.fromList [1,1,2,2]
--   [[1,1],[2,2]]
--   </pre>
groups :: (IsStream t, Monad m, Eq a) => Fold m a b -> t m a -> t m b

-- | <tt>groupsBy cmp f $ S.fromList [a,b,c,...]</tt> assigns the element
--   <tt>a</tt> to the first group, if <tt>b `cmp` a</tt> is <a>True</a>
--   then <tt>b</tt> is also assigned to the same group. If <tt>c `cmp`
--   a</tt> is <a>True</a> then <tt>c</tt> is also assigned to the same
--   group and so on. When the comparison fails a new group is started.
--   Each group is folded using the fold <tt>f</tt> and the result of the
--   fold is emitted in the output stream.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.groupsBy (&gt;) Fold.toList $ Stream.fromList [1,3,7,0,2,5]
--   [[1,3,7],[0,2,5]]
--   </pre>
groupsBy :: (IsStream t, Monad m) => (a -> a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Unlike <tt>groupsBy</tt> this function performs a rolling comparison
--   of two successive elements in the input stream. <tt>groupsByRolling
--   cmp f $ S.fromList [a,b,c,...]</tt> assigns the element <tt>a</tt> to
--   the first group, if <tt>a `cmp` b</tt> is <a>True</a> then <tt>b</tt>
--   is also assigned to the same group. If <tt>b `cmp` c</tt> is
--   <a>True</a> then <tt>c</tt> is also assigned to the same group and so
--   on. When the comparison fails a new group is started. Each group is
--   folded using the fold <tt>f</tt>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.groupsByRolling (\a b -&gt; a + 1 == b) Fold.toList $ Stream.fromList [1,2,3,7,8,9]
--   [[1,2,3],[7,8,9]]
--   </pre>
groupsByRolling :: (IsStream t, Monad m) => (a -> a -> Bool) -> Fold m a b -> t m a -> t m b

-- | Run the action <tt>m b</tt> before the stream yields its first
--   element.
--   
--   Same as the following but more efficient due to fusion:
--   
--   <pre>
--   &gt;&gt;&gt; before action xs = Stream.nilM action &lt;&gt; xs
--   
--   &gt;&gt;&gt; before action xs = Stream.concatMap (const xs) (Stream.fromEffect action)
--   </pre>
before :: (IsStream t, Monad m) => m b -> t m a -> t m a

-- | Run the action <tt>m b</tt> whenever the stream <tt>t m a</tt> stops
--   normally, or if it is garbage collected after a partial lazy
--   evaluation.
--   
--   The semantics of the action <tt>m b</tt> are similar to the semantics
--   of cleanup action in <a>bracket</a>.
--   
--   <i>See also <a>after_</a></i>
after :: (IsStream t, MonadIO m, MonadBaseControl IO m) => m b -> t m a -> t m a

-- | Run the alloc action <tt>m b</tt> with async exceptions disabled but
--   keeping blocking operations interruptible (see <a>mask</a>). Use the
--   output <tt>b</tt> as input to <tt>b -&gt; t m a</tt> to generate an
--   output stream.
--   
--   <tt>b</tt> is usually a resource under the state of monad <tt>m</tt>,
--   e.g. a file handle, that requires a cleanup after use. The cleanup
--   action <tt>b -&gt; m c</tt>, runs whenever the stream ends normally,
--   due to a sync or async exception or if it gets garbage collected after
--   a partial lazy evaluation.
--   
--   <a>bracket</a> only guarantees that the cleanup action runs, and it
--   runs with async exceptions enabled. The action must ensure that it can
--   successfully cleanup the resource in the face of sync or async
--   exceptions.
--   
--   When the stream ends normally or on a sync exception, cleanup action
--   runs immediately in the current thread context, whereas in other cases
--   it runs in the GC context, therefore, cleanup may be delayed until the
--   GC gets to run.
--   
--   <i>See also: <a>bracket_</a></i>
--   
--   <i>Inhibits stream fusion</i>
bracket :: (IsStream t, MonadAsync m, MonadCatch m) => m b -> (b -> m c) -> (b -> t m a) -> t m a

-- | Run the action <tt>m b</tt> if the stream aborts due to an exception.
--   The exception is not caught, simply rethrown.
--   
--   <i>Inhibits stream fusion</i>
onException :: (IsStream t, MonadCatch m) => m b -> t m a -> t m a

-- | Run the action <tt>m b</tt> whenever the stream <tt>t m a</tt> stops
--   normally, aborts due to an exception or if it is garbage collected
--   after a partial lazy evaluation.
--   
--   The semantics of running the action <tt>m b</tt> are similar to the
--   cleanup action semantics described in <a>bracket</a>.
--   
--   <pre>
--   finally release = bracket (return ()) (const release)
--   </pre>
--   
--   <i>See also <a>finally_</a></i>
--   
--   <i>Inhibits stream fusion</i>
finally :: (IsStream t, MonadAsync m, MonadCatch m) => m b -> t m a -> t m a

-- | When evaluating a stream if an exception occurs, stream evaluation
--   aborts and the specified exception handler is run with the exception
--   as argument.
--   
--   <i>Inhibits stream fusion</i>
handle :: (IsStream t, MonadCatch m, Exception e) => (e -> t m a) -> t m a -> t m a

-- | Lift the inner monad <tt>m</tt> of a stream <tt>t m a</tt> to <tt>tr
--   m</tt> using the monad transformer <tt>tr</tt>.
liftInner :: (Monad m, IsStream t, MonadTrans tr, Monad (tr m)) => t m a -> t (tr m) a

-- | Evaluate the inner monad of a stream as <a>ReaderT</a>.
runReaderT :: (IsStream t, Monad m) => m s -> t (ReaderT s m) a -> t m a

-- | Evaluate the inner monad of a stream as <a>StateT</a> and emit the
--   resulting state and value pair after each step.
--   
--   This is supported only for <a>SerialT</a> as concurrent state updation
--   may not be safe.
runStateT :: Monad m => m s -> SerialT (StateT s m) a -> SerialT m (s, a)

-- | For <a>SerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>serial</a> -- <a>Monad</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(1,4),(2,3),(2,4)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data SerialT m a

-- | For <a>WSerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wSerial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wSerial</a> -- <a>Monad</a>
--   </pre>
--   
--   Note that <a>&lt;&gt;</a> is associative only if we disregard the
--   ordering of elements in the resulting stream.
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like interleaved nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   It is a result of interleaving all the nested iterations corresponding
--   to element <tt>1</tt> in the first stream with all the nested
--   iterations of element <tt>2</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromList [(1,3),(1,4)] `Stream.wSerial` Stream.fromList [(2,3),(2,4)]
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>SerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WSerialT m a

-- | For <a>AheadT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>ahead</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>ahead</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations executed concurrently, ahead of time, producing side
--   effects of iterations out of order, but results in order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [2,1]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, ahead of time:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,5,4,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>ahead</tt>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
data AheadT m a

-- | For <a>AsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>async</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>async</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>async</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>async</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>async</tt>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
data AsyncT m a

-- | For <a>WAsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wAsync</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wAsync</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>wAsync</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>wAsync</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one <a>WAsyncT</a> output stream and all the iterations corresponding
--   to <tt>2</tt> constitute another <a>WAsyncT</a> output stream and
--   these two output streams are merged using <tt>wAsync</tt>.
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>AsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WAsyncT m a

-- | For <a>ParallelT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>parallel</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>parallel</a>
--   </pre>
--   
--   See <a>AsyncT</a>, <a>ParallelT</a> is similar except that all
--   iterations are strictly concurrent while in <tt>AsyncT</tt> it depends
--   on the consumer demand and available threads. See <tt>parallel</tt>
--   for more details.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
--   
--   <i>Since: 0.7.0 (maxBuffer applies to ParallelT streams)</i>
data ParallelT m a

-- | For <a>ZipSerialM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped serially:
--   
--   <pre>
--   &gt;&gt;&gt; s1 = Stream.fromFoldable [1, 2]
--   
--   &gt;&gt;&gt; s2 = Stream.fromFoldable [3, 4]
--   
--   &gt;&gt;&gt; s3 = Stream.fromFoldable [5, 6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipSerial $ (,,) &lt;$&gt; s1 &lt;*&gt; s2 &lt;*&gt; s3
--   [(1,3,5),(2,4,6)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipSerialM m a

-- | For <a>ZipAsyncM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipAsyncWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped concurrently, the
--   following would take half the time that it would take in serial
--   zipping:
--   
--   <pre>
--   &gt;&gt;&gt; s = Stream.fromFoldableM $ Prelude.map delay [1, 1, 1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipAsync $ (,) &lt;$&gt; s &lt;*&gt; s
--   ...
--   [(1,1),(1,1),(1,1)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipAsyncM m a

-- | A serial IO stream of elements of type <tt>a</tt>. See <a>SerialT</a>
--   documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Serial = SerialT IO

-- | An interleaving serial IO stream of elements of type <tt>a</tt>. See
--   <a>WSerialT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WSerial = WSerialT IO

-- | A serial IO stream of elements of type <tt>a</tt> with concurrent
--   lookahead. See <a>AheadT</a> documentation for more details.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
type Ahead = AheadT IO

-- | A demand driven left biased parallely composing IO stream of elements
--   of type <tt>a</tt>. See <a>AsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Async = AsyncT IO

-- | A round robin parallely composing IO stream of elements of type
--   <tt>a</tt>. See <a>WAsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WAsync = WAsyncT IO

-- | A parallely composing IO stream of elements of type <tt>a</tt>. See
--   <a>ParallelT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Parallel = ParallelT IO

-- | An IO stream whose applicative instance zips streams serially.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipSerial = ZipSerialM IO

-- | An IO stream whose applicative instance zips streams wAsyncly.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipAsync = ZipAsyncM IO

-- | A monad that can perform concurrent or parallel IO operations. Streams
--   that can be composed concurrently require the underlying monad to be
--   <a>MonadAsync</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
type MonadAsync m = (MonadIO m, MonadBaseControl IO m, MonadThrow m)

-- | Class of types that can represent a stream of elements of some type
--   <tt>a</tt> in some monad <tt>m</tt>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
class (forall m a. MonadAsync m => Semigroup (t m a), forall m a. MonadAsync m => Monoid (t m a), forall m. Monad m => Functor (t m), forall m. MonadAsync m => Applicative (t m)) => IsStream t

-- | Fix the type of a polymorphic stream as <a>SerialT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromSerial :: IsStream t => SerialT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>WSerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromWSerial :: IsStream t => WSerialT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>AsyncT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromAsync :: IsStream t => AsyncT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>AheadT</a>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
fromAhead :: IsStream t => AheadT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>WAsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromWAsync :: IsStream t => WAsyncT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>ParallelT</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
fromParallel :: IsStream t => ParallelT m a -> t m a

-- | Fix the type of a polymorphic stream as <a>ZipSerialM</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromZipSerial :: IsStream t => ZipSerialM m a -> t m a

-- | Fix the type of a polymorphic stream as <a>ZipAsyncM</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
fromZipAsync :: IsStream t => ZipAsyncM m a -> t m a

-- | Adapt any specific stream type to any other specific stream type.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
adapt :: (IsStream t1, IsStream t2) => t1 m a -> t2 m a

-- | Same as fromEffect

-- | <i>Deprecated: Please use fromEffect instead.</i>
once :: (Monad m, IsStream t) => m a -> t m a

-- | Same as <a>fromPure</a>

-- | <i>Deprecated: Please use fromPure instead.</i>
yield :: IsStream t => a -> t m a

-- | Same as <a>fromEffect</a>

-- | <i>Deprecated: Please use fromEffect instead.</i>
yieldM :: (Monad m, IsStream t) => m a -> t m a

-- | Same as <a>fromFoldable</a>.

-- | <i>Deprecated: Please use fromFoldable instead.</i>
each :: (IsStream t, Foldable f) => f a -> t m a

-- | Strict left scan with an extraction function. Like <a>scanl'</a>, but
--   applies a user supplied extraction function (the third argument) at
--   each step. This is designed to work with the <tt>foldl</tt> library.
--   The suffix <tt>x</tt> is a mnemonic for extraction.
--   
--   <i>Since 0.2.0</i>
--   
--   <i>Since: 0.7.0 (Monad m constraint)</i>

-- | <i>Deprecated: Please use scanl followed by map instead.</i>
scanx :: (IsStream t, Monad m) => (x -> a -> x) -> x -> (x -> b) -> t m a -> t m b

-- | Strict left fold with an extraction function. Like the standard strict
--   left fold, but applies a user supplied extraction function (the third
--   argument) to the folded value at the end. This is designed to work
--   with the <tt>foldl</tt> library. The suffix <tt>x</tt> is a mnemonic
--   for extraction.

-- | <i>Deprecated: Please use foldl' followed by fmap instead.</i>
foldx :: Monad m => (x -> a -> x) -> x -> (x -> b) -> SerialT m a -> m b

-- | Like <a>foldx</a>, but with a monadic step function.

-- | <i>Deprecated: Please use foldlM' followed by fmap instead.</i>
foldxM :: Monad m => (x -> a -> m x) -> m x -> (x -> m b) -> SerialT m a -> m b

-- | Lazy right fold for non-empty streams, using first element as the
--   starting value. Returns <a>Nothing</a> if the stream is empty.

-- | <i>Deprecated: Use foldrM instead.</i>
foldr1 :: Monad m => (a -> a -> a) -> SerialT m a -> m (Maybe a)

-- | Run a stream, discarding the results. By default it interprets the
--   stream as <a>SerialT</a>, to run other types of streams use the type
--   adapting combinators for example <tt>runStream .
--   <tt>fromAsync</tt></tt>.

-- | <i>Deprecated: Please use "drain" instead</i>
runStream :: Monad m => SerialT m a -> m ()

-- | <pre>
--   runN n = runStream . take n
--   </pre>
--   
--   Run maximum up to <tt>n</tt> iterations of a stream.

-- | <i>Deprecated: Please use "drainN" instead</i>
runN :: Monad m => Int -> SerialT m a -> m ()

-- | <pre>
--   runWhile p = runStream . takeWhile p
--   </pre>
--   
--   Run a stream as long as the predicate holds true.

-- | <i>Deprecated: Please use "drainWhile" instead</i>
runWhile :: Monad m => (a -> Bool) -> SerialT m a -> m ()

-- | Read lines from an IO Handle into a stream of Strings.

-- | <i>Deprecated: Please use Streamly.FileSystem.Handle module (see the
--   changelog)</i>
fromHandle :: (IsStream t, MonadIO m) => Handle -> t m String

-- | <pre>
--   toHandle h = S.mapM_ $ hPutStrLn h
--   </pre>
--   
--   Write a stream of Strings to an IO Handle.

-- | <i>Deprecated: Please use Streamly.FileSystem.Handle module (see the
--   changelog)</i>
toHandle :: MonadIO m => Handle -> SerialT m String -> m ()

-- | <i>Deprecated: Please use unfoldMany instead.</i>
concatUnfold :: (IsStream t, Monad m) => Unfold m a b -> t m a -> t m b


module Streamly.Internal.Unicode.Array.Prim.Pinned

-- | Break a string up into a stream of strings at newline characters. The
--   resulting strings do not contain newlines.
--   
--   <pre>
--   lines = S.lines A.write
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.lines $ Stream.fromList "lines\nthis\nstring\n\n\n"
--   [fromListN 5 "lines",fromListN 4 "this",fromListN 6 "string",fromListN 0 "",fromListN 0 ""]
--   </pre>
lines :: (MonadIO m, IsStream t) => t m Char -> t m (Array Char)

-- | Break a string up into a stream of strings, which were delimited by
--   characters representing white space.
--   
--   <pre>
--   words = S.words A.write
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.words $ Stream.fromList "A  newline\nis considered white space?"
--   [fromListN 1 "A",fromListN 7 "newline",fromListN 2 "is",fromListN 10 "considered",fromListN 5 "white",fromListN 6 "space?"]
--   </pre>
words :: (MonadIO m, IsStream t) => t m Char -> t m (Array Char)

-- | Flattens the stream of <tt>Array Char</tt>, after appending a
--   terminating newline to each string.
--   
--   <a>unlines</a> is an inverse operation to <a>lines</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.unlines $ Stream.fromList ["lines", "this", "string"]
--   "lines\nthis\nstring\n"
--   </pre>
--   
--   <pre>
--   unlines = S.unlines A.read
--   </pre>
--   
--   Note that, in general
--   
--   <pre>
--   unlines . lines /= id
--   </pre>
unlines :: (MonadAsync m, IsStream t) => t m (Array Char) -> t m Char

-- | Flattens the stream of <tt>Array Char</tt>, after appending a
--   separating space to each string.
--   
--   <a>unwords</a> is an inverse operation to <a>words</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.unwords $ Stream.fromList ["unwords", "this", "string"]
--   "unwords this string"
--   </pre>
--   
--   <pre>
--   unwords = S.unwords A.read
--   </pre>
--   
--   Note that, in general
--   
--   <pre>
--   unwords . words /= id
--   </pre>
unwords :: (MonadAsync m, IsStream t) => t m (Array Char) -> t m Char


module Streamly.Internal.Unicode.Array.Char

-- | Break a string up into a stream of strings at newline characters. The
--   resulting strings do not contain newlines.
--   
--   <pre>
--   lines = S.lines A.write
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.lines $ Stream.fromList "lines\nthis\nstring\n\n\n"
--   ["lines","this","string","",""]
--   </pre>
lines :: (MonadIO m, IsStream t) => t m Char -> t m (Array Char)

-- | Break a string up into a stream of strings, which were delimited by
--   characters representing white space.
--   
--   <pre>
--   words = S.words A.write
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.words $ Stream.fromList "A  newline\nis considered white space?"
--   ["A","newline","is","considered","white","space?"]
--   </pre>
words :: (MonadIO m, IsStream t) => t m Char -> t m (Array Char)

-- | Flattens the stream of <tt>Array Char</tt>, after appending a
--   terminating newline to each string.
--   
--   <a>unlines</a> is an inverse operation to <a>lines</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.unlines $ Stream.fromList ["lines", "this", "string"]
--   "lines\nthis\nstring\n"
--   </pre>
--   
--   <pre>
--   unlines = S.unlines A.read
--   </pre>
--   
--   Note that, in general
--   
--   <pre>
--   unlines . lines /= id
--   </pre>
unlines :: (MonadIO m, IsStream t) => t m (Array Char) -> t m Char

-- | Flattens the stream of <tt>Array Char</tt>, after appending a
--   separating space to each string.
--   
--   <a>unwords</a> is an inverse operation to <a>words</a>.
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Unicode.unwords $ Stream.fromList ["unwords", "this", "string"]
--   "unwords this string"
--   </pre>
--   
--   <pre>
--   unwords = S.unwords A.read
--   </pre>
--   
--   Note that, in general
--   
--   <pre>
--   unwords . words /= id
--   </pre>
unwords :: (MonadAsync m, IsStream t) => t m (Array Char) -> t m Char


-- | This module is a an experimental replacement for
--   <a>Streamly.FileSystem.Handle</a>. The former module provides IO
--   facilities based on the GHC Handle type. The APIs in this module avoid
--   the GHC handle layer and provide more explicit control over buffering.
--   
--   Read and write data as streams and arrays to and from files.
--   
--   This module provides read and write APIs based on handles. Before
--   reading or writing, a file must be opened first using <a>openFile</a>.
--   The <a>Handle</a> returned by <a>openFile</a> is then used to access
--   the file. A <a>Handle</a> is backed by an operating system file
--   descriptor. When the <a>Handle</a> is garbage collected the underlying
--   file descriptor is automatically closed. A handle can be explicitly
--   closed using <tt>closeFile</tt>.
--   
--   Reading and writing APIs are divided into two categories, sequential
--   streaming APIs and random or seekable access APIs. File IO APIs are
--   quite similar to <a>Streamly.Data.Array.Foreign</a> read write APIs.
--   In that regard, arrays can be considered as in-memory files or files
--   can be considered as on-disk arrays.
--   
--   <pre>
--   import qualified Streamly.Internal.FileSystem.FD as FD
--   </pre>
module Streamly.Internal.FileSystem.FD

-- | A <a>Handle</a> is returned by <a>openFile</a> and is subsequently
--   used to perform read and write operations on a file.
data Handle

-- | File handle for standard input
stdin :: Handle

-- | File handle for standard output
stdout :: Handle

-- | File handle for standard error
stderr :: Handle

-- | Open a file that is not a directory and return a file handle.
--   <a>openFile</a> enforces a multiple-reader single-writer locking on
--   files. That is, there may either be many handles on the same file
--   which manage input, or just one handle on the file which manages
--   output. If any open handle is managing a file for output, no new
--   handle can be allocated for that file. If any open handle is managing
--   a file for input, new handles can only be allocated if they do not
--   manage output. Whether two files are the same is
--   implementation-dependent, but they should normally be the same if they
--   have the same absolute path name and neither has been renamed, for
--   example.
openFile :: FilePath -> IOMode -> IO Handle

-- | Generate a stream of elements of the given type from a file
--   <a>Handle</a>. The stream ends when EOF is encountered.
read :: (IsStream t, MonadIO m) => Handle -> t m Word8

-- | <tt>readInChunksOf chunkSize handle</tt> reads a byte stream from a
--   file handle, reads are performed in chunks of up to
--   <tt>chunkSize</tt>. The stream ends as soon as EOF is encountered.
readInChunksOf :: (IsStream t, MonadIO m) => Int -> Handle -> t m Word8

-- | <tt>readArrays h</tt> reads a stream of arrays from file handle
--   <tt>h</tt>. The maximum size of a single array is limited to
--   <tt>defaultChunkSize</tt>. <a>readArrays</a> ignores the prevailing
--   <tt>TextEncoding</tt> and <tt>NewlineMode</tt> on the <a>Handle</a>.
--   
--   <pre>
--   readArrays = readArraysOfUpto defaultChunkSize
--   </pre>
readArrays :: (IsStream t, MonadIO m) => Handle -> t m (Array Word8)
readArraysOfUpto :: (IsStream t, MonadIO m) => Int -> Handle -> t m (Array Word8)

-- | Write a byte stream to a file handle. Combines the bytes in chunks of
--   size up to <a>defaultChunkSize</a> before writing. Note that the write
--   behavior depends on the <a>IOMode</a> and the current seek position of
--   the handle.
write :: MonadIO m => Handle -> SerialT m Word8 -> m ()

-- | Like <a>write</a> but provides control over the write buffer. Output
--   will be written to the IO device as soon as we collect the specified
--   number of input elements.
writeInChunksOf :: MonadIO m => Int -> Handle -> SerialT m Word8 -> m ()

-- | Write a stream of arrays to a handle.
writeArrays :: (MonadIO m, Storable a) => Handle -> SerialT m (Array a) -> m ()

-- | Write a stream of arrays to a handle after coalescing them in chunks
--   of specified size. The chunk size is only a maximum and the actual
--   writes could be smaller than that as we do not split the arrays to fit
--   them to the specified size.
writeArraysPackedUpto :: (MonadIO m, Storable a) => Int -> Handle -> SerialT m (Array a) -> m ()


-- | <h1>Overview</h1>
--   
--   Use <tt>watchPaths</tt> with a list of file system paths you want to
--   watch as argument. It returns a stream of <a>Event</a> representing
--   the file system events occurring under the watched paths.
--   
--   <pre>
--   Stream.mapM_ (putStrLn . <a>showEvent</a>) $ <tt>watchPaths</tt> [Array.fromCString# "dir"#]
--   </pre>
--   
--   <a>Event</a> is an opaque type. Accessor functions (e.g.
--   <a>showEvent</a> above) provided in this module are used to determine
--   the attributes of the event.
--   
--   Identical successive events may be coalesced into a single event.
--   
--   <h1>Design notes</h1>
--   
--   For reference documentation see:
--   
--   <ul>
--   <li><a>inotify man page</a></li>
--   </ul>
--   
--   We try to keep the macOS/Linux/Windows event handling APIs and
--   defaults semantically and syntactically as close as possible.
--   
--   <h1>BUGs</h1>
--   
--   When testing on Linux Kernel version <tt>5.3.0-53-generic
--   #47-Ubuntu</tt>, the last event for the root path seems to be delayed
--   until one more event occurs.
--   
--   <h1>Differences between macOS and Linux APIs:</h1>
--   
--   <ol>
--   <li>macOS watch is based on the path provided to it, if the path is
--   deleted and recreated it will still be watched, if the path moves to
--   another path it won't be watched anymore. Whereas Linux watch is based
--   on a handle to the path, if the path is deleted and recreated it won't
--   be watched, if the path moves to another it can still be watched
--   (though this is configurable).</li>
--   </ol>
--   
--   <ol>
--   <li>macOS watches the directory hierarchy recursively, Linux watches
--   only one level of dir, recursive watch has to be built in user space
--   by watching for create events and adding the new directories to the
--   watch. Not sure how this will scale for too many paths.</li>
--   <li>In macOS the path of the subject of the event is absolute, in
--   Linux the path is the name of the object inside the dir being
--   watched.</li>
--   <li>On Linux <tt>watchPaths</tt> fails if a path does not exist, on
--   macOS it does not fail.</li>
--   </ol>
module Streamly.Internal.FileSystem.Event.Linux

-- | Watch configuration, used to specify the events of interest and the
--   behavior of the watch.
--   
--   <i>Pre-release</i>
data Config
Config :: Bool -> Word32 -> Config
[watchRec] :: Config -> Bool
[createFlags] :: Config -> Word32

-- | Whether a setting is <a>On</a> or <a>Off</a>.
--   
--   <i>Pre-release</i>
data Toggle
On :: Toggle
Off :: Toggle

-- | The default configuration settings are:
--   
--   <ul>
--   <li><a>setFollowSymLinks</a> <a>On</a></li>
--   <li><a>setUnwatchMoved</a> <a>On</a></li>
--   <li><a>setOneShot</a> <a>Off</a></li>
--   <li><a>setOnlyDir</a> <a>Off</a></li>
--   <li><a>setWhenExists</a> <a>AddIfExists</a></li>
--   </ul>
--   
--   The tunable events enabled by default are:
--   
--   <ul>
--   <li>setCreated On</li>
--   <li>setDeleted On</li>
--   <li>setMovedFrom On</li>
--   <li>setMovedTo On</li>
--   <li>setModified On</li>
--   </ul>
--   
--   <i>Pre-release</i>
defaultConfig :: Config

-- | Watch the whole directory tree recursively instead of watching just
--   one level of directory.
--   
--   <i>default: Off</i>
--   
--   <i>Pre-release</i>
setRecursiveMode :: Toggle -> Config -> Config

-- | If the pathname to be watched is a symbolic link then watch the target
--   of the symbolic link instead of the symbolic link itself.
--   
--   Note that the path location in the events is through the original
--   symbolic link path rather than the resolved path.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setFollowSymLinks :: Toggle -> Config -> Config

-- | If an object moves out of the directory being watched then stop
--   watching it.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setUnwatchMoved :: Toggle -> Config -> Config

-- | Watch the object only for one event and then remove it from the watch.
--   
--   <i>default: Off</i>
--   
--   <i>Pre-release</i>
setOneShot :: Toggle -> Config -> Config

-- | Watch the object only if it is a directory. This provides a race-free
--   way to ensure that the watched object is a directory.
--   
--   <i>default: Off</i>
--   
--   <i>Pre-release</i>
setOnlyDir :: Toggle -> Config -> Config

-- | What to do if a watch already exists when <a>openWatch</a> or
--   <a>addToWatch</a> is called for a path.
--   
--   <i>Pre-release</i>
data WhenExists

-- | Do not set an existing setting to <a>Off</a> only set to <a>On</a>
AddIfExists :: WhenExists

-- | Replace the existing settings with new settings
ReplaceIfExists :: WhenExists

-- | Fail the API
FailIfExists :: WhenExists

-- | When adding a new path to the watch, specify what to do if a watch
--   already exists on that path.
--   
--   <i>default: FailIfExists</i>
--   
--   <i>Pre-release</i>
setWhenExists :: WhenExists -> Config -> Config

-- | Report when the watched path itself gets deleted.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setRootDeleted :: Toggle -> Config -> Config

-- | Report when the watched root path itself gets renamed.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setRootMoved :: Toggle -> Config -> Config

-- | Report when the watched root path itself gets deleted or renamed.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setRootPathEvents :: Toggle -> Config -> Config

-- | Report when the metadata e.g. owner, permission modes, modifications
--   times of an object changes.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setAttrsModified :: Toggle -> Config -> Config

-- | Report when a file is accessed.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setAccessed :: Toggle -> Config -> Config

-- | Report when a file is opened.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setOpened :: Toggle -> Config -> Config

-- | Report when a file that was opened for writes is closed.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setWriteClosed :: Toggle -> Config -> Config

-- | Report when a file that was opened for not writing is closed.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setNonWriteClosed :: Toggle -> Config -> Config

-- | Report when a file is created.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setCreated :: Toggle -> Config -> Config

-- | Report when a file is deleted.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setDeleted :: Toggle -> Config -> Config

-- | Report the source of a move.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setMovedFrom :: Toggle -> Config -> Config

-- | Report the target of a move.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setMovedTo :: Toggle -> Config -> Config

-- | Report when a file is modified.
--   
--   <i>default: On</i>
--   
--   <i>Pre-release</i>
setModified :: Toggle -> Config -> Config

-- | Set all tunable events <a>On</a> or <a>Off</a>. Equivalent to setting:
--   
--   <ul>
--   <li>setRootDeleted</li>
--   <li>setRootMoved</li>
--   <li>setAttrsModified</li>
--   <li>setAccessed</li>
--   <li>setOpened</li>
--   <li>setWriteClosed</li>
--   <li>setNonWriteClosed</li>
--   <li>setCreated</li>
--   <li>setDeleted</li>
--   <li>setMovedFrom</li>
--   <li>setMovedTo</li>
--   <li>setModified</li>
--   </ul>
--   
--   <i>Pre-release</i>
setAllEvents :: Toggle -> Config -> Config

-- | Same as <a>watchWith</a> using defaultConfig and non-recursive mode.
--   
--   <pre>
--   &gt;&gt;&gt; watch = watchWith id
--   </pre>
--   
--   <i>Pre-release</i>
watch :: NonEmpty (Array Word8) -> SerialT IO Event

-- | Same as <a>watchWith</a> using <a>defaultConfig</a> and recursive
--   mode.
--   
--   <pre>
--   &gt;&gt;&gt; watchRecursive = watchWith (setRecursiveMode On)
--   </pre>
--   
--   See <a>watchWith</a> for pitfalls and bugs when using recursive watch
--   on Linux.
--   
--   <i>Pre-release</i>
watchRecursive :: NonEmpty (Array Word8) -> SerialT IO Event

-- | Start monitoring a list of file system paths for file system events
--   with the supplied configuration operation over the
--   <a>defaultConfig</a>. The paths could be files or directories. When
--   recursive mode is set and the path is a directory, the whole directory
--   tree under it is watched recursively. Monitoring starts from the
--   current time onwards. The paths are specified as UTF-8 encoded
--   <a>Array</a> of <a>Word8</a>.
--   
--   <i>Non-existing Paths:</i> the API fails if a watch is started on a
--   non-exsting path.
--   
--   <i>Performance:</i> Note that recursive watch on a large directory
--   tree could be expensive. When starting a watch, the whole tree must be
--   read and watches are started on each directory in the tree. The
--   initial time to start the watch as well as the memory required is
--   proportional to the number of directories in the tree.
--   
--   <i>Bugs:</i> When new directories are created under the tree they are
--   added to the watch on receiving the directory create event. However,
--   the creation of a dir and adding a watch for it is not atomic. The
--   implementation takes care of this and makes sure that watches are
--   added for all directories. However, In the mean time, the directory
--   may have received more events which may get lost. Handling of any such
--   lost events is yet to be implemented.
--   
--   See the Linux <b>inotify</b> man page for more details.
--   
--   <pre>
--   watchwith
--        (<a>setFollowSymLinks</a> On . <a>setUnwatchMoved</a> Off)
--        [Array.fromCString# "dir"#]
--   </pre>
--   
--   <i>Pre-release</i>
watchWith :: (Config -> Config) -> NonEmpty (Array Word8) -> SerialT IO Event

-- | <tt>addToWatch cfg watch root subpath</tt> adds <tt>subpath</tt> to
--   the list of paths being monitored under <tt>root</tt> via the watch
--   handle <tt>watch</tt>. <tt>root</tt> must be an absolute path and
--   <tt>subpath</tt> must be relative to <tt>root</tt>.
--   
--   <i>Pre-release</i>
addToWatch :: Config -> Watch -> Array Word8 -> Array Word8 -> IO ()

-- | Remove an absolute root path from a <a>Watch</a>, if a path was moved
--   after adding you need to provide the original path which was used to
--   add the Watch.
--   
--   <i>Pre-release</i>
removeFromWatch :: Watch -> Array Word8 -> IO ()

-- | An Event generated by the file system. Use the accessor functions to
--   examine the event.
--   
--   <i>Pre-release</i>
data Event
Event :: CInt -> Word32 -> Word32 -> Array Word8 -> IntMap (Array Word8, Array Word8) -> Event
[eventWd] :: Event -> CInt
[eventFlags] :: Event -> Word32
[eventCookie] :: Event -> Word32
[eventRelPath] :: Event -> Array Word8
[eventMap] :: Event -> IntMap (Array Word8, Array Word8)

-- | Get the watch root corresponding to the <a>Event</a>.
--   
--   Note that if a path was moved after adding to the watch, this will
--   give the original path and not the new path after moving.
--   
--   TBD: we can possibly update the watch root on a move self event.
--   
--   <i>Pre-release</i>
getRoot :: Event -> Array Word8

-- | Get the file system object path for which the event is generated,
--   relative to the watched root. The path is a "/" separated array of
--   bytes.
--   
--   <i>Pre-release</i>
getRelPath :: Event -> Array Word8

-- | Get the absolute file system object path for which the event is
--   generated.
--   
--   When the watch root is a symlink, the absolute path returned is via
--   the original symlink and not through the resolved path.
--   
--   <i>Pre-release</i>
getAbsPath :: Event -> Array Word8

-- | Cookie is set when a rename occurs. The cookie value can be used to
--   connect the <a>isMovedFrom</a> and <a>isMovedTo</a> events, if both
--   the events belong to the same move operation then they will have the
--   same cookie value.
--   
--   <i>Pre-release</i>
getCookie :: Event -> Cookie

-- | Determine whether the event indicates a change of path of the
--   monitored object itself. Note that the object may become unreachable
--   or deleted after a change of path.
--   
--   <i>Occurs only for a watched path</i>
--   
--   <i>Pre-release</i>
isRootPathEvent :: Event -> Bool

-- | A path was removed from the watch explicitly using
--   <a>removeFromWatch</a> or automatically (file was deleted, or
--   filesystem was unmounted).
--   
--   Note that in recursive watch mode all the subdirectories are watch
--   roots, therefore, they will all generate this event.
--   
--   <i>Occurs only for a watched path</i>
--   
--   <i>Pre-release</i>
isRootUnwatched :: Event -> Bool

-- | Watched file/directory was itself deleted. (This event also occurs if
--   an object is moved to another filesystem, since mv(1) in effect copies
--   the file to the other filesystem and then deletes it from the original
--   filesystem.) In addition, an <a>isRootUnwatched</a> event will
--   subsequently be generated for the watch descriptor.
--   
--   Note that in recursive watch mode all the subdirectories are watch
--   roots, therefore, they will all generate this event.
--   
--   <i>Occurs only for a watched path</i>
--   
--   <i>Pre-release</i>
isRootDeleted :: Event -> Bool

-- | Watched file/directory was itself moved within the file system.
--   
--   Note that in recursive watch mode all the subdirectories are watch
--   roots, therefore, they will all generate this event.
--   
--   <i>Occurs only for a watched path</i>
--   
--   <i>Pre-release</i>
isRootMoved :: Event -> Bool

-- | Filesystem containing watched object was unmounted. In addition, an
--   <a>isRootUnwatched</a> event will subsequently be generated for the
--   watch descriptor.
--   
--   <i>Occurs only for a watched path</i>
--   
--   <i>Pre-release</i>
isRootUnmounted :: Event -> Bool

-- | Determine whether the event indicates inode metadata change for an
--   object contained within the monitored path.
--   
--   Metadata change may include, permissions (e.g., chmod(2)), timestamps
--   (e.g., utimensat(2)), extended attributes (setxattr(2)), link count
--   (since Linux 2.6.25; e.g., for the target of link(2) and for
--   unlink(2)), and user/group ID (e.g., chown(2)).
--   
--   <i>Can occur for watched path or a file inside it</i>
--   
--   <i>Pre-release</i>
isAttrsModified :: Event -> Bool

-- | File was accessed (e.g. read, execve).
--   
--   <i>Occurs only for a file inside the watched directory</i>
--   
--   <i>Pre-release</i>
isAccessed :: Event -> Bool

-- | File or directory was opened.
--   
--   <i>Occurs only for a file inside the watched directory</i>
--   
--   <i>Pre-release</i>
isOpened :: Event -> Bool

-- | File opened for writing was closed.
--   
--   <i>Occurs only for a file inside the watched directory</i>
--   
--   <i>Pre-release</i>
isWriteClosed :: Event -> Bool

-- | File or directory opened for read but not write was closed.
--   
--   <i>Can occur for watched path or a file inside it</i>
--   
--   <i>Pre-release</i>
isNonWriteClosed :: Event -> Bool

-- | File/directory created in watched directory (e.g., open(2) O_CREAT,
--   mkdir(2), link(2), symlink(2), bind(2) on a UNIX domain socket).
--   
--   <i>Occurs only for an object inside the watched directory</i>
--   
--   <i>Pre-release</i>
isCreated :: Event -> Bool

-- | File/directory deleted from watched directory.
--   
--   <i>Occurs only for an object inside the watched directory</i>
--   
--   <i>Pre-release</i>
isDeleted :: Event -> Bool

-- | Generated for the original path when an object is moved from under a
--   monitored directory.
--   
--   <i>Occurs only for an object inside the watched directory</i>
--   
--   <i>Pre-release</i>
isMovedFrom :: Event -> Bool

-- | Generated for the new path when an object is moved under a monitored
--   directory.
--   
--   <i>Occurs only for an object inside the watched directory</i>
--   
--   <i>Pre-release</i>
isMovedTo :: Event -> Bool

-- | Generated for a path that is moved from or moved to the monitored
--   directory.
--   
--   <pre>
--   &gt;&gt;&gt; isMoved ev = isMovedFrom ev || isMovedTo ev
--   </pre>
--   
--   <i>Occurs only for an object inside the watched directory</i>
--   
--   <i>Pre-release</i>
isMoved :: Event -> Bool

-- | Determine whether the event indicates modification of an object within
--   the monitored path. This event is generated only for files and not
--   directories.
--   
--   <i>Occurs only for an object inside the watched directory</i>
--   
--   <i>Pre-release</i>
isModified :: Event -> Bool

-- | Determine whether the event is for a directory path.
--   
--   <i>Pre-release</i>
isDir :: Event -> Bool

-- | Event queue overflowed (WD is invalid for this event) and we may have
--   lost some events.. The user application must scan everything under the
--   watched paths to know the current state.
--   
--   <i>Pre-release</i>
isEventsLost :: Event -> Bool

-- | Convert an <a>Event</a> record to a String representation.
showEvent :: Event -> String
instance GHC.Classes.Eq Streamly.Internal.FileSystem.Event.Linux.Toggle
instance GHC.Show.Show Streamly.Internal.FileSystem.Event.Linux.Toggle
instance GHC.Show.Show Streamly.Internal.FileSystem.Event.Linux.WD
instance GHC.Classes.Eq Streamly.Internal.FileSystem.Event.Linux.Cookie
instance GHC.Show.Show Streamly.Internal.FileSystem.Event.Linux.Cookie
instance GHC.Classes.Eq Streamly.Internal.FileSystem.Event.Linux.Event
instance GHC.Classes.Ord Streamly.Internal.FileSystem.Event.Linux.Event
instance GHC.Show.Show Streamly.Internal.FileSystem.Event.Linux.Event


-- | File system event notification API portable across Linux, macOS and
--   Windows platforms.
--   
--   Note that recursive directory tree watch does not work reliably on
--   Linux (see notes in the Linux module), therefore, recursive watch API
--   is not provided in this module. However, you can use it from the
--   platform specific modules.
--   
--   For platform specific APIs please see the following modules:
--   
--   <ul>
--   <li><a>Streamly.Internal.FileSystem.Event.Darwin</a></li>
--   <li><a>Streamly.Internal.FileSystem.Event.Linux</a></li>
--   <li><a>Streamly.Internal.FileSystem.Event.Windows</a></li>
--   </ul>
module Streamly.Internal.FileSystem.Event

-- | Start monitoring a list of directories or symbolic links to
--   directories for file system events. Monitoring starts from the current
--   time onwards. The paths are specified as UTF-8 encoded <a>Array</a> of
--   <a>Word8</a>.
--   
--   If a watch root is a symbolic link then the target of the link is
--   watched. Fails if the watched path does not exist. If the user does
--   not have permissions (read and execute?) on the watch root then no
--   events are generated. No events are generated if the watch root itself
--   is renamed or deleted.
--   
--   This API watches for changes in the watch root directory only, any
--   changes in the subdirectories of the watch root are not watched.
--   However, on macOS the watch is always recursive, but do not rely on
--   that behavior, it may change without notice in future. If you want to
--   use recursive watch please use platform specific modules.
--   
--   <i>Pre-release</i>
watch :: NonEmpty (Array Word8) -> SerialT IO Event

-- | An Event generated by the file system. Use the accessor functions to
--   examine the event.
--   
--   <i>Pre-release</i>
data Event

-- | Get the absolute path of the file system object for which the event is
--   generated. The path is a UTF-8 encoded array of bytes.
--   
--   When the watch root is a symlink the behavior is different on
--   different platforms:
--   
--   <ul>
--   <li>On Linux and Windows, the absolute path returned is via the
--   original symlink.</li>
--   <li>On macOS the absolute path returned is via the real path of the
--   root after resolving the symlink.</li>
--   </ul>
--   
--   This API is subject to removal in future, to be replaced by a platform
--   independent <tt>getRelPath</tt>.
--   
--   <i>Pre-release</i>
getAbsPath :: Event -> Array Word8

-- | Determine whether the event indicates creation of an object within the
--   monitored path. This event is generated when any file system object is
--   created.
--   
--   For hard links the behavior is different on different operating
--   systems. On macOS hard linking does not generate a create event, it
--   generates an <tt>isInodeAttrsChanged</tt> event on the directory
--   instead (see the Darwin module). On Linux and Windows hard linking
--   generates a create event.
--   
--   <i>Pre-release</i>
isCreated :: Event -> Bool

-- | Determine whether the event indicates deletion of an object within the
--   monitored path. On Linux and Windows hard link deletion generates a
--   delete event.
--   
--   On Linux and Windows, this event does not occur when the watch root
--   itself is deleted. On macOS it occurs on deleting the watch root when
--   it is not a symbolic link.
--   
--   See also <tt>isRootDeleted</tt> event for Linux.
--   
--   <i>Pre-release</i>
isDeleted :: Event -> Bool

-- | Determine whether the event indicates rename of an object within the
--   monitored path. This event is generated when an object is renamed
--   within the watched directory or if it is moved out of or in the
--   watched directory. Moving hard links is no different than other types
--   of objects.
--   
--   <i>Pre-release</i>
isMoved :: Event -> Bool

-- | Determine whether the event indicates modification of an object within
--   the monitored path. This event is generated on file modification on
--   all platforms.
--   
--   On Linux and macOS this event is never generated for directories. On
--   Windows (in recursive watch mode) this event is generated for
--   directories as well when an object is created in or deleted from the
--   directory.
--   
--   <i>Pre-release</i>
isModified :: Event -> Bool

-- | An event that indicates that some events before this may have been
--   lost, therefore, we need to take some recovery action.
--   
--   <i>Pre-release</i>
isEventsLost :: Event -> Bool

-- | Convert an <a>Event</a> record to a String representation. Note that
--   the output of this function may be different on different platforms
--   because it may contain platform specific details.
--   
--   <i>Internal</i>
showEvent :: Event -> String


-- | Streamly is a general purpose programming framework using cocnurrent
--   data flow programming paradigm. It can be considered as a
--   generalization of Haskell lists to monadic streaming with concurrent
--   composition capability. The serial stream type in streamly <tt>SerialT
--   m a</tt> is like the list type <tt>[a]</tt> parameterized by the monad
--   <tt>m</tt>. For example, <tt>SerialT IO a</tt> is a moral equivalent
--   of <tt>[a]</tt> in the IO monad. Streams are constructed very much
--   like lists, except that they use <a>nil</a> and <a>cons</a> instead of
--   '[]' and <tt>:</tt>.
--   
--   <pre>
--   &gt; import <a>Streamly</a>
--   &gt; import <a>Streamly.Prelude</a> (cons, consM)
--   &gt; import qualified <a>Streamly.Prelude</a> as S
--   &gt;
--   &gt; S.toList $ 1 `cons` 2 `cons` 3 `cons` nil
--   [1,2,3]
--   </pre>
--   
--   Unlike lists, streams can be constructed from monadic effects:
--   
--   <pre>
--   &gt; S.<a>toList</a> $ <a>getLine</a> `consM` <a>getLine</a> `consM` S.<a>nil</a>
--   hello
--   world
--   ["hello","world"]
--   </pre>
--   
--   Streams are processed just like lists, with list like combinators,
--   except that they are monadic and work in a streaming fashion. Here is
--   a simple console echo program example:
--   
--   <pre>
--   &gt; S.drain $ S.repeatM getLine &amp; S.mapM putStrLn
--   </pre>
--   
--   <tt>SerialT Identity a</tt> is a moral equivalent of pure lists.
--   Streamly utilizes fusion for high performance, therefore, we can
--   represent and process strings as streams of <a>Char</a>, encode and
--   decode the streams to/from UTF8 and serialize them to <tt>Array
--   Word8</tt> obviating the need for special purpose libraries like
--   <tt>bytestring</tt> and <tt>text</tt>.
--   
--   For more details please see the <a>Streamly.Tutorial</a> module and
--   the examples directory in this package.

-- | <i>Deprecated: Please use <a>Streamly.Prelude</a> instead.</i>
module Streamly

-- | A monad that can perform concurrent or parallel IO operations. Streams
--   that can be composed concurrently require the underlying monad to be
--   <a>MonadAsync</a>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
type MonadAsync m = (MonadIO m, MonadBaseControl IO m, MonadThrow m)

-- | For <a>SerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>serial</a> -- <a>Monad</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(1,4),(2,3),(2,4)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data SerialT m a

-- | For <a>WSerialT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wSerial</a>                       -- <a>Semigroup</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wSerial</a> -- <a>Monad</a>
--   </pre>
--   
--   Note that <a>&lt;&gt;</a> is associative only if we disregard the
--   ordering of elements in the resulting stream.
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--        x &lt;- Stream.fromList [1,2] -- foreach x in stream
--        return x
--   :}
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like interleaved nested <tt>for</tt> loops:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWSerial $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [3,4] -- foreach y in stream
--       return (x, y)
--   :}
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   It is a result of interleaving all the nested iterations corresponding
--   to element <tt>1</tt> in the first stream with all the nested
--   iterations of element <tt>2</tt>:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromList [(1,3),(1,4)] `Stream.wSerial` Stream.fromList [(2,3),(2,4)]
--   [(1,3),(2,3),(1,4),(2,4)]
--   </pre>
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>SerialT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WSerialT m a

-- | For <a>AheadT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>ahead</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>ahead</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations executed concurrently, ahead of time, producing side
--   effects of iterations out of order, but results in order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [2,1]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, ahead of time:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAhead $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,5,4,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>ahead</tt>.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
data AheadT m a

-- | For <a>AsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>async</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>async</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>async</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>async</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one output stream and all the iterations corresponding to <tt>2</tt>
--   constitute another output stream and these two output streams are
--   merged using <tt>async</tt>.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
data AsyncT m a

-- | For <a>WAsyncT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>wAsync</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>wAsync</a>
--   </pre>
--   
--   A single <a>Monad</a> bind behaves like a <tt>for</tt> loop with
--   iterations of the loop executed concurrently a la the <tt>wAsync</tt>
--   combinator, producing results and side effects of iterations out of
--   order:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--        x &lt;- Stream.fromList [2,1] -- foreach x in stream
--        Stream.fromEffect $ delay x
--   :}
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   Nested monad binds behave like nested <tt>for</tt> loops with nested
--   iterations executed concurrently, a la the <tt>wAsync</tt> combinator:
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.toList $ Stream.fromWAsync $ do
--       x &lt;- Stream.fromList [1,2] -- foreach x in stream
--       y &lt;- Stream.fromList [2,4] -- foreach y in stream
--       Stream.fromEffect $ delay (x + y)
--   :}
--   3 sec
--   4 sec
--   5 sec
--   6 sec
--   [3,4,5,6]
--   </pre>
--   
--   The behavior can be explained as follows. All the iterations
--   corresponding to the element <tt>1</tt> in the first stream constitute
--   one <a>WAsyncT</a> output stream and all the iterations corresponding
--   to <tt>2</tt> constitute another <a>WAsyncT</a> output stream and
--   these two output streams are merged using <tt>wAsync</tt>.
--   
--   The <tt>W</tt> in the name stands for <tt>wide</tt> or breadth wise
--   scheduling in contrast to the depth wise scheduling behavior of
--   <a>AsyncT</a>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data WAsyncT m a

-- | For <a>ParallelT</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>parallel</a>
--   (&gt;&gt;=) = flip . <a>concatMapWith</a> <a>parallel</a>
--   </pre>
--   
--   See <a>AsyncT</a>, <a>ParallelT</a> is similar except that all
--   iterations are strictly concurrent while in <tt>AsyncT</tt> it depends
--   on the consumer demand and available threads. See <tt>parallel</tt>
--   for more details.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
--   
--   <i>Since: 0.7.0 (maxBuffer applies to ParallelT streams)</i>
data ParallelT m a

-- | For <a>ZipSerialM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped serially:
--   
--   <pre>
--   &gt;&gt;&gt; s1 = Stream.fromFoldable [1, 2]
--   
--   &gt;&gt;&gt; s2 = Stream.fromFoldable [3, 4]
--   
--   &gt;&gt;&gt; s3 = Stream.fromFoldable [5, 6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipSerial $ (,,) &lt;$&gt; s1 &lt;*&gt; s2 &lt;*&gt; s3
--   [(1,3,5),(2,4,6)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipSerialM m a

-- | For <a>ZipAsyncM</a> streams:
--   
--   <pre>
--   (&lt;&gt;) = <a>serial</a>
--   (<a>*</a>) = 'Streamly.Prelude.serial.zipAsyncWith' id
--   </pre>
--   
--   Applicative evaluates the streams being zipped concurrently, the
--   following would take half the time that it would take in serial
--   zipping:
--   
--   <pre>
--   &gt;&gt;&gt; s = Stream.fromFoldableM $ Prelude.map delay [1, 1, 1]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromZipAsync $ (,) &lt;$&gt; s &lt;*&gt; s
--   ...
--   [(1,1),(1,1),(1,1)]
--   </pre>
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
data ZipAsyncM m a

-- | Parallel transform application operator; applies a stream
--   transformation function <tt>t m a -&gt; t m b</tt> to a stream <tt>t m
--   a</tt> concurrently; the input stream is evaluated asynchronously in
--   an independent thread yielding elements to a buffer and the
--   transformation function runs in another thread consuming the input
--   from the buffer. <a>|$</a> is just like regular function application
--   operator <a>$</a> except that it is concurrent.
--   
--   If you read the signature as <tt>(t m a -&gt; t m b) -&gt; (t m a
--   -&gt; t m b)</tt> you can look at it as a transformation that converts
--   a transform function to a buffered concurrent transform function.
--   
--   The following code prints a value every second even though each stage
--   adds a 1 second delay.
--   
--   <pre>
--   &gt;&gt;&gt; :{
--   Stream.drain $
--      Stream.mapM (\x -&gt; threadDelay 1000000 &gt;&gt; print x)
--        |$ Stream.replicateM 3 (threadDelay 1000000 &gt;&gt; return 1)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|$) :: (IsStream t, MonadAsync m) => (t m a -> t m b) -> t m a -> t m b
infixr 0 |$

-- | Same as <a>|$</a> but with arguments reversed.
--   
--   (|&amp;) = flip (|$)
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|&) :: (IsStream t, MonadAsync m) => t m a -> (t m a -> t m b) -> t m b
infixl 1 |&

-- | Parallel fold application operator; applies a fold function <tt>t m a
--   -&gt; m b</tt> to a stream <tt>t m a</tt> concurrently; The the input
--   stream is evaluated asynchronously in an independent thread yielding
--   elements to a buffer and the folding action runs in another thread
--   consuming the input from the buffer.
--   
--   If you read the signature as <tt>(t m a -&gt; m b) -&gt; (t m a -&gt;
--   m b)</tt> you can look at it as a transformation that converts a fold
--   function to a buffered concurrent fold function.
--   
--   The <tt>.</tt> at the end of the operator is a mnemonic for
--   termination of the stream.
--   
--   In the example below, each stage introduces a delay of 1 sec but
--   output is printed every second because both stages are concurrent.
--   
--   <pre>
--   &gt;&gt;&gt; import Control.Concurrent (threadDelay)
--   
--   &gt;&gt;&gt; import Streamly.Prelude ((|$.))
--   
--   &gt;&gt;&gt; :{
--    Stream.foldlM' (\_ a -&gt; threadDelay 1000000 &gt;&gt; print a) (return ())
--        |$. Stream.replicateM 3 (threadDelay 1000000 &gt;&gt; return 1)
--   :}
--   1
--   1
--   1
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|$.) :: (IsStream t, MonadAsync m) => (t m a -> m b) -> t m a -> m b
infixr 0 |$.

-- | Same as <a>|$.</a> but with arguments reversed.
--   
--   <pre>
--   (|&amp;.) = flip (|$.)
--   </pre>
--   
--   <i>Concurrent</i>
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
(|&.) :: (IsStream t, MonadAsync m) => t m a -> (t m a -> m b) -> m b
infixl 1 |&.

-- | Make a stream asynchronous, triggers the computation and returns a
--   stream in the underlying monad representing the output generated by
--   the original computation. The returned action is exhaustible and must
--   be drained once. If not drained fully we may have a thread blocked
--   forever and once exhausted it will always return <tt>empty</tt>.
mkAsync :: (IsStream t, MonadAsync m) => t m a -> m (t m a)

-- | Appends two streams sequentially, yielding all elements from the first
--   stream, and then all elements from the second stream.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (serial)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [3,4]
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `serial` stream2
--   [1,2,3,4]
--   </pre>
--   
--   This operation can be used to fold an infinite lazy container of
--   streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
serial :: IsStream t => t m a -> t m a -> t m a
infixr 6 `serial`

-- | Interleaves two streams, yielding one element from each stream
--   alternately. When one stream stops the rest of the other stream is
--   used in the output stream.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (wSerial)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [3,4]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWSerial $ stream1 `wSerial` stream2
--   [1,3,2,4]
--   </pre>
--   
--   Note, for singleton streams <a>wSerial</a> and <a>serial</a> are
--   identical.
--   
--   Note that this operation cannot be used to fold a container of
--   infinite streams but it can be used for very large streams as the
--   state that it needs to maintain is proportional to the logarithm of
--   the number of streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
wSerial :: IsStream t => t m a -> t m a -> t m a
infixr 6 `wSerial`

-- | Appends two streams, both the streams may be evaluated concurrently
--   but the outputs are used in the same order as the corresponding
--   actions in the original streams, side effects will happen in the order
--   in which the streams are evaluated:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (ahead, SerialT)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromEffect (delay 4) :: SerialT IO Int
--   
--   &gt;&gt;&gt; stream2 = Stream.fromEffect (delay 2) :: SerialT IO Int
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `ahead` stream2 :: IO [Int]
--   2 sec
--   4 sec
--   [4,2]
--   </pre>
--   
--   Multiple streams can be combined. With enough threads, all of them can
--   be scheduled simultaneously:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `ahead` stream2 `ahead` stream3
--   1 sec
--   2 sec
--   4 sec
--   [4,2,1]
--   </pre>
--   
--   With 2 threads, only two can be scheduled at a time, when one of those
--   finishes, the third one gets scheduled:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 2 $ stream1 `ahead` stream2 `ahead` stream3
--   2 sec
--   1 sec
--   4 sec
--   [4,2,1]
--   </pre>
--   
--   Only streams are scheduled for ahead evaluation, how actions within a
--   stream are evaluated depends on the stream type. If it is a concurrent
--   stream they will be evaluated concurrently. It may not make much sense
--   combining serial streams using <a>ahead</a>.
--   
--   <a>ahead</a> can be safely used to fold an infinite lazy container of
--   streams.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
ahead :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `ahead`

-- | Merges two streams, both the streams may be evaluated concurrently,
--   outputs from both are used as they arrive:
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (async)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromEffect (delay 4)
--   
--   &gt;&gt;&gt; stream2 = Stream.fromEffect (delay 2)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2
--   2 sec
--   4 sec
--   [2,4]
--   </pre>
--   
--   Multiple streams can be combined. With enough threads, all of them can
--   be scheduled simultaneously:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2 `async` stream3
--   ...
--   [1,2,4]
--   </pre>
--   
--   With 2 threads, only two can be scheduled at a time, when one of those
--   finishes, the third one gets scheduled:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3
--   ...
--   [2,1,4]
--   </pre>
--   
--   With a single thread, it becomes serial:
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.maxThreads 1 $ stream1 `async` stream2 `async` stream3
--   ...
--   [4,2,1]
--   </pre>
--   
--   Only streams are scheduled for async evaluation, how actions within a
--   stream are evaluated depends on the stream type. If it is a concurrent
--   stream they will be evaluated concurrently.
--   
--   In the following example, both the streams are scheduled for
--   concurrent evaluation but each individual stream is evaluated
--   serially:
--   
--   <pre>
--   &gt;&gt;&gt; stream1 = Stream.fromListM $ Prelude.map delay [3,3] -- SerialT IO Int
--   
--   &gt;&gt;&gt; stream2 = Stream.fromListM $ Prelude.map delay [1,1] -- SerialT IO Int
--   
--   &gt;&gt;&gt; Stream.toList $ stream1 `async` stream2 -- IO [Int]
--   ...
--   [1,1,3,3]
--   </pre>
--   
--   If total threads are 2, the third stream is scheduled only after one
--   of the first two has finished:
--   
--   <pre>
--   stream3 = Stream.fromListM $ Prelude.map delay [2,2] -- SerialT IO Int
--   Stream.toList $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3 -- IO [Int]
--   </pre>
--   
--   ... [1,1,3,2,3,2]
--   
--   Thus <a>async</a> goes deep in first few streams rather than going
--   wide in all streams. It prefers to evaluate the leftmost streams as
--   much as possible. Because of this behavior, <a>async</a> can be safely
--   used to fold an infinite lazy container of streams.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
async :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `async`

-- | For singleton streams, <a>wAsync</a> is the same as <a>async</a>. See
--   <a>async</a> for singleton stream behavior. For multi-element streams,
--   while <a>async</a> is left biased i.e. it tries to evaluate the left
--   side stream as much as possible, <a>wAsync</a> tries to schedule them
--   both fairly. In other words, <a>async</a> goes deep while
--   <a>wAsync</a> goes wide. However, outputs are always used as they
--   arrive.
--   
--   With a single thread, <a>async</a> starts behaving like <a>serial</a>
--   while <a>wAsync</a> starts behaving like <a>wSerial</a>.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (async, wAsync)
--   
--   &gt;&gt;&gt; stream1 = Stream.fromList [1,2,3]
--   
--   &gt;&gt;&gt; stream2 = Stream.fromList [4,5,6]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAsync $ Stream.maxThreads 1 $ stream1 `async` stream2
--   [1,2,3,4,5,6]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWAsync $ Stream.maxThreads 1 $ stream1 `wAsync` stream2
--   [1,4,2,5,3,6]
--   </pre>
--   
--   With two threads available, and combining three streams:
--   
--   <pre>
--   &gt;&gt;&gt; stream3 = Stream.fromList [7,8,9]
--   
--   &gt;&gt;&gt; Stream.toList $ Stream.fromAsync $ Stream.maxThreads 2 $ stream1 `async` stream2 `async` stream3
--   [1,2,3,4,5,6,7,8,9]
--   </pre>
--   
--   <pre>
--   &gt;&gt;&gt; Stream.toList $ Stream.fromWAsync $ Stream.maxThreads 2 $ stream1 `wAsync` stream2 `wAsync` stream3
--   [1,4,2,7,5,3,8,6,9]
--   </pre>
--   
--   This operation cannot be used to fold an infinite lazy container of
--   streams, because it schedules all the streams in a round robin manner.
--   
--   Note that <tt>WSerialT</tt> and single threaded <tt>WAsyncT</tt> both
--   interleave streams but the exact scheduling is slightly different in
--   both cases.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
wAsync :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `wAsync`

-- | Like <a>async</a> except that the execution is much more strict. There
--   is no limit on the number of threads. While <a>async</a> may not
--   schedule a stream if there is no demand from the consumer,
--   <a>parallel</a> always evaluates both the streams immediately. The
--   only limit that applies to <a>parallel</a> is <a>maxBuffer</a>.
--   Evaluation may block if the output buffer becomes full.
--   
--   <pre>
--   &gt;&gt;&gt; import Streamly.Prelude (parallel)
--   
--   &gt;&gt;&gt; stream = Stream.fromEffect (delay 2) `parallel` Stream.fromEffect (delay 1)
--   
--   &gt;&gt;&gt; Stream.toList stream -- IO [Int]
--   1 sec
--   2 sec
--   [1,2]
--   </pre>
--   
--   <a>parallel</a> guarantees that all the streams are scheduled for
--   execution immediately, therefore, we could use things like starting
--   timers inside the streams and relying on the fact that all timers were
--   started at the same time.
--   
--   Unlike <a>async</a> this operation cannot be used to fold an infinite
--   lazy container of streams, because it schedules all the streams
--   strictly concurrently.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
parallel :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a
infixr 6 `parallel`

-- | Specify the maximum number of threads that can be spawned concurrently
--   for any concurrent combinator in a stream. A value of 0 resets the
--   thread limit to default, a negative value means there is no limit. The
--   default value is 1500. <a>maxThreads</a> does not affect
--   <tt>ParallelT</tt> streams as they can use unbounded number of
--   threads.
--   
--   When the actions in a stream are IO bound, having blocking IO calls,
--   this option can be used to control the maximum number of in-flight IO
--   requests. When the actions are CPU bound this option can be used to
--   control the amount of CPU used by the stream.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxThreads :: IsStream t => Int -> t m a -> t m a

-- | Specify the maximum size of the buffer for storing the results from
--   concurrent computations. If the buffer becomes full we stop spawning
--   more concurrent tasks until there is space in the buffer. A value of 0
--   resets the buffer size to default, a negative value means there is no
--   limit. The default value is 1500.
--   
--   CAUTION! using an unbounded <a>maxBuffer</a> value (i.e. a negative
--   value) coupled with an unbounded <a>maxThreads</a> value is a recipe
--   for disaster in presence of infinite streams, or very large streams.
--   Especially, it must not be used when <a>pure</a> is used in
--   <tt>ZipAsyncM</tt> streams as <a>pure</a> in applicative zip streams
--   generates an infinite stream causing unbounded concurrent generation
--   with no limit on the buffer or threads.
--   
--   <i>Since: 0.4.0 (<a>Streamly</a>)</i>
maxBuffer :: IsStream t => Int -> t m a -> t m a

-- | Specifies the stream yield rate in yields per second (<tt>Hertz</tt>).
--   We keep accumulating yield credits at <a>rateGoal</a>. At any point of
--   time we allow only as many yields as we have accumulated as per
--   <a>rateGoal</a> since the start of time. If the consumer or the
--   producer is slower or faster, the actual rate may fall behind or
--   exceed <a>rateGoal</a>. We try to recover the gap between the two by
--   increasing or decreasing the pull rate from the producer. However, if
--   the gap becomes more than <a>rateBuffer</a> we try to recover only as
--   much as <a>rateBuffer</a>.
--   
--   <a>rateLow</a> puts a bound on how low the instantaneous rate can go
--   when recovering the rate gap. In other words, it determines the
--   maximum yield latency. Similarly, <a>rateHigh</a> puts a bound on how
--   high the instantaneous rate can go when recovering the rate gap. In
--   other words, it determines the minimum yield latency. We reduce the
--   latency by increasing concurrency, therefore we can say that it puts
--   an upper bound on concurrency.
--   
--   If the <a>rateGoal</a> is 0 or negative the stream never yields a
--   value. If the <a>rateBuffer</a> is 0 or negative we do not attempt to
--   recover.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
data Rate
Rate :: Double -> Double -> Double -> Int -> Rate

-- | The lower rate limit
[rateLow] :: Rate -> Double

-- | The target rate we want to achieve
[rateGoal] :: Rate -> Double

-- | The upper rate limit
[rateHigh] :: Rate -> Double

-- | Maximum slack from the goal
[rateBuffer] :: Rate -> Int

-- | Specify the pull rate of a stream. A <a>Nothing</a> value resets the
--   rate to default which is unlimited. When the rate is specified,
--   concurrent production may be ramped up or down automatically to
--   achieve the specified yield rate. The specific behavior for different
--   styles of <a>Rate</a> specifications is documented under <a>Rate</a>.
--   The effective maximum production rate achieved by a stream is governed
--   by:
--   
--   <ul>
--   <li>The <a>maxThreads</a> limit</li>
--   <li>The <a>maxBuffer</a> limit</li>
--   <li>The maximum rate that the stream producer can achieve</li>
--   <li>The maximum rate that the stream consumer can achieve</li>
--   </ul>
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
rate :: IsStream t => Maybe Rate -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r (2*r) maxBound)</tt>
--   
--   Specifies the average production rate of a stream in number of yields
--   per second (i.e. <tt>Hertz</tt>). Concurrent production is ramped up
--   or down automatically to achieve the specified average yield rate. The
--   rate can go down to half of the specified rate on the lower side and
--   double of the specified rate on the higher side.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
avgRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r (2*r) maxBound)</tt>
--   
--   Specifies the minimum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go below the
--   specified rate, even though it may possibly go above it at times, the
--   upper limit is double of the specified rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
minRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate (r/2) r r maxBound)</tt>
--   
--   Specifies the maximum rate at which the stream should yield values. As
--   far as possible the yield rate would never be allowed to go above the
--   specified rate, even though it may possibly go below it at times, the
--   lower limit is half of the specified rate. This can be useful in
--   applications where certain resource usage must not be allowed to go
--   beyond certain limits.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
maxRate :: IsStream t => Double -> t m a -> t m a

-- | Same as <tt>rate (Just $ Rate r r r 0)</tt>
--   
--   Specifies a constant yield rate. If for some reason the actual rate
--   goes above or below the specified rate we do not try to recover it by
--   increasing or decreasing the rate in future. This can be useful in
--   applications like graphics frame refresh where we need to maintain a
--   constant refresh rate.
--   
--   <i>Since: 0.5.0 (<a>Streamly</a>)</i>
constRate :: IsStream t => Double -> t m a -> t m a

-- | Class of types that can represent a stream of elements of some type
--   <tt>a</tt> in some monad <tt>m</tt>.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
class (forall m a. MonadAsync m => Semigroup (t m a), forall m a. MonadAsync m => Monoid (t m a), forall m. Monad m => Functor (t m), forall m. MonadAsync m => Applicative (t m)) => IsStream t
serially :: IsStream t => SerialT m a -> t m a
wSerially :: IsStream t => WSerialT m a -> t m a
asyncly :: IsStream t => AsyncT m a -> t m a
aheadly :: IsStream t => AheadT m a -> t m a
wAsyncly :: IsStream t => WAsyncT m a -> t m a
parallely :: IsStream t => ParallelT m a -> t m a
zipSerially :: IsStream t => ZipSerialM m a -> t m a
zipAsyncly :: IsStream t => ZipAsyncM m a -> t m a

-- | Adapt any specific stream type to any other specific stream type.
--   
--   <i>Since: 0.1.0 (<a>Streamly</a>)</i>
adapt :: (IsStream t1, IsStream t2) => t1 m a -> t2 m a

-- | A serial IO stream of elements of type <tt>a</tt>. See <a>SerialT</a>
--   documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Serial = SerialT IO

-- | An interleaving serial IO stream of elements of type <tt>a</tt>. See
--   <a>WSerialT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WSerial = WSerialT IO

-- | A serial IO stream of elements of type <tt>a</tt> with concurrent
--   lookahead. See <a>AheadT</a> documentation for more details.
--   
--   <i>Since: 0.3.0 (<a>Streamly</a>)</i>
type Ahead = AheadT IO

-- | A demand driven left biased parallely composing IO stream of elements
--   of type <tt>a</tt>. See <a>AsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Async = AsyncT IO

-- | A round robin parallely composing IO stream of elements of type
--   <tt>a</tt>. See <a>WAsyncT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type WAsync = WAsyncT IO

-- | A parallely composing IO stream of elements of type <tt>a</tt>. See
--   <a>ParallelT</a> documentation for more details.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type Parallel = ParallelT IO

-- | An IO stream whose applicative instance zips streams serially.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipSerial = ZipSerialM IO

-- | An IO stream whose applicative instance zips streams wAsyncly.
--   
--   <i>Since: 0.2.0 (<a>Streamly</a>)</i>
type ZipAsync = ZipAsyncM IO

-- | Same as <a>concatFoldableWith</a>
foldWith :: (IsStream t, Foldable f) => (t m a -> t m a -> t m a) -> f (t m a) -> t m a

-- | Same as <a>concatMapFoldableWith</a>
foldMapWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> (a -> t m b) -> f a -> t m b

-- | Same as <a>concatForFoldableWith</a>
forEachWith :: (IsStream t, Foldable f) => (t m b -> t m b -> t m b) -> f a -> (a -> t m b) -> t m b

-- | The class of semigroups (types with an associative binary operation).
--   
--   Instances should satisfy the following:
--   
--   <ul>
--   <li><i>Associativity</i> <tt>x <a>&lt;&gt;</a> (y <a>&lt;&gt;</a> z) =
--   (x <a>&lt;&gt;</a> y) <a>&lt;&gt;</a> z</tt></li>
--   </ul>
class Semigroup a

-- | An associative operation.
--   
--   <pre>
--   &gt;&gt;&gt; [1,2,3] &lt;&gt; [4,5,6]
--   [1,2,3,4,5,6]
--   </pre>
(<>) :: Semigroup a => a -> a -> a

-- | Reduce a non-empty list with <a>&lt;&gt;</a>
--   
--   The default definition should be sufficient, but this can be
--   overridden for efficiency.
--   
--   <pre>
--   &gt;&gt;&gt; import Data.List.NonEmpty (NonEmpty (..))
--   
--   &gt;&gt;&gt; sconcat $ "Hello" :| [" ", "Haskell", "!"]
--   "Hello Haskell!"
--   </pre>
sconcat :: Semigroup a => NonEmpty a -> a

-- | Repeat a value <tt>n</tt> times.
--   
--   Given that this works on a <a>Semigroup</a> it is allowed to fail if
--   you request 0 or fewer repetitions, and the default definition will do
--   so.
--   
--   By making this a member of the class, idempotent semigroups and
--   monoids can upgrade this to execute in &lt;math&gt; by picking
--   <tt>stimes = <a>stimesIdempotent</a></tt> or <tt>stimes =
--   <a>stimesIdempotentMonoid</a></tt> respectively.
--   
--   <pre>
--   &gt;&gt;&gt; stimes 4 [1]
--   [1,1,1,1]
--   </pre>
stimes :: (Semigroup a, Integral b) => b -> a -> a
infixr 6 <>

-- | Same as <a>IsStream</a>.

-- | <i>Deprecated: Please use IsStream instead.</i>
type Streaming = IsStream

-- | Same as "Streamly.Prelude.runStream".
runStream :: Monad m => SerialT m a -> m ()

-- | Same as <a>runStream</a>
runStreaming :: (Monad m, IsStream t) => t m a -> m ()

-- | Same as <tt>runStream</tt>.
runStreamT :: Monad m => SerialT m a -> m ()

-- | Same as <tt>drain . fromWSerial</tt>.
runInterleavedT :: Monad m => WSerialT m a -> m ()

-- | Same as <tt>drain . fromAsync</tt>.
runAsyncT :: Monad m => AsyncT m a -> m ()

-- | Same as <tt>drain . fromParallel</tt>.
runParallelT :: Monad m => ParallelT m a -> m ()

-- | Same as <tt>drain . zipping</tt>.
runZipStream :: Monad m => ZipSerialM m a -> m ()

-- | Same as <tt>drain . zippingAsync</tt>.
runZipAsync :: Monad m => ZipAsyncM m a -> m ()


-- | <i>Deprecated: Please use <a>SerialT</a> instead.</i>
type StreamT = SerialT


-- | <i>Deprecated: Please use <a>WSerialT</a> instead.</i>
type InterleavedT = WSerialT


-- | <i>Deprecated: Please use <a>ZipSerialM</a> instead.</i>
type ZipStream = ZipSerialM

-- | Same as <a>fromWSerial</a>.

-- | <i>Deprecated: Please use fromWSerial instead.</i>
interleaving :: IsStream t => WSerialT m a -> t m a

-- | Same as <a>fromZipSerial</a>.

-- | <i>Deprecated: Please use fromZipSerial instead.</i>
zipping :: IsStream t => ZipSerialM m a -> t m a

-- | Same as <a>fromZipAsync</a>.

-- | <i>Deprecated: Please use fromZipAsync instead.</i>
zippingAsync :: IsStream t => ZipAsyncM m a -> t m a

-- | Same as <a>wSerial</a>.

-- | <i>Deprecated: Please use <a>wSerial</a> instead.</i>
(<=>) :: IsStream t => t m a -> t m a -> t m a
infixr 5 <=>

-- | Same as <a>async</a>.

-- | <i>Deprecated: Please use <a>async</a> instead.</i>
(<|) :: (IsStream t, MonadAsync m) => t m a -> t m a -> t m a


-- | <h1>Processing Unicode Strings</h1>
--   
--   A <a>Char</a> stream is the canonical representation to process
--   Unicode strings. It can be processed efficiently using regular stream
--   processing operations. A byte stream of Unicode text read from an IO
--   device or from an <a>Array</a> in memory can be decoded into a
--   <a>Char</a> stream using the decoding routines in this module. A
--   <a>String</a> (<tt>[Char]</tt>) can be converted into a <a>Char</a>
--   stream using <a>fromList</a>. An <tt>Array Char</tt> can be
--   <a>unfold</a>ed into a stream using the array <a>read</a> unfold.
--   
--   <h1>Storing Unicode Strings</h1>
--   
--   A stream of <a>Char</a> can be encoded into a byte stream using the
--   encoding routines in this module and then written to IO devices or to
--   arrays in memory.
--   
--   If you have to store a <a>Char</a> stream in memory you can convert it
--   into a <a>String</a> using <a>toList</a> or using the <a>toList</a>
--   fold. The <a>String</a> type can be more efficient than pinned arrays
--   for short and short lived strings.
--   
--   For longer or long lived streams you can <a>fold</a> the <a>Char</a>
--   stream as <tt>Array Char</tt> using the array <a>write</a> fold. The
--   <tt>Array</tt> type provides a more compact representation and pinned
--   memory reducing GC overhead. If space efficiency is a concern you can
--   use <a>encodeUtf8'</a> on the <a>Char</a> stream before writing it to
--   an <tt>Array</tt> providing an even more compact representation.
--   
--   <h1>String Literals</h1>
--   
--   <tt>SerialT Identity Char</tt> and <tt>Array Char</tt> are instances
--   of <tt>IsString</tt> and <tt>IsList</tt>, therefore,
--   <tt>OverloadedStrings</tt> and <tt>OverloadedLists</tt> extensions can
--   be used for convenience when specifying unicode strings literals using
--   these types.
--   
--   <h1>Idioms</h1>
--   
--   Some simple text processing operations can be represented simply as
--   operations on Char streams. Follow the links for the following idioms:
--   
--   <ul>
--   <li><a>lines</a></li>
--   <li><a>words</a></li>
--   <li><a>unlines</a></li>
--   <li><a>unwords</a></li>
--   </ul>
--   
--   <h1>Pitfalls</h1>
--   
--   <ul>
--   <li>Case conversion: Some unicode characters translate to more than
--   one code point on case conversion. The <tt>toUpper</tt> and
--   <tt>toLower</tt> functions in <tt>base</tt> package do not handle such
--   characters. Therefore, operations like <tt>map toUpper</tt> on a
--   character stream or character array may not always perform correct
--   conversion.</li>
--   <li>String comparison: In some cases, visually identical strings may
--   have different unicode representations, therefore, a character stream
--   or character array cannot be directly compared. A normalized
--   comparison may be needed to check string equivalence correctly.</li>
--   </ul>
--   
--   <h1>Experimental APIs</h1>
--   
--   Some experimental APIs to conveniently process text using the
--   <tt>Array Char</tt> represenation directly can be found in
--   <a>Streamly.Internal.Unicode.Array.Char</a>.
module Streamly.Unicode.Stream

-- | Decode a stream of bytes to Unicode characters by mapping each byte to
--   a corresponding Unicode <a>Char</a> in 0-255 range.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
decodeLatin1 :: (IsStream t, Monad m) => t m Word8 -> t m Char

-- | Decode a UTF-8 encoded bytestream to a stream of Unicode characters.
--   Any invalid codepoint encountered is replaced with the unicode
--   replacement character.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
decodeUtf8 :: (Monad m, IsStream t) => t m Word8 -> t m Char

-- | Decode a UTF-8 encoded bytestream to a stream of Unicode characters.
--   The function throws an error if an invalid codepoint is encountered.
decodeUtf8' :: (Monad m, IsStream t) => t m Word8 -> t m Char

-- | Like <a>encodeLatin1'</a> but silently maps input codepoints beyond
--   255 to arbitrary Latin1 chars in 0-255 range. No error or exception is
--   thrown when such mapping occurs.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
encodeLatin1 :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to bytes by mapping each
--   character to a byte in 0-255 range. Throws an error if the input
--   stream contains characters beyond 255.
encodeLatin1' :: (IsStream t, Monad m) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to a UTF-8 encoded bytestream.
--   Any Invalid characters (U+D800-U+D8FF) in the input stream are
--   replaced by the Unicode replacement character U+FFFD.
--   
--   <i>Since: 0.7.0 (<a>Streamly.Data.Unicode.Stream</a>)</i>
--   
--   <i>Since: 0.8.0 (Lenient Behaviour)</i>
encodeUtf8 :: (Monad m, IsStream t) => t m Char -> t m Word8

-- | Encode a stream of Unicode characters to a UTF-8 encoded bytestream.
--   When any invalid character (U+D800-U+D8FF) is encountered in the input
--   stream the function errors out.
encodeUtf8' :: (Monad m, IsStream t) => t m Char -> t m Word8

-- | Encode a stream of <a>String</a> using the supplied encoding scheme.
--   Each string is encoded as an <tt>Array Word8</tt>.
encodeStrings :: (MonadIO m, IsStream t) => (SerialT m Char -> SerialT m Word8) -> t m String -> t m (Array Word8)
